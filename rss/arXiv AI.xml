<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 12 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>XMainframe：用于大型机现代化的大型语言模型</title>
      <link>https://arxiv.org/abs/2408.04660</link>
      <description><![CDATA[arXiv:2408.04660v2 公告类型：交叉 
摘要：大型机操作系统尽管诞生于 20 世纪 40 年代，但仍在支持金融和政府等关键部门。然而，这些系统通常被视为过时的，需要大量的维护和现代化。应对这一挑战需要能够理解和与遗留代码库交互的创新工具。为此，我们推出了 XMainframe，这是一种最先进的大型语言模型 (LLM)，专门设计用于了解大型机遗留系统和 COBOL 代码库。我们的解决方案涉及创建一个广泛的数据收集管道以生成高质量的训练数据集，从而增强 XMainframe 在这个专业领域的性能。此外，我们还提出了 MainframeBench，这是一个用于评估大型机知识的综合基准，包括多项选择题、问答和 COBOL 代码摘要。我们的实证评估表明，XMainframe 在这些任务中始终优于现有的最先进的 LLM。具体来说，XMainframe 在多项选择题上的准确率比 DeepSeek-Coder 高 30%，在问答题上的 BLEU 得分是 Mixtral-Instruct 8x7B 的两倍，在 COBOL 摘要上的得分比 GPT-3.5 高六倍。我们的工作凸显了 XMainframe 在管理和现代化遗留系统方面取得重大进步的潜力，从而提高软件开发人员的生产力并节省时间。]]></description>
      <guid>https://arxiv.org/abs/2408.04660</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:51 GMT</pubDate>
    </item>
    <item>
      <title>Citekit：用于大型语言模型引文生成的模块化工具包</title>
      <link>https://arxiv.org/abs/2408.04662</link>
      <description><![CDATA[arXiv:2408.04662v1 公告类型：交叉 
摘要：使大型语言模型 (LLM) 能够在问答 (QA) 任务中生成引文是一种新兴的范例，旨在提高 LLM 利用外部参考生成答案时其响应的可验证性。然而，目前还没有统一的框架来标准化和公平地比较不同的引文生成方法，导致难以重现不同的方法和进行全面的评估。为了解决上述问题，我们引入了 \name，这是一个开源的模块化工具包，旨在促进现有引文生成方法的实施和评估，同时也促进了新方法的开发，以提高 LLM 输出中的引文质量。该工具具有高度的可扩展性，允许用户利用 4 个主要模块和 14 个组件来构建管道，评估现有方法或创新设计。我们对两个最先进的 LLM 和 11 个引文生成基线进行了实验，结果表明不同模块在答案准确性和引文质量改进方面具有不同的优势，并且存在提高粒度的挑战。基于对组件有效性的分析，我们提出了一种新方法，即 self-RAG \snippet，可实现答案准确性和引文质量的平衡。Citekit 发布在 https://github.com/SjJ1017/Citekit。]]></description>
      <guid>https://arxiv.org/abs/2408.04662</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:51 GMT</pubDate>
    </item>
    <item>
      <title>Dopamin：通过领域后训练和多层级聚合实现的基于 Transformer 的评论分类器</title>
      <link>https://arxiv.org/abs/2408.04663</link>
      <description><![CDATA[arXiv:2408.04663v1 公告类型：交叉 
摘要：代码注释为理解源代码提供了重要信息。它们可以帮助开发人员了解函数或类的总体目的，以及识别错误和技术债务。然而，过多的评论是毫无意义和适得其反的。因此，自动过滤掉这些用于特定目的的评论至关重要。在本文中，我们提出了一种基于 Transformer 的工具 Dopamin 来处理这个问题。我们的模型不仅在呈现跨多种语言的常见类别的知识共享方面表现出色，而且还通过改进评论表示在评论分类中实现了稳健的性能。因此，它在 NLBSE&#39;24 工具竞赛数据集上的平均 F1 分数比 STACC 基线高出 3%，同时保持了实际使用中可比的推理时间。源代码可在 https://github.com/FSoft-AI4Code/Dopamin 上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2408.04663</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:51 GMT</pubDate>
    </item>
    <item>
      <title>通过语言对比解码 (LCD) 缓解大型视觉语言模型 (LVLM) 中的幻觉</title>
      <link>https://arxiv.org/abs/2408.04664</link>
      <description><![CDATA[arXiv:2408.04664v1 公告类型：交叉 
摘要：大型视觉语言模型 (LVLM) 是大型语言模型 (LLM) 的扩展，有助于处理图像和文本输入，扩展 AI 功能。然而，由于 LVLM 依赖文本提示和学习到的对象共现偏差，因此难以应对对象幻觉。虽然大多数研究都量化了这些幻觉，但缓解策略仍然缺乏。我们的研究引入了一种语言对比解码 (LCD) 算法，该算法根据 LLM 分布置信度调整 LVLM 输出，有效减少对象幻觉。我们展示了 LCD 在领先 LVLM 方面的优势，显示 POPE F1 分数提高了 %4，COCO 验证集上的 CHAIR 分数降低了 %36，同时还提高了字幕质量分数。我们的方法有效地改进了 LVLM，而无需复杂的后处理或再训练，并且很容易应用于不同的模型。我们的研究结果凸显了进一步探索 LVLM 特定解码算法的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.04664</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:51 GMT</pubDate>
    </item>
    <item>
      <title>批量 BPE 标记化合并</title>
      <link>https://arxiv.org/abs/2408.04653</link>
      <description><![CDATA[arXiv:2408.04653v1 公告类型：交叉 
摘要：在构建标记器词汇表时，可以安全地批量处理字节对编码算法，以一次合并数百对标记。这种技术与减少词汇训练中使用的文本的内存占用相结合，使得在基本笔记本电脑上训练高质量的标记器成为可能。本文介绍了 BatchBPE，这是这些概念的开源纯 Python 实现，目的是使新的标记化策略的实验更容易进行，尤其是在计算和内存受限的环境中。通过训练几个标记词汇表来探索批量合并过程并尝试预处理停用词列表并忽略数据集中最不常见的文本块，证明了 BatchBPE 的实用性和可塑性。文本的结果编码长度用作基本评估指标。]]></description>
      <guid>https://arxiv.org/abs/2408.04653</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:50 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型与人类价值观的强对齐和弱对齐</title>
      <link>https://arxiv.org/abs/2408.04655</link>
      <description><![CDATA[arXiv:2408.04655v2 公告类型：交叉 
摘要：在没有人类监督的情况下，将人工智能 (AI) 系统对人类社会的负面影响降至最低需要它们能够与人类价值观保持一致。然而，目前大多数研究仅从技术角度解决这个问题，例如，改进当前依赖于从人类反馈中进行强化学习的方法，而忽略了它的含义以及对齐所需的条件。在这里，我们建议区分强和弱价值对齐。强对齐需要认知能力（类似于人类或不同于人类），例如理解和推理代理的意图以及它们因果产生预期效果的能力。我们认为，这对于大型语言模型 (LLM) 等人工智能系统来说是必需的，以便能够识别存在违反人类价值观风险的情况。为了说明这种区别，我们提出了一系列提示，展示了 ChatGPT、Gemini 和 Copilot 未能识别其中一些情况。此外，我们还分析了词向量，以表明 LLM 中某些人类值的最近邻居与人类的语义表示不同。然后，​​我们提出了一个新的思想实验，我们称之为“带有词转换词典的中文房间”，这是 John Searle 著名提议的延伸。最后，我们提到了当前有希望的研究方向，即弱对齐，它可以在许多常见情况下产生统计上令人满意的答案，但到目前为止还不能确保任何真值。]]></description>
      <guid>https://arxiv.org/abs/2408.04655</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:50 GMT</pubDate>
    </item>
    <item>
      <title>荣获亚马逊 KDD Cup'24</title>
      <link>https://arxiv.org/abs/2408.04658</link>
      <description><![CDATA[arXiv:2408.04658v1 公告类型：交叉 
摘要：本文介绍了亚马逊 KDD Cup 2024 法学硕士多任务在线购物挑战赛所有 5 项任务的获胜解决方案。挑战是构建一个有用的助手，回答在线购物领域的问题。比赛包含 57 项不同的任务，涵盖 5 种不同的任务类型（例如多项选择）和 4 种不同的赛道（例如多语言）。我们的解决方案是每个赛道一个模型。我们在自己的训练数据集上对 Qwen2-72B-Instruct 进行了微调。由于比赛只发布了 96 个示例问题，我们通过处理多个公共数据集或使用大型语言模型进行数据增强和合成数据生成来开发自己的训练数据集。我们应用 wise-ft 来考虑分布变化，并在一个模型中集成多个 LoRA 适配器。我们使用 Logits 处理器将模型输出约束在与任务相关的标记上。推理过程中使用 AWQ 4 位量化和 vLLM 来预测测试数据集，时间限制为 20 到 140 分钟（具体取决于赛道）。我们的解决方案在每个单独的赛道中都获得了第一名，并且是 2024 年亚马逊 KDD Cup 的总冠军。]]></description>
      <guid>https://arxiv.org/abs/2408.04658</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:50 GMT</pubDate>
    </item>
    <item>
      <title>PLUGH：大型语言模型中空间理解和推理的基准</title>
      <link>https://arxiv.org/abs/2408.04648</link>
      <description><![CDATA[arXiv:2408.04648v1 公告类型：交叉 
摘要：我们提出了 PLUGH（https://www.urbandictionary.com/define.php?term=plugh），这是一个现代基准，目前由 5 个任务组成，每个任务都有从 48 个不同的游戏中提取的 125 个输入文本，代表 61 个不同的（非同构）空间图，以评估大型语言模型 (LLM) 的空间理解和推理能力。我们对基于 API 和开源 LLM 的评估表明，虽然一些商业 LLM 表现出强大的推理能力，但开源竞争对手可以展示几乎相同的质量水平；然而，所有模型仍然有很大的改进空间。我们确定了 LLM 失败的典型原因并讨论了可能的解决方法。数据集和评估代码已发布（https://github.com/altsoph/PLUGH）。]]></description>
      <guid>https://arxiv.org/abs/2408.04648</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>立场链：使用大型语言模型进行立场检测</title>
      <link>https://arxiv.org/abs/2408.04649</link>
      <description><![CDATA[arXiv:2408.04649v1 公告类型：交叉 
摘要：立场检测是自然语言处理 (NLP) 中的一项主动任务，旨在识别作者对文本中特定目标的立场。鉴于大型语言模型 (LLM) 出色的语言理解能力和百科全书式的先验知识，如何探索 LLM 在立场检测中的潜力已受到广泛关注。与现有的仅专注于使用大规模数据集进行微调的基于 LLM 的方法不同，我们提出了一种新的提示方法，称为 \textit{Chain of Stance} (CoS)。具体而言，它通过将立场检测过程分解为一系列中间立场相关断言并最终得出最终判断，将 LLM 定位为专家立场检测器。这种方法可以显着提高分类性能。我们在 SemEval 2016 数据集上使用四个 SOTA LLM 进行了广泛的实验，涵盖了零样本和少量样本学习设置。结果表明，所提出的方法在小样本设置中取得了最先进的结果，F1 分数为 79.84。]]></description>
      <guid>https://arxiv.org/abs/2408.04649</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>建立对心理健康聊天机器人的信任：安全指标和基于 LLM 的评估工具</title>
      <link>https://arxiv.org/abs/2408.04650</link>
      <description><![CDATA[arXiv:2408.04650v1 公告类型：交叉 
摘要：目的：本研究旨在开发和验证一个评估框架，以确保心理健康聊天机器人的安全性和可靠性，这些聊天机器人因其可访问性、类似人类的交互和情境感知支持而越来越受欢迎。材料和方法：我们创建了一个评估框架，其中包含 100 个基准问题和理想答案，以及 5 个聊天机器人响应的指导性问题。该框架经过心理健康专家的验证，并在基于 GPT-3.5-turbo 的聊天机器人上进行了测试。探索的自动评估方法包括基于大型语言模型 (LLM) 的评分、使用实时数据的代理方法以及嵌入模型以将聊天机器人响应与地面实况标准进行比较。结果：结果强调了指导方针和地面实况对于提高 LLM 评估准确性的重要性。代理方法动态访问可靠信息，与人类评估表现出最佳一致性。遵守标准化、专家验证的框架显着提高了聊天机器人响应的安全性和可靠性。讨论：我们的研究结果强调了心理健康聊天机器人需要全面的、专家量身定制的安全评估指标。虽然 LLM 具有巨大的潜力，但必须谨慎实施才能降低风险。代理方法的卓越性能凸显了实时数据访问在增强聊天机器人可靠性方面的重要性。结论：该研究验证了心理健康聊天机器人的评估框架，证明了其在提高安全性和可靠性方面的有效性。未来的工作应该将评估扩展到准确性、偏见、同理心和隐私，以确保整体评估和负责任地融入医疗保健。标准化评估将在用户和专业人士之间建立信任，促进更广泛的采用并通过技术改善心理健康支持。]]></description>
      <guid>https://arxiv.org/abs/2408.04650</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>知识人工智能：微调 NLP 模型以促进科学知识的提取和理解</title>
      <link>https://arxiv.org/abs/2408.04651</link>
      <description><![CDATA[arXiv:2408.04651v1 公告类型：交叉 
摘要：该项目研究大型语言模型 (LLM) 在理解和提取特定领域的科学知识方面的功效，并创建一个深度学习框架：知识人工智能。作为该框架的一部分，我们使用预先训练的模型并在科学领域的数据集上对其进行微调。这些模型适用于四个关键的自然语言处理 (NLP) 任务：摘要、文本生成、问答和命名实体识别。我们的结果表明，特定领域的微调显着提高了模型在每个任务中的性能，从而提高了它们在科学环境中的适用性。这种适应性使非专家能够有效地查询和提取目标科学领域内的信息，展示了微调的 LLM 作为科学知识发现工具的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.04651</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>利用具有思路链和快速工程的大型语言模型进行交通事故严重程度分析和推理</title>
      <link>https://arxiv.org/abs/2408.04652</link>
      <description><![CDATA[arXiv:2408.04652v1 公告类型：交叉 
摘要：利用大型语言模型 (LLM) 的强大功能，本研究探索了三种最先进的 LLM（特别是 GPT-3.5-turbo、LLaMA3-8B 和 LLaMA3-70B）用于碰撞严重程度推断，并将其作为分类任务。我们使用注入领域知识的预建模板从原始交通事故表格数据中生成文本叙述。此外，我们结合了思路链 (CoT) 推理来指导 LLM 分析碰撞原因，然后推断严重程度。本研究还研究了专门为碰撞严重程度推断设计的提示工程的影响。LLM 的任务是进行碰撞严重程度推断：(1) 评估模型在碰撞严重程度分析方面的能力，(2) 评估 CoT 和领域知情提示工程的有效性，以及 (3) 使用 CoT 框架检查推理能力。我们的结果表明，LLaMA3-70B 的表现始终优于其他模型，尤其是在零样本设置中。CoT 和 Prompt Engineering 技术显著提高了性能，改善了逻辑推理并解决了对齐问题。值得注意的是，CoT 为 LLM 的推理过程提供了宝贵的见解，释放了它们在严重性分析和推理中考虑各种因素（例如环境条件、驾驶员行为和车辆特性）的能力。]]></description>
      <guid>https://arxiv.org/abs/2408.04652</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>关于使用神经符号人工智能防御网络攻击</title>
      <link>https://arxiv.org/abs/2408.04996</link>
      <description><![CDATA[arXiv:2408.04996v1 公告类型：新
摘要：人们普遍认为，所有网络攻击都无法预防，因此需要具备检测和应对网络攻击的能力。目前，联结主义和符号人工智能都用于支持这种检测和响应。在本文中，我们提出了使用神经符号人工智能将它们结合起来的案例。我们确定了当今使用人工智能时面临的一系列挑战，并提出了一组神经符号用例，我们认为这两者都是神经符号人工智能社区有趣的研究方向，并可能对网络安全领域产生影响。我们通过两个概念验证实验证明了可行性。]]></description>
      <guid>https://arxiv.org/abs/2408.04996</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:48 GMT</pubDate>
    </item>
    <item>
      <title>无监督人工神经网络（ANN）自组织映射（SOM）在汽车销售主要因素识别中的应用</title>
      <link>https://arxiv.org/abs/2408.05110</link>
      <description><![CDATA[arXiv:2408.05110v1 公告类型：新
摘要：吸引顾客并说服他们购买新车的因素因消费者口味而异。有一些方法可以从大量数据中提取模式。在这种情况下，我们首先要求乘用车营销专家使用模糊德尔菲技术对影响客户决策行为的更重要的因素进行排名，然后我们从问卷中提供了一个样本集，并尝试应用一种有用的人工神经网络方法，即自组织映射 SOM，以找出哪些因素对伊朗客户的购买决策有更大的影响。使用模糊工具来调整研究以使其更加真实。MATLAB 软件用于开发和培训网络。结果显示四个因素比其他因素更重要。结果与营销专家的排名有很大不同。这样的结果将有助于制造商专注于更重要的因素并提高公司的销售水平。]]></description>
      <guid>https://arxiv.org/abs/2408.05110</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:48 GMT</pubDate>
    </item>
    <item>
      <title>GPT-3 支持的信息提取，用于构建强大的知识库</title>
      <link>https://arxiv.org/abs/2408.04641</link>
      <description><![CDATA[arXiv:2408.04641v1 公告类型：交叉 
摘要：这项工作使用最先进的语言模型 GPT-3 为知识库开发提供了一种新颖的信息提取方法。所建议的方法试图解决从非结构化文本中获取相关实体和关系以提取结构化信息的困难。我们对来自不同领域的大量文本语料库进行了实验，以评估我们提出的技术的性能。信息提取任务中经常使用的评估指标包括精度、召回率和 F1 分数。研究结果表明，GPT-3 可用于高效准确地从文本中提取相关和正确的信息，从而提高知识库创建的精度和生产力。我们还评估了我们建议的方法与已经在使用的最先进的信息提取技术相比的表现。研究结果表明，通过在上下文学习中仅使用少量实例，我们提出的策略就能产生具有竞争力的结果，并且在数据注释和工程费用方面显着节省。此外，我们使用我们提出的方法来检索生物医学信息，证明了它在现实环境中的实用性。总而言之，我们提出的方法提供了一种可行的方法来克服从非结构化文本中获取结构化数据以创建知识库的困难。它可以大大提高信息提取的准确性和有效性，这对于包括聊天机器人、推荐引擎和问答系统在内的许多应用都是必需的。]]></description>
      <guid>https://arxiv.org/abs/2408.04641</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:48 GMT</pubDate>
    </item>
    <item>
      <title>评估高级法学硕士技术对机器人课程人工智能讲师的影响</title>
      <link>https://arxiv.org/abs/2408.04645</link>
      <description><![CDATA[arXiv:2408.04645v1 公告类型：交叉 
摘要：本研究评估了大型语言模型 (LLM) 作为大学课程的人工智能导师的表现。特别是，使用了不同的先进技术，例如即时工程、检索增强生成 (RAG) 和微调。我们使用常见的相似性指标（如 BLEU-4、ROUGE 和 BERTScore）评估了不同的模型并应用了技术，并辅以对有用性和可信度的小型人工评估。我们的研究结果表明，RAG 与即时工程相结合可显着增强模型响应并产生更好的事实答案。在教育背景下，RAG 似乎是一种理想的技术，因为它基于使用通常已经存在于大学课程中的附加信息和材料来丰富模型的输入。另一方面，微调可以产生非常小但仍然强大的专家模型，但存在过度拟合的危险。我们的研究进一步询问我们如何衡量法学硕士的表现，以及当前的测量方法如何代表正确性或相关性？我们发现相似性指标具有很高的相关性，并且大多数这些指标都偏向于较短的回答。总体而言，我们的研究指出了将法学硕士融入教育环境的潜力和挑战，这表明需要平衡的培训方法和先进的评估框架。]]></description>
      <guid>https://arxiv.org/abs/2408.04645</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能用于从太空监测甲烷排放源</title>
      <link>https://arxiv.org/abs/2408.04745</link>
      <description><![CDATA[arXiv:2408.04745v1 公告类型：新
摘要：减少甲烷排放是短期内阻止全球变暖和为人类争取脱碳时间的最快方法。尽管遥感仪器具有探测甲烷羽流的能力，但目前还没有系统可以定期监测和应对这些事件。我们介绍了 MARS-S2L，这是一种由人工智能驱动的自动化甲烷排放监测系统，用于 Sentinel-2 和 Landsat 卫星图像，部署在联合国环境规划署国际甲烷排放观测站。我们汇编了一个包含数千个超级排放事件的全球数据集，用于训练和评估，表明 MARS-S2L 可以熟练地监测全球不同地区的排放，与目前最先进的检测方法相比，平均精度提高了 216%。该系统运行六个月以来，已在 22 个不同的国家/地区实现了 457 次近实时检测，其中 62 次已用于向政府和利益相关者提供正式通知。]]></description>
      <guid>https://arxiv.org/abs/2408.04745</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:47 GMT</pubDate>
    </item>
    <item>
      <title>基于样本的解释器的公理特征</title>
      <link>https://arxiv.org/abs/2408.04903</link>
      <description><![CDATA[arXiv:2408.04903v2 公告类型：新
摘要：解释黑盒分类器的决策既重要又具有计算挑战性。在本文中，我们仔细研究了从样本或数据集生成基于特征的解释的解释器。我们首先介绍一组解释器理想情况下会满足的理想属性，深入研究它们之间的关系，并强调其中一些属性的不兼容性。我们确定了满足两个关键属性的解释器家族，这两个属性与所有其他属性兼容。它的实例提供了充分的理由，称为弱溯因解释。然后，我们解开了满足兼容属性子集的各种子家族。事实上，我们完全描述了满足任何兼容属性子集的所有解释器。特别是，我们介绍了第一个（广泛的）解释器家族，它们保证了解释的存在及其全局一致性。我们讨论了它的一些实例，包括无可辩驳的解释器和可以在多项式时间内找到解释的替代解释器。]]></description>
      <guid>https://arxiv.org/abs/2408.04903</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:47 GMT</pubDate>
    </item>
    <item>
      <title>释放人工智能认知：整合多种人工智能系统</title>
      <link>https://arxiv.org/abs/2408.04910</link>
      <description><![CDATA[arXiv:2408.04910v2 公告类型：新
摘要：在本研究中，我们提出了一种创新的语言模型和查询分析技术的融合，以解锁人工智能中的认知。我们的系统将国际象棋引擎与语言模型无缝集成，使其能够预测动作并提供战略解释。通过可检索的答案生成利用矢量数据库，我们的 OpenSI AI 系统阐明了其决策过程，弥合了原始计算和类似人类的理解之间的差距。我们选择国际象棋作为演示环境强调了我们方法的多功能性。除了国际象棋之外，我们的系统还有望应用于从医疗诊断到财务预测等各种应用。]]></description>
      <guid>https://arxiv.org/abs/2408.04910</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:47 GMT</pubDate>
    </item>
    <item>
      <title>知识库嵌入：语义和理论属性</title>
      <link>https://arxiv.org/abs/2408.04913</link>
      <description><![CDATA[arXiv:2408.04913v1 公告类型：新
摘要：知识图谱嵌入研究最近已发展为知识库嵌入，其目标不仅是将事实映射到向量空间，而且还要约束模型，以便它们考虑到可用的相关概念知识。本文通过基于几何语义的视角，研究了最近提出的将描述逻辑中的知识库嵌入向量空间的方法。我们确定了几个相关的理论特性，这些特性是我们从文献中得出的，有时是概括或统一的。然后，我们研究具体的嵌入方法如何适应这个理论框架。]]></description>
      <guid>https://arxiv.org/abs/2408.04913</guid>
      <pubDate>Tue, 13 Aug 2024 03:23:47 GMT</pubDate>
    </item>
    </channel>
</rss>