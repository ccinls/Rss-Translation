<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 04 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基础代理商的进步和挑战：从脑启发的智能到进化，协作和安全系统</title>
      <link>https://arxiv.org/abs/2504.01990</link>
      <description><![CDATA[ARXIV：2504.01990V1公告类型：新 
摘要：大型语言模型的出现（LLM）催化了人工智能的变革性转变，为能够具有复杂推理，强大的感知和多功能动作的高级智能代理铺平了道路。随着这些代理人越来越多地推动了人工智能研究和实际应用，它们的设计，评估和持续改进会带来复杂的多方面挑战。这项调查提供了全面的概述，在模块化的，脑为灵感的体系结构中构建了智能代理，该体系结构整合了认知科学，神经科学和计算研究的原理。我们将探索组织成四个相互连接的部分。首先，我们深入研究了智能代理的模块化基础，将其认知，感知和操作模块映射到类似的人脑功能上，并阐明诸如记忆，世界建模，奖励处理和类似情感的系统之类的核心组件。其次，我们讨论了自我增强和自适应演化机制，探讨了代理人如何自主提炼其能力，适应动态环境，并通过自动优化范式（包括新兴的AutoML和LLM驱动的优化策略）通过自动优化范式进行持续学习。第三，我们研究了协作和进化的多代理系统，研究了从代理人的互动，合作和社会结构中出现的集体情报，从而突出了与人类社会动态的相似之处。最后，我们解决建立安全，安全和有益的AI系统的关键当务之急，强调内在和外部安全威胁，道德一致性，鲁棒性和实践缓解策略，这是可信赖的现实世界部署所必需的。]]></description>
      <guid>https://arxiv.org/abs/2504.01990</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大脑与字节：评估OlympiaD数学的LLM能力</title>
      <link>https://arxiv.org/abs/2504.01995</link>
      <description><![CDATA[ARXIV：2504.01995V1公告类型：新 
摘要：大语言模型（LLM）的最新进展在数学推理任务中显示出令人印象深刻的进步。但是，当前的评估基准主要集中在最终答案的准确性上，通常忽视对解决数学问题解决的逻辑严格性。关于最先进的LLM可以解决数学奥林匹克级问题的说法需要仔细检查。为了探讨这一点，我们对LLMS产生的证明进行了定性和定量人类评估，并开发了一种用于自动评估其推理能力的模式。我们的研究表明，目前的LLM明显缺乏解决挑战性奥林匹克级问题，并且经常无法将正确的数学推理与明显有缺陷的解决方案区分开。我们还发现，偶尔由LLM提供的正确最终答案通常是由模式识别或启发式快捷方式而不是真正的数学推理产生的。这些发现强调了LLM绩效与高级数学推理方面的人类专业知识之间的巨大差距，并强调了开发基准的重要性，该基准优先考虑数学论点的严格性和连贯性，而不仅仅是最终答案的正确性。]]></description>
      <guid>https://arxiv.org/abs/2504.01995</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>认知封闭和未对准的不可逆性：建模系统性障碍的一致性创新</title>
      <link>https://arxiv.org/abs/2504.02058</link>
      <description><![CDATA[ARXIV：2504.02058V1公告类型：新 
摘要：确保人工通用情报（AGI）的安全发展的努力通常依赖于基于共识的一致性方法，该方法基于公理形式主义，可解释性和经验验证。但是，这些方法在结构上可能无法识别或纳入其所接受的认知框架之外的新颖解决方案。本文介绍了认知封闭的功能模型，其中认知，机构，社会和基础设施过滤器结合使用，以使许多对现有评估系统难以辨认的建议提案。我们提出了一个由理论和经验来源支持的加权闭合模型，包括由AI系统对拒绝和不参与模式进行的荟萃分析，并使用分散的集体智能框架（DCI）进行。我们认为，递归未能评估DCI之类的模型不仅是社会学的监督，而且是一种结构吸引子，反映了我们旨在避免AGI中的未对准的风险。如果没有采用DCI或类似的认知校正模型，我们可能会处于无法可逆的不对对准的可预测途径。首先，通过模拟审查，然后通过正式渠道提供了本文的开发和接受，提供了一个支持其核心主张的案例研究：只有通过对维持限制的约束的递归建模才能克服认知封闭。]]></description>
      <guid>https://arxiv.org/abs/2504.02058</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过受控的及时变化探索LLM推理</title>
      <link>https://arxiv.org/abs/2504.02111</link>
      <description><![CDATA[ARXIV：2504.02111V1公告类型：新 
摘要：这项研究研究了在系统地引入输入扰动下的数学解决问题任务上的大语言模型（LLM）的推理鲁棒性。使用GSM8K数据集作为受控测试床，我们评估了面对四种及时扰动的四类模型的最新模型如何保持逻辑一致性和正确性：无关紧要的上下文，病理学指示，事实相关但非必需的上下文以及后两者的组合。我们对13个开源和封闭源LLM进行的实验表明，在模型上下文窗口中引入不相关的环境会大大降低性能，这表明将必不可少的细节与外部细节区分开是一个紧迫的挑战。出乎意料的是，绩效回归对推理任务的复杂性相对不敏感，这是根据所需步骤数来衡量的，并且与模型大小不严格相关。此外，我们观察到，即使没有明确提示，某些扰动也无意中触发了类似思想链的推理行为。我们的发现突出了当前LLM中的关键脆弱性，并强调了对嘈杂，误导性和上下文致密输入的鲁棒性的需求，为在现实世界应用中更有弹性和可靠的推理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2504.02111</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OMNICELLTOSG：关节LLM和GNN建模的第一个单元格文本信号图数据集</title>
      <link>https://arxiv.org/abs/2504.02148</link>
      <description><![CDATA[ARXIV：2504.02148V1公告类型：新 
摘要：复杂的细胞信号系统 - 受不同蛋白质丰度和相互作用的约束 - 在跨器官之间产生各种细胞类型。这些系统在年龄，性别，饮食，环境暴露和疾病等影响下的发展，鉴于成千上万的基因和蛋白质的参与，它们使它们具有挑战性。最近，数亿个单细胞OMIC数据为理解各种细胞亚群和条件中的这些信号网络提供了强大的基础。受到大型基础模型（例如，大型语言模型和大型视觉模型）的成功启发，我们介绍了Omnicelltosg，Omnicelltosg是单元文本 - 乐器信号图​​（TOSGS）的第一个数据集。每个TOSG代表个体或元细胞的信号网络，并标有器官，疾病，性别，年龄和细胞亚型等信息。 Omnicelltosg提供了两个关键贡献。首先，它引入了一个新的图形模型，该模型将人类可读注释（例如生物学功能，细胞位置，信号通路，相关疾病和药物）与定量基因和蛋白质丰度数据相结合，从而使图形推理能够解码细胞信号。这种方法要求将大型语言模型和图形神经网络结合在一起的新联合模型。其次，数据集是由来自不同组织和条件（健康和患病）的大约1.2亿个细胞的单细胞RNA测序数据构建，并且与Pytorch完全兼容。这有助于开发创新的细胞信号传导模型，这些模型可以改变生命科学，医疗保健和精密医学的研究。 Omnicelltosg数据集正在不断扩展，并将定期更新。该数据集和代码可在https://github.com/fuhailiailab/omnicelltosg上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.02148</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型推理的缩放调查</title>
      <link>https://arxiv.org/abs/2504.02181</link>
      <description><![CDATA[ARXIV：2504.02181V1公告类型：新 
摘要：大语言模型（LLM）的快速进步已大大提高了其推理能力，这是由多种策略（例如多代理协作）驱动的。但是，与通过缩放数据和模型大小实现的良好的性能改进不同，LLMS中推理的缩放更为复杂，甚至可能对推理性能产生负面影响，从而在模型对齐和稳健性中引入了新的挑战。在这项调查中，我们对LLM推理中的缩放量表进行了全面的检查，将其分为多个维度，并分析了如何以及在何种程度上不同的缩放策略有助于提高推理能力。我们首先要探索输入大小的缩放，这使LLM可以处理并利用更广泛的上下文来改善推理。接下来，我们在推理步骤中分析缩放，以提高多步推理和逻辑一致性。然后，我们在推理巡回赛中检查缩放，其中迭代相互作用完善了推理结果。此外，我们讨论了培训推理的扩展，并通过迭代模型改进着重于优化。最后，我们回顾跨域扩展的应用，并概述未来的方向，以进一步推进LLM推理。通过综合这些不同的观点，这项调查旨在提供有关扩展策略如何从根本上增强LLM的推理能力的见解，并进一步指导下一代AI系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2504.02181</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更多是：DPO安全对齐中多模型合成偏好数据的陷阱</title>
      <link>https://arxiv.org/abs/2504.02193</link>
      <description><![CDATA[ARXIV：2504.02193V1公告类型：新 
摘要：将大语言模型（LLM）与人类价值观保持一致是训练后越来越重要的一步。直接偏好优化（DPO）已成为一种简单但有效的替代方法，可以从人类反馈（RLHF）中学习。合成偏好数据及其低成本和高质量通过单模型或多模型生成的偏好数据有效对齐。我们的研究揭示了与DPO一致性相关的引人注目的，特定于安全的现象：尽管多模型生成的数据增强了一般任务的性能（ARC，Hellaswag，MMLU，MMLU，MMLU，Elthfulqa，Winogrande，Winogrande），通过提供多样化的响应，但它也倾向于在培训过程中促进奖励黑客。当模型遇到越狱提示时，这可能会导致高攻击成功率（ASR）。当在同一家族中使用诸如GPT-4O或更大模型之类的更强大模型来生成所选的响应与目标模型自生的拒绝响应配对时，问题尤其明显，从而产生了较大的安全结果。此外，在安全方面，对所选和拒绝的配对使用仅使用自我生成的响应（单模型生成）都显着优于合并更强模型的响应的配置，无论是直接用作选择的数据还是作为多模型响应池的一部分。我们证明，多模型偏好数据在所选响应和被拒绝的响应之间表现出很高的线性可分离性，这允许模型利用浅表提示，而不是内部化强大的安全性约束。我们的实验是对骆驼，米斯特拉尔和Qwen家族的模型进行的，始终验证了这些发现。]]></description>
      <guid>https://arxiv.org/abs/2504.02193</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>拉斯维加斯：朝着视觉上解释和扎根的人工社会智能</title>
      <link>https://arxiv.org/abs/2504.02227</link>
      <description><![CDATA[ARXIV：2504.02227V1公告类型：新 
摘要：社会智能查询（社会IQ）是评估模型的社会智能水平的主要多模式基准。尽管当前的解决方案可以实现令人印象深刻的多项选择问题（MCQ）精度，但越来越多的证据表明，它们在很大程度上是在很大程度上取决于语言方式，忽略了视觉上下文。此外，封闭式性质进一步阻止了选择背后的推理路径是否正确的探索。为了解决这些局限性，我们提出了可视上可解释的人工社会智能（Vegas）模型。作为一种生成的多模式模型，维加斯利用开放式的答案来提供可解释的响应，从而增强了推理路径的清晰度和评估。为了实现视觉接地的答案，我们提出了一种新颖的抽样策略，以为模型提供更相关的视觉框架。然后，我们通过通才教学微调（礼物）来增强模型对这些框架的解释，该教学的目的是：i）学习基本情感社会特征的多模态转换，ii）建立多模式的联合推理能力。包括模态消融，开放式评估和监督MCQ评估的广泛实验始终表明，维加斯有效地利用了视觉信息来产生正确的和可信的答案。我们希望这项工作能够对社会智商产生新的看法，并推动类似人类的社会AI的发展。]]></description>
      <guid>https://arxiv.org/abs/2504.02227</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>工程人工智能：框架，挑战和未来方向</title>
      <link>https://arxiv.org/abs/2504.02269</link>
      <description><![CDATA[ARXIV：2504.02269V1公告类型：新 
摘要：在过去的十年中，人工智能（AI）和机器学习（ML）在工程领域中的应用已广泛流行，展现了它们在数据驱动的环境中的潜力。但是，工程问题的复杂性和多样性通常需要开发特定于域的AI方法，这些方法经常因缺乏系统的方法，可伸缩性和在开发过程中的鲁棒性而阻碍。为了解决这一差距，本文介绍了“ ABCDE”作为工程AI的关键要素，并提出了一个统一的系统工程AI生态系统框架，包括八个基本层，以及属性，目标和应用，以指导针对特定工程需求的AI解决方案的开发和部署。此外，研究了主要的挑战，并突出了九个未来的研究方向。通过提供全面的观点，本文旨在推进AI的战略实施，从而促进下一代工程AI解决方案的发展。]]></description>
      <guid>https://arxiv.org/abs/2504.02269</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>叙事工作室：使用LLM和Monte Carlo Tree搜索的视觉叙事探索</title>
      <link>https://arxiv.org/abs/2504.02426</link>
      <description><![CDATA[ARXIV：2504.02426V1公告类型：新 
摘要：互动讲故事从计划和探索多个“如果”场景中受益。现代LLM是用于构想和探索的有用工具，但是当前基于聊天的用户接口将用户限制为单个线性流。为了解决这一限制，我们提出了叙事工作室 - 一种新颖的浏览器叙事探索环境，具有类似树状的界面，可以从故事中的用户定义点进行分支探索。每个分支都通过迭代LLM推理扩展，这些推理由系统和用户定义的提示指导。此外，我们采用蒙特卡洛树搜索（MCT）自动根据用户指定的标准扩展有希望的叙事途径，从而实现更多样化和强大的故事发展。我们还允许用户通过在代表故事的演员和环境的实体图中扎根生成的文本来增强叙事连贯性。]]></description>
      <guid>https://arxiv.org/abs/2504.02426</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何导致知识的原因：亚里士多德后验分析启发的询问</title>
      <link>https://arxiv.org/abs/2504.02430</link>
      <description><![CDATA[ARXIV：2504.02430V1公告类型：新 
摘要：贝叶斯网络和因果模型提供了处理有关外部干预和反事实的查询的框架，从而使任务超出了仅概率分布的问题。尽管这些形式主义通常被非正式地描述为捕获因果知识，但缺乏形式的理论来表征预测外部干预措施影响所需的知识类型。这项工作介绍了因果系统的理论框架，以阐明亚里士多德在人工智能中的知识和知识之间的区别。通过将现有的人工智能技术解释为因果系统，它研究了相应的知识类型。此外，它认为，只有知识才能预测外部干预措施的效果是可行的，为什么提供对此类任务所需的知识的更精确的理解。]]></description>
      <guid>https://arxiv.org/abs/2504.02430</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提升：引导策略驱动的推理程序，用于程序指导事实检查</title>
      <link>https://arxiv.org/abs/2504.02467</link>
      <description><![CDATA[ARXIV：2504.02467V1公告类型：新 
摘要：程序指导的推理通过将索赔分解为函数呼叫和执行推理程序，在复杂的索赔事实检查中表现出了承诺。但是，先前的工作主要依赖于具有临时演示的几乎没有镜头的内在学习（ICL），这限制了程序多样性，并且需要具有实质性领域知识的手动设计。从根本上讲，有效推理计划产生的基本原则仍然没有被忽视，这使得构建有效的示威活动具有挑战性。为了解决这个问题，我们提出了BOOST，这是一种基于自举的框架，用于几次推理计划生成。 Boost明确地将索赔分解和信息收集策略整合为计划生成的结构指导，以策略驱动的且以数据为中心的方式进行迭代精炼，而无需人工干预。这使从零射击到几乎没有战略计划指导学习的无缝过渡，增强了解释性和有效性。实验结果表明，在零射击和少数拍摄设置中，提高表现优于先前的几杆基线，以进行复杂的索赔验证。]]></description>
      <guid>https://arxiv.org/abs/2504.02467</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们需要改进AI中的数据策划和归因于科学发现</title>
      <link>https://arxiv.org/abs/2504.02486</link>
      <description><![CDATA[ARXIV：2504.02486V1公告类型：新 
摘要：随着人类生成和合成数据之间的相互作用的发展，有关数据完整性和模型稳定性的科学发现出现了新的挑战。在这项工作中，我们研究了合成数据的作用，而不是实际实验数据的科学研究。我们的分析表明，在开放式平台上可用的实验数据集的近四分之三的采用率相对较低，为通过自动方法提供了新的机会，以增强其可发现性和可用性。此外，我们观察到将合成与实际实验数据区分开的困难越来越困难。我们建议通过增加对水印实际实验数据的关注，从而增强数据可追溯性和完整性，从而补充正在进行的合成数据检测中的持续努力。我们的估计表明，即使每年生成的现实世界数据中，水印甚至不到一半可以帮助维持模型的鲁棒性，同时促进了合成和人类生成的含量的平衡整合。]]></description>
      <guid>https://arxiv.org/abs/2504.02486</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有渐进神经网络集成变压器的自学代理</title>
      <link>https://arxiv.org/abs/2504.02489</link>
      <description><![CDATA[ARXIV：2504.02489V1公告类型：新 
摘要：本文介绍了一种自学代理，将Llama 3.2与渐进神经网络（PNN）集成在一起，以在对话式AI和代码生成中持续学习。该框架动态收集数据，用最少样本的微型任务，并利用元学习来快速适应。洛拉（Lora）优化了微调，而弹性重量巩固（EWC）则增强了知识的保留率。实验结果表明，改善了适应性和记忆稳定性，将这种方法定位为迈向人工智能（AGI）的可扩展步骤。]]></description>
      <guid>https://arxiv.org/abs/2504.02489</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于自动合并3D打印工作订单的自动合并的内存启动LLM驱动的方法</title>
      <link>https://arxiv.org/abs/2504.02509</link>
      <description><![CDATA[ARXIV：2504.02509V1公告类型：新 
摘要：随着3D打印的迅速发展，对制造线上的个性化和定制生产的需求正在稳步增加。有效合并印刷工件可以显着提高生产线的加工效率。在应对挑战时，本文在本文中建立了一种大型语言模型（LLM）驱动的方法，用于自动合并3D打印工作订单，并与内存振奋的学习策略集成在一起。在工业场景中，设备和订单功能均模型为LLM可读的自然语言提示模板，并开发订单设备匹配工具以及合并干扰检查模块。通过纳入自我内存学习策略，构建了自主命令合并的智能代理，从而提高了准确性和精确度以分配的顺序。提出的方法有效地利用了LLM在工业应用中的优势，同时减少了幻觉。]]></description>
      <guid>https://arxiv.org/abs/2504.02509</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理不一致以及如何在深度学习中减轻它们</title>
      <link>https://arxiv.org/abs/2504.02577</link>
      <description><![CDATA[ARXIV：2504.02577V1公告类型：新 
摘要：深度学习模型和技术的最新进步导致了各种任务和方式的绩效取得了重大进步。但是，尽管模型的总体能力显示出有希望的增长，但我们对它们的内部推理过程的理解仍然有限，尤其是关于逻辑或推理缺陷的系统不一致或错误模式。这些不一致可能表现为矛盾的输出，未能跨越相似的任务或在特定情况下的错误结论。即使检测和衡量这种推理差异也是一项挑战，因为它们可能是由于训练数据中不透明的内部程序，偏见和失衡而引起的，或者任务的固有复杂性。没有有效的方法来检测，测量和减轻这些错误，就有部署具有偏见，可利用或逻辑上不可靠的模型的风险。本文旨在通过为深度学习模型生产新的方法来解决这些问题，这些方法推理了知识图，自然语言和图像。该论文贡献了两种技术，用于检测和量化自然语言和图像处理模型中不透明的内部程序的预测不一致。为了减轻培训数据中偏见的不一致，本文提出了一种有效的抽样方法，以提高公平性和性能，并在低资源方案中一种合成数据集生成方法。最后，论文提供了两种技术来优化复杂推理任务的模型。这些方法增强了模型性能，同时允许推理期间更加忠实，可解释的探索和剥削。至关重要的是，本文提供了一个综合框架，以提高各种任务和方式深度学习模型的鲁棒性，公平性和解释性。]]></description>
      <guid>https://arxiv.org/abs/2504.02577</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多损新工具工作台：通过相关和动态任务评估基于LLM的代理的鲁棒性</title>
      <link>https://arxiv.org/abs/2504.02623</link>
      <description><![CDATA[ARXIV：2504.02623V1公告类型：新 
摘要：大型语言模型（LLMS）由于其高级理解和计划能力而显示出强大的刀具援引代理的潜力。用户越来越多地依靠基于LLM的代理来通过迭代互动来解决复杂的任务。但是，现有的基准测试主要访问单个误差方案中的代理，但未能捕获现实世界中的复杂性。为了弥合这一差距，我们提出了多损新工具工作台。在基准中，每个测试案例包括多个相互关联的任务。该设计要求代理人动态适应不断发展的需求。此外，拟议的基准测试探索了固定任务编号内的所有可能的任务转换模式。具体而言，我们提出了一个多代理数据生成框架来构建基准测试。我们还提出了一种新型方法，以通过动态决策树评估代理决策的准确性和效率。关于各种开源和封闭源LLM的实验揭示了影响剂的鲁棒性的关键因素，并为工具调用社会提供了可行的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.02623</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SYMDQN：基于神经网络的强化学习中的象征性知识和推理</title>
      <link>https://arxiv.org/abs/2504.02654</link>
      <description><![CDATA[ARXIV：2504.02654V1公告类型：新 
摘要：我们提出了一种学习体系结构，可以通过深层神经网络进行象征性的控制和指导。我们介绍了Symdqn，这是一种新型的模块化方法，可增强现有的Duuling Deep Q-Networks（Dueldqn）体系结构，该体系结构具有基于逻辑张量网络（LTNS）神经符号框架的模块。模块指导行动政策学习，并允许加强学习者显示与环境推理一致的行为。我们的实验是对模块进行的消融研究。它是在遇到各种形状的代理商导航的5x5网格的增强学习环境中进行的，每种都与给定的奖励相关。基本的DueldQN试图在这种环境中学习代理的最佳行为，而模块有助于形状识别和奖励预测。我们表明，在绩效和代理商的精度方面，我们的体系结构都大大改善了学习。 Symdqn的模块化允许反思结合增强学习中神经和符号方法的复杂性和复杂性。]]></description>
      <guid>https://arxiv.org/abs/2504.02654</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负担得起的AI助手具有思想的知识图</title>
      <link>https://arxiv.org/abs/2504.02670</link>
      <description><![CDATA[ARXIV：2504.02670V1公告类型：新 
摘要：大型语言模型（LLM）正在彻底改变能够在跨领域执行各种任务的AI助手的发展。但是，当前最先进的LLM驱动的代理商面临着重大挑战，包括高运营成本和诸如Gaia等复杂基准的成功率有限。为了解决这些问题，我们提出了思想的知识图（KGOT），这是一种创新的AI助手体系结构，将LLM推理与动态构建的知识图（KGS）集成在一起。 KGOT将与任务相关的知识提取到动态kg表示形式，并通过数学求解器，Web爬网和Python脚本等外部工具进行迭代增强。与任务相关的知识的结构化表示使低成本模型能够有效地解决复杂的任务。例如，与拥有GPT-4O Mini的拥抱面孔相比，KGOT在GAIA基准测试的任务成功率上提高了29％，而与GPT-4O相比，成本降低了36倍。最近推理模型的改进相似，例如QWEN2.5-32B和DEEPSEEK-R1-70B分别为36％和37.5％。 KGOT为AI助手提供了可扩展，负担得起且高性能的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2504.02670</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负责进攻性AI的负责发展</title>
      <link>https://arxiv.org/abs/2504.02701</link>
      <description><![CDATA[ARXIV：2504.02701V1公告类型：新 
摘要：随着AI的进步，需要更广泛的共识来确定研究重点。这项工作讨论了进攻性AI，并通过利用可持续发展目标（SDG）和可解释性技术来提供指导。目的是更有效地确定平衡社会利益与风险的优先事项。在本研究中评估的两种进攻性AI形式是脆弱性检测剂，这些漏洞检测剂解决了捕获的挑战和AI驱动的恶意软件。]]></description>
      <guid>https://arxiv.org/abs/2504.02701</guid>
      <pubDate>Fri, 04 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>