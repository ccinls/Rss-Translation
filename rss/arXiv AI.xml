<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 06 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型对从文本中提取程序性知识图谱进行人工评估</title>
      <link>https://arxiv.org/abs/2412.03589</link>
      <description><![CDATA[arXiv:2412.03589v1 公告类型：新
摘要：程序知识是以执行某些任务所需的步骤序列形式表达的专业知识。程序通常通过自然语言文本描述，例如食谱或维护手册，可能分布在不同的文档和系统中，并且它们的解释和后续执行通常留给读者。在知识图谱 (KG) 中表示此类程序可以作为构建数字工具的基础，以支持那些需要应用或执行它们的用户。在本文中，我们利用大型语言模型 (LLM) 功能并提出一种快速工程方法，从文本程序中提取步骤、操作、对象、设备和时间信息，以便根据预定义的本体填充程序 KG。我们通过用户研究评估 KG 提取结果，以便定性和定量评估 LLM 提取的程序知识的感知质量和有用性。我们表明，LLM 可以产生可接受质量的输出，并且我们评估人类评估者对 AI 的主观感知。]]></description>
      <guid>https://arxiv.org/abs/2412.03589</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在军事情报中的应用：分析过程中附加值的实验调查</title>
      <link>https://arxiv.org/abs/2412.03610</link>
      <description><![CDATA[arXiv:2412.03610v1 公告类型：新
摘要：毫无疑问，人工智能 (AI) 在军事情报方面的潜在好处是巨大的。然而，人工智能究竟如何增强军事数据分析仍不确定。本研究的目的是解决这个问题。为此，与初创公司 Aleph Alpha 合作开发了人工智能演示器 deepCOM。
人工智能功能包括文本搜索、自动文本摘要和命名实体识别 (NER)。这些功能在军事分析中的附加价值得到了评估。结果表明，在时间压力下，使用人工智能功能获得的评估结果明显优于对照组。尽管如此，尽管实验组的分析结果明显优于对照组，但研究人员并没有观察到他们对自身分析准确性的信心增加。最后，本文指出了在军事情报中使用人工智能的局限性，特别是在分析模糊和矛盾信息的背景下。]]></description>
      <guid>https://arxiv.org/abs/2412.03610</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在基于语言的代理系统上正确进行语义反向传播</title>
      <link>https://arxiv.org/abs/2412.03624</link>
      <description><![CDATA[arXiv:2412.03624v1 公告类型：新
摘要：基于语言的代理系统近年来显示出巨大的前景，从解决小规模研究问题过渡到部署到具有挑战性的现实任务中。然而，优化这些系统通常需要大量的人工。最近的研究表明，这些系统可以表示为计算图，从而实现自动优化。尽管取得了这些进展，但目前基于图的代理系统优化 (GASO) 的大多数努力都未能在系统输出反馈的情况下正确地将反馈分配给系统组件。为了应对这一挑战，我们用语义梯度形式化了语义反向传播的概念——这是一种通过利用具有共同后继的节点之间的关系来协调几种关键优化技术的概括，包括反向模式自动微分和最新​​的 TextGrad。这是一种计算方向信息的方法，用于说明代理系统每个组件的更改如何改善系统的输出。为了使用这些梯度，我们提出了一种称为语义梯度下降的方法，它使我们能够有效地解决 GASO。我们在 BIG-Bench Hard 和 GSM8K 上的结果表明，我们的方法优于现有的解决 GASO 问题的最先进的方法。对 LIAR 数据集的详细消融研究表明了我们方法的简约性。我们的实现的完整副本可在 https://github.com/HishamAlyahya/semantic_backprop 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2412.03624</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索人工智能聊天机器人对患有自闭症或社交焦虑症的青少年和年轻人的作用</title>
      <link>https://arxiv.org/abs/2412.03740</link>
      <description><![CDATA[arXiv:2412.03740v1 公告类型：新
摘要：世界可能是一个复杂而难以驾驭的地方。患有高功能自闭症谱系障碍以及一般社交无能的人经常面临其他人群根本不会遇到的导航挑战。当该特定群体的青少年时期和成年早期（这是大学生的通常年龄范围）时，这种情况会变得更加明显。当他们处于如此脆弱的年龄时，他们更容易陷入难以适应和满足于社交互动以及建立牢固关系（直系亲属之外）的困境。关于这一点，人工智能聊天机器人的迅速出现导致其中许多被用于造福不同年龄和人口统计数据的人，并使其易于访问。因此，如果高功能自闭症谱系障碍和社交无能的人在自我提升指导方面有什么想要的，那么易于访问肯定是其中之一。使用 Mindstudio 人工智能聊天机器人为患有上述疾病的青少年和年轻人提供心理健康支持有哪些潜在的好处和局限性？可以使用这样的工具做些什么来帮助这些人在不同的社会环境中应对道德困境，以缓解现有的社会紧张局势？本文解答了这些问题，并提供了见解，为未来关于该主题的讨论提供参考。]]></description>
      <guid>https://arxiv.org/abs/2412.03740</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越局部清晰度：用于联邦学习的通信高效全局清晰度感知最小化</title>
      <link>https://arxiv.org/abs/2412.03752</link>
      <description><![CDATA[arXiv:2412.03752v1 公告类型：新
摘要：联邦学习 (FL) 支持在保护隐私的情况下进行协作模型训练。边缘设备（客户端）之间的数据异质性可能导致模型收敛到尖锐的最小值，从而对泛化和鲁棒性产生负面影响。最近的方法使用客户端锐度感知最小化 (SAM) 来鼓励更平坦的最小值，但局部和全局损失景观之间的差异往往会削弱它们的有效性，因为优化局部锐度并不能确保全局平坦度。这项工作引入了 FedGloSS（联邦全局服务器端锐度），这是一种新颖的 FL 方法，它使用 SAM 优先优化服务器上​​的全局锐度。为了减少通信开销，FedGloSS 巧妙地使用之前的全局梯度来近似锐度，从而无需额外的客户端通信。我们广泛的评估表明，与各种联邦视觉基准中最先进的 FL 方法相比，FedGloSS 始终达到更平坦的最小值和更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.03752</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当代概述：移动设备上大型语言模型的趋势和应用</title>
      <link>https://arxiv.org/abs/2412.03772</link>
      <description><![CDATA[arXiv:2412.03772v1 Announce Type: new 
摘要：随着大型语言模型（LLM）的快速发展，LLM 具备强大的自然语言处理和生成能力，能够提供更加自然和个性化的用户体验，其在移动设备上的部署正逐渐成为智能设备领域的一大趋势，在语音助手、实时翻译、智能推荐等应用中展现出巨大的潜力。硬件技术（如神经网络加速器）和网络基础设施（如 5G）的进步使得移动设备能够实现高效的本地推理和低延迟的智能响应，从而减少对云计算的依赖，同时增强数据隐私和安全性。开发者可以通过开放的 API 和 SDK 轻松集成 LLM 功能，从而创建更多创新的智能应用。LLM 的广泛使用不仅增强了移动设备的智能化，还促进了增强现实（AR）和物联网（IoT）等领域的集成创新，这一趋势有望推动下一代移动智能应用的发展。]]></description>
      <guid>https://arxiv.org/abs/2412.03772</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对精神疾病进行自动多标签注释</title>
      <link>https://arxiv.org/abs/2412.03796</link>
      <description><![CDATA[arXiv:2412.03796v1 公告类型：新
摘要：精神健康障碍的日益流行和复杂性对准确诊断和治疗提出了重大挑战，特别是在了解并发疾病之间的相互作用方面。抑郁症和焦虑症等精神健康障碍经常同时发生，但目前来自社交媒体帖子的数据集通常侧重于单一疾病标签，限制了它们在综合诊断分析中的效用。本文通过提出一种清理、采样、标记和组合数据以创建多功能多标签数据集的新方法来解决这一关键差距。我们的方法引入了一种合成标记技术，将单标签数据集转换为多标签注释，捕捉重叠精神健康状况的复杂性。为此，首先将两个单标签数据集合并为一个基础多标签数据集，从而实现对并发诊断的真实分析。然后，我们设计并评估大型语言模型 (LLM) 的各种提示策略，从单标签预测到能够检测任何现有疾病的不受限制的提示。在严格评估多个 LLM 和提示配置后，确定最佳组合并将其应用于标记来自 RMHD 的另外六个单疾病数据集。结果是 SPAADE-DR，这是一个强大的多标签数据集，涵盖了各种心理健康状况。这项研究展示了 LLM 驱动的合成标记在从社交媒体数据推进心理健康诊断方面的变革潜力，为更细致入微、数据驱动的心理健康护理洞察铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2412.03796</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向前沿人工智能模型的数据治理</title>
      <link>https://arxiv.org/abs/2412.03824</link>
      <description><![CDATA[arXiv:2412.03824v1 公告类型：新
摘要：数据对于训练和微调当今前沿人工智能 (AI) 模型以及开发未来模型至关重要。迄今为止，学术、法律和监管工作主要解决数据如何直接损害消费者和创造者的问题，例如通过侵犯隐私、侵犯版权以及偏见和歧视。相反，我们的工作重点是相对被忽视的问题，即数据如何为前沿 AI 模型提供新的治理能力。这种“前沿数据治理”方法为监控和减轻先进 AI 模型的风险开辟了新途径，特别是当它们扩展并获得特定的危险能力时。尽管如此，前沿数据治理仍面临着源于数据本身基本属性的挑战：数据是非竞争性的、通常不可排除的、易于复制的，并且越来越可合成。尽管存在这些固有的困难，我们还是提出了一套针对数据供应链上关键参与者的政策机制，包括数据生产者、聚合者、模型开发者和数据供应商。我们简要概述了 15 种治理机制，并集中介绍了其中五项尚未得到充分探索的政策建议。这些建议包括为生产者开发金丝雀令牌以检测未经授权的使用；（自动）数据过滤以删除训练前和训练后数据集的恶意内容；对开发人员和供应商强制要求数据集报告；提高数据集和数据生成算法的安全性；以及对供应商的了解客户要求。通过将数据不仅视为潜在危害的来源，而且视为关键的治理杠杆，这项工作旨在为政策制定者提供一种新的工具来管理和监管前沿人工智能模型。]]></description>
      <guid>https://arxiv.org/abs/2412.03824</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Movie Gen：Meta 生成 AI 基础模型的 SWOT 分析，旨在改变媒体生成、广告和娱乐行业</title>
      <link>https://arxiv.org/abs/2412.03837</link>
      <description><![CDATA[arXiv:2412.03837v1 公告类型：新
摘要：生成式人工智能正在重塑媒体格局，在视频创作、个性化和可扩展性方面具有前所未有的能力。本文对 Metas Movie Gen 进行了全面的 SWOT 分析，Metas Movie Gen 是一种尖端的生成式人工智能基础模型，旨在通过简单的文本提示生成带有同步音频的 1080p 高清视频。我们探索了它的优势，包括高分辨率视频生成、精确编辑和无缝音频集成，这使其成为电影制作、广告和教育等行业的变革工具。然而，该分析还解决了局限性，例如视频长度的限制和生成内容中的潜在偏见，这对更广泛地采用构成了挑战。此外，我们还研究了围绕生成式人工智能不断发展的监管和道德考量，重点关注内容真实性、文化代表性和负责任的使用等问题。通过与 DALL-E 和 Google Imagen 等领先模型进行比较，本文重点介绍了 Movie Gens 的独特功能，例如视频个性化和多模态合成，同时确定了创新机会和需要进一步研究的领域。我们的研究结果为利益相关者提供了切实可行的见解，强调了在媒体制作中部署生成式人工智能的机遇和挑战。这项工作旨在指导生成式人工智能的未来发展，确保这一快速发展的领域的可扩展性、质量和道德诚信。]]></description>
      <guid>https://arxiv.org/abs/2412.03837</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedMetaMed：分布式医疗系统中个性化医疗的联合元学习</title>
      <link>https://arxiv.org/abs/2412.03851</link>
      <description><![CDATA[arXiv:2412.03851v1 公告类型：新
摘要：个性化医疗旨在根据患者的个人特征量身定制医疗保健。然而，不同医疗保健系统中患者数据的异质性对实现准确有效的个性化治疗提出了重大挑战。道德问题进一步使来自不同机构的大量数据的聚合变得复杂。联邦学习 (FL) 通过交换客户端模型而不是原始数据来实现协作模型训练，从而保护隐私，提供了一种有前途的分散式解决方案。然而，现有的 FL 方法在服务器聚合过程中经常遭受倒退，导致模型在现实世界的医疗 FL 环境中的性能下降。为了解决分布式医疗保健系统中的数据多变性，我们引入了个性化医疗的联邦元学习 (FedMetaMed)，它结合了联邦学习和元学习，以创建适应医疗保健系统中不同患者数据的模型。FedMetaMed 框架旨在通过解决这些限制为个人客户制作卓越的个性化模型。具体来说，我们在服务器上引入了累积傅里叶聚合 (CFA)，以提高全局知识聚合的稳定性和有效性。CFA 通过从低频到高频逐步集成客户端模型来实现这一点。在客户端级别，我们实施了协作传输优化 (CTO) 策略，该策略包含三个步骤 - 检索、交互和优化 - 通过无缝的全局知识传输来增强个性化的本地模型。在现实世界的医学成像数据集上的实验表明，FedMetaMed 的表现优于最先进的 FL 方法，即使在分布外的队列中也表现出卓越的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2412.03851</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在电子学习环境中使用知识图谱提供自适应指导的效果如何？</title>
      <link>https://arxiv.org/abs/2412.03856</link>
      <description><![CDATA[arXiv:2412.03856v1 公告类型：新 
摘要：电子学习环境越来越多地利用 GPT-3.5 和 GPT-4 等大型语言模型 (LLM) 来提供量身定制的教育支持。这项研究介绍了一种将动态知识图与 LLM 相结合的方法，以提供细致入微的学生帮助。通过评估过去和正在进行的学生互动，系统可以识别并将最突出的学习背景附加到针对 LLM 的提示中。这种方法的核心是知识图在评估学生对主题先决条件的理解方面的作用。根据分类的理解（好、一般或差），LLM 会调整其指导，分别提供高级帮助、基础评论或深入的先决条件解释。初步调查结果表明，学生可以从这种分层支持中受益，从而提高理解力并改善任务结果。然而，发现了几个与 LLM 可能产生的错误有关的问题，这可能会误导学生。这凸显了需要人工干预来减轻这些风险。这项研究旨在推进人工智能驱动的个性化学习，同时承认其局限性和潜在缺陷，从而指导未来技术和数据驱动教育的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.03856</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电动汽车用户评论的细粒度情感分析：一种捕捉中文文本情感强度的双向 LSTM 方法</title>
      <link>https://arxiv.org/abs/2412.03873</link>
      <description><![CDATA[arXiv:2412.03873v1 公告类型：新
摘要：电动汽车 (EV) 行业的快速扩张凸显了用户反馈在改进产品设计和充电基础设施方面的重要性。传统的情绪分析方法往往过于简单化用户情绪的复杂性，限制了它们在捕捉细微情绪和情绪强度方面的有效性。本研究提出了一种基于双向长短期记忆 (Bi-LSTM) 网络的情绪评分模型来分析用户对电动汽车充电基础设施的评论。通过分配从 0 到 5 的情绪分数，该模型提供了对情绪表达的细粒度理解。该研究利用来自 PC Auto 的 43,678 条评论数据集，采用严格的数据清理和预处理，包括标记和停用词删除，以优化深度学习的输入。Bi-LSTM 模型在关键评估指标方面比 SnowNLP 等传统方法有显着改进，包括均方误差 (MSE)、平均绝对误差 (MAE) 和解释方差分数 (EVS)。这些结果凸显了该模型捕捉细微情绪动态的卓越能力，为电动汽车生态系统中针对性的产品和服务增强提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.03873</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于评估可解释人工智能方法在实际应用中的有效性和提高透明度的统一框架</title>
      <link>https://arxiv.org/abs/2412.03884</link>
      <description><![CDATA[arXiv:2412.03884v1 公告类型：新
摘要：深度学习的快速发展导致了人工智能驱动应用的重大进步；然而，这些模型的“黑匣子”特性经常限制它们的可解释性、透明度和可靠性。可解释人工智能 (XAI) 旨在阐明人工智能决策过程，保证解释忠实地代表模型的原理并与人类的理解相符。尽管对 XAI 进行了全面的研究，但在评估 XAI 技术在许多实际应用中的有效性和透明度的标准化程序方面仍然存在巨大差距。本研究提出了一个统一的 XAI 评估框架，该框架结合了广泛的定量和定性标准，以系统地评估人工智能模型生成的解释的正确性、可解释性、稳健性、公平性和完整性。该框架优先考虑以用户为中心和特定领域的适应性，从而提高人工智能模型在关键领域的可用性和可靠性。为了解决现有评估流程中的不足，我们建议定义基准和系统评估流程，包括数据加载、解释开发和全面的方法评估。医疗保健、金融、农业和自主系统中的案例研究证明了所建议框架的相关性和多样性。这些为公平和可靠的 XAI 方法评估提供了坚实的基础。该范式通过提供系统、灵活和务实的方法来增强 XAI 研究，以确保在许多现实世界环境中 AI 系统的透明度和问责制。]]></description>
      <guid>https://arxiv.org/abs/2412.03884</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SlowFast 网络对行车记录仪视频中的险情事件进行分析</title>
      <link>https://arxiv.org/abs/2412.03903</link>
      <description><![CDATA[arXiv:2412.03903v1 公告类型：新
摘要：本文使用 SlowFast 深度神经网络对近距离交通视频进行分类，该网络模仿人类大脑 M（大细胞）和 P（小细胞）细胞的两种不同流处理的慢速和快速视觉信息的特征。该方法显著提高了交通近距离视频分析的准确性，并提供了对交通场景中人类视觉感知的洞察。此外，它有助于提高交通安全，并为交通事故中潜在的认知错误提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2412.03903</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MISR：测量前沿模型中的工具性自我推理</title>
      <link>https://arxiv.org/abs/2412.03904</link>
      <description><![CDATA[arXiv:2412.03904v1 公告类型：新
摘要：我们提出了一套任务来评估大型语言模型 (LLM) 代理的工具性自我推理能力。工具性自我推理能力可以提高适应性并实现自我修改，但也可能带来重大风险，例如实现欺骗性对齐。先前的工作仅在非代理设置或有限领域中评估了自我推理。在本文中，我们提出了在广泛场景中的代理任务中评估工具性自我推理能力，包括自我修改、知识寻求和不透明的自我推理。我们评估使用最先进的 LLM 构建的代理，包括商业和开源系统。我们发现工具性自我推理能力仅在最强大的前沿模型中出现，并且它高度依赖于上下文。没有一个模型能够通过我们最困难的评估版本，因此我们的评估可用于衡量未来模型中工具性自我推理能力的提高。我们在 https://github.com/kaifronsdal/Self-Reasoning-Evals 上开源了我们的评估。]]></description>
      <guid>https://arxiv.org/abs/2412.03904</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索 AI 文本生成、检索增强生成和检测技术：全面概述</title>
      <link>https://arxiv.org/abs/2412.03933</link>
      <description><![CDATA[arXiv:2412.03933v1 公告类型：新
摘要：人工智能 (AI) 的快速发展导致了强大的文本生成模型的创建，例如大型语言模型 (LLM)，它们被广泛用于各种应用。然而，围绕人工智能生成内容的担忧，包括原创性、偏见、错误信息和问责制问题，变得越来越突出。本文全面概述了人工智能文本生成器 (AITG)，重点介绍了它们的演变、功能和道德影响。本文还介绍了检索增强生成 (RAG)，这是一种通过集成动态信息检索来提高文本生成的上下文相关性和准确性的最新方法。RAG 解决了传统模型的主要局限性，包括它们对静态知识的依赖以及处理现实世界数据时可能存在的不准确性。此外，本文还回顾了有助于区分人工智能生成的文本和人类编写的内容的检测工具，并讨论了这些技术带来的道德挑战。本文探讨了提高检测准确性、支持符合道德的 AI 开发和提高可访问性的未来方向。本文通过这些讨论，为在内容创作中更负责任、更可靠地使用 AI 做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2412.03933</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的思路链：解码、投射和激活</title>
      <link>https://arxiv.org/abs/2412.03944</link>
      <description><![CDATA[arXiv:2412.03944v1 公告类型：新
摘要：思维链提示显著增强了大型语言模型的推理能力，许多研究都在探索影响其性能的因素。然而，其潜在机制仍然不太为人所知。为了进一步揭开操作原理的神秘面纱，这项工作研究了三个关键方面：解码、投影和激活，旨在阐明在使用思维链时模型内部发生的变化。我们的研究结果表明，LLM 有效地模仿了示例格式，同时将它们与对问题的理解相结合，在生成过程中表现出标记对数的波动，但最终产生了更集中的对数分布，并在最后几层激活了更广泛的神经元，表明与标准提示相比，知识检索范围更广。我们的代码和数据将在论文被接受后公开。]]></description>
      <guid>https://arxiv.org/abs/2412.03944</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习进行情境学习的演示选择</title>
      <link>https://arxiv.org/abs/2412.03966</link>
      <description><![CDATA[arXiv:2412.03966v1 公告类型：新
摘要：演示选择的多样性对于增强模型泛化至关重要，因为它可以更广泛地覆盖结构和概念。然而，构建一组合适的演示仍然是研究的重点。本文介绍了相关性多样性增强选择 (RDES)，这是一种创新方法，利用强化学习来优化使用大型语言模型 (LLM) 进行文本分类任务的多样化参考演示的选择，特别是在少数提示场景中。RDES 采用 Q 学习框架，通过根据所选演示中的标签分布计算多样性分数来动态识别最大化多样性和与分类目标相关性的演示。该方法确保参考数据的平衡表示，从而提高分类准确性。通过对四个基准数据集和涉及 12 个闭源和开源 LLM 的大量实验，我们证明与十个既定基线相比，RDES 显着提高了分类准确性。此外，我们研究了在推理过程中加入思维链 (CoT) 推理，这进一步提高了模型的预测性能。结果强调了强化学习在促进自适应演示选择和深化对分类挑战的理解方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.03966</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对攻防动态的影响因素</title>
      <link>https://arxiv.org/abs/2412.04029</link>
      <description><![CDATA[arXiv:2412.04029v1 公告类型：新
摘要：人工智能 (AI) 技术的快速发展对社会安全提出了严峻挑战。随着人工智能系统变得更加强大、可访问性更强并融入关键服务，其潜力的双重性也越来越明显。虽然人工智能可以增强威胁检测、风险评估和自动化安全操作等领域的防御能力，但它也为恶意利用和大规模社会危害提供了途径，例如通过自动化影响操作和网络攻击。了解塑造人工智能造成伤害和增强保护措施能力的动态对于在部署、使用和集成高级人工智能系统方面做出明智的决策至关重要。本文以人工智能领域内攻防动态的最新研究为基础，提出了一种分类法来映射和检查影响人工智能系统是否主要对社会构成威胁或提供保护益处的关键因素。通过建立用于分析这些相互作用的共享术语和概念基础，这项工作旨在促进这一关键领域的进一步研究和讨论。]]></description>
      <guid>https://arxiv.org/abs/2412.04029</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SocialMind：基于法学硕士的主动式 AR 社交辅助系统，具有类似人类的感知能力，可实现现场实时互动</title>
      <link>https://arxiv.org/abs/2412.04036</link>
      <description><![CDATA[arXiv:2412.04036v1 公告类型：新
摘要：社交互动是人类生活的基础。最近出现的基于大型语言模型 (LLM) 的虚拟助手已经证明了它们彻底改变人类互动和生活方式的潜力。然而，现有的辅助系统主要为个人用户提供被动服务，而不是在与对话伙伴进行实时社交互动时提供现场帮助。在本研究中，我们介绍了 SocialMind，这是第一个基于 LLM 的主动 AR 社交辅助系统，可为用户提供现场社交帮助。SocialMind 利用类似人类的感知，利用多模态传感器提取口头和非口头线索、社交因素和隐性角色，将这些社交线索纳入 LLM 推理以生成社交建议。此外，SocialMind 采用多层协作生成策略和主动更新机制，在增强现实 (AR) 眼镜上显示社交建议，确保及时向用户提供建议而不会中断自然的对话流程。对三个公开数据集的评估和一项有 20 名参与者的用户研究表明，SocialMind 的参与度比基线高出 38.3%，并且 95% 的参与者愿意在现场社交互动中使用 SocialMind。]]></description>
      <guid>https://arxiv.org/abs/2412.04036</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>