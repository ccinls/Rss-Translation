<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>FLARE：忠实的逻辑辅助推理和探索</title>
      <link>https://arxiv.org/abs/2410.11900</link>
      <description><![CDATA[arXiv:2410.11900v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的现代问答 (QA) 和推理方法通常使用提示技术，例如思维链 (CoT)，假设生成的生成将对问题空间和范围进行更细致的探索和推理。然而，这种方法很难生成忠实于模型产生的中间推理链的输出。另一方面，神经符号方法，如忠实 CoT (F-CoT)，建议将 LLM 与外部符号求解器相结合。虽然这种方法具有很高的忠实度，但它们通常需要经过代码生成训练的模型，并且很难处理模棱两可或难以严格形式化的任务。我们引入了 \textbf{F}aithful \textbf{L}ogic-\textbf{A}ided \textbf{R}easoning 和 \textbf{E}xploration (\textbf{\ours})，这是一种使用任务分解遍历问题空间的新型可解释方法。我们使用 LLM 来规划解决方案，使用逻辑编程代码将查询软形式化为事实和谓词，并使用在定义空间上的详尽多跳搜索模拟该代码执行。我们的方法使我们能够计算推理过程相对于生成代码的忠实度，并分析多跳搜索的步骤，而无需依赖外部求解器。我们的方法在 $\mathbf{9}$ 个不同的推理基准中获得了 $\mathbf{7}$ 的 SOTA 结果。我们还表明模型忠诚度与整体性能呈正相关，并进一步证明{\textbf{\ours}} 能够在多跳搜索过程中精确定位足以通过最佳推理得出正确答案的决定性因素。]]></description>
      <guid>https://arxiv.org/abs/2410.11900</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用于大型语言模型网络的可扩展通信协议</title>
      <link>https://arxiv.org/abs/2410.11905</link>
      <description><![CDATA[arXiv:2410.11905v1 公告类型：新
摘要：沟通是协作的先决条件。在扩展 AI 驱动的代理网络时，通信必须是多功能、高效和可移植的。这些要求，我们称之为代理通信三难困境，在大型代理网络中很难实现。我们引入了 Agora，这是一种元协议，它利用现有的通信标准使 LLM 驱动的代理有效地解决复杂问题。在 Agora 中，代理通常使用标准化例程进行频繁通信，使用自然语言进行罕见通信，使用 LLM 编写的例程进行介于两者之间的所有通信。Agora 避开了代理通信三难困境，并稳健地处理接口和成员的变化，实现了前所未有的可扩展性，完全分散化，最大限度地减少了人类的参与。在大型 Agora 网络上，我们观察到自组织、全自动协议的出现，这些协议无需人工干预即可实现复杂目标。]]></description>
      <guid>https://arxiv.org/abs/2410.11905</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>受限最长公共子序列问题的学习搜索算法</title>
      <link>https://arxiv.org/abs/2410.12031</link>
      <description><![CDATA[arXiv:2410.12031v1 公告类型：新
摘要：本文讨论了受限最长公共子序列 (RLCS) 问题，这是众所周知的最长公共子序列 (LCS) 问题的扩展。该问题在生物信息学中具有重要应用，特别是用于识别相似性并发现 DNA、RNA 和蛋白质序列之间的共同模式和重要主题。基于通过通用搜索框架解决此问题的最新进展，本文介绍了两种新颖的启发式方法，旨在通过将其引导至搜索空间中的有希望的区域来增强搜索过程。第一个启发式方法采用概率模型来评估搜索过程中的部分解决方案。第二种启发式方法基于使用遗传算法离线训练的神经网络模型。这种方法的一个关键方面是提取部分解决方案和完整问题实例的问题特定特征。通过将训练有素的神经网络模型与波束搜索框架相结合，开发了一种称为学习波束搜索的有效混合方法。本文的一个重要贡献在于生成真实世界的实例，其中科学摘要作为输入字符串，文献中一组经常出现的学术词汇作为受限模式。全面的实验评估证明了所提出的方法在解决 RLCS 问题方面的有效性。最后，对获得的结果进行了经验可解释性分析。通过这种方式，可以确定关键特征组合及其对不同问题类型算法成功或失败的各自贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.12031</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>严谨规划一切：基于 LLM 的形式化编程的通用零样本规划</title>
      <link>https://arxiv.org/abs/2410.12112</link>
      <description><![CDATA[arXiv:2410.12112v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 最近在解决规划问题方面表现出强大的潜力，但灵活性和复杂性之间存在权衡。LLM 作为零样本规划器本身，仍然无法直接为复杂的规划问题（例如多约束或长期任务）生成有效的计划。另一方面，许多旨在解决复杂规划问题的框架通常依赖于特定于任务的准备工作，例如特定于任务的上下文示例和预定义的批评者/验证者，这限制了它们的跨任务泛化能力。在本文中，我们通过观察许多规划问题的核心在于优化问题来应对这些挑战：在目标受到约束（决策的前提条件和影响）的情况下寻找最优解（最佳计划）。凭借 LLM 的常识、推理和编程能力，这为基于 LLM 的通用规划问题方法开辟了可能性。受此观察的启发，我们提出了 LLMFP，这是一个通用框架，它利用 LLM 从规划问题中捕获关键信息，并从头开始正式制定和解决优化问题，而无需特定于任务的示例。我们将 LLMFP 应用于 9 个规划问题，从多约束决策到多步骤规划问题，并证明 LLMFP 在 GPT-4o 和 Claude 3.5 Sonnet 的 9 个任务中平均实现了 83.7% 和 86.8% 的最佳速率，显著优于最佳基线（使用 OpenAI o1-preview 直接规划），分别提高了 37.6% 和 40.7%。我们还通过消融实验验证了 LLMFP 的组件，并分析了成功和失败的根本原因。]]></description>
      <guid>https://arxiv.org/abs/2410.12112</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基础模型时代的参数化图形表示：调查与定位</title>
      <link>https://arxiv.org/abs/2410.12126</link>
      <description><![CDATA[arXiv:2410.12126v1 公告类型：新
摘要：在过去的几十年里，大数据和人工智能广泛使用图来建模综合关系数据。在分析图的统计特性时，图规律是参数化其结构的重要工具。识别有意义的图规律可以显著提高各种应用的有效性，比如图生成和链接预测。面对当今大规模基础模型的发展，图规律的研究揭示了新的研究潜力，例如，为图神经表征学习提供多模态信息，打破不同图数据的领域不一致。在本综述中，我们首先从多个角度回顾了先前对图规律的研究，即图的宏观和微观、低阶和高阶图、静态和动态图、不同的观察空间以及新提出的图参数。在回顾了受益于图规律指导的各种实际应用之后，我们总结了当前的挑战和未来的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2410.12126</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>划分-验证-改进：将 LLM 响应与复杂指令对齐</title>
      <link>https://arxiv.org/abs/2410.12207</link>
      <description><![CDATA[arXiv:2410.12207v1 公告类型：新
摘要：最近的研究表明，LLM，尤其是开源模型，很难遵循具有多个约束的复杂指令。尽管这很重要，但提高 LLM 遵守此类约束的方法仍未得到探索，当前的研究侧重于评估这种能力，而不是开发解决方案。虽然一些研究通过模型调整来增强约束遵守性，但这种方法在计算上很昂贵，并且严重依赖于训练数据质量。另一种方法是利用 LLM 的自我修正能力，使它们能够调整响应以更好地满足指定的约束。然而，LLM 的这种自我修正能力受到反馈质量的限制，因为 LLM 无法自主生成可靠的反馈或检测错误。此外，自我改进过程严重依赖于说明如何修改响应以满足约束的少量样本示例。由于复杂指令中的约束多种多样且差异很大，因此手动为每种约束类型制作少量样本示例可能非常耗费人力且不是最优的。为了应对这两个挑战，我们提出了分为三个步骤的划分-验证-细化 (DVR) 框架：（1）将复杂指令划分为单个约束并准备适当的工具；（2）验证：为了解决反馈质量问题，这些工具将严格验证响应并提供可靠的反馈；（3）细化：为了应对约束多样性挑战，我们设计了一个细化存储库，用于收集成功的细化过程并将其用作未来案例的少样本演示，让 LLM 在推理过程中从过去的经验中学习。此外，我们开发了一个新的复杂指令数据集，每个指令包含 1-6 个约束。实验表明，该框架显著提高了性能，使 LLama3.1-8B 对具有 6 个约束的指令的约束遵守率翻了一番。]]></description>
      <guid>https://arxiv.org/abs/2410.12207</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OmnixR：评估全模态语言模型在跨模态推理中的作用</title>
      <link>https://arxiv.org/abs/2410.12219</link>
      <description><![CDATA[arXiv:2410.12219v1 公告类型：新 
摘要：我们介绍了 OmnixR，这是一款评估套件，旨在对 SoTA 全模态语言模型（例如 GPT-4o 和 Gemini）进行基准测试。评估集成了文本、视觉和音频等多种模态的 OLM 带来了独特的挑战。特别是，用户消息可能通常由多种模态组成，因此 OLM 必须建立跨模态的整体理解和推理才能完成任务。现有的基准测试仅限于单模态或双模态任务，忽略了对模型推理的全面多模态评估。为了解决这个问题，OmnixR 提供了两种评估变体：(1) 合成子集：通过将文本转换为多种模态（音频、图像、视频和混合）自动生成的合成数据集（Omnify）。 (2) 现实子集：由专家手动整理和注释的真实世界数据集，用于评估自然环境中的跨模态推理。OmnixR 提供了一种独特的评估方法，用于评估多种模态组合中的 OLM，例如涉及视频、音频和文本的问题，从而提供了与任何现有基准不同的严格跨模态推理测试平台。我们的实验发现，所有最先进的 OLM 都难以回答需要整合多种模态信息才能回答的 OmnixR 问题。进一步的分析突出了推理行为的差异，强调了全模态 AI 对齐的挑战。]]></description>
      <guid>https://arxiv.org/abs/2410.12219</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的通用上下文推理知识图谱基础模型</title>
      <link>https://arxiv.org/abs/2410.12288</link>
      <description><![CDATA[arXiv:2410.12288v1 公告类型：新
摘要：广泛的知识图谱（KG）已被构建以促进各种场景中知识驱动的任务。然而，现有的工作通常为不同的 KG 开发单独的推理模型，缺乏在不同的 KG 和推理设置之间概括和迁移知识的能力。在本文中，我们提出了一种基于提示的 KG 基础模型，通过上下文学习，即 KG-ICL，以实现通用推理能力。具体而言，我们引入了一个以查询相关的示例事实为中心作为上下文的提示图来理解查询关系。为了对具有对查询中看不见的实体和关系的泛化能力的提示图进行编码，我们首先提出一个统一的标记器，将提示图中的实体和关系映射到预定义的标记。然后，我们提出了两个消息传递神经网络来分别执行提示编码和 KG 推理。我们在传导和归纳设置中对 43 个不同的 KG 进行了评估。结果表明，提出的 KG-ICL 在大多数数据集上的表现优于基线，展示了其出色的泛化和通用推理能力。源代码可在 GitHub 上访问：https://github.com/nju-websoft/KG-ICL。]]></description>
      <guid>https://arxiv.org/abs/2410.12288</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>主动代理：将法学硕士代理从被动响应转变为主动协助</title>
      <link>https://arxiv.org/abs/2410.12361</link>
      <description><![CDATA[arXiv:2410.12361v1 公告类型：新
摘要：由大型语言模型驱动的代理在解决复杂任务方面表现出了非凡的能力。然而，大多数代理系统仍然是被动的，这限制了它们在需要预见和自主决策的场景中的有效性。在本文中，我们解决了开发能够在没有明确人工指令的情况下预测和启动任务的主动代理的挑战。我们为这个问题提出了一种新颖的数据驱动方法。首先，我们收集现实世界的人类活动以生成主动任务预测。然后，这些预测被人类注释者标记为接受或拒绝。标记数据用于训练一个奖励模型，该模型模拟人类判断，并作为 LLM 代理主动性的自动评估器。在此基础上，我们开发了一个全面的数据生成管道来创建一个包含 6,790 个事件的多样化数据集 ProactiveBench。最后，我们证明使用提出的 ProactiveBench 对模型进行微调可以显著提高 LLM 代理的主动性。实验结果表明，经过微调的模型在主动提供帮助方面实现了 66.47% 的 F1 得分，优于所有开源和闭源模型。这些结果凸显了我们的方法在创建更主动、更有效的代理系统方面的潜力，为未来人机协作的进步铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.12361</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PRefLexOR：基于偏好的递归语言建模，用于推理和代理思维的探索性优化</title>
      <link>https://arxiv.org/abs/2410.12375</link>
      <description><![CDATA[arXiv:2410.12375v1 公告类型：新
摘要：PRefLexOR（基于偏好的递归语言建模，用于探索性优化推理）将偏好优化与强化学习的概念相结合，使模型能够通过迭代推理改进进行自我学习。我们提出了一种递归学习方法，让模型参与多步推理、重新审视和改进中间步骤，然后在训练和推理阶段产生最终输出。通过多个训练阶段，模型首先通过优化首选和非首选响应之间的对数几率来学习使其推理与准确的决策路径保持一致。在此过程中，PRefLexOR 通过从随机文本块生成问题和检索增强来构建动态知识图谱，以将整个训练语料库中的相关细节情境化。在第二阶段，偏好优化通过使用拒绝抽样来微调推理质量，通过不断生成现场训练数据同时掩盖推理步骤来提高模型性能。思维标记框架内的递归优化引入了迭代反馈循环，模型在其中改进推理，实现更深层次的连贯性、一致性和适应性。在只有 30 亿个参数的小型语言模型中实现，我们应该相信即使是微小的模型也可以迭代地自学以更深入和反射性地推理。我们的实现很简单，可以合并到任何现有的预训练 LLM 中。我们将示例重点放在生物材料科学中的应用上，并在从域内到跨域应用的各种案例研究中展示该方法。使用包括思考和反思模式在内的推理策略，我们构建了一种多智能体递归自我改进推理方法，通过在推理时间内重复采样来连续改进响应。]]></description>
      <guid>https://arxiv.org/abs/2410.12375</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ShapefileGPT：用于自动处理 Shapefile 的多智能体大型语言模型框架</title>
      <link>https://arxiv.org/abs/2410.12376</link>
      <description><![CDATA[arXiv:2410.12376v1 公告类型：新
摘要：矢量数据是地理信息科学 (GIS) 中的两种核心数据结构之一，对于准确存储和表示地理空间信息至关重要。Shapefile 是最广泛使用的矢量数据格式，已成为所有主要地理信息系统支持的行业标准。然而，处理这些数据通常需要专门的 GIS 知识和技能，这为其他领域的研究人员设置了障碍，并阻碍了空间数据分析的跨学科研究。此外，虽然大型语言模型 (LLM) 在自然语言处理和任务自动化方面取得了重大进展，但它们在处理 GIS 矢量数据固有的复杂空间和拓扑关系方面仍然面临挑战。为了应对这些挑战，我们提出了 ShapefileGPT，这是一个由 LLM 驱动的创新框架，专门用于自动化 Shapefile 任务。ShapefileGPT 采用多代理架构，其中规划代理负责任务分解和监督，而工作者代理执行任务。我们开发了专门处理Shapefile的函数库，并提供了完整的API文档，使Worker Agent能够通过函数调用高效地操作Shapefile。在评估方面，我们基于权威教科书开发了基准数据集，涵盖了几何操作、空间查询等类别的任务。ShapefileGPT的任务成功率达到95.24%，优于GPT系列模型。与传统LLM相比，ShapefileGPT能够有效处理复杂的矢量数据分析任务，突破了传统LLM在空间分析方面的局限性。这一突破为GIS领域的自动化和智能化发展开辟了新途径，在跨学科数据分析和应用领域具有巨大的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.12376</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>快速复杂的故事：整数运算的扩展概率推理</title>
      <link>https://arxiv.org/abs/2410.12389</link>
      <description><![CDATA[arXiv:2410.12389v1 公告类型：新
摘要：正如整数线性规划的成功所示，线性整数算术是建模组合问题的强大工具。此外，线性规划的概率扩展已用于制定神经符号 AI 中的问题。然而，仍然存在两个关键问题，阻碍了神经符号技术在玩具问题之外的应用。首先，概率推理本质上很难，准确地说是 #P-hard。其次，整数的离散性质使得构建有意义的梯度具有挑战性，这对学习来说是个问题。为了缓解这些问题，我们将整数值随机变量的线性算术制定为张量操作，可以使用现代深度学习库以简单的方式实现。我们公式的核心是观察结果，即可以通过将快速傅立叶变换调整为对数域中的概率来执行两个整数值随机变量的加法。通过依赖张量运算，我们获得了可微分的数据结构，这几乎可以免费解锁基于梯度的学习。在我们的实验验证中，我们表明，张量化概率线性整数算法并利用快速傅里叶变换使我们能够在推理和学习时间方面将现有技术提高几个数量级。]]></description>
      <guid>https://arxiv.org/abs/2410.12389</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示语言代理在规划中的障碍</title>
      <link>https://arxiv.org/abs/2410.12409</link>
      <description><![CDATA[arXiv:2410.12409v1 公告类型：新
摘要：自人工智能诞生以来，自主规划一直是一项持续的追求。基于精心策划的问题求解器，早期的规划代理可以为特定任务提供精确的解决方案，但缺乏泛化能力。大型语言模型 (LLM) 的出现及其强大的推理能力通过自动为给定任务生成合理的解决方案重新点燃了人们对自主规划的兴趣。然而，先前的研究和我们的实验表明，当前的语言代理仍然缺乏人类水平的规划能力。即使是最先进的推理模型 OpenAI o1，在复杂的现实世界规划基准之一上也只达到了 15.6%。这突出了一个关键问题：是什么阻碍了语言代理实现人类水平的规划？虽然现有研究强调了代理规划中的薄弱表现，但更深层次的根本问题以及为解决这些问题而提出的策略的机制和局限性仍未得到充分理解。在这项研究中，我们应用了特征归因研究，并确定了阻碍代理规划的两个关键因素：约束的作用有限和问题的影响逐渐减弱。我们还发现，尽管当前的策略有助于缓解这些挑战，但并不能完全解决这些问题，这表明代理在达到人类水平的智能之前还有很长的路要走。]]></description>
      <guid>https://arxiv.org/abs/2410.12409</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对可废止推理进行基准测试——初步实验和未来方向</title>
      <link>https://arxiv.org/abs/2410.12509</link>
      <description><![CDATA[arXiv:2410.12509v1 公告类型：新
摘要：大型语言模型 (LLM) 因其出色的性能而在 AI 领域占据了重要地位。因此，更好地了解它们的能力和局限性（其中包括非单调推理方面）至关重要。本文提出了一个与各种可废止规则推理模式相对应的基准。我们通过将可废止规则转换为适合 LLM 的文本，修改了现有的可废止逻辑推理器基准。我们使用 ChatGPT 对非单调规则推理进行了初步实验，并将其与可废止逻辑定义的推理模式进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2410.12509</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体序贯决策中的反事实效应分解</title>
      <link>https://arxiv.org/abs/2410.12539</link>
      <description><![CDATA[arXiv:2410.12539v1 公告类型：新
摘要：我们解决了解释多智能体马尔可夫决策过程中反事实结果的挑战。具体来说，我们旨在通过智能体的行为对环境动态和智能体行为的影响来解释其对已实现场景结果的总体反事实影响。为了实现这一点，我们引入了一种新颖的因果解释公式，该公式通过将反映其对影响的各自贡献的分数归因于每个智能体和状态变量来分解反事实效应。首先，我们表明，智能体行为的总体反事实效应可以分解为两个部分：一个部分衡量通过所有后续智能体行为传播的影响，另一个部分与通过状态转换传播的影响有关。基于因果贡献分析的最新进展，我们进一步分解这两个影响如下。对于前者，我们考虑特定于代理的效应——一种因果概念，它量化了代理行为在代理子集中传播的反事实效应。基于这一概念，我们使用 Shapley 值将效应归因于单个代理。对于后者，我们考虑结构保留干预的概念，并根据状态变量的“内在”贡献将效应归因于状态变量。通过大量实验，我们证明了我们的分解方法在具有 LLM 辅助代理和败血症管理模拟器的 Gridworld 环境中的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2410.12539</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的道德价值观：价值分类的神经符号方法</title>
      <link>https://arxiv.org/abs/2410.12631</link>
      <description><![CDATA[arXiv:2410.12631v1 公告类型：新
摘要：这项工作探索了基于本体的推理和机器学习技术的集成，以实现可解释的价值分类。通过依赖道德基础理论中的道德价值观的本体形式化，依赖 DnS 本体设计模式，\textit{sandra} 神经符号推理器用于推断某个句子\emph{满足} 的值（形式化为描述）。句子及其结构化表示是使用开源大型语言模型自动生成的。推断出的描述用于自动检测与句子相关的值。我们表明，仅依靠推理器的推理就能产生可解释的分类，这与其他更复杂的方法相当。我们表明，将推理器的推理与分布式语义方法相结合，在很大程度上优于所有基线，包括基于神经网络架构的复杂模型。最后，我们构建了一个可视化工具来探索基于理论的价值分类的潜力，该工具可在http://xmv.geomeaning.com/上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2410.12631</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>JudgeBench：评估法学硕士法官的基准</title>
      <link>https://arxiv.org/abs/2410.12784</link>
      <description><![CDATA[arXiv:2410.12784v1 公告类型：新
摘要：基于 LLM 的评判员已成为人类评估的可扩展替代方案，并越来越多地用于评估、比较和改进模型。然而，基于 LLM 的评判员本身的可靠性很少受到审查。随着 LLM 变得越来越先进，他们的反应也变得越来越复杂，需要更强大的评判员来评估它们。现有的基准主要关注评判员与人类偏好的一致性，但往往无法解释更具挑战性的任务，在这些任务中，众包的人类偏好无法很好地反映事实和逻辑的正确性。为了解决这个问题，我们提出了一个新颖的评估框架来客观地评估基于 LLM 的评判员。基于这个框架，我们提出了 JudgeBench，这是一个用于评估基于 LLM 的评判员在知识、推理、数学和编码方面的具有挑战性的响应对上的基准。JudgeBench 利用一种新颖的管道将现有的困难数据集转换为具有挑战性的响应对，其偏好标签反映了客观正确性。我们对一系列提示性评判、微调评判、多智能体评判和奖励模型进行了全面评估，结果表明 JudgeBench 的挑战性远高于之前的基准，许多强大的模型（例如 GPT-4o）的表现仅略优于随机猜测。总体而言，JudgeBench 为评估日益先进的 LLM 评判提供了一个可靠的平台。数据和代码可在 https://github.com/ScalerLab/JudgeBench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.12784</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OD-Stega：基于 LLM 的、通过优化分布实现的近乎不可察觉的隐写术</title>
      <link>https://arxiv.org/abs/2410.04328</link>
      <description><![CDATA[arXiv:2410.04328v1 公告类型：交叉 
摘要：我们考虑无封面隐写术，其中大型语言模型 (LLM) 驱动算术编码解码器生成隐写文本。一种有效的方法应该将秘密消息位嵌入尽可能少的语言标记中，同时仍保持隐写文本的自然和流畅。我们表明，在单个标记级别上，这个问题在数学上等同于最大化下一个标记生成的替换概率分布的熵，但要受到所选概率分布与 LLM 给出的原始分布之间的 KL 散度的约束。为优化问题提供了一个闭式解，可以高效计算。还解决了几个重要的实际问题：1）通过简单的提示选择方法解决经常被忽视的标记不匹配问题，2）考虑优化分布和词汇截断技术的组合，3）研究优化分布与其他序列级选择启发式方法的组合，以进一步提高效率和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2410.04328</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于操作足迹的法学硕士融合架构调查与评估</title>
      <link>https://arxiv.org/abs/2410.11381</link>
      <description><![CDATA[arXiv:2410.11381v1 公告类型：交叉 
摘要：Attention 机制和 Transformer 架构的出现实现了上下文自然的文本生成，并将处理整个源信息压缩为奇异向量的负担。基于这两个主要思想，模型大小逐渐增加以容纳更精确和全面的信息，导致当前最先进的 LLM 非常大，参数约为 700 亿。随着模型大小的增长，对大量存储和计算能力的需求也在增加。这导致了高带宽内存和加速器的发展，以及为满足这些要求而设计的各种模型架构。我们注意到 LLM 架构越来越趋同。本文分析了这些融合架构在层配置、操作机制和模型大小方面的表现，并考虑了各种超参数设置。在本文中，我们通过追踪 LLM 操作改进的演变，对其历史进行了简要的概述。此外，我们总结了使用 RTX 6000（采用最先进的 Ada Lovelace 架构）在不同超参数设置下 LLM 的性能趋势。我们得出结论，即使是同一个模型，也会根据超参数或部署在服务器或边缘环境中而表现出不同的行为。]]></description>
      <guid>https://arxiv.org/abs/2410.11381</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从命令到提示：基于 LLM 的 AIOS 语义文件系统</title>
      <link>https://arxiv.org/abs/2410.11843</link>
      <description><![CDATA[arXiv:2410.11843v1 公告类型：交叉 
摘要：大型语言模型（LLM）在开发智能应用程序和系统（例如基于LLM的代理和代理操作系统（AIOS））方面表现出巨大潜力。但是，当这些应用程序和系统与底层文件系统交互时，文件系统仍然是传统范式：依赖于通过精确命令进行手动导航。这种范式对这些系统的可用性构成了瓶颈，因为用户需要浏览复杂的文件夹层次结构并记住神秘的文件名。为了解决这一限制，我们提出了一种基于LLM的语义文件系统（LSFS），用于提示驱动的文件管理。与传统方法不同，LSFS结合了LLM，使用户或代理能够通过自然语言提示与文件交互，从而促进语义文件管理。在宏观层面，我们开发了一套全面的API来实现语义文件管理功能，例如语义文件检索、文件更新监控和摘要以及语义文件回滚）。在微观层面，我们通过为文件构建语义索引来存储文件，并设计和实现基于向量数据库的各种语义操作（例如 CRUD、group by、join）的系统调用。我们的实验表明，LSFS 在用户便利性、支持功能的多样性以及文件操作的准确性和效率方面比传统文件系统有显著的改进。此外，通过集成 LLM，我们的系统可以实现更智能的文件管理任务，例如内容摘要和版本比较，从而进一步增强其功能。]]></description>
      <guid>https://arxiv.org/abs/2410.11843</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>