<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 27 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>提高肝病临床试验效率：安全，大型语言模型的预筛查管道</title>
      <link>https://arxiv.org/abs/2502.18531</link>
      <description><![CDATA[ARXIV：2502.18531V1公告类型：新 
摘要：背景：涉及复杂肝疾病的队列招募，例如肝细胞癌和肝肝硬化，通常需要解释语义上复杂的标准。传统的手动筛选方法是耗时的，容易出现错误。尽管AI驱动的预筛查提供了潜在的解决方案，但在准确性，效率和数据隐私方面仍然存在挑战。方法：我们开发了一种新型的患者预筛查管道，该管道利用临床专业知识来指导大型语言模型的精确，安全和有效的应用。该管道将​​复杂的标准分解为一系列复合问题，然后采用两种策略来通过电子健康记录执行语义问题 - （1）途径A，拟人化专家的思想策略链的链条，（2）Pathway B，Pathway B，Prepet b，PrestEt the PresteT Stances in e Agent Agent策略中，尤其是在管理复杂的临床原因方面，尤其是在管理复杂的临床原因方面。在问题和标准级别上，对三个关键指标过度，时间消耗和反事实推断进行了评估。结果：我们的管道达到了高精度（标准水平为0.921）和效率（每个任务为0.44）。途径B在复杂的推理方面表现出色，而途径A则可以随着更快的处理时间有效地提取数据提取。两种途径都达到了可比的精度。该管道在肝细胞癌（0.878）和肝硬化试验（0.843）中显示出令人鼓舞的结果。结论：该数据安全和耗时的管道在肝病试验中显示出很高的精度，为简化临床试验工作流程提供了有希望的解决方案。它的效率和适应性使其适合改善患者招聘。其在资源受限环境中运行的能力进一步增强了其在临床环境中的效用。]]></description>
      <guid>https://arxiv.org/abs/2502.18531</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CUDIP：通过基于课程学习的直接偏好优化在LLM中增强定理证明定理</title>
      <link>https://arxiv.org/abs/2502.18532</link>
      <description><![CDATA[ARXIV：2502.18532V1公告类型：新 
摘要：自动定理证明（ATP）是大语言模型（LLMS）最具挑战性的数学推理任务之一。大多数现有的基于LLM的ATP方法都依赖于监督的微调，这导致定理证明过程与人类偏好之间的一致性有限。将LLM与人类偏好保持一致的直接偏好优化（DPO）对某些任务显示了积极影响。但是，缺乏针对定理的高质量偏好数据证明带来了重大挑战。在本文中，我们对正式的自动定理进行了创新的DPO证明，并介绍了基于课程学习的DPO迭代定理证明（CUDIP）方法。具体而言，我们提出了一种构建偏好数据的方法，该方法利用LLM和现有定理证明数据来增强偏好数据的多样性，同时减少对人类偏好注释的依赖。然后，我们将这种偏好数据构建方法与课程学习整合在一起，以通过DPO迭代地调整定理模型。 MiniF2F和验证数据集的实验结果证明了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.18532</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动化知识成分生成和知识跟踪编码问题</title>
      <link>https://arxiv.org/abs/2502.18632</link>
      <description><![CDATA[ARXIV：2502.18632V1公告类型：新 
摘要：映射到问题的知识组成部分（KCS）有助于建模学生学习，跟踪他们在细粒技能上的精通水平，从而促进在线学习平台中的个性化学习和反馈。但是，传统上由人类领域专家执行的问题和标记为问题，这是高度劳动力密集的。我们提出了一条完全自动化的，基于LLM的管道，用于KC生成，并标记开放式编程问题。我们还开发了一个基于LLM的知识跟踪（KT）框架来利用这些LLM生成的KCS，我们称为KCGEN-KT。我们进行了广泛的定量和定性评估，以验证KCGEN-KT的有效性。在针对开放式编程问题的学生代码提交的实际数据集中，KCGEN-KT优于现有的KT方法。我们研究了生成的KCS的学习曲线，并表明LLM生成的KC在绩效因子分析（PFA）模型下具有与人写的KC相当的拟合水平。我们还进行了人类评估，以表明与人类领域专家相比，我们的管道的KC标记准确性相当准确。]]></description>
      <guid>https://arxiv.org/abs/2502.18632</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>独立移动性GPT（IDM-GPT）：使用机器学习模型的自定义交通移动性分析的自我监督的大型语言模型框架</title>
      <link>https://arxiv.org/abs/2502.18652</link>
      <description><![CDATA[ARXIV：2502.18652V1公告类型：新 
摘要：随着城市化过程，运输系统中正在部署越来越多的传感器，从而导致大数据爆炸。为了利用这些庞大的运输数据的力量，已经引入了各种机器学习（ML）和人工智能（AI）方法，以应对众多运输挑战。但是，这些方法通常需要在数据收集，处理，存储以及具有运输和ML专业知识的专业人士的就业方面进行大量投资。此外，在处理现实世界流量控制和管理数据时，隐私问题是一个主要问题。为了应对这些挑战，研究团队提出了一个创新的多项式框架，该框架基于大型语言模型（LLMS），用于定制的流量分析，管理建议和隐私保护。 IDM-GPT有效地连接用户，运输数据库和ML模型。 IDM-GPT列车，自定义并应用了各种基于LLM的AI代理，用于多种功能，包括用户查询理解，提示优化，数据分析，模型选择以及绩效评估和增强。借助IDM-GPT，没有任何运输或ML背景的用户可以根据问题有效，直观地获得数据分析和定制建议。实验结果表明，IDM-GPT在多个与交通相关的任务中提供令人满意的性能，从而提供全面且可行的见解，以支持有效的交通管理和城市移动性的改善。]]></description>
      <guid>https://arxiv.org/abs/2502.18652</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>说正确的语言：专业知识对齐在用户-AI交互中的影响</title>
      <link>https://arxiv.org/abs/2502.18685</link>
      <description><![CDATA[ARXIV：2502.18685V1公告类型：新 
摘要：使用25,000个Bing Copilot对话的样本，我们研究代理如何响应不同级别的域专业知识的用户以及沿多个维度对用户体验的影响。我们的发现表明，在各种局部领域中，代理商在很大程度上以熟练或专家的专业水平（占对话的77％）做出反应，这与积极的用户体验相关，无论用户的专业水平如何。未对准的代理商以低于用户的专业知识的水平做出反应，对整体用户体验产生了负面影响，对更复杂的任务的影响更大。我们还表明，当代理商以与用户相称的专业知识响应时，用户可以更多地参与对话中的单词数量。我们的发现强调了用户和AI在设计以人为本的AI系统时对齐的重要性，以确保令人满意和富有成效的互动。]]></description>
      <guid>https://arxiv.org/abs/2502.18685</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>角色扮演游戏中基于混合投票的任务分配</title>
      <link>https://arxiv.org/abs/2502.18690</link>
      <description><![CDATA[ARXIV：2502.18690V1公告类型：新 
摘要：在角色扮演游戏（RPG）中，沉浸式的水平至关重要 - 尤其是当游戏中的代理商将任务，提示或想法传达给玩家时。为了使代理准确解释玩家的情绪状态和上下文细微差别，需要使用大型语言模型（LLM）来实现基础的理解水平。但是，在多个上下文更改中保持LLM的重点，因此需要采取更强大的方法，例如将LLM与专用任务分配模型集成在一起，以指导其整个游戏的性能。为了应对这种需求，我们介绍了基于投票的任务分配（VBTA），该框架灵感来自于人类的任务分配和完成中的推理。 VBTA将功能配置文件和任务描述分配给任务，然后生成一个适合性矩阵，该矩阵量化了代理能力和任务要求之间的一致性。利用六种不同的投票方法，一种预先培训的LLM并集成基于冲突的搜索（CBS）进行路径计划，VBTA有效地识别并为每个任务分配了最合适的代理。尽管现有的方法着重于生成游戏玩法的各个方面，例如单个任务或战斗相遇，但由于其可推广的性质，我们的方法在产生独特的战斗相遇和叙事时会显示出希望。]]></description>
      <guid>https://arxiv.org/abs/2502.18690</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>trajllm：一个模块化LLM增强代理的基于现实的人类轨迹模拟的框架</title>
      <link>https://arxiv.org/abs/2502.18712</link>
      <description><![CDATA[ARXIV：2502.18712V1公告类型：新 
摘要：这项工作利用大型语言模型（LLMS）模拟人类的流动性，应对传统模型中的高成本和隐私问题等挑战。我们的分层框架使用现实世界中的人口统计学和心理数据来整合角色生成，活动选择和目的地预测，以创建现实的运动模式。物理模型和语言模型均被用于探索和演示人类移动模拟的不同方法。通过用汇总和加权密度指标构建数据，该系统可确保可扩展的内存管理，同时保留可行的见解。初步结果表明，LLM驱动的模拟与观察到的现实世界模式保持一致，为城市规划，交通管理和公共卫生等社会问题提供可扩展，可解释的见解。该框架动态生成角色和活动的能力使其能够提供适应性和现实的日常工作。这项研究证明了LLM在推进社会和城市应用的流动性建模方面的变革潜力。我们的框架的源代码和交互式演示可在https://github.com/cju0/trajllm上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.18712</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与大脑交谈：使用大型语言模型作为代理来建模大脑语义表示</title>
      <link>https://arxiv.org/abs/2502.18725</link>
      <description><![CDATA[ARXIV：2502.18725V1公告类型：新 
摘要：使用自然主义刺激的传统心理实验在手动注释和生态有效性中面临挑战。为了解决这个问题，我们引入了一种新颖的范式，利用多模式大语模型（LLMS）作为代理，通过视觉问题答案（VQA）策略从自然主义图像中提取丰富的语义信息，以分析人类的视觉语义表示。 LLM衍生的表示成功地预测了通过fMRI（例如面部，建筑物）衡量的确定的神经活动模式，从而验证了其可行性并揭示了整个皮质区域的分层语义组织。由LLM衍生表示构建的大脑语义网络标识了有意义的群集，反映了功能和上下文关联。这种创新的方法论为通过自然主义刺激，克服传统注释方法的局限性调查大脑语义组织提供了一种强大的解决方案，并为对人类认知的更生态有效探索铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.18725</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>像父亲一样，像儿子一样：亲属意识偏好映射（业力），以自动对齐大语模型</title>
      <link>https://arxiv.org/abs/2502.18744</link>
      <description><![CDATA[ARXIV：2502.18744V1公告类型：新 
摘要：大语言模型（LLM）一致性的最新进展已通过利用预告片的模型生成偏好数据来减轻人类注释的成本。但是，现有方法通常会比较具有实质不同功能的模型的响应，从而产生了表面的区别，这些区别无法就构成较高响应的内容提供有意义的指导。为了解决这一限制，我们提出了亲属感知的偏好映射（业力），这是一个新颖的框架，该框架从具有可比的能力的模型中系统地配对了响应。通过将偏好比较与类似复杂性和质量的输出进行限制，业力增强了偏好数据的信息，并提高了对齐信号的粒度。经验评估表明，我们的亲属感知方法会导致更加一致和可解释的结果，最终促进了将LLM行为与人类偏好保持一致的更有原则和可靠的途径。]]></description>
      <guid>https://arxiv.org/abs/2502.18744</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过知识图遍历和去除冗余的整体审核数据集生成LLM学习</title>
      <link>https://arxiv.org/abs/2502.18810</link>
      <description><![CDATA[ARXIV：2502.18810V1公告类型：新 
摘要：近年来，大型语言模型（LLMS）面临着越来越多的需求，可以选择性地删除敏感信息，保护隐私并通过未学习，通过机器学习来遵守版权法规。虽然评估学习效率至关重要，但现有基准的规模和全面性有限，通常仅包含几百个测试案例。我们确定了生成整体审核数据集的两个关键挑战：确保审核充足性并处理忘记和保留数据集之间的知识冗余。为了应对这些挑战，我们建议汉克（Hanker），这是一个自动化审计数据集生成的自动框架，利用知识图来实现细粒度的覆盖范围并消除冗余知识。将汉克（Hanker）应用于受欢迎的Muse Benchmark，分别为新闻和书籍数据集生成了超过69,000和111,000个审计案例，确定了成千上万的知识记忆实例，以前的基准测试实例未能检测到。我们的经验分析发现，知识冗余如何显着偏向学习效率指标，冗余实例人为地将观察到的记忆测量结果从19.7％到26.1％，并从32.4％到35.2％，从而强调了准确的重复评估的必要性。]]></description>
      <guid>https://arxiv.org/abs/2502.18810</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用LLM的数据有效的多代理空间计划</title>
      <link>https://arxiv.org/abs/2502.18822</link>
      <description><![CDATA[Arxiv：2502.18822V1公告类型：新 
摘要：在这个项目中，我们的目标是确定如何利用经过验证的大语言模型的世界知识，以在多基金会决策中进行有效而健壮的学习。我们在出租车路由和任务问题中进行了研究，代理必须决定如何最好地接乘客，以最大程度地减少总体等待时间。尽管此问题位于图形道路网络上，但我们表明，在适当的提示零射击性能上，这项任务非常强大。此外，通过有限的微调以及一次性的推出算法，LLM可以以少50倍的环境相互作用来超越现有方法。我们还探讨了各种语言提示方法的好处，并表明在及时及时包括某些易于计算的信息可以显着提高性能。最后，我们重点介绍了LLM的内置语义理解，显示了它通过简单提示适应环境因素的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.18822</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>领域基础：LLM和多代理系统的现实世界计划基准</title>
      <link>https://arxiv.org/abs/2502.18836</link>
      <description><![CDATA[ARXIV：2502.18836V1公告类型：新 
摘要：此基准套件提供了一个全面的评估框架，用于评估现实世界计划场景中的单个LLM和多代理系统。该套件涵盖了11个设计的问题，这些问题从基本到高度复杂，结合了关键方面，例如多代理协调，代理间的依赖和动态环境中断。每个问题都可以沿三个维度缩放：并行计划线程的数量，相互依存关系的复杂性以及需要实时适应的意外中断的频率。基准包括使用Langgraph等当代框架的详细规范，评估指标和基线实现，从而可以对单机构和多代理计划功能进行严格的测试。通过标准化的评估标准和可扩展的复杂性，该基准旨在推动为真实应用程序开发更健壮和适应性的AI计划系统的进步。]]></description>
      <guid>https://arxiv.org/abs/2502.18836</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>智能测试</title>
      <link>https://arxiv.org/abs/2502.18858</link>
      <description><![CDATA[ARXIV：2502.18858V1公告类型：新 
摘要：情报如何出现？我们建议智力不是突然的礼物或随机发生，而是物种通过自然选择生存的必要特征。如果一个物种通过自然选择的测试，则证明了在自然界生存的智力。扩展了这一观点，我们引入了情报测试，这是一种量化任何任务上任何主题的智能的方法。就像物种通过反复试验演变一样，智能测试通过在成功前的失败尝试数量量化智力。较少的失败对应于更高的智能。当失败计数的期望和差异都是有限的时，它标志着实现了自主智能水平的实现。使用智能测试，我们全面评估了现有的AI系统。我们的结果表明，尽管AI系统在简单任务中达到了一定的自主权，但在更复杂的任务（例如视觉，搜索，建议和语言）中，它们仍然远非自主。虽然缩放模型的大小可能有帮助，但这将以天文成本产生。预测表明，实现一般自主权将需要难以想象的$ 10^{26} $参数。即使摩尔的法律不断成立，这种参数量表也将花费70美元。这种惊人的成本突出了人类任务的复杂性和当前AI的不足。为了进一步了解这一现象，我们进行了理论分析。我们的模拟表明人类任务具有关键性能。结果，自治需要对任务的基本机制有深入的了解。但是，当前的AI并未完全掌握这些机制，而是依赖于表面模仿，因此很难达到自主水平。我们认为，情报测试不仅可以指导AI的未来发展，而且还可以深入了解人类的智慧。]]></description>
      <guid>https://arxiv.org/abs/2502.18858</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向AI共同科学家</title>
      <link>https://arxiv.org/abs/2502.18864</link>
      <description><![CDATA[ARXIV：2502.18864V1公告类型：新 
摘要：科学发现依赖于科学家产生了经过严格实验验证的新假设。为了增加此过程，我们引入了AI共同科学家，这是一种基于Gemini 2.0的多代理系统。 AI共同科学家旨在帮助揭示新的原始知识，并在先前的证据基础上提出新颖的研究假设和建议，并与科学家提供的研究目标和指导保持一致。该系统的设计结合了受科学方法的启发，并通过缩放测试时间计算加速了假设产生的生成，辩论和进化方法。主要贡献包括：（1）具有异步任务执行框架的多代理体系结构，用于灵活的计算缩放； （2）自我提出假设产生的比赛进化过程。自动化评估显示测试时间计算的持续好处，改善了假设质量。虽然通用目的，但我们集中于三个生物医学领域的开发和验证：药物重新利用，新的靶标发现以及解释细菌进化和抗微生物抗性的机制。为了重新利用药物，该系统提出了具有有前途的验证结果的候选者，包括急性髓样白血病的候选者，这些候选在临床适用浓度下在体外显示肿瘤抑制。对于新的靶标发现，AI共同科学家提出了用于肝纤维化的新表观遗传靶标，并通过人肝癌的抗纤维化活性和肝细胞再生进行了验证。最后，AI共同科学家通过在细菌进化中发现了新型基因转移机制的硅酸盐发现，从而概括了未发表的实验结果。这些结果在单独的，合时的报告中详细介绍了增强生物医学和科学发现的潜力，并引入了AI授权科学家的时代。]]></description>
      <guid>https://arxiv.org/abs/2502.18864</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多LLLM协作搜索复杂的问题解决</title>
      <link>https://arxiv.org/abs/2502.18873</link>
      <description><![CDATA[ARXIV：2502.18873V1公告类型：新 
摘要：大型语言模型（LLMS）经常在复杂的推理任务中挣扎，因为它们在解决了自然语言的巨大推理空间和固有的歧义方面的局限性。我们提出了搜索代理（MOSA）范式的混合物，这是一种新型方法，利用了多个LLM的集体专业知识来增强基于搜索的推理。 MOSA通过将独立探索与LLM之间的迭代改进相结合，整合了多种推理途径，从而减轻了单模方法的局限性。 MOSA将MOSA使用Monte Carlo Tree搜索（MCT）作为主链，使多个代理能够提出和汇总推理步骤，从而提高了精度。我们对四个推理基准测试的全面评估表明，MOSA对单一代理和其他多机构基准的绩效持续改进，尤其是在复杂的数学和常识性推理任务中。]]></description>
      <guid>https://arxiv.org/abs/2502.18873</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>像管道和仪器图（P＆ID）这样说话</title>
      <link>https://arxiv.org/abs/2502.18928</link>
      <description><![CDATA[ARXIV：2502.18928V1公告类型：新 
摘要：我们提出了一种方法，该方法允许使用自然语言与管道和仪器图（P＆amp; ids）进行通信。特别是，我们通过DEXPI数据模型代表p＆amp; ids标记为属性图，并将其与大语言模型（LLMS）集成在一起。该方法由三个主要部分组成：1）p＆amp; id使用我们的pydexpi python软件包将dexpi格式的图表施放到图表中。 2）一种从PYDEXPI生成P＆amp; ID知识图的工具。 3）使用基于图的检索增强生成（Graph-rag）将P＆amp; ID知识图集成到LLMS。这种方法使用户可以使用自然语言与P＆amp; ID进行通信。它扩展了LLM从P＆amp; IDS和减轻幻觉中检索上下文数据的能力。该模型利用LLM的大型语料库，也能够解释PID中的过程信息，这可以帮助工程师完成日常任务。将来，这项工作还将在其他有关P＆amp; ID和AI-HAZOP研究的生成人工智能（Genai）解决方案的背景下开放机会。]]></description>
      <guid>https://arxiv.org/abs/2502.18928</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>处理有关知识图的推理的不一致性：一项调查</title>
      <link>https://arxiv.org/abs/2502.19023</link>
      <description><![CDATA[ARXIV：2502.19023V1公告类型：新 
摘要：在知识图（kgs）中，数据通常由特定本体论来定义，推理是执行一系列任务的必要条件，例如检索信息，问题答案和新知识的推导。但是，通常从自然语言资源自动提取（半）的信息，或通过集成遵循不同语义模式的数据集，从而导致KG不一致。但是，这阻碍了推理的过程。在这项调查中，我们专注于如何通过对三个互补方向进行艺术状态分析艺术的状态来对不一致的kg进行推理：a）检测导致不一致的kg部分的部分，b）固定不一致的kg以使其保持一致，以及c）c）不一致的理由。我们从一系列相关领域讨论了现有的工作，这些领域的重点是如何以及它们与上述方向相关的情况。我们还强调了持续的挑战和未来的方向。]]></description>
      <guid>https://arxiv.org/abs/2502.19023</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Nexus：复杂任务自动化的轻巧且可扩展的多代理框架</title>
      <link>https://arxiv.org/abs/2502.19091</link>
      <description><![CDATA[ARXIV：2502.19091V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展具有实质性发展的多代理系统（质量）功能，使能够自动化任务，而且可以利用近人类的推理能力。为了实现这一目标，需要围绕两个关键原则建立基于LLM的质量：（i）一个强大的体系结构，该体系结构完全利用LLM的特定任务（或相关任务集）的潜力 - 以及（$ ii $）一种有效的方法，用于将LLMS配备有必要的功能来执行任务并有效地管理信息。不用说，先验的架构设计可以限制给定MAS的可扩展性和域的适应性。
  为了应对这些挑战，在本文中，我们介绍了Nexus：一个轻巧的Python框架，旨在轻松构建和管理基于LLM的质量。 Nexus介绍了以下创新：（i）灵活的多探测器层次结构，（ii）简化的工作流程设计，以及（iii）易于安装和开源灵活性：可以通过PIP安装Nexus，并通过PIP安装，并在宽松的开放式载体许可下分布，从而使用户可以自由修改和扩展其能力。
  实验结果表明，以Nexus为基础建造的架构在各种领域都表现出最先进的性能。在编码任务中，Nexus驱动的质量对人类事件的通过率达到99％，而Verilogeval-Human的100％的通行率超过了尖端的推理语言模型，例如O3-Mini和DeepSeek-R1。此外，这些体系结构在复杂的推理和数学问题解决方面表现出良好的熟练程度，从而为从数学数据集中的所有随机选择问题实现了正确的解决方案。在多目标优化的领域中，基于Nexus的架构成功地解决了VTR基准套件的设计上的挑战性时机封闭任务，同时平均保证了节省近30％的动力。]]></description>
      <guid>https://arxiv.org/abs/2502.19091</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过LLM辅助知识库管理为多代理系统的时间计划框架</title>
      <link>https://arxiv.org/abs/2502.19135</link>
      <description><![CDATA[ARXIV：2502.19135V1公告类型：新 
摘要：本文介绍了一个新颖的框架，称为Plantor（使用自然语言为任务的机器人进行计划），该框架将大型语言模型（LLMS）与基于原始的知识管理和多机器人任务的计划集成在一起。该系统采用了面向机器人的知识库的两阶段生成，确保可重复性和组成推理以及三步计划程序，通过混合智能线性编程来处理时间依赖，资源约束和并行任务执行。最终计划将转换为行为树，以直接在ROS2中使用。我们测试了一个块世界中多机器人组装任务和拱形构建方案中的框架。结果表明，LLM可以以适中的人为反馈产生准确的知识库，而Prolog可以保证正式的正确性和解释性。这种方法强调了LLM集成在需要灵活，可扩展和人类可行计划的高级机器人技术任务中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.19135</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多代理安全税：交易多代理系统中的安全性和协作功能</title>
      <link>https://arxiv.org/abs/2502.19145</link>
      <description><![CDATA[ARXIV：2502.19145V1公告类型：新 
摘要：随着AI代理人越来越多地采用用于复杂目标的协作，确保自主多代理系统的安全变得至关重要。我们开发了对共同目标合作的代理商进行模拟，以研究这些安全风险和安全权衡。我们专注于攻击者妥协的方案，使用它来引导整个系统通过破坏其他代理来使整个系统转向未对准的结果。在这种情况下，我们观察到传染性的恶意提示 - 恶意说明的多跳传播。为了减轻这种风险，我们评估了几种策略：两种“疫苗接种”方法，这些方法将安全处理恶意输入的错误记忆插入代理的内存流中，以及两个通用安全指导策略的版本。尽管这些防御能力减少了我们实验中恶意指示的传播和实现，但它们倾向于降低代理网络中的协作能力。我们的发现说明了多代理系统的安全性与协作效率之间的潜在权衡，从而提供了设计更安全而有效的AI协作的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.19145</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>