<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于概率风险评估的美国核电站关闭启动事件分类的知识型大型语言模型框架</title>
      <link>https://arxiv.org/abs/2410.00929</link>
      <description><![CDATA[arXiv:2410.00929v1 公告类型：新
摘要：识别和分类停机起始事件 (SDIE) 对于开发核电站低功率停机概率风险评估至关重要。现有的计算方法由于缺乏大型标记数据集、事件类型不平衡以及标签噪声等挑战而无法实现令人满意的性能。为了应对这些挑战，我们提出了一种混合流程，该流程集成了知识型机器学习模式来预筛选非 SDIE，以及大型语言模型 (LLM) 将 SDIE 分为四类。在预筛选阶段，我们提出了一组 44 个 SDIE 文本模式，这些模式由六种 SDIE 类型中最突出的关键字和短语组成。基于 SDIE 模式的文本矢量化通过使用简单的二元分类器生成高度可分离的特征向量。第二阶段构建基于 Transformer 的双向编码器表征 (BERT) 的 LLM，该 LLM 通过对大型数据集进行自监督预训练来学习通用英语语言表征，并通过在 SDIE 数据集上对其进行微调来适应 SDIE 分类。使用精度、召回率、F1 分数和平均准确率在包含 10,928 个事件的数据集上评估了所提出的方法。结果表明，预筛选阶段可以排除 97% 以上的非 SDIE，LLM 对 SDIE 分类的平均准确率达到 93.4%。]]></description>
      <guid>https://arxiv.org/abs/2410.00929</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RATIONALYST：用于提高推理能力的预训练过程监督</title>
      <link>https://arxiv.org/abs/2410.01044</link>
      <description><![CDATA[arXiv:2410.01044v1 公告类型：新
摘要：LLM 生成的推理步骤可能不完整，因为它们模仿了日常交流中常见的逻辑跳跃，这些跳跃在预训练数据中可以发现：底层原理经常是隐含的（未说明的）。为了应对这一挑战，我们引入了 RATIONALYST，这是一种基于对从未标记数据中提取的大量原理注释进行预训练的推理过程监督模型。我们从网络规模的未标记数据集（Pile）和推理数据集组合中提取了 79k 个原理，几乎无需人工干预。这种网络规模的推理预训练使 RATIONALYST 能够在各种推理任务中一致地进行概括，包括数学、常识、科学和逻辑推理。从 LLaMa-3-8B 微调后，RATIONALYST 在 7 个代表性推理基准上将推理准确率平均提高了 3.9%。与 GPT-4 等明显更大的验证器以及在匹配训练集上进行微调的类似大小的模型相比，它还表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.01044</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>真相还是谎言？贝叶斯解码游戏增强了一致性和可靠性</title>
      <link>https://arxiv.org/abs/2410.01064</link>
      <description><![CDATA[arXiv:2410.01064v1 公告类型：新 
摘要：大型语言模型 (LLM) 产生的输出虽然看似合理，但往往缺乏一致性和可靠性，尤其是在模棱两可或复杂的情况下。挑战在于确保输出符合事实正确性和人类意图。这在现有方法中是有问题的，因为现有方法以较低的准确性换取了一致性的提高。为了缓解这些挑战，我们提出了一种新颖的博弈论方法来增强 LLM 输出生成解码阶段的一致性和可靠性。我们的方法将解码过程建模为多阶段贝叶斯解码游戏。这通过正确性对齐确保一致性，并通过歧义性校准提高可靠性。该模型动态收敛到最可靠输出的共识，并区分 {Valid, Specious} 输出，无需人工反馈或额外训练。我们的游戏设计允许较小的模型通过游戏机制（例如 78.1 LLaMA13B 对 76.6 PaLM540B）胜过较大的模型，并整合各种 LL 策略和模型，展示了博弈论工具在提高 LLM 真实性和可靠性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.01064</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建筑行业的生成式人工智能应用</title>
      <link>https://arxiv.org/abs/2410.01098</link>
      <description><![CDATA[arXiv:2410.01098v1 公告类型：新
摘要：本文探讨了生成式 AI 技术，特别是大型语言模型 (LLM) 在建筑行业的变革潜力。通过利用这些先进的 AI 工具，该研究探索了它们在能源法规合规性、建筑设计优化和劳动力培训等关键领域的应用。该研究强调了 LLM 如何自动化劳动密集型流程，从而显著提高建筑实践的效率、准确性和安全性。本文还解决了解释建筑规划和监管规范中复杂的视觉和文本数据所面临的挑战，提出了创新解决方案来增强 AI 驱动的合规性检查和设计流程。此外，该研究还考虑了 AI 集成的更广泛影响，包括开发 AI 驱动的工具以实现跨各个监管领域的全面规范合规性，以及 AI 通过逼真的模拟彻底改变劳动力培训的潜力。本文全面分析了生成式人工智能在建筑行业的当前能力，同时概述了未来的研究和开发方向，旨在为更智能、更可持续、更灵敏的建筑实践铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2410.01098</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合：多任务微调对法学硕士表现的鸡尾酒效应——金融案例研究</title>
      <link>https://arxiv.org/abs/2410.01109</link>
      <description><![CDATA[arXiv:2410.01109v1 公告类型：新
摘要：大型语言模型 (LLM) 在包括金融在内的特定领域环境中的应用迅速扩展。特定领域的 LLM 通常根据其在与该领域相关的各种下游任务中的表现进行评估。在这项工作中，我们对针对此类任务的微调 LLM 进行了详细分析。有些违反直觉的是，我们发现在特定领域的情况下，仅对目标任务进行微调并不总是最有效的策略。相反，多任务微调（在一系列相关任务上训练模型）可以显着提高性能。我们展示了这种方法如何使小型模型（例如 Phi-3-Mini）获得最先进的结果，甚至在金融基准上超越了更大的 GPT-4-o 模型。我们的研究涉及一项大规模实验，使用几种广泛采用的 LLM 作为基线训练了 200 多个模型，并通过经验证实了多任务微调的好处。此外，我们探索了使用一般指令数据作为一种正则化形式，表明它有助于最大限度地减少性能下降。我们还研究了数学数据的纳入，发现数字推理的改进可以有效地转移到金融任务上。最后，我们注意到，虽然下游任务的微调可以有针对性地提高任务性能，但它并不一定会导致领域知识或复杂领域推理能力的更广泛提升。]]></description>
      <guid>https://arxiv.org/abs/2410.01109</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过构建自己的指令来学习构建</title>
      <link>https://arxiv.org/abs/2410.01111</link>
      <description><![CDATA[arXiv:2410.01111v1 公告类型：新
摘要：对复杂视觉对象的结构理解是人工智能中一个尚未解决的重要组成部分。为了研究这个问题，我们为最近提出的 LTRON 中的拆分和组装问题开发了一种新技术，其中代理必须学习使用单个交互式会话来构建以前未见过的 LEGO 组件，以收集有关其组件及其结构的信息。我们通过构建一个称为 \textbf{\ours} 的代理来解决这个问题，该代理能够制作自己的视觉说明书。通过拆卸未见过的组件并定期保存其图像，代理能够创建一组指令，以便它拥有重建它所需的信息。这些指令形成一个显式记忆，允许模型一步一步地推理组装过程，避免了对长期隐式记忆的需求。这反过来又使我们能够在比过去更大的 LEGO 组件上进行训练。为了展示该模型的强大功能，我们发布了一个新的程序化构建的乐高车辆数据集，每个车辆平均包含 31 块积木，需要一百多个步骤才能拆卸和重新组装。我们使用在线模仿学习来训练这些模型，使模型能够从自己的错误中学习。最后，我们还对 LTRON 和 Break-and-Make 问题进行了一些小改进，以简化学习环境并提高可用性。]]></description>
      <guid>https://arxiv.org/abs/2410.01111</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于生成扩散的契约设计，实现车载人工智能网络中人工智能双胞胎的高效迁移</title>
      <link>https://arxiv.org/abs/2410.01176</link>
      <description><![CDATA[arXiv:2410.01176v1 公告类型：新
摘要：具身人工智能是一个快速发展的领域，它弥合了网络空间和物理空间之间的差距，实现了广泛的应用。这一发展导致了车载具身人工智能网络 (VEANET) 的发展，其中先进的人工智能功能被集成到车辆系统中，以增强自主操作和决策。具身代理，例如自动驾驶汽车 (AV)，是能够感知其环境并采取行动实现特定目标的自主实体，积极与物理世界互动。具身双胞胎是这些具身代理的数字模型，具有各种具身人工智能双胞胎，可用于网络空间中的智能应用。在 VEANET 中，具身人工智能双胞胎充当车载人工智能助手，使用生成人工智能模型执行支持自动驾驶的各种任务。由于自动驾驶汽车的计算资源有限，它们通常会将计算密集型任务（例如构建和更新具象人工智能双胞胎）转移到附近的 RSU。然而，由于自动驾驶汽车的快速移动性和单个 RSU 的供应覆盖范围有限，具象人工智能双胞胎需要实时从当前 RSU 动态迁移到其他 RSU，从而导致选择合适的 RSU 进行高效的具象人工智能双胞胎迁移的挑战。鉴于信息不对称，自动驾驶汽车无法了解 RSU 的详细信息。为此，本文构建了自动驾驶汽车与备选 RSU 之间的多维契约理论模型。考虑到自动驾驶汽车可能表现出非理性行为，我们利用前景理论而不是预期效用理论来模拟自动驾驶汽车的实际效用。最后，我们采用基于生成扩散模型的算法来确定最优契约设计。与传统深度强化学习算法相比，数值结果证明了所提方案的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.01176</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性感知的人类移动建模和异常检测</title>
      <link>https://arxiv.org/abs/2410.01281</link>
      <description><![CDATA[arXiv:2410.01281v1 公告类型：新
摘要：给定大量人类代理随时间变化的 GPS 坐标，我们如何在没有任何标记数据的情况下对其移动行为进行建模，以实现有效的异常检测（例如，用于不良行为者或恶意行为检测）？人类移动性和轨迹建模已被广泛研究，具有处理复杂输入和性能效率权衡的不同能力。随着机器学习中更具表现力的模型的出现，我们尝试将 GPS 数据建模为一系列停留点事件，每个事件都有一组特征时空特征，并利用现代序列模型（如 Transformers）进行无/自监督训练和推理。值得注意的是，受某些个体行为固有随机性的驱动，我们为模型配备了随机/数据不确定性估计。此外，为了处理各种行为的数据稀疏性，我们将认知/模型不确定性纳入我们的模型中。随机不确定性和认知不确定性共同实现了稳健的损失和训练动态，以及异常评分中的不确定性感知决策。在包含数万名代理的大型专家模拟数据集上进行的实验证明了我们的模型在预测和异常检测基线上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.01281</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>启发式估计的迭代期望定律</title>
      <link>https://arxiv.org/abs/2410.01290</link>
      <description><![CDATA[arXiv:2410.01290v1 公告类型：新
摘要：Christiano 等人 (2022) 将 *启发式估计器* 定义为一种假设算法，该算法根据参数估计数学表达式的值。简而言之，启发式估计器 $\mathbb{G}$ 将数学表达式 $Y$ 和正式的“启发式参数”$\pi$ 作为输入，并输出 $Y$ 的估计值 $\mathbb{G}(Y \mid \pi)$。在这项工作中，我们主张启发式估计器不应该能够预测其自身误差的非正式原则，并探索形式化该原则的方法。最简单地说，该原则表明，对于所有 $Y$ 和 $\pi$，$\mathbb{G}(Y - \mathbb{G}(Y \mid \pi) \mid \pi)$ 应该等于零。我们认为，理想的启发式估计量应该满足这方面的两个更强的属性，我们称之为*迭代估计*（类似于迭代期望定律）和*误差正交性*。
虽然迭代估计和误差正交性在直观上很有吸引力，但很难确定给定的启发式估计量是否满足这些属性。作为一种替代方法，我们探索*准确性*：一种属性，它（粗略地）表明$ \mathbb{G}$在数学表达式分布上的平均误差为零。然而，在两个估计问题的背景下，我们展示了创建准确启发式估计量的障碍。最后，我们讨论了寻找符合我们对这种估计量应该如何表现的直观理解的启发式估计量的挑战和潜在前进方向，以及启发式估计量在理解神经网络行为方面的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2410.01290</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FanCric：打造梦幻 11 支板球队的多智能体框架</title>
      <link>https://arxiv.org/abs/2410.01307</link>
      <description><![CDATA[arXiv:2410.01307v1 公告类型：新
摘要：板球以其复杂的策略和悠久的历史，越来越吸引着全球观众。印度板球超级联赛 (IPL) 是二十20板球的缩影，与较长的比赛形式相比，它以仅持续几个小时的形式展示了才华。IPL 以其技术和球迷参与的融合而闻名，是世界上最受欢迎的板球联赛。本研究集中于 Dream11，印度领先的 IPL 梦幻板球联赛，参与者根据真实球员的表现组建虚拟球队参加国际比赛。打造一支获胜的梦幻球队需要考虑各种复杂因素，包括球员状态和比赛条件。传统上，这是通过运筹学和机器学习来实现的。本研究介绍了 FanCric 框架，这是一个利用大型语言模型 (LLM) 和强大的编排框架的先进多智能体系统，可增强板球中的梦幻球队选择。 FanCric 结合结构化和非结构化数据，通过整合复杂的 AI 技术超越传统方法。分析涉及仔细审查 Dream11 竞赛中大约 1270 万个独特参赛作品，评估 FanCric 与群体智慧和更简单的 Prompt Engineering 方法的有效性。消融研究进一步评估了产生不同数量团队的影响。探索性发现很有希望，表明有必要进一步研究 FanCric 的能力，以充分发挥其在幻想体育和一般商业领域使用 LLM 增强战略决策的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.01307</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生命总会找到出路：系统神经搜索</title>
      <link>https://arxiv.org/abs/2410.01349</link>
      <description><![CDATA[arXiv:2410.01349v1 公告类型：新
摘要：我们应对快速调整代理行为以解决新环境中时空连续问题的挑战。动物表现出适应新环境的非凡能力，这是人工系统无法比拟的能力。我们不是专注于通过深度强化学习进行泛化，而是建议将行为视为搜索过程的物理表现，其中稳健的问题解决方案来自对所有可能行为的详尽搜索。令人惊讶的是，这可以通过在线修改指导行动的认知图来有效地完成，挑战了在连续空间中进行详尽搜索不切实际的主流观点。我们描述了一种通过调节行为执行和图突变之间的紧密反馈回路来隐式枚举行为的算法，并提供了基于赫布学习的神经实现和受内嗅皮层启发的新型高维谐波表示。通过将行为定义为搜索，我们为实时行为适应提供了一个数学上简单且生物学上合理的模型，成功解决了各种连续状态空间导航问题。该框架不仅为其他应用提供了灵活的神经基础，还为理解自适应行为提供了强大的范例。我们的结果表明，发展学习和无监督技能习得方面可能取得进展，为自主机器人在需要灵活性的数据稀疏环境中掌握复杂技能铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.01349</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>烤箱调度问题的理论下界</title>
      <link>https://arxiv.org/abs/2410.01368</link>
      <description><![CDATA[arXiv:2410.01368v1 公告类型：新
摘要：烤箱调度问题 (OSP) 是半导体行业中出现的 NP 难现实世界并行批处理调度问题。该问题的目标是在烤箱上安排一组作业，同时最小化几个因素，即烤箱总运行时间、作业延迟和设置成本。同时，它必须遵守各种约束，例如烤箱的合格性和可用性、作业发布日期、批次之间的设置时间和烤箱容量限制。获得有效调度的关键是同时批量处理兼容的作业。在本文中，我们为 OSP 开发了理论上的、针对特定问题的下限，这些下限可以非常快速地计算出来。我们彻底检查了这些下限，评估了它们的质量并探索了它们与现有解决方法的集成。具体来说，我们研究了它们对精确方法和使用模拟退火的元启发式局部搜索方法的贡献。此外，这些特定于问题的下限使我们能够评估大型实例的解决方案质量，而精确方法通常无法提供严格的下限。]]></description>
      <guid>https://arxiv.org/abs/2410.01368</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过头脑风暴优化和规则修改改进模糊规则分类器</title>
      <link>https://arxiv.org/abs/2410.01413</link>
      <description><![CDATA[arXiv:2410.01413v1 公告类型：新
摘要：搜索空间中不断扩大的复杂性和维数会对模糊规则分类器中的归纳学习产生不利影响，从而影响模糊系统的可扩展性和准确性。本研究专门针对糖尿病分类的挑战，采用头脑风暴优化 (BSO) 算法提出了一种新的模糊系统，重新定义了这种情况下规则的生成。指数模型被集成到标准 BSO 算法中以增强规则推导，专门针对糖尿病相关数据进行定制。创新的模糊系统随后应用于涉及糖尿病数据集的分类任务，我们的实验证明了分类准确性的显着提高。]]></description>
      <guid>https://arxiv.org/abs/2410.01413</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从奖励塑造到 Q 塑造：通过法学硕士指导的知识实现无偏学习</title>
      <link>https://arxiv.org/abs/2410.01458</link>
      <description><![CDATA[arXiv:2410.01458v1 公告类型：新
摘要：Q 整形是 Q 值初始化的扩展，可作为奖励整形的替代方案，用于结合领域知识来加速代理训练，从而通过直接塑造 Q 值来提高样本效率。这种方法在不同任务中既通用又稳健，可以立即评估影响，同时保证最优性。我们使用大型语言模型 (LLM) 作为启发式提供者，在 20 种不同的环境中评估了 Q 整形。结果表明，Q 整形显著提高了样本效率，在每个环境中都比最佳基线提高了 \textbf{16.87\%}，与基于 LLM 的奖励整形方法相比提高了 \textbf{253.80\%}。这些发现表明 Q 整形是强化学习中传统奖励整形的优越且无偏见的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2410.01458</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedQA-CS：使用 AI-SCE 框架对大型语言模型临床技能进行基准测试</title>
      <link>https://arxiv.org/abs/2410.01553</link>
      <description><![CDATA[arXiv:2410.01553v1 公告类型：新
摘要：医疗保健中的人工智能 (AI) 和大型语言模型 (LLM) 需要高级临床技能 (CS)，但当前的基准无法全面评估这些技能。我们引入了 MedQA-CS，这是一个受医学教育客观结构化临床考试 (OSCE) 启发的 AI-SCE 框架，以解决这一差距。MedQA-CS 通过两个指令遵循任务来评估 LLM，即 LLM-as-medical-student 和 LLM-as-CS-examiner，旨在反映真实的临床场景。我们的贡献包括开发 MedQA-CS，这是一个具有公开数据和专家注释的综合评估框架，并提供 LLM 作为 CS 评估中可靠判断者的定量和定性评估。我们的实验表明，与传统的多项选择 QA 基准（例如 MedQA）相比，MedQA-CS 是评估临床技能的更具挑战性的基准。结合现有的基准，MedQA-CS 可以对开源和闭源 LLM 的临床能力进行更全面的评估。]]></description>
      <guid>https://arxiv.org/abs/2410.01553</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>带有链接学习的迭代局部搜索</title>
      <link>https://arxiv.org/abs/2410.01583</link>
      <description><![CDATA[arXiv:2410.01583v1 公告类型：新
摘要：在伪布尔优化中，变量交互图将变量表示为顶点，将变量对之间的交互表示为边。在黑盒优化中，变量交互图可以至少部分地通过使用经验链接学习技术来发现。这些方法从不报告错误的变量交互，但它们的计算成本很高。最近提出的带有链接学习的局部搜索发现了部分变量交互图，这是迭代局部搜索的副作用。但是，算法不会学习有关交互强度的信息。我们提出了带有链接学习的局部搜索 2，它构建了一个加权变量交互图，该图存储了有关变量之间交互强度的信息。加权变量交互图可以提供有关优化问题和优化器行为的新见解。对 NK 景观、背包问题和特征选择的实验表明，带有链接学习 2 的局部搜索能够有效地构建加权变量交互图。具体来说，特征选择实验表明，加权变量交互图可用于可视化机器学习中的特征交互。此外，还可以设计利用变量之间交互的新转换算子。我们通过为迭代局部搜索提出一种新的扰动算子来说明这种能力。]]></description>
      <guid>https://arxiv.org/abs/2410.01583</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度强化学习在图表中查找路径和循环计数公式</title>
      <link>https://arxiv.org/abs/2410.01661</link>
      <description><![CDATA[arXiv:2410.01661v1 公告类型：新
摘要：本文介绍了语法强化学习 (GRL)，这是一种使用蒙特卡洛树搜索 (MCTS) 的强化学习算法，以及在上下文无关语法 (CFG) 框架内对下推自动机 (PDA) 进行建模的转换器架构。以有效计算图中的路径和循环的问题为用例，这是网络分析、计算机科学、生物学和社会科学中的一个关键挑战，GRL 发现了新的基于矩阵的路径/循环计数公式，与最先进的方法相比，计算效率提高了两到六倍。我们的贡献包括：(i) 用于生成在 CFG 内运行的语法生成器的框架，(ii) 开发用于优化语法结构内公式的 GRL，以及 (iii) 发现用于图形子结构计数的新公式，从而显着提高计算效率。]]></description>
      <guid>https://arxiv.org/abs/2410.01661</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思维混乱：通过 Typoglycemia 揭示大型语言模型心理学</title>
      <link>https://arxiv.org/abs/2410.01677</link>
      <description><![CDATA[arXiv:2410.01677v1 公告类型：新
摘要：对大型语言模型（LLM）的外部行为和内部机制的研究已显示出在解决物理世界中的复杂任务方面的前景。研究表明，像 GPT-4 这样强大的 LLM 开始表现出类似人类的认知能力，包括规划、推理和反思。在本文中，我们介绍了一种称为 LLM 心理学的研究方向和方法，利用人类心理学实验来研究 LLM 的认知行为和机制。我们将 Typoglycemia 现象从心理学中迁移到探索 LLM 的“思维”。与依赖上下文和单词模式来理解乱码文本的人脑不同，LLM 使用不同的编码和解码过程。通过字符、单词和句子级别的 Typoglycemia 实验，我们观察到：（I）LLM 在宏观尺度上表现出类似人类的行为，例如任务准确率较低和 token/时间消耗较高； (II) LLM 对乱序输入表现出不同的鲁棒性，这使得 Typoglycemia 成为无需新数据集即可进行模型评估的基准；(III) 不同的任务类型有不同的影响，复杂的逻辑任务（例如数学）在乱序形式下更具挑战性；(IV) 每个 LLM 在不同任务之间都有独特且一致的“认知模式”，揭示了其心理过程中的一般机制。我们对隐藏层进行了深入分析以解释这些现象，为 LLM 心理学的未来研究和更深层次的可解释性铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.01677</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么上下文在 VQA 和推理中很重要：VLM 输入模式的语义干预</title>
      <link>https://arxiv.org/abs/2410.01690</link>
      <description><![CDATA[arXiv:2410.01690v1 公告类型：新
摘要：生成式人工智能的各种局限性，例如幻觉和模型失败，使得了解不同模态在视觉语言模型 (VLM) 预测中的作用至关重要。我们的工作研究了来自图像和文本模态的信息整合如何影响 VLM 在视觉问答 (VQA) 和推理任务中的性能和行为。我们通过答案准确性、推理质量、模型不确定性和模态相关性来衡量这种影响。我们研究不同配置下文本和图像模态之间的相互作用，其中视觉内容对于解决 VQA 任务至关重要。我们的贡献包括 (1) 语义干预 (SI)-VQA 数据集、(2) 不同模态配置下各种 VLM 架构的基准研究，以及 (3) 交互式语义干预 (ISI) 工具。 SI-VQA 数据集是基准测试的基础，而 ISI 工具则提供了一个界面来测试和应用图像和文本输入中的语义干预，从而实现更细粒度的分析。我们的结果表明，模态之间的互补信息可以提高答案和推理质量，而矛盾的信息会损害模型的性能和置信度。图像文本注释对准确性和不确定性的影响微乎其微，略微增加了图像相关性。注意力分析证实了在 VQA 任务中图像输入相对于文本的主导作用。在本研究中，我们评估了最先进的 VLM，这些 VLM 使我们能够提取每种模态的注意力系数。一个关键发现是 PaliGemma 的有害过度自信，与 LLaVA 模型相比，它带来了更高的无声失败风险。这项工作为严格分析模态集成奠定了基础，并得到了专门为此目的设计的数据集的支持。]]></description>
      <guid>https://arxiv.org/abs/2410.01690</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型新兴能力背后的 U 型和倒 U 型扩展</title>
      <link>https://arxiv.org/abs/2410.01692</link>
      <description><![CDATA[arXiv:2410.01692v1 公告类型：新
摘要：大型语言模型 (LLM) 已被证明在某些下游任务中表现出突发能力，其中性能似乎一开始停滞不前，然后在超过阈值的规模下急剧且不可预测地提高。通过根据难度级别将数据集中的问题除以平均表现，我们观察到难题的 U 形缩放，以及简单问题的倒 U 形缩放，然后稳步改善。此外，出现阈值大致与简单问题的性能从反向缩放恢复到标准缩放的点相吻合。利用简单和难题上可观察到但相反的缩放趋势，我们提出了一个简单而有效的流程，称为 Slice-and-Sandwich，以预测出现阈值和超出阈值的模型性能。]]></description>
      <guid>https://arxiv.org/abs/2410.01692</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>