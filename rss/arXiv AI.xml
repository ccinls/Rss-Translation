<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 18 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于LLM的数据分析中洞察力生成的方法</title>
      <link>https://arxiv.org/abs/2503.11664</link>
      <description><![CDATA[ARXIV：2503.11664V1公告类型：新 
摘要：从数据库中生成洞察力和可行的信息对于数据分析至关重要。本文介绍了一种使用大语言模型（LLM）的新方法来自动生成文本见解。给定一个多桌数据库作为输入，我们的方法利用LLMS产生简洁的基于文本的见解，这些见解反映了表中有趣的模式。我们的框架包括一个假设生成器，以提出与域相关的问题，一个查询代理，通过针对数据库生成SQL查询来回答此类问题，以及一个摘要模块以口头表达洞察力。使用人类判断力和自动指标的混合模型评估了见解的正确性和主观见解。公共和企业数据库的实验结果表明，我们的方法比其他方法在保持正确性的同时产生的见解更多。]]></description>
      <guid>https://arxiv.org/abs/2503.11664</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索HRI因果关系：关于机器人心理健康教练的案例研究</title>
      <link>https://arxiv.org/abs/2503.11684</link>
      <description><![CDATA[ARXIV：2503.11684V1公告类型：新 
摘要：人类机器人相互作用（HRI）研究的主要目标之一是开发可以解释人类行为并相应地调整其反应的机器人。诸如持续和强化学习之类的自适应学习模型在提高机器人在现实环境中有效互动的能力方面起着至关重要的作用。但是，由于现实世界数据的可用性有限，尤其是在医疗保健和福祉等敏感领域，这些模型面临着重大挑战。这些数据稀缺会阻碍机器人适应新情况的能力。为了应对这些挑战，因果关系提供了一个结构化的框架，用于理解和建模行动，事件和结果之间的基本关系。通过超越单纯的模式识别，因果关系使机器人能够做出更容易解释和可推广的决策。本文通过对自适应机器人教练的案例研究提供了基于探索性因果关系的分析，该教练在工作场所环境中进行了四个星期的积极心理学练习。机器人教练会自主适应多模式的人类行为，例如面值和言语持续时间。通过进行宏观和微观因果分析，本研究旨在更深入地了解适应性如何在相互作用过程中增强幸福感。最终，这项研究旨在促进我们对因果关系如何帮助克服HRI挑战的理解，尤其是在现实世界中。]]></description>
      <guid>https://arxiv.org/abs/2503.11684</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向支持LLM的室内导航</title>
      <link>https://arxiv.org/abs/2503.11702</link>
      <description><![CDATA[ARXIV：2503.11702V1公告类型：新 
摘要：由于复杂的布局，缺乏GPS信号和可访问性问题，室内导航提出了独特的挑战。现有的解决方案通常在实时适应性和特定用户的需求方面遇到困难。在这项工作中，我们探讨了大型语言模型（LLM）的潜力，即chatgpt，从室内地图图像中生成自然的，上下文感知的导航说明。我们在不同的现实环境中设计和评估测试案例，分析LLM在解释空间布局，处理用户约束和计划有效路线方面的有效性。我们的发现证明了LLMS支持个性化室内导航的潜力，平均正确的指示为52％，最多为62％。结果似乎不取决于布局的复杂性或预期路径的复杂性，而是取决于感兴趣点的数量和丰富的视觉信息，这会对性能产生负面影响。]]></description>
      <guid>https://arxiv.org/abs/2503.11702</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果知识的相对论</title>
      <link>https://arxiv.org/abs/2503.11718</link>
      <description><![CDATA[ARXIV：2503.11718V1公告类型：新 
摘要：人工智能的最新进展揭示了纯粹的预测系统的局限性，并呼吁转向因果关系和协作推理。我们从数学中的革命中汲取灵感，我们介绍了因果知识的相对性，该因果知识认为结构性因果模型（SCM）本质上是不完美的，主观的表示，嵌入了关系网络中。通过利用类别理论，我们将SCM安排为函子类别，并表明它们的观察和介入概率衡量可以自然形成凸结构。这个结果使我们能够用概率度量的凸空间编码非中间的SCM。接下来，使用捆绑理论，我们构建了因果知识的网络捆绑和Cosheaf。这些结构使因果知识在整个网络中传递，同时结合了介入的一致性和对象的观点，最终导致了相对因果知识的正式数学定义。]]></description>
      <guid>https://arxiv.org/abs/2503.11718</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于物理学的仿真本体：支持基于物理模拟的数据建模和重复使用的本体论</title>
      <link>https://arxiv.org/abs/2503.11723</link>
      <description><![CDATA[ARXIV：2503.11723V1公告类型：新 
摘要：当前的工作介绍了为基于物理学的工程设计模拟开发的本体，称为基于物理学的模拟本体论（PSO）。本体论的目的是帮助以清晰的方式建模感兴趣的物理现象，同时捕获基于物理的模拟求解器的必要和可重复使用的信息。该发展涉及扩展现有的上层本体论，基本的正式本体论（BFO），以定义PSO的下层术语。 PSO有两个部分：PSO生理学，它由用于对物理现象进行建模的术语和关系，基于涉及部分微分方程的经典力学的观点和PSO-SIM的观点，该术语由代表有关物理现象的术语组成。前一种术语用于模拟与求解器特定解释无关的物理现象，该现象可以在不同的求解器上重复使用，而后者则用于实例化求解器特定的输入数据。进行了涉及两个模拟求解器的案例研究，以证明PSO的这种能力。还提供了有关将BFO用于当前工作的收益和局限性的讨论，这对于将来扩展了现有上层本体论以开发工程应用的本体论的任何工作都应该是有价值的。]]></description>
      <guid>https://arxiv.org/abs/2503.11723</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PublicsPeak：在地方政府中以概率框架聆听公众</title>
      <link>https://arxiv.org/abs/2503.11743</link>
      <description><![CDATA[ARXIV：2503.11743V1公告类型：新 
摘要：世界各地的地方政府正在代表其选民做出结果决定，这些选民在公开会议上以其官员的要求，建议和评估做出回应。传统新闻编辑室不能大规模涵盖如此多的小型会议。我们提出了PublicsPeak，这是一个概率框架，可以利用会议结构，领域知识和语言信息来发现当地政府会议中的公开言论。然后，我们使用我们的方法来检查美国7个城市中选民提出的问题。我们在当地政府会议的新型数据集上评估了我们的方法，并发现PublicSpeak平均将最先进的时间提高了10％，高达40％。]]></description>
      <guid>https://arxiv.org/abs/2503.11743</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可视化思想：概念图在LMMS中启用强大的计划</title>
      <link>https://arxiv.org/abs/2503.11790</link>
      <description><![CDATA[ARXIV：2503.11790V1公告类型：新 
摘要：人类推理依赖于我们用来理解和解决问题的情况的构建和操纵精神模型的内部表示。概念图（例如，由人类绘制的素描以帮助推理）将这些心理模型进行外部化，从而使细节无关紧要，以有效捕获关系和空间信息。相比之下，大语言模型（LLM）和大型多模式模型（LMM）主要通过文本表示，限制了它们在复杂的多步组合和计划任务中的有效性。在本文中，我们提出了一个零射击的全自动框架，该框架使LMM能够通过多个自我生成的中间概念图的链条进行推理，从而显着增强了其组合计划功能。除了对任务的自然语言描述之外，我们的方法不需要任何人类初始化。它将文本和图形推理集成在优化的思想图推理框架中，通过梁搜索和深度回溯来增强。我们在多个具有挑战性的PDDL计划域进行了评估，我们的方法大大提高了GPT-4O的性能（例如，Blockworld中的35.5％至90.2％）。在更困难的计划域，解决方案深度高达40个，我们的方法甚至超过O1概述推理模型（例如，停车位提高了13％）。这些结果突出了概念图作为LMM中互补推理介质的价值。]]></description>
      <guid>https://arxiv.org/abs/2503.11790</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率图形模型的道德化和三角剖分的代数方法</title>
      <link>https://arxiv.org/abs/2503.11820</link>
      <description><![CDATA[ARXIV：2503.11820V1公告类型：新 
摘要：道德化和三角剖分是转换，可以在将概率分布的不同方式之间切换到图形模型。道德化允许将贝叶斯网络（指示模型）视为马尔可夫网络（无方向的模型），而三角剖分朝相反的方向起作用。我们提出了一个分类框架，其中将这些转换建模为贝叶斯网络和马尔可夫网络之一之间的函子。两种网络（这些类别的对象）本身是函子，从“语法”域到“语义语法” codomain。值得注意的是，道德化和三角剖分在此类语法上可以定义，并作为函子预组成的一种形式。这种方法在概率图形模型理论中引入了模块化的代数观点。]]></description>
      <guid>https://arxiv.org/abs/2503.11820</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>安全幻影：虚假的相关性如何破坏VLM安全性微调</title>
      <link>https://arxiv.org/abs/2503.11832</link>
      <description><![CDATA[ARXIV：2503.11832V1公告类型：新 
摘要：最近的视觉模型（VLM）在具有多模式输入（尤其是文本和图像的生成建模）方面取得了显着步骤。但是，在暴露于不安全的查询时产生有害内容的敏感性引起了关键的安全问题。虽然当前的一致性策略主要依赖于与策划数据集进行监督的安全性微调，但我们确定了一个基本的限制，我们称为“安全幻影”，在该限制中，无意中监督的微调无意间加强了浅表文本模式和安全响应之间的虚假相关性，而不是促进深层的，内在的，内在的危害。我们表明，这些虚假的相关性使微调的VLM脆弱甚至遭受了简单的基于单词修改的攻击，在此攻击中，在文本查询中用单个单词用虚假的相关诱导的替代方案代替单个单词可以有效地绕过保障措施。此外，这些相关性有助于过度审慎，导致微调的VLM不必要地拒绝良性查询。为了解决这个问题，我们将机器学习（MU）作为监督安全性微调的有力替代方案，因为它可以避免偏见的特征标签映射映射，并直接从VLM中删除VLMS的有害知识，同时保留其一般功能。跨安全基准的广泛评估表明，在单个字攻击下，基于MU的一线将攻击的成功率降低了60.17％，并将不必要的拒绝减少了84.20％以上。代码可在https://github.com/optml-group/vlm-safety-mu上找到。警告：存在AI世代，可能是令人反感的。]]></description>
      <guid>https://arxiv.org/abs/2503.11832</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实可实现</title>
      <link>https://arxiv.org/abs/2503.11870</link>
      <description><![CDATA[ARXIV：2503.11870V1公告类型：新 
摘要：通常认为，在实际环境中，只能从观察和介入分布中得出样品，与珍珠因果层次结构的1和2相对应。根据定义，代表反事实分布的第3层被认为是无法访问的。但是，Bareinboim，Forney和Pearl（2015）引入了一种程序，该程序允许代理直接从反事实分布中采样，从而打开了可以直接通过物理实验直接估算哪些其他反事实数量的问题。我们通过引入对可变性的形式定义，从分布中绘制样品的能力，然后开发完整的算法来确定在给定基本的物理约束的情况下是否可以实现，例如无法及时回到不同的实验条件，从而解决了这一问题。我们使用因果公平和因果增强学习中的激励示例来说明这种新框架对反事实数据收集的含义。尽管这些激励设置的基线方法通常遵循介入或观察策略，但我们表明，反事实策略证明两者兼而有之。]]></description>
      <guid>https://arxiv.org/abs/2503.11870</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>监测行为不当的推理模型和促进混淆的风险</title>
      <link>https://arxiv.org/abs/2503.11926</link>
      <description><![CDATA[ARXIV：2503.11926V1公告类型：新 
摘要：缓解奖励黑客 - 由于其学习目标中的缺陷或错误的特异性，AI系统的行为不当 - 犯有构建能力和一致模型的关键挑战。我们表明，我们可以通过使用另一个观察该模型的经济链（COT）推理的LLM来监视诸如OpenAI O3-Mini之类的前沿推理模型，以便在代理编码环境中进行奖励黑客入侵。 COT监视可以比单独监测剂的动作和输出更有效，我们进一步发现，比O3-Mini（即GPT-4O）弱的LLM可以有效地监视更强的模型。由于COT监视器可以有效地检测漏洞，因此自然要问是否可以通过将COT监视器直接纳入代理商的训练目标来抑制这些漏洞。尽管我们表明将COT监视纳入加强学习奖励确实可以在低优化制度中产生更有能力，更合适的代理，但我们发现，经过过多优化，代理商学习了混淆的奖励黑客攻击，将其隐藏在COT中，同时仍然表现出很大的奖励黑客攻击率。因为很难分辨出COTS何时变得混淆，因此可能有必要通过不直接将强大的优化压力直接施加到思想链上来缴纳可监视性税，从而确保COTS保持可监控且可用于检测未对准的行为。]]></description>
      <guid>https://arxiv.org/abs/2503.11926</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sagallm：多代理LLM计划的上下文管理，验证和交易保证</title>
      <link>https://arxiv.org/abs/2503.11951</link>
      <description><![CDATA[ARXIV：2503.11951V2公告类型：新 
摘要：最近的基于LLM的代理框架在任务授权和工作流程编排中表现出了令人印象深刻的能力，但是在保持环境意识和确保计划一致性方面面临着重大挑战。本文介绍了Sagallm，这是一个结构化的多代理框架，该框架解决了当前LLM方法中的四个基本限制：自我验证不足，上下文缩小，缺乏交易属性和不足的间距协调。通过实施专业的上下文管理代理和验证协议，Sagallm在复杂的计划过程中保留了关键的约束和状态信息，即使在中断期间，也可以实现稳健和一致的决策。我们使用领域基准中选定的问题评估我们的方法，重点介绍了挑战上下文保留和自适应推理的顺序和反应性计划方案。我们对最先进的LLMS，Claude 3.7，DeepSeek R1，GPT-4O和GPT-O1进行的实验表明，尽管这些模型具有令人印象深刻的推理能力，但它们在复杂的计划任务中尤其是在调整出意外的更改时在复杂的计划任务中保持全球约束意识。相比之下，Sagallm的分布式认知结构在计划一致性，约束执行和适应各种情况下的破坏方面显示出显着改善。]]></description>
      <guid>https://arxiv.org/abs/2503.11951</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在高速公路上自动化交通事故管理的循环</title>
      <link>https://arxiv.org/abs/2503.12085</link>
      <description><![CDATA[ARXIV：2503.12085V1公告类型：新 
摘要：有效的交通事故管理对于确保在紧急情况下的安全性，最大程度地减少拥塞和减少响应时间至关重要。传统的高速公路事件管理很大程度上依赖无线电室操作员，他们必须在高风险环境中做出快速，明智的决定。本文提出了一种创新的解决方案，以通过将大型语言模型（LLM）集成到交通事故管理的决策支持系统中来支持和增强这些决策。我们介绍了两种方法：（1）LLM +优化混合体，既利用自然语言互动的灵活性和优化技术的鲁棒性，以及（2）一种完整的LLM方法，该方法仅使用LLM功能自动生成决策。我们使用来自Italia的AutoStrade的历史事件数据测试了解决方案。实验结果表明，尽管两种方法都表现出希望，但LLM +优化解决方案表现出了卓越的可靠性，使其特别适合一致性和准确性至关重要的关键应用。这项研究突出了LLM通过启用可访问的，以数据驱动的决策支持来改变高速公路事件管理的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.12085</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>亚里士多德的最初想法：在人工智能时代，对逻辑进行反对</title>
      <link>https://arxiv.org/abs/2503.12161</link>
      <description><![CDATA[ARXIV：2503.12161V1公告类型：新 
摘要：亚里士多德通常被认为是逻辑之父。他在研究逻辑推理的研究中提出的思想在几个世纪以来都发展了科学的发展。如今，在AI时代，这个逻辑父亲的头衔具有重新意义。它的背后是他最初的想法，即可以将人类推理作为一个过程进行研究，并且也许存在普遍的推理系统，无论我们的推理内容如何，​​所有人类推理的基础。在本文中，我们研究了亚里士多德关于人类思想的工作，他在推理上的工作，以及从现代人工智能的现代角度，更广泛地与科学和人类努力的关系，并询问这是否可以帮助我们更普遍地了解我们对AI和科学的理解。]]></description>
      <guid>https://arxiv.org/abs/2503.12161</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有连续（PO）MDP的动作自适应搜索树的价值梯度</title>
      <link>https://arxiv.org/abs/2503.12181</link>
      <description><![CDATA[ARXIV：2503.12181V1公告类型：新 
摘要：在连续状态，行动和观察空间中解决部分可观察到的马尔可夫决策过程（POMDP）是许多现实世界中的移动性和机器人应用程序中自主计划的关键。当前的方法主要基于样本，并且不能希望在合理的时间内达到近乎最佳的解决方案。我们提出了两个互补的理论贡献。首先，我们制定了一种新颖的多重重要性采样（MIS）树以进行价值估计，从而可以在同胞动作分支之间共享价值信息。小说MIS树支持搜索时间的动作更新，例如基于梯度的更新。其次，我们提出了一种新的方法，以基于过渡可能性来计算在线抽样的价值梯度。它适用于MDP，我们通过应用传播信念技巧的粒子信念将其扩展到POMDP。使用有效的蒙特卡洛采样的MIS树在实践中计算梯度估计器。这两个部分合并为新的计划算法动作梯度蒙特卡洛树搜索（AGMCTS）。我们在模拟的环境中证明其适用性，比仅依靠采样的连续在线POMDP求解器具有优势，我们讨论了进一步的含义。]]></description>
      <guid>https://arxiv.org/abs/2503.12181</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的生存模型，用于预测心力衰竭患者全因死亡率的生存模型：一项多核研究</title>
      <link>https://arxiv.org/abs/2503.12317</link>
      <description><![CDATA[ARXIV：2503.12317V1公告类型：新 
摘要：我们开发并验证了Trisk，这是一种基于变压器的AI模型，通过分析来自英国电子健康记录（EHR）的时间患者旅行，预测心力衰竭患者的36个月死亡率。我们的研究包括403,534例心力衰竭患者（40-90岁），从1,418种英语一般做法，有1,063种模型推导的做法，外部验证355例。将Trisk与各个患者亚组的Maggic-EHR模型进行了比较。随着9个月的中位随访，Trisk的一致性指数为0.845（95％置信区间：[0.841，0.849]），明显优于Maggic-Ehr的0.728（0.723，0.733），用于预测36个月的全部因子死亡率。 Trisk在性别，年龄和基线特征中表现出更一致的性能，这表明偏见较少。我们通过转移学习成功地改编了美国医院数据，获得了0.802（0.789，0.816）的C索引，患者有21,767名患者。解释性分析表明，捕获了既定的危险因素，同时识别出癌症和肝衰竭等未充分考虑的预测因素，这在两个人群中都很重要。值得注意的是，即使在诊断后的十年，癌症也保持了强大的预后价值。 Trisk在两个医疗保健系统中均表现出良好的死亡率预测。我们的发现突出了跟踪纵向健康概况的价值，并揭示了以前由专家驱动的模型中未包含的风险因素。]]></description>
      <guid>https://arxiv.org/abs/2503.12317</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Spin Bench：LLMS在战略上和社会上的计划如何？</title>
      <link>https://arxiv.org/abs/2503.12349</link>
      <description><![CDATA[ARXIV：2503.12349V2公告类型：新 
摘要：社会互动中的推理和战略行为是智力的标志。这种形式的推理比静态设置中的孤立计划或推理任务要复杂得多（例如，数学问题解决）。在本文中，我们提出了战略规划，互动和谈判（Spin Bench），这是一种新的多域评估，旨在衡量战略规划和社会推理的智能。尽管许多现有的基准都集中在狭窄的计划或单一代理推理上，但Spin Bench结合了一个统一的框架中的经典PDDL任务，竞争性棋盘游戏，合作纸牌游戏和多代理谈判场景。该框架既包括一个基准，也包括一个竞技场，可以模拟和评估各种社交环境，以测试AI代理的推理和战略行为。我们通过系统地变化的动作空间，状态复杂性以及相互作用的代理的数量来模拟各种社交环境，从而制定了基准旋转基础，在这些空间中，成功不仅取决于有条理和逐步的决策，还取决于其他（对抗性或合作）参与者的概念推断。我们的实验表明，虽然当代LLM可以很好地处理基本事实检索和短期计划，但它们在需要对大型状态空间进行深度多跳上推理的任务中遇到了重要的性能瓶颈，并且在不确定性下需要进行社会熟练的协调。我们设想自旋基础作为对强大的多代理计划，社会推理和人类的未来研究的催化剂。项目网站：https：//spinbench.github.io/]]></description>
      <guid>https://arxiv.org/abs/2503.12349</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IPCGRL：程序级生成语言的强化学习</title>
      <link>https://arxiv.org/abs/2503.12358</link>
      <description><![CDATA[ARXIV：2503.12358V2公告类型：新 
摘要：最近的研究强调了自然语言在增强生成模型的可控性方面的重要性。尽管已做出了各种努力来利用自然语言进行内容的生成，但使用基于文本的指令进行程序内容生成的深入强化学习（DRL）代理人仍然有限。在本文中，我们提出了IPCGRL，这是一种通过强化学习的基于指导的程序内容生成方法，该方法结合了句子嵌入模型。 IPCGRL微调特定于任务的嵌入表示形式，以有效地压缩游戏级别的条件。我们在二维生成任务中评估IPCGRL，并将其性能与通用嵌入方法进行比较。结果表明，IPCGRL的可控性提高了21.4％，看不见的说明的概括性提高了17.2％。此外，提出的方法扩展了条件输入的方式，从而为程序内容生成提供了更灵活和表达的交互框架。]]></description>
      <guid>https://arxiv.org/abs/2503.12358</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Fedgai：与云边缘合作的联合风格学习，用于时装设计的生成AI</title>
      <link>https://arxiv.org/abs/2503.12389</link>
      <description><![CDATA[ARXIV：2503.12389V1公告类型：新 
摘要：协作可以将各种思想，样式和视觉元素融合在一起，从而促进不同设计师之间的创造力和创新。在协作设计中，草图在表达设计创造力的一种手段中发挥了关键作用。但是，设计师通常倾向于不公开共享这些精心制作的草图。在设计区域中，数据岛的这种现象阻碍了在第三波AI浪潮下的数字转换。在本文中，我们介绍了联合生成的人工智能服装系统，即Fedgai，采用联邦学习来帮助素描设计。 FedGai致力于建立一个生态系统，设计师可以在其中交换素描样式。通过FedGai，设计师可以生成草图，这些草图将各种设计师的样式从同行中汲取了灵感，而无需进行数据披露或上传。广泛的绩效评估表明，我们的Fedgai系统可以产生与人工设计的质量可比质量相当的多样式草图，同时与手绘草图相比显着提高了效率。]]></description>
      <guid>https://arxiv.org/abs/2503.12389</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一项关于优化基于语言模型的代理的调查</title>
      <link>https://arxiv.org/abs/2503.12434</link>
      <description><![CDATA[ARXIV：2503.12434V1公告类型：新 
摘要：随着大语言模型（LLM）的快速发展，基于LLM的代理在各个领域都广泛采用，这对于自主决策和互动任务至关重要。但是，当前的工作通常依赖于适用于Vanilla LLM的及时设计或微调策略，这通常会导致在复杂的代理相关环境中的有效性或次优性能。尽管LLM优化技术可以改善许多一般任务中的模型性能，但它们缺乏针对关键代理功能的专门优化，例如长期计划，动态环境互动和复杂的决策。尽管许多最近的研究探讨了各种策略以优化基于LLM的代理进行复杂的代理任务，但仍缺乏从整体角度进行总结和比较这些方法的系统评价。在这项调查中，我们对基于LLM的代理优化方法进行了全面综述，将其分类为参数驱动和无参数的方法。我们首先关注参数驱动的优化，涵盖基于微调的优化，基于增强学习的优化以及混合策略，分析诸如轨迹数据构建，微调技术，奖励功能设计和优化算法等关键方面。此外，我们简要讨论通过及时工程和外部知识检索来优化代理行为的无参数策略。最后，我们总结了用于评估和调整的数据集和基准，审查基于LLM的代理的关键应用，并讨论主要挑战和有希望的未来方向。我们的相关参考存储库可从https://github.com/youngdubbydu/llm-agent-optimization获得。]]></description>
      <guid>https://arxiv.org/abs/2503.12434</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>