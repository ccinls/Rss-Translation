<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 12 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>单细胞基因组学中的增强基因选择：预过滤协同和强化优化</title>
      <link>https://arxiv.org/abs/2406.07418</link>
      <description><![CDATA[arXiv:2406.07418v1 公告类型：新
摘要：单细胞基因组学的最新进展要求精确选择基因组，以有效解释复杂的生物数据。这些方法旨在通过关注对特定分析任务有重大贡献的最具信息量的基因来简化 scRNA-seq 数据的分析。传统的选择方法通常依赖于专家领域知识、嵌入式机器学习模型或基于启发式的迭代优化，容易出现偏差和效率低下，从而可能掩盖关键的基因组信号。认识到传统方法的局限性，我们旨在通过改进的策略超越这些限制。在本研究中，我们介绍了一种适用于单细胞基因组学聚类任务的迭代基因组选择策略。我们的方法独特地整合了其他基因选择算法的结果，提供了有价值的初步边界或先验知识作为搜索空间中的初始指南，以提高我们框架的效率。此外，我们结合了强化学习 (RL) 中探索过程的随机性及其通过基于奖励的反馈进行持续优化的能力。这种组合减轻了初始边界固有的偏差，并利用 RL 的适应性来动态优化和目标基因组选择。为了说明我们方法的有效性，我们进行了详细的比较实验、案例研究和可视化分析。]]></description>
      <guid>https://arxiv.org/abs/2406.07418</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>OceanCastNet：具有能量守恒的深度学习海浪模型</title>
      <link>https://arxiv.org/abs/2406.03848</link>
      <description><![CDATA[arXiv:2406.03848v2 Announce Type: cross 
摘要：传统的波浪预报模型虽然基于能量守恒方程，但计算成本高昂。另一方面，现有的深度学习地球物理流体模型虽然计算效率高，但在长期预报中往往会出现能量耗散等问题。本文提出了一种新型的能量平衡深度学习波浪预报模型OceanCastNet (OCN)。通过将当前、前一个和未来时间步长的风场以及当前和前一个时间步长的波浪场作为输入变量，OCN在模型内保持能量平衡。此外，该模型采用自适应傅里叶算子作为核心组件，并设计了掩蔽损失函数以更好地处理陆海边界的影响。在ERA5数据集上的一系列实验表明，OCN可以实现与传统模型相当的短期预测精度，同时展现对波浪生成过程的理解。在正常和极端条件下的对比实验中，OCN始终优于业界广泛使用的WaveWatch III模型。即使经过长期预报，OCN仍保持稳定且能量丰富的状态。通过进一步构建考虑能量平衡的简单气象模型OCN-wind，本文证实了能量约束对于提高深度学习气象模型长期预报性能的重要性。这一发现为未来深度学习地球物理流体模型的研究提供了新思路。]]></description>
      <guid>https://arxiv.org/abs/2406.03848</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>借助大型语言模型实现目标的世界模型</title>
      <link>https://arxiv.org/abs/2406.07381</link>
      <description><![CDATA[arXiv:2406.07381v1 公告类型：新
摘要：由于手动奖励指定困难，强化学习在长期任务和稀疏目标方面举步维艰。虽然现有方法通过添加内在奖励来解决这个问题，但它们可能无法在具有大状态和动作空间的长期决策任务中提供有意义的指导，缺乏有目的的探索。受人类认知的启发，我们提出了一种新的基于多模态模型的强化学习方法，称为大型语言模型的梦想 (DLLM)。DLLM 将 LLM 中提出的提示子目标集成到模型部署中，以鼓励在具有挑战性的任务中发现和实现目标。通过在模型部署期间为与语言模型概述的提示一致的样本分配更高的内在奖励，DLLM 引导代理进行有意义且有效的探索。大量实验表明，DLLM 在各种具有挑战性的稀疏奖励环境（例如 HomeGrid、Crafter 和 Minecraft）中的表现分别比近期方法高出 27.7%、21.1% 和 9.9%。]]></description>
      <guid>https://arxiv.org/abs/2406.07381</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>通过蒙特卡洛树访问 GPT-4 级数学奥林匹克解决方案，使用 LLaMa-3 8B 进行自我优化</title>
      <link>https://arxiv.org/abs/2406.07394</link>
      <description><![CDATA[arXiv:2406.07394v1 公告类型：新
摘要：本文介绍了 MCT 自优化 (MCTSr) 算法，这是大型语言模型 (LLM) 与蒙特卡洛树搜索 (MCTS) 的创新集成，旨在提高复杂数学推理任务的性能。为了解决 LLM 的准确性和可靠性挑战，特别是在战略和数学推理方面，MCTSr 利用系统探索和启发式自优化机制来改进 LLM 中的决策框架。该算法通过选择、自优化、自评估和反向传播的迭代过程构建蒙特卡洛搜索树，利用改进的上置信区间 (UCB) 公式来优化探索-利用平衡。大量实验证明了 MCTSr 在解决奥林匹克数学问题方面的有效性，显著提高了多个数据集（包括 GSM8K、GSM Hard、MATH）和奥林匹克级基准（包括 Math Odyssey、AIME 和 OlympiadBench）的成功率。该研究推动了 LLM 在复杂推理任务中的应用，并为未来的 AI 集成奠定了基础，提高了 LLM 驱动应用中的决策准确性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2406.07394</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能沙袋：语言模型在评估中可能战略性地表现不佳</title>
      <link>https://arxiv.org/abs/2406.07358</link>
      <description><![CDATA[arXiv:2406.07358v1 公告类型：新
摘要：值得信赖的能力评估对于确保人工智能系统的安全至关重要，并且正在成为人工智能监管的关键组成部分。然而，人工智能系统的开发者或人工智能系统本身可能有动机在评估中低估人工智能的实际能力。这些利益冲突导致了沙袋问题$\unicode{x2013}$，我们将其定义为“评估中的战略表现不佳”。在本文中，我们评估了当代语言模型 (LM) 中的沙袋能力。我们提示前沿 LM，如 GPT-4 和 Claude 3 Opus，在危险能力评估中选择性表现不佳，同时在一般（无害）能力评估中保持性能。此外，我们发现可以在合成数据集上对模型进行微调，以隐藏特定功能，除非给出密码。这种行为推广到高质量、坚持的基准，例如 WMDP。此外，我们表明，无论是前沿模型还是较小的模型，都可以被提示或密码锁定，以针对能力评估的特定分数。此外，我们发现一个功能强大的密码锁定模型（Llama 3 70b）能够合理地模拟一个功能较弱的模型（Llama 2 7b）。总体而言，我们的结果表明，能力评估容易受到沙袋攻击。这种弱点降低了评估的可信度，从而破坏了有关开发和部署高级人工智能系统的重要安全决策。]]></description>
      <guid>https://arxiv.org/abs/2406.07358</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:06 GMT</pubDate>
    </item>
    <item>
      <title>基于约束的因果发现的大型语言模型</title>
      <link>https://arxiv.org/abs/2406.07378</link>
      <description><![CDATA[arXiv:2406.07378v1 公告类型：新
摘要：因果关系对于理解复杂系统（例如经济、大脑和气候）至关重要。构建因果图通常依赖于数据驱动或专家驱动的方法，这两种方法都充满挑战。前一种方法，如著名的 PC 算法，面临着数据要求和因果充分性假设的问题，而后者则需要大量的时间和领域知识。这项工作探索了大型语言模型 (LLM) 作为领域专家生成因果图的替代方案的能力。我们将条件独立查询构建为 LLM 的提示，并使用 PC 算法来回答。基于 LLM 的条件独立性预言机在具有已知因果图的系统上的性能表现出高度的可变性。我们通过提出的统计启发投票模式来提高性能，该模式允许对假阳性和假阴性率进行一些控制。通过检查思路链论证，我们发现因果推理可以证明其对概率查询的回答。我们证明，基于知识的 CIT 最终可以成为数据驱动因果发现的补充工具。]]></description>
      <guid>https://arxiv.org/abs/2406.07378</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:06 GMT</pubDate>
    </item>
    <item>
      <title>形式化验证的近似策略迭代</title>
      <link>https://arxiv.org/abs/2406.07340</link>
      <description><![CDATA[arXiv:2406.07340v1 公告类型：新
摘要：我们使用交互式定理证明器 Isabelle/HOL 正式验证了分解马尔可夫决策过程的近似策略迭代算法。接下来，我们展示如何将形式化算法细化为可执行的、经过验证的实现。在基准问题上评估实现以显示其实用性。作为细化的一部分，我们开发了经过验证的软件来认证线性规划解决方案。该算法建立在多样化的形式化数学库之上，并将现有的交互式定理证明器方法推向极限。我们讨论了验证项目的过程以及形式验证所需的算法修改。]]></description>
      <guid>https://arxiv.org/abs/2406.07340</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:05 GMT</pubDate>
    </item>
    <item>
      <title>超越训练：通过自适应动作抽样优化基于强化学习的车间调度</title>
      <link>https://arxiv.org/abs/2406.07325</link>
      <description><![CDATA[arXiv:2406.07325v1 公告类型：新
摘要：近年来，用于调度问题的学习构造启发式方法与成熟的求解器和启发式方法的竞争力越来越强。特别是，使用深度强化学习 (DRL) 的解决方法取得了显着的改进。虽然人们非常关注网络架构和训练算法的设计以获得最先进的结果，但很少有研究调查在推理过程中训练有素的 DRL 代理的最佳使用。我们的工作基于这样的假设：与搜索算法类似，训练有素的 DRL 代理的利用应该取决于可接受的计算预算。我们提出了一种简单而有效的参数化，称为 $\delta$-sampling，它操纵训练有素的动作向量，使代理行为在解决方案构建期间偏向探索或利用。通过遵循这种方法，我们可以实现对搜索空间的更全面覆盖，同时仍然生成可接受数量的解决方案。此外，我们提出了一种算法，用于获得给定数量的解决方案和任何给定的训练有素的代理的最佳参数化。使用我们的推理方法扩展现有的车间调度问题训练协议的实验验证了我们的假设，并导致了生成的解决方案的预期改进。]]></description>
      <guid>https://arxiv.org/abs/2406.07325</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:04 GMT</pubDate>
    </item>
    <item>
      <title>3D-Properties：识别 DPO 中的挑战并规划前进的道路</title>
      <link>https://arxiv.org/abs/2406.07327</link>
      <description><![CDATA[arXiv:2406.07327v1 公告类型：新
摘要：将大型语言模型 (LLM) 与人类偏好对齐最近引起了极大的关注，其中典型但成本高昂的 RLHF-PPO 和简单直接的直接偏好优化 (DPO) 就是两个例子。尽管效率很高，但 DPO 很少用于最先进的生产级 LLM，这意味着它存在潜在的病态。在这项工作中，我们重新审视 DPO，全面检查其经验有效性并与 RLHF-PPO 进行系统比较。我们通过精心设计的玩具模型和实际的 LLM 进行实验，确定了 DPO 学习结果的 \textbf{3D} 属性：拒绝回答的可能性的 \textbf{D} 急剧下降、\textbf{D} 退化为 LLM 反学习，以及对未见回答的 \textbf{D} 分散效应，这些实验包括数学问题解决和指令遵循等任务。这些发现与相关工作的一些观察结果有着内在联系，我们还为它们提供了一个合理的理论解释。因此，我们提出了简单的正则化方法来缓解 \textbf{3D} 属性引起的问题，从而提高 DPO 的训练稳定性和最终性能。我们的贡献还包括调查成对偏好数据的分布如何影响 DPO 的有效性。我们希望这项工作可以提供研究方向，以缩小无奖励偏好学习方法和基于奖励的偏好学习方法之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2406.07327</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:04 GMT</pubDate>
    </item>
    <item>
      <title>扩展基于大型语言模型的多智能体协作</title>
      <link>https://arxiv.org/abs/2406.07155</link>
      <description><![CDATA[arXiv:2406.07155v1 公告类型：新
摘要：大型语言模型驱动的代理的开创性进步强调了多代理协作的设计模式，表明集体智慧可以超越每个个体的能力。受神经缩放定律的启发，该定律认为增加神经元会导致出现能力，本研究调查了类似的原则是否适用于多代理协作中代理的增加。从技术上讲，我们提出了多代理协作网络 (MacNet)，它利用有向无环图来组织代理并通过拓扑排序简化其交互推理，解决方案来自他们的对话。大量实验表明，MacNet 始终优于基线模型，能够在各种网络拓扑中实现有效的代理协作，并支持一千多个代理之间的合作。值得注意的是，我们观察到了一种小世界协作现象，其中类似于小世界属性的拓扑实现了卓越的性能。此外，我们确定了协作扩展定律，表明标准化解决方案质量遵循逻辑增长模式作为扩展代理，协作出现的时间比以前观察到的神经出现时间要早得多。代码和数据将在 https://github.com/OpenBMB/ChatDev 上提供。]]></description>
      <guid>https://arxiv.org/abs/2406.07155</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>DCA-Bench：数据集管理代理的基准</title>
      <link>https://arxiv.org/abs/2406.07275</link>
      <description><![CDATA[arXiv:2406.07275v1 公告类型：新
摘要：数据集的质量在现代人工智能（AI）的研究和开发中起着越来越重要的作用。尽管如今开放数据集平台激增，但数据质量问题（例如文档不足、注释不准确和道德问题）在人工智能中广泛使用的数据集中仍然很常见。此外，这些问题通常很微妙，难以通过基于规则的脚本检测到，需要数据集用户或维护者进行昂贵的手动识别和验证。随着大型语言模型（LLM）功能的不断增强，使用 LLM 代理简化数据集的管理有望成为可能。在这项工作中，作为实现这一目标的第一步，我们提出了一个数据集管理代理基准 DCA-Bench，以衡量 LLM 代理检测隐藏数据集质量问题的能力。具体来说，我们从八个开放数据集平台收集了各种现实世界的数据集质量问题作为测试平台。此外，为了建立评估 LLM 代理成功与否的自动管道（这需要对代理输出有细致的理解），我们使用另一个 LLM 代理实现了专用评估器。我们证明基于 LLM 的评估器在经验上与人工评估非常吻合，可以在所提出的基准上进行可靠的自动评估。我们进一步在所提出的基准上对几个基线 LLM 代理进行了实验，并展示了任务的复杂性，这表明将 LLM 应用于现实世界的数据集管理仍然需要进一步深入探索和创新。最后，所提出的基准还可以作为衡量 LLM 在问题发现而不仅仅是解决问题方面的能力的试验台。基准套件可在 \url{https://github.com/TRAIS-Lab/dca-bench} 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.07275</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>CHARME：一种基于链的强化学习方法，用于解决小嵌入问题</title>
      <link>https://arxiv.org/abs/2406.07124</link>
      <description><![CDATA[arXiv:2406.07124v1 公告类型：新
摘要：量子退火 (QA) 在有效解决组合优化问题方面具有巨大潜力。然而，QA 算法的有效性在很大程度上依赖于将问题实例（表示为逻辑图）嵌入到量子单元处理 (QPU) 中，其拓扑形式为有限连通图，称为次要嵌入问题。现有的次要嵌入问题方法在面对更大的问题规模时会遇到可扩展性问题。在本文中，我们提出了一种利用强化学习 (RL) 技术解决次要嵌入问题的新方法，称为 CHARME。CHARME 包括三个关键组件：用于策略建模的图神经网络 (GNN) 架构、确保解决方案有效性的状态转换算法和用于有效训练的顺序探索策略。通过对合成和真实世界实例的全面实验，我们证明了我们提出的顺序探索策略以及我们提出的 RL 框架 CHARME 的效率。具体来说，与 Minorminer 和 ATOM 等快速嵌入方法相比，CHARME 可产生更优的解决方案。此外，我们的方法在某些情况下优于基于 OCT 的方法，后者以运行时间较慢但解决方案质量较高而闻名。此外，我们提出的探索通过提供比贪婪策略更好的解决方案来提高 CHARME 框架的训练效率。]]></description>
      <guid>https://arxiv.org/abs/2406.07124</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:02 GMT</pubDate>
    </item>
    <item>
      <title>挖掘概念模型中的频繁结构</title>
      <link>https://arxiv.org/abs/2406.07129</link>
      <description><![CDATA[arXiv:2406.07129v1 公告类型：新
摘要：使用结构化方法表示知识的问题在概念建模中是众所周知的，并且已经研究了很多年。已经证明，采用建模模式是一种有效的结构方法。模式确实是可推广的递归结构，可以用作设计问题的解决方案。它们有助于理解和改进创建模型的过程。在概念建模中使用模式的不可否认的价值已在几项实验研究中得到证明。然而，在概念模型中发现模式被广泛认为是一项高度复杂的任务，目前缺乏对模式识别的系统解决方案。在本文中，我们提出了一种通用方法来发现概念建模语言中出现的频繁结构。作为我们科学贡献的概念证明，我们通过关注 UML 类图，特别是 OntoUML 模型，提供了该方法的实现。该实现包括一个探索性工具，通过结合频繁子图挖掘算法和图形操作技术，可以处理多个概念模型并根据多个标准发现递归结构。主要目标是为语言工程师提供支持设施。这可以用于利用好的和坏的建模实践，发展和维护概念建模语言，并促进在使用给定语言设计更好的模型时重复使用编码经验。]]></description>
      <guid>https://arxiv.org/abs/2406.07129</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:02 GMT</pubDate>
    </item>
    <item>
      <title>利用上下文感知查询表示学习改进知识图谱中的多跳逻辑推理</title>
      <link>https://arxiv.org/abs/2406.07034</link>
      <description><![CDATA[arXiv:2406.07034v1 公告类型：新
摘要：知识图谱上的多跳逻辑推理是自然语言处理中的一项关键任务，有许多方法旨在回答一阶逻辑 (FOL) 查询。最近的基于几何（例如，盒子、锥体）和概率（例如，beta 分布）的方法已经有效地解决了复杂的 FOL 查询。然而，这些方法面临的一个共同挑战在于确定这些查询的准确几何边界或概率参数。挑战的出现是因为现有方法依赖于其计算图中的线性顺序操作，忽略了查询的逻辑结构和可以从查询关系中收集的关系诱导信息，我们称之为查询的上下文。为了解决这个问题，我们提出了一种与模型无关的方法，通过完全集成 FOL 查询图的上下文来提高现有多跳逻辑推理方法的有效性。我们的方法可以清晰地辨别 (1) 查询结构固有的结构上下文和 (2) 查询图中每个节点独有的关系诱导上下文，如相应的知识图谱所示。这种双重上下文范式可帮助查询图中的节点在整个多跳推理步骤中获得精细的内部表示。通过对两个数据集的实验，我们的方法持续增强了三个多跳推理基础模型，实现了高达 19.5% 的性能提升。我们的代码可在 https://github.com/kjh9503/caqr 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.07034</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:01 GMT</pubDate>
    </item>
    <item>
      <title>使用未标记数据增强离线强化学习</title>
      <link>https://arxiv.org/abs/2406.07117</link>
      <description><![CDATA[arXiv:2406.07117v1 公告类型：新
摘要：离线强化学习 (Offline RL) 的最新进展导致人们更加关注基于保守策略更新的方法来解决分布外 (OOD) 问题。这些方法通常涉及添加行为正则化或修改批评学习目标，主要关注具有大量数据集支持的状态或动作。然而，我们通过断言数据集中缺少动作或状态并不一定意味着其次优性来挑战这一流行观念。在本文中，我们提出了一种解决 OOD 问题的新方法。我们引入了一个离线 RL 师生框架，并辅以策略相似性度量。该框架使学生政策不仅可以从离线 RL 数据集中获得见解，还可以从教师政策传递的知识中获得见解。教师政策使用另一个由状态-动作对组成的数据集进行训练，这些数据集可以被视为无需与环境直接交互即可获得的实际领域知识。我们相信这些额外的知识是有效解决 OOD 问题的关键。这项研究代表了将师生网络融入演员-评论家框架的重大进步，为离线 RL 中的知识转移研究开辟了新途径，并有效地解决了 OOD 挑战。]]></description>
      <guid>https://arxiv.org/abs/2406.07117</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:01 GMT</pubDate>
    </item>
    <item>
      <title>CAAP：情境感知行动规划，仅使用前端 UI 即可解决计算机任务</title>
      <link>https://arxiv.org/abs/2406.06947</link>
      <description><![CDATA[arXiv:2406.06947v1 公告类型：新
摘要：软件机器人早已被部署在机器人过程自动化 (RPA) 中，以自动执行平凡而重复的计算机任务。具有高级推理能力的大型语言模型 (LLM) 的出现为这些代理现在可以执行更复杂甚至以前从未见过的任务奠定了基础。然而，最近文献中基于 LLM 的自动化技术经常依赖 HTML 源代码进行输入，将其应用限制在 Web 环境中。此外，HTML 代码中包含的信息通常不准确或不完整，使得代理在实际应用中不太可靠。我们提出了一种基于 LLM 的代理，它仅基于屏幕截图来识别环境，同时利用上下文学习来消除收集大量人类演示数据集的需要。我们的策略称为上下文感知行动计划 (CAAP) 提示，鼓励代理从各个角度仔细审查上下文。通过我们提出的方法，我们在 67 种 MiniWoB++ 问题上实现了 94.4% 的成功率，每种问题类型仅使用 1.48 次演示。我们的方法为更广泛的应用提供了潜力，尤其是对于需要在计算机或智能手机上进行应用程序间协调的任务，展示了自动化代理领域的重大进步。代码和模型可在 https://github.com/caap-agent/caap-agent 上访问。]]></description>
      <guid>https://arxiv.org/abs/2406.06947</guid>
      <pubDate>Wed, 12 Jun 2024 06:27:00 GMT</pubDate>
    </item>
    <item>
      <title>嵌入物中有什么？嵌入任何植物的玫瑰都会散发出同样芬芳的香气吗？</title>
      <link>https://arxiv.org/abs/2406.06870</link>
      <description><![CDATA[arXiv:2406.06870v1 公告类型：新
摘要：大型语言模型 (LLM) 经常被批评为缺乏真正的“理解”和用知识“推理”的能力，仅仅被视为高级自动完成系统。我们认为这种观点可能缺少一个重要的见解。我们认为 LLM 确实发展了一种类似于“几何”的经验“理解”，这似乎足以满足 NLP、计算机视觉、编码辅助等一系列应用的需求。然而，这种基于不完整和嘈杂数据的“几何”理解使它们不可靠、难以概括，并且缺乏推理能力和解释，类似于几十年前基于启发式的专家系统所面临的挑战。
为了克服这些限制，我们建议 LLM 应该与知识的“代数”表示相结合，其中包括专家系统中使用的符号 AI 元素。这种整合旨在创建大型知识模型 (LKM)，这些模型不仅拥有基于第一原理的“深度”知识，而且还具有推理和解释能力，模仿人类专家的能力。为了安全有效地利用生成式人工智能的全部潜力，需要从 LLM 转向更全面的 LKM。]]></description>
      <guid>https://arxiv.org/abs/2406.06870</guid>
      <pubDate>Wed, 12 Jun 2024 06:26:59 GMT</pubDate>
    </item>
    <item>
      <title>联合演示和偏好学习提高了策略与人类反馈的一致性</title>
      <link>https://arxiv.org/abs/2406.06874</link>
      <description><![CDATA[arXiv:2406.06874v1 公告类型：新
摘要：协调人类偏好和价值观是构建当代基础模型和具身人工智能的重要要求。然而，诸如带人类反馈的强化学习 (RLHF) 等流行方法将任务分解为连续阶段，例如监督微调 (SFT)、奖励建模 (RM) 和强化学习 (RL)，每个阶段执行一项特定的学习任务。这种顺序方法会导致严重问题，例如数据利用率严重不足以及学习到的奖励模型与生成的策略之间的分布不匹配，最终导致对齐性能不佳。我们开发了一种名为集成人类反馈对齐 (AIHF) 的单阶段方法，能够整合人类偏好和演示来训练奖励模型和策略。所提出的方法采用了一套高效的算法，可以轻松简化并利用流行的对齐算法，例如 RLHF 和直接策略优化 (DPO)，并且只需要对现有的对齐管道进行微小的更改。我们通过大量实验证明了所提解决方案的有效性，这些实验涉及 LLM 中的对齐问题和 MuJoCo 中的机器人控制问题。我们观察到，所提解决方案的性能远胜于现有的对齐算法（如 RLHF 和 DPO），尤其是在高质量偏好数据量相对有限的情况下。]]></description>
      <guid>https://arxiv.org/abs/2406.06874</guid>
      <pubDate>Wed, 12 Jun 2024 06:26:59 GMT</pubDate>
    </item>
    <item>
      <title>DISCOVERYWORLD：开发和评估自动化科学发现代理的虚拟环境</title>
      <link>https://arxiv.org/abs/2406.06769</link>
      <description><![CDATA[arXiv:2406.06769v1 公告类型：新
摘要：自动化科学发现有望加速各个科学领域的进步。然而，开发和评估人工智能代理的端到端科学推理能力具有挑战性，因为运行现实世界的实验通常成本过高或不可行。在这项工作中，我们引入了 DISCOVERYWORLD，这是第一个用于开发和基准测试代理执行完整新颖科学发现周期的能力的虚拟环境。DISCOVERYWORLD 包含各种不同的挑战，涵盖放射性同位素测年、火箭科学和蛋白质组学等多种主题，以鼓励开发一般的发现技能而不是特定于任务的解决方案。DISCOVERYWORLD 本身是一个廉价的、模拟的、基于文本的环境（带有可选的 2D 视觉叠加）。它包括 120 个不同的挑战任务，涵盖八个主题，每个主题有三个难度级别和几个参数变化。每个任务都需要一个代理形成假设、设计和运行实验、分析结果并根据结论采取行动。 DISCOVERYWORLD 还提供了三个自动指标来评估绩效，基于 (a) 任务完成情况、(b) 采取的与任务相关的行动以及 (c) 发现的解释性知识。我们发现，在之前发布的环境中表现良好的强大基线代理在大多数 DISCOVERYWORLD 任务中都表现不佳，这表明 DISCOVERYWORLD 抓住了一些新的发现挑战，因此 DISCOVERYWORLD 可能有助于加速代理的科学发现能力的近期发展和评估。代码可在以下网址获取：www.github.com/allenai/discoveryworld]]></description>
      <guid>https://arxiv.org/abs/2406.06769</guid>
      <pubDate>Wed, 12 Jun 2024 06:26:58 GMT</pubDate>
    </item>
    <item>
      <title>目测组合问题：使用多模态大型语言模型解决旅行商问题的案例研究</title>
      <link>https://arxiv.org/abs/2406.06865</link>
      <description><![CDATA[arXiv:2406.06865v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 已证明能够熟练处理多种模态，包括文本、图像和音频。这些模型利用大量预先存在的知识，使它们能够用最少甚至没有特定的训练示例来解决复杂问题，这一点在少数样本和零样本上下文学习场景中得到了证明。本文通过分析二维平面上的点分布图像，研究了如何使用 MLLM 的视觉能力来“目测”旅行商问题 (TSP) 的解决方案。我们的实验旨在验证 MLLM 可以有效“目测”可行的 TSP 路线的假设。零样本、少数样本、自集成和自优化零样本评估的结果显示出令人鼓舞的结果。我们预计这些发现将激发进一步探索 MLLM 的视觉推理能力，以解决其他组合问题。]]></description>
      <guid>https://arxiv.org/abs/2406.06865</guid>
      <pubDate>Wed, 12 Jun 2024 06:26:58 GMT</pubDate>
    </item>
    </channel>
</rss>