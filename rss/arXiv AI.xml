<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>转型机构。论大型语言模型的存在方式</title>
      <link>https://arxiv.org/abs/2407.10735</link>
      <description><![CDATA[arXiv:2407.10735v2 公告类型：新
摘要：本文研究了 ChatGPT 等大型语言模型 (LLM) 的本体论特征。在通货膨胀和通货紧缩账户之间，我们特别关注它们作为代理的状态。这需要详细解释使 LLM 能够展示其能力的架构、处理和训练程序，以及用于将 LLM 转变为类似代理的系统的扩展。经过系统分析，我们得出结论，根据具身心理理论，LLM 未能满足自主代理的必要和充分条件：个性条件（它不是其自身活动的产物，甚至不受其直接影响）、规范性条件（它不会产生自己的规范或目标），以及部分交互不对称条件（它不是其与环境交互的起源和持续来源）。如果不是代理，那么……LLM 是什么？我们认为 ChatGPT 应该被描述为一个对话者或语言自动机，一个会说话的图书馆，没有（自主）代理，但能够有效地参与无目的但有目的的结构和有目的的任务。在与人类互动时，人机交互的“幽灵”组件使得使用 LLM 实现真正的对话体验成为可能。尽管缺乏感觉运动和生物体现，但 LLM 的文本体现（训练语料库）和资源密集型计算体现显著改变了现有的人类代理形式。除了辅助和扩展代理之外，LLM-人类耦合可以产生中间形式的代理，更接近于产生有意图的代理，而不是任何先前技术的扩展工具。]]></description>
      <guid>https://arxiv.org/abs/2407.10735</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:42 GMT</pubDate>
    </item>
    <item>
      <title>基于心理测量理论的XEQ量表用于评估XAI体验质量</title>
      <link>https://arxiv.org/abs/2407.10662</link>
      <description><![CDATA[arXiv:2407.10662v1 公告类型：新
摘要：可解释人工智能 (XAI) 旨在通过解释提高自主决策的透明度。最近的文献强调了用户对整体“多镜头”解释的需求以及个性化他们与 XAI 系统的互动的能力。我们将这种以用户为中心的互动称为 XAI 体验。尽管在创建 XAI 体验方面取得了进展，但以用户为中心的方式评估它们仍然具有挑战性。为了解决这个问题，我们引入了 XAI 体验质量 (XEQ) 量表（发音为“Seek”量表），用于评估以用户为中心的 XAI 体验质量。此外，XEQ 从四个评估维度量化体验质量：学习、实用性、成就感和参与度。这些贡献扩展了 XAI 评估的最新水平，超越了经常为评估单镜头解释而开发的一维指标。在本文中，我们介绍了 XEQ 量表的开发和验证过程，包括与 XAI 专家进行内容验证以及通过大规模试点研究进行判别和结构验证。我们的试点研究结果提供了强有力的证据，确立了 XEQ 量表是评估以用户为中心的 XAI 体验的综合框架。]]></description>
      <guid>https://arxiv.org/abs/2407.10662</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:41 GMT</pubDate>
    </item>
    <item>
      <title>Sibyl：用于复杂现实世界推理的简单而有效的代理框架</title>
      <link>https://arxiv.org/abs/2407.10718</link>
      <description><![CDATA[arXiv:2407.10718v2 公告类型：新
摘要：现有的基于大型语言模型 (LLM) 的代理通过整合 LLM 的固有知识、强大的上下文学习和零样本能力以及工具的使用与人类精心设计的 LLM 调用工作流相结合，展示了强大的问题解决能力。然而，这些代理在长期推理方面仍然存在缺陷，并且未充分利用现有工具的潜力，导致在复杂的现实世界推理场景中存在明显缺陷。为了解决这些限制，我们引入了 Sibyl，这是一个简单但功能强大的基于 LLM 的代理框架，旨在通过有效利用一组最少的工具来解决复杂的推理任务。从全局工作区理论中汲取灵感，Sibyl 整合了一个全局工作区，以增强整个系统的知识和对话历史的管理和共享。此外，在心智社会理论的指导下，Sibyl 实施了一个基于多代理辩论的陪审团来自我完善最终答案，确保全面而平衡的方法。这种方法旨在降低系统复杂性，同时扩大可解决问题的范围——从通常由人类在几分钟内解决的问题到需要数小时甚至数天才能解决的问题，从而促进从系统 1 到系统 2 思维的转变。Sibyl 的设计侧重于可扩展性和易于调试，从一开始就融入了函数式编程中的可重入性概念，旨在无缝且轻松地集成到其他 LLM 应用程序中以提高功能。我们在 GAIA 基准测试集上的实验结果表明，与其他基于 GPT-4 的代理相比，使用 GPT-4 实例化的 Sibyl 代理实现了最佳性能，平均得分为 34.55%。我们希望 Sibyl 能够激发更多可靠且可重复使用的基于 LLM 的代理解决方案来解决复杂的现实世界推理任务。]]></description>
      <guid>https://arxiv.org/abs/2407.10718</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:41 GMT</pubDate>
    </item>
    <item>
      <title>利用混合智能实现可持续且节能的机器学习</title>
      <link>https://arxiv.org/abs/2407.10580</link>
      <description><![CDATA[arXiv:2407.10580v1 公告类型：新
摘要：混合智能旨在通过结合人类认知能力和人工智能的优势来增强决策、解决问题和整体系统性能。随着大型语言模型 (LLM) 的兴起，混合智能逐渐作为智能代理参与加速机器学习的发展，成为人机有效交互的一个越来越重要的主题。本文介绍了一种利用混合智能实现可持续和节能机器学习的方法。在开发机器学习模型时，最终模型性能通常决定优化过程，而过程本身的效率往往被忽视。此外，近年来，由于复杂和大规模计算过程对环境的重大影响，能源效率变得同样重要。这项工作的贡献包括通过人机交互 (HITL) 和 LLM 代理交互式地纳入二级知识源，以缓解和进一步解决机器学习开发过程中的低效率问题。]]></description>
      <guid>https://arxiv.org/abs/2407.10580</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:40 GMT</pubDate>
    </item>
    <item>
      <title>强化学习的三大原则</title>
      <link>https://arxiv.org/abs/2407.10583</link>
      <description><![CDATA[arXiv:2407.10583v1 公告类型：新
摘要：现代强化学习至少受到三个教条的制约。第一个是环境聚焦，这指的是我们倾向于关注建模环境而不是代理。第二个是我们将学习视为寻找任务的解决方案，而不是适应。第三个是奖励假设，它指出所有目标和目的都可以被认为是奖励信号的最大化。这三个教条塑造了我们所认为的强化学习科学的大部分内容。虽然每个教条都在发展该领域方面发挥了重要作用，但现在是时候将它们带到表面并反思它们是否属于我们科学范式的基本成分了。为了实现强化学习作为研究智能代理的规范框架的潜力，我们建议是时候完全摆脱教条一和二，并采用细致入微的方法对待第三个教条了。]]></description>
      <guid>https://arxiv.org/abs/2407.10583</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:40 GMT</pubDate>
    </item>
    <item>
      <title>多智能体寻路的合作奖励塑造</title>
      <link>https://arxiv.org/abs/2407.10403</link>
      <description><![CDATA[arXiv:2407.10403v1 公告类型：新
摘要：多智能体寻路 (MAPF) 的主要目标是为所有智能体规划高效且无冲突的路径。传统的多智能体路径规划算法难以为多个智能体实现高效的分布式路径规划。相比之下，多智能体强化学习 (MARL) 已被证明是实现此目标的有效方法。通过将 MAPF 问题建模为 MARL 问题，智能体可以在部分观察下通过分布式策略实现高效的路径规划和防撞。然而，由于缺乏全局信息，MARL 策略通常缺乏智能体之间的合作，从而导致 MAPF 效率降低。为了应对这一挑战，本信介绍了一种基于独立 Q 学习 (IQL) 的独特奖励塑造技术。该方法的目的是评估一个智能体对其邻居的影响，并将这种交互集成到奖励函数中，从而促进智能体之间的积极合作。这种奖励塑造方法促进了智能体在分布式操作中的合作。所提出的方法已通过各种场景的实验进行了评估，这些场景具有不同的规模和代理数量。结果与其他最先进的 (SOTA) 规划器的结果进行了比较。证据表明，本信中提出的方法在许多方面与其他规划器相似，并且在具有大量代理的场景中表现优于它们。]]></description>
      <guid>https://arxiv.org/abs/2407.10403</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>加强建筑物安全设计以应对枪击事件：使用基于强化学习的模拟探索建筑物出口参数</title>
      <link>https://arxiv.org/abs/2407.10441</link>
      <description><![CDATA[arXiv:2407.10441v1 公告类型：新
摘要：随着美国枪击事件 (ASI) 的惊人增长，通过建筑设计提高公共安全已成为迫切需要。本研究提出了一种基于强化学习的模拟方法，解决了现有研究中忽视射手动态行为的空白。我们开发了一个自主代理来模拟现实办公环境中的活跃射手，旨在深入了解建筑设计参数与 ASI 结果之间的相互作用。进行了一项案例研究，以定量研究建筑物出口数量（可访问出口的总数）和配置（哪些出口可用或不可用的安排）对疏散和伤害率的影响。研究结果表明，出口可用性越高，疏散结果就越好，伤害就越少。离射手初始位置较近的出口对可达性的重要性高于离射手初始位置较远的出口。通过涵盖动态射手行为，本研究为有效的建筑安全设计以应对不断变化的威胁提供了初步见解。]]></description>
      <guid>https://arxiv.org/abs/2407.10441</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>IDEAL：利用大型语言模型的无限和动态特征进行以查询为中心的摘要</title>
      <link>https://arxiv.org/abs/2407.10486</link>
      <description><![CDATA[arXiv:2407.10486v1 公告类型：新
摘要：以查询为中心的摘要 (QFS) 旨在生成回答特定感兴趣的问题的摘要，从而实现更大的用户控制和个性化。随着大型语言模型 (LLM) 的出现，它们通过大规模预训练展示了其令人印象深刻的文本理解能力，这意味着提取片段生成的巨大潜力。在本文中，我们系统地研究了基于 LLM 的 QFS 模型应利用的两个不可或缺的特征，分别是长文档摘要和高效细粒度查询-LLM 对齐。相应地，我们提出了两个称为查询感知 HyperExpert 和查询聚焦 Infini-attention 的模块来访问上述特征。这些创新为 QFS 技术领域的更广泛应用和可访问性铺平了道路。在现有 QFS 基准上进行的大量实验表明了所提出方法的有效性和通用性。我们的代码可在https://github.com/DCDmllm/IDEAL_Summary上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2407.10486</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>Sora 与 V-JEPA 尚未学会完整的现实世界模型——从生产性想象理论对视频 AI 进行哲学分析</title>
      <link>https://arxiv.org/abs/2407.10311</link>
      <description><![CDATA[arXiv:2407.10311v1 公告类型：新
摘要：Open AI 的 Sora 表现出色，但它面临着对其技术实力是否等同于对现实的真实理解的审查。批评者认为它缺乏对世界的根本把握，Meta 的 V-JEPA 旨在通过联合嵌入方法修正这一缺陷。这场辩论对于指导人工智能 (AGI) 的未来方向至关重要。我们通过开发一种基于康德哲学的产生连贯世界模型的生产性想象理论来丰富这场辩论。我们确定了能够真正理解世界的连贯世界模型的三个不可或缺的组成部分：孤立对象的表示、跨空间和时间的先验变化规律和康德范畴。我们的分析表明，Sora 的局限性在于它忽视了先验变化规律和康德范畴，这些缺陷无法通过扩大训练来纠正。 V-JEPA 学习了先验变化定律中与上下文相关的方面。然而，它未能完全理解康德的范畴并融入经验，这导致我们得出结论，这两个系统目前都没有实现全面的世界理解。尽管如此，每个系统都开发了推进集成 AI 生产性想象理解引擎所必需的组件。最后，我们提出了一个创新的 AI 生产性想象理解引擎训练框架，该框架以联合嵌入系统为中心，旨在将无序的感知输入转化为结构化、连贯的世界模型。我们的哲学分析指出了当代视频 AI 技术中的关键挑战，以及实现能够真正理解世界的 AI 系统的途径，以便它可以应用于未来的推理和规划。]]></description>
      <guid>https://arxiv.org/abs/2407.10311</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:38 GMT</pubDate>
    </item>
    <item>
      <title>LAB-Bench：测量生物学研究语言模型的能力</title>
      <link>https://arxiv.org/abs/2407.10362</link>
      <description><![CDATA[arXiv:2407.10362v2 公告类型：新
摘要：人们普遍乐观地认为，前沿大型语言模型 (LLM) 和 LLM 增强系统有可能迅速加速跨学科的科学发现。如今，有许多基准可以衡量 LLM 对教科书式科学问题的知识和推理，但很少有基准旨在评估语言模型在科学研究所需的实际任务（例如文献检索、协议规划和数据分析）上的表现。作为建立此类基准的一步，我们引入了语言代理生物学基准 (LAB-Bench)，这是一个包含 2,400 多个多项选择题的广泛数据集，用于评估 AI 系统在一系列实际生物学研究能力方面的水平，包括对文献的回忆和推理、图形解释、数据库的访问和导航以及对 DNA 和蛋白质序列的理解和操作。重要的是，与之前的科学基准相比，我们预计能够在更困难的 LAB-Bench 任务上取得持续高分的 AI 系统将成为文献检索和分子克隆等领域研究人员的有用助手。作为对前沿语言模型新兴科学任务能力的初步评估，我们根据基准测量了几个模型的性能，并报告了与人类专家生物学研究人员的比较结果。我们将继续更新和扩展 LAB-Bench，并期望它成为未来自动化研究系统开发的有用工具。LAB-Bench 的公共子集可在以下 URL 上使用：https://huggingface.co/datasets/futurehouse/lab-bench]]></description>
      <guid>https://arxiv.org/abs/2407.10362</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:38 GMT</pubDate>
    </item>
    <item>
      <title>Lean-STaR：学习交织思考与证明</title>
      <link>https://arxiv.org/abs/2407.10040</link>
      <description><![CDATA[arXiv:2407.10040v1 公告类型：新
摘要：传统的基于语言模型的定理证明假设通过对足够数量的形式化证明数据进行训练，模型将学会证明定理。我们的主要观察是，形式化证明中不存在的大量非正式信息对于学习证明定理很有用。例如，人类会思考证明的步骤，但这种思考过程在生成的代码中是不可见的。我们提出了 Lean-STaR，这是一个用于训练语言模型的框架，可在证明的每个步骤之前产生非正式的想法，从而增强模型的定理证明能力。Lean-STaR 使用回顾性基本事实策略来生成用于训练语言模型的综合想法。在推理时，训练后的模型会在每个证明步骤中预测策略之前直接生成想法。在自学推理框架的基础上，我们应用专家迭代进一步微调模型，使其能够使用 Lean 求解器对正确证明进行采样和验证。Lean-STaR 在 Lean 定理证明环境中的 miniF2F 测试基准上取得了最佳结果，显著优于基础模型（$\boldsymbol{43.4\% \rightarrow 46.3\%,}$ Pass@64）。我们还分析了增强思维对定理证明过程各个方面的影响，从而深入了解了它们的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.10040</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>ChatLogic：将逻辑编程与大型语言模型相结合，实现多步推理</title>
      <link>https://arxiv.org/abs/2407.10162</link>
      <description><![CDATA[arXiv:2407.10162v1 公告类型：新
摘要：大型语言模型（LLM）如 ChatGPT 和 GPT-4 在各种生成任务中表现出令人印象深刻的能力。然而，它们的性能往往受到访问和利用长期记忆的限制，导致特定的脆弱性和偏见，尤其是在长时间交互期间。本文介绍了 ChatLogic，这是一个专门针对 LLM 推理任务的创新框架，它可以通过集成逻辑编程来提高 LLM 在多步演绎推理任务中的性能。在 ChatLogic 中，语言模型起着核心作用，充当控制器并参与每个系统操作阶段。我们提出了一种将逻辑问题转换为带有推理引​​擎的符号集成的新方法。这种方法利用大型语言模型的情境理解和模仿技能，并使用符号记忆来增强多步演绎推理能力。我们的结果表明，ChatLogic 框架显着提高了 LLM 的多步推理能力。源代码和数据可在 \url{https://github.com/Strong-AI-Lab/ChatLogic} 获取]]></description>
      <guid>https://arxiv.org/abs/2407.10162</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>AlphaDou：集成竞价的高性能端到端斗地主AI</title>
      <link>https://arxiv.org/abs/2407.10279</link>
      <description><![CDATA[arXiv:2407.10279v1 Announce Type: new 
摘要：卡牌游戏人工智能一直是人工智能研究的热门话题，近年来，麻将、德州扑克等复杂卡牌游戏陆续被攻克，相应的人工智能程序也达到了人类专家的水平。然而，斗地主游戏由于其巨大的状态/动作空间，以及涉及竞争与合作推理的独特特点，给游戏带来了巨大的挑战，使得该游戏极难解决。使用深度蒙特卡洛算法框架训练的强化学习模型DouZero在斗地主游戏中表现出色，但其简化的游戏环境与实际的斗地主环境存在差异，其性能与人类专家仍有相当大的距离。本文利用强化学习对深度蒙特卡洛算法框架进行修改，得到一个同时估计胜率和期望的神经网络，利用期望对动作空间进行剪枝，并根据胜率生成策略。该 RL 模型在真实的豆滴猪环境中进行训练，在公开模型中达到了最先进水平。]]></description>
      <guid>https://arxiv.org/abs/2407.10279</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>利用语言模型加速 A* 搜索的训练数据方法</title>
      <link>https://arxiv.org/abs/2407.09985</link>
      <description><![CDATA[arXiv:2407.09985v1 公告类型：新 
摘要：AI 规划领域的最新研究提出将 LLM 与 A* 和 MCTS 等迭代树搜索算法相结合，其中 LLM 通常用于计算启发式算法，引导规划器实现目标。然而，结合这些技术并不是一件容易的事：基于 LM 的启发式算法非常弱，计算成本很高，而性能却没有显著提高。现有的学习这些启发式方法没有考虑规划器的要求，通常需要大量的计算。因此，在这项工作中，我们提出了一种分布，通过识别相关数据点来下采样训练数据，以学习高性能的启发式算法，同时限制计算成本。为了得到这个模型，我们将规划器（在我们的例子中是 A* 搜索）的要求与语言模型的要求区分开来，以概括这项任务。令人惊讶的是，我们发现它们的需求有重叠； A* 需要对目标附近的节点进行更准确的预测，而 LM 需要相同的节点集才能有效泛化。有了这些见解，我们可以量化每个节点对加速 A* 搜索的贡献，并随后得出用于学习基于 LM 的启发式方法的训练分布。根据最近的一项研究，我们在两个经典规划领域（迷宫导航和推箱子）上进行了实验，每个领域有两个测试分割，以及两个常规损失函数。我们将找到解决方案所需的迭代次数减少了 13 倍，挂钟速度提高了 5 倍。]]></description>
      <guid>https://arxiv.org/abs/2407.09985</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:36 GMT</pubDate>
    </item>
    <item>
      <title>AtomAgents：通过物理感知多模态多智能体人工智能进行合金设计和发现</title>
      <link>https://arxiv.org/abs/2407.10022</link>
      <description><![CDATA[arXiv:2407.10022v1 公告类型：新
摘要：合金设计是一个多尺度问题，需要采用整体方法，包括检索相关知识、应用先进的计算方法、进行实验验证和分析结果，这个过程通常由人类专家完成。机器学习 (ML) 可以帮助加速这一过程，例如，通过使用将结构特征与材料特性联系起来的深度替代模型，反之亦然。然而，现有的数据驱动模型通常针对特定的材料目标，在整合领域外知识方面灵活性有限，无法适应新的、不可预见的挑战。在这里，我们通过利用多个 AI 代理的独特功能来克服这些限制，这些代理在动态环境中自主协作以解决复杂的材料设计任务。所提出的物理感知生成式 AI 平台 AtomAgents 结合了大型语言模型 (LLM) 的智能以及在各个领域具有专业知识的 AI 代理之间的动态协作，包括知识检索、多模态数据集成、基于物理的模拟以及跨模态的综合结果分析，其中包括数值数据和物理模拟结果的图像。多智能体系统的协同努力可以解决复杂的材料设计问题，例如自主设计与纯金属相比性能增强的金属合金。我们的结果能够准确预测合金的关键特性，并强调了固溶体合金化在引导先进金属合金开发方面的关键作用。我们的框架提高了复杂多目标设计任务的效率，并为生物医学材料工程、可再生能源和环境可持续性等领域开辟了新途径。]]></description>
      <guid>https://arxiv.org/abs/2407.10022</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:36 GMT</pubDate>
    </item>
    <item>
      <title>通过欺骗手段保护 MDP 中奖励函数的隐私</title>
      <link>https://arxiv.org/abs/2407.09809</link>
      <description><![CDATA[arXiv:2407.09809v1 公告类型：新
摘要：当决策可观察时，保护顺序决策代理的偏好（或奖励）的隐私在许多物理和网络安全领域至关重要。例如，在野生动物监测中，代理必须分配巡逻资源而不向偷猎者透露动物位置。本文讨论了在 MDP 中规划一系列动作时的隐私保护，其中奖励函数表示要保护的偏好结构。观察者可以使用逆 RL (IRL) 来学习这些偏好，这是一项具有挑战性的任务。
当前对奖励函数中的差异隐私的研究无法确保对最低预期奖励的保证，并且提供的理论保证不足以对抗基于 IRL 的观察者。为了弥补这一差距，我们提出了一种基于欺骗理论的新方法。欺骗包括两种模型：掩饰（隐藏真相）和模拟（显示错误）。我们的第一个贡献从理论上证明了现有基于掩饰的方法中存在严重的隐私泄露。我们的第二个贡献是一种新颖的基于 RL 的规划算法，该算法使用模拟来有效解决这些隐私问题，同时确保预期奖励的保证。对多个基准问题的实验表明，我们的方法在保护奖励函数隐私方面优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.09809</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:35 GMT</pubDate>
    </item>
    <item>
      <title>CellAgent：一个由 LLM 驱动的用于自动单细胞数据分析的多代理框架</title>
      <link>https://arxiv.org/abs/2407.09811</link>
      <description><![CDATA[arXiv:2407.09811v1 公告类型：新
摘要：单细胞 RNA 测序 (scRNA-seq) 数据分析对于生物研究至关重要，因为它能够精确表征细胞异质性。然而，手动操作各种工具来实现预期结果对研究人员来说可能是劳动密集型的。为了解决这个问题，我们引入了 CellAgent (http://cell.agent4science.cn/)，这是一个 LLM 驱动的多智能体框架，专门设计用于自动处理和执行 scRNA-seq 数据分析任务，无需人工干预即可提供高质量的结果。首先，为了将一般的 LLM 应用于生物领域，CellAgent 构建了 LLM 驱动的生物专家角色——规划者、执行者和评估者，每个角色都有特定的职责。然后，CellAgent 引入了一种分层决策机制来协调这些生物专家，有效地推动了复杂数据分析任务的规划和分步执行。此外，我们提出了一种自迭代优化机制，使 CellAgent 能够自主评估和优化解决方案，从而保证输出质量。我们在包含数十种组织和数百种不同细胞类型的综合基准数据集上评估了 CellAgent。评估结果一致表明，CellAgent 有效地识别了最适合单细胞分析任务的工具和超参数，实现了最佳性能。这种自动化框架大大减少了科学数据分析的工作量，将我们带入了“科学代理”时代。]]></description>
      <guid>https://arxiv.org/abs/2407.09811</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:35 GMT</pubDate>
    </item>
    <item>
      <title>让 GPT-4o 发挥作用：对语言、视觉、语音和多模态能力的全面评估</title>
      <link>https://arxiv.org/abs/2407.09519</link>
      <description><![CDATA[arXiv:2407.09519v1 公告类型：新
摘要：随着大型语言模型（LLM）的不断发展，评估其综合能力对于其在各个领域的应用具有重要意义。本研究全面评估了 GPT-4o 的语言、视觉、语音和多模态能力。该研究采用标准化考试问题、推理任务和翻译评估来评估模型的语言能力。此外，GPT-4o 的视觉和语音能力通过图像分类和对象识别任务以及口音分类进行测试。多模态评估评估模型在整合视觉和语言数据方面的表现。我们的研究结果表明，GPT-4o 在语言和推理能力的多个领域表现出很高的准确性和效率，在需要少量学习的任务中表现出色。与前代产品相比，GPT-4o 在多模态任务方面也有了显着的改进。然而，该模型表现出多变性，在处理复杂和模糊的输入方面面临局限性，特别是在音频和视觉能力方面。本文强调需要更全面的基准和强大的评估框架，包括涉及人类判断的定性评估以及错误分析。未来的工作应侧重于扩展数据集、研究基于提示的评估以及增强少量学习技术，以测试模型在现实场景中的实际适用性和性能。]]></description>
      <guid>https://arxiv.org/abs/2407.09519</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:34 GMT</pubDate>
    </item>
    <item>
      <title>我们达到 AGI 了吗？将 ChatGPT、Claude 和 Gemini 与人类识字和教育基准进行比较</title>
      <link>https://arxiv.org/abs/2407.09573</link>
      <description><![CDATA[arXiv:2407.09573v1 公告类型：新
摘要：人工智能的最新进展，尤其是 ChatGPT、Claude 和 Gemini 等大型语言模型 (LLM) 的进展，引发了人们对它们与通用人工智能 (AGI) 的接近程度的质疑。本研究使用美国人口普查局和技术报告的数据，将 LLM 在教育基准上的表现与美国人的平均教育水平和识字水平进行了比较。结果表明，LLM 在本科知识和高级阅读理解等任务上的表现明显优于人类基准，表明在 AGI 方面取得了实质性进展。然而，真正的 AGI 需要更广泛的认知评估。该研究强调了对人工智能发展、教育和社会影响的影响，强调需要持续研究和道德考虑。]]></description>
      <guid>https://arxiv.org/abs/2407.09573</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:34 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 有意识吗？</title>
      <link>https://arxiv.org/abs/2407.09517</link>
      <description><![CDATA[arXiv:2407.09517v1 公告类型：新
摘要：GPT-4 经常被誉为领先的商业 AI 产品，引发了关于其作为迈向通用人工智能的垫脚石的潜力的争论。但它有意识吗？本文使用构建块理论的九个定性测量来研究这个关键问题。将 GPT-4 的设计、架构和实现与意识的每个构建块进行比较，以确定它是否已达到被归类为意识的必要里程碑，如果没有，GPT-4 离意识有多近。我们的评估是，虽然 GPT-4 在其原生配置下目前没有意识，但当前的技术研究和开发足以修改 GPT-4 以拥有意识的所有构建块。因此，我们认为有意识的人工智能模型在短期内出现是合理的。本文最后全面讨论了设计有意识的人工智能实体的伦理影响和社会影响。]]></description>
      <guid>https://arxiv.org/abs/2407.09517</guid>
      <pubDate>Wed, 17 Jul 2024 03:23:33 GMT</pubDate>
    </item>
    </channel>
</rss>