<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 24 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 Lyapunov Barrier 证书正式验证深度强化学习控制器</title>
      <link>https://arxiv.org/abs/2405.14058</link>
      <description><![CDATA[arXiv:2405.14058v1 公告类型：新 
摘要：深度强化学习（DRL）是一种强大的机器学习范例，用于生成控制自主系统的代理。然而，DRL 代理的“黑匣子”性质限制了它们在现实世界的安全关键型应用中的部署。为代理的行为提供强有力保证的一种有前途的方法是使用神经李亚普诺夫屏障（NLB）证书，它是系统学习的函数，其属性间接暗示代理的行为符合预期。然而，基于 NLB 的证书通常难以学习，甚至更难以验证，尤其是对于复杂的系统。在这项工作中，我们提出了一种为离散时间系统训练和验证基于 NLB 的证书的新方法。具体来说，我们引入了一种证书组合技术，该技术通过策略性地设计证书序列来简化高度复杂系统的验证。当与神经网络验证引擎联合验证时，这些证书提供了 DRL 代理实现其目标并避免不安全行为的正式保证。此外，我们引入了一种证书过滤技术，该技术大大简化了生成正式验证证书的过程。我们通过一个为 DRL 控制的航天器提供安全性和活性保证的案例研究来展示我们方法的优点。]]></description>
      <guid>https://arxiv.org/abs/2405.14058</guid>
      <pubDate>Fri, 24 May 2024 06:26:36 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的意义和感受：生成人工智能中潜在状态的可观测性</title>
      <link>https://arxiv.org/abs/2405.14061</link>
      <description><![CDATA[arXiv:2405.14061v1 公告类型：新 
摘要：我们解决了大型语言模型（LLM）是否可观察的问题，该模型被视为在符号标记的嵌入空间中状态演化的动态系统。也就是说，是否存在多个产生相同生成标记序列的“心理”状态轨迹，或者属于同一 Nerode 等价类（“含义”）的序列。如果不可观察，由输入（“感知”）或模型自身状态（“想法”）的反馈引起的心理状态轨迹（“体验”）可能会保持独立，并在用户不知情的情况下演变，同时可能被其他人访问。模型提供者。这种“由感知或思想引发的独立体验”类似于美国心理学会（APA）所定义的“感觉”。除了词汇上的好奇心之外，我们还表明，根据此定义，当前由自回归 Transformer 实现的 LLM 不能具有“感觉”：与标记化输出无法区分的状态轨迹集是单例。但是，如果存在用户看不到的“系统提示”，那么这组无法区分的轨迹就变得很重要，并且可能有多个状态轨迹产生相同的语言输出。我们通过分析证明了这些主张，并展示了对标准法学硕士进行修改的例子，这些修改产生了这种“感觉”。我们的分析揭示了可能的设计，使模型能够执行用户不可见的重要计算，以及使用该模型的服务提供商可以采取的控制措施，以防止意外行为。]]></description>
      <guid>https://arxiv.org/abs/2405.14061</guid>
      <pubDate>Fri, 24 May 2024 06:26:36 GMT</pubDate>
    </item>
    <item>
      <title>不确定性因果模型</title>
      <link>https://arxiv.org/abs/2405.14001</link>
      <description><![CDATA[arXiv:2405.14001v1 公告类型：新 
摘要：我将非循环确定性结构方程模型推广到非确定性情况，并认为它为反事实提供了改进的语义。 Halpern 开发的标准、确定性语义（基于 Galles 和 Pearl 的最初提议）假设，对于父变量的每次赋值，其子变量都有一个唯一的赋值，并且它假设现实世界（为模型的所有变量赋值）为每次干预指定一个独特的反事实世界。这两个假设都是不现实的，因此我在我的提案中放弃了这两个假设。我通过在结构方程中允许多值函数来实现这一点。此外，我还调整了语义，以便在现实世界中获得的方程的解可以保留在任何反事实世界中。我通过将其与 Halpern 的标准逻辑以及更接近我的最新提议进行比较来激发由此产生的逻辑。最后，我将这些模型扩展到概率案例，并表明即使在因果贝叶斯网络中，它们也为识别反事实开辟了道路。]]></description>
      <guid>https://arxiv.org/abs/2405.14001</guid>
      <pubDate>Fri, 24 May 2024 06:26:35 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行即时本体驱动的符号知识捕获</title>
      <link>https://arxiv.org/abs/2405.14012</link>
      <description><![CDATA[arXiv:2405.14012v1 公告类型：新 
摘要：在个人助理等应用中，大语言模型（LLM）必须考虑用户的个人信息和偏好。然而，法学硕士缺乏从用户交互中学习的固有能力。本文探索使用本体论和知识图谱方法从用户提示中捕获个人信息。我们使用 KNOW 本体的一个子集（对个人信息进行建模）来训练这些概念的语言模型。然后，我们使用专门构建的数据集评估知识捕获的成功。我们的代码和数据集可在 https://github.com/HaltiaAI/paper-PTODSKC 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2405.14012</guid>
      <pubDate>Fri, 24 May 2024 06:26:35 GMT</pubDate>
    </item>
    <item>
      <title>FiDeLiS：知识图问答大语言模型中的忠实推理</title>
      <link>https://arxiv.org/abs/2405.13873</link>
      <description><![CDATA[arXiv:2405.13873v1 公告类型：新 
摘要：虽然大型语言模型（LLM）在各种应用中取得了巨大的成功，但它们经常与幻觉作斗争，特别是在需要深度和负责任的推理的场景中。通过在法学硕士推理中集成外部知识图（KG）可以部分缓解这些问题。然而，它们的结合方法仍然很大程度上未被探索。在本文中，我们提出了一种检索探索交互方法 FiDelis 来处理基于知识图谱的推理中间步骤。具体来说，我们提出了 Path-RAG 模块，用于从 KG 中调用有用的中间知识以进行 LLM 推理。我们将LLM的逻辑和常识推理以及知识图谱的拓扑连通性融入到知识检索过程中，从而提供更准确的回忆性能。此外，我们建议利用法学硕士的演绎推理能力作为更好的标准，以逐步且可推广的方式自动指导推理过程。演绎验证可以作为何时停止进一步推理的精确指标，从而避免误导推理链和不必要的计算。大量的实验表明，我们的方法作为一种免训练方法，具有较低的计算成本和更好的通用性，在三个基准测试中优于现有的强基线。]]></description>
      <guid>https://arxiv.org/abs/2405.13873</guid>
      <pubDate>Fri, 24 May 2024 06:26:34 GMT</pubDate>
    </item>
    <item>
      <title>使用决斗 Q 学习和 Hebbian 可塑性学习玩 Atari 游戏</title>
      <link>https://arxiv.org/abs/2405.13960</link>
      <description><![CDATA[arXiv:2405.13960v1 公告类型：新 
摘要：在这项工作中，先进的深度强化学习架构被用来训练玩 atari 游戏的神经网络代理。仅给定原始游戏像素、动作空间和奖励信息，系统就可以训练智能体玩任何 Atari 游戏。首先，该系统使用深度 Q 网络和决斗 Q 网络等先进技术来训练高效的智能体，这与 DeepMind 用来训练在 Atari 游戏中击败人类玩家的智能体的技术相同。作为扩展，使用可塑神经网络作为代理，并在此场景中分析其可行性。可塑性的实现基于反向传播和赫布更新规则。可塑神经网络具有初始训练后终身学习等优异特性，这使得它们非常适合自适应学习环境。作为这种背景下对可塑性的新分析，这项工作可能为未来的工作提供有价值的见解和方向。]]></description>
      <guid>https://arxiv.org/abs/2405.13960</guid>
      <pubDate>Fri, 24 May 2024 06:26:34 GMT</pubDate>
    </item>
    <item>
      <title>论代理大型语言模型的 ReAct 提示的脆弱基础</title>
      <link>https://arxiv.org/abs/2405.13966</link>
      <description><![CDATA[arXiv:2405.13966v1 公告类型：新 
摘要：大型语言模型（LLM）的推理能力仍然是一个争论的话题。一些方法（例如基于 ReAct 的提示）因声称可以增强代理法学硕士的顺序决策能力而受到欢迎。然而，目前尚不清楚基于 ReAct 的提示对 LLM 推理的改进来源是什么。在本文中，我们研究了基于 ReAct 的提示在改进代理法学硕士以进行顺序决策方面的这些主张。通过在输入提示中引入系统变化，我们根据 ReAct 的声明进行了敏感性分析，发现性能受“推理跟踪与动作执行交错”或 ReAct 中生成的推理跟踪内容的影响最小，这与原始的相反声明和常见用法。相反，法学硕士的性能是由输入示例任务和查询之间的相似性驱动的，隐含地迫使提示设计者提供特定于实例的示例，这显着增加了人类的认知负担。我们的调查表明，法学硕士的感知推理能力源于样本查询相似性和近似检索，而不是任何固有的推理能力。]]></description>
      <guid>https://arxiv.org/abs/2405.13966</guid>
      <pubDate>Fri, 24 May 2024 06:26:34 GMT</pubDate>
    </item>
    <item>
      <title>用于可证明安全的强化学习的动态模型预测屏蔽</title>
      <link>https://arxiv.org/abs/2405.13863</link>
      <description><![CDATA[arXiv:2405.13863v1 公告类型：新 
摘要：在可证明安全的强化学习方法中，模型预测屏蔽（MPS）已被证明可以有效地处理连续、高维状态空间中的复杂任务，当学习到的策略尝试采取危险行动时，通过利用备份策略来确保安全。然而，虽然 MPS 可以确保训练期间和训练后的安全，但由于备份策略的保守性和任务遗忘性，它常常阻碍任务进度。本文介绍了动态模型预测屏蔽（DMPS），它可以优化强化学习目标，同时保持可证明的安全性。 DMPS 聘请本地规划人员动态选择安全恢复行动，以最大限度地提高短期进展和长期回报。至关重要的是，规划器和神经策略在 DMPS 中发挥着协同作用。在规划恢复行动以确保安全时，规划器利用神经策略来估计长期奖励，使其能够超越短期规划范围进行观察。相反，训练中的神经策略从规划者提出的恢复计划中学习，收敛到在实践中既高性能又安全的策略。这种方法保证了训练期间和训练后的安全，并且有限的恢复遗憾随着规划水平深度呈指数下降。实验结果表明，与几个最先进的基线相比，DMPS 收敛于训练后很少需要屏蔽干预的策略，并获得更高的奖励。]]></description>
      <guid>https://arxiv.org/abs/2405.13863</guid>
      <pubDate>Fri, 24 May 2024 06:26:33 GMT</pubDate>
    </item>
    <item>
      <title>思维图像提示有助于多模态大型语言模型中的视觉推理细化</title>
      <link>https://arxiv.org/abs/2405.13872</link>
      <description><![CDATA[arXiv:2405.13872v1 公告类型：新 
摘要：思想链（CoT）和相关基于理论基础的工作的最新进展显着提高了大型语言模型（LLM）在复杂推理任务中的性能。随着多模态大语言模型（MLLM）的发展，增强其解决复杂多模态推理问题的能力是一个关键前沿。然而，将多模式纳入 CoT 的基本原理尚未得到彻底研究。我们提出了思维图像（IoT）提示方法，帮助 MLLM 逐步提取视觉原理。具体来说，物联网提示可以根据输入图像和问题自动设计关键视觉信息提取操作。视觉信息细化的每一步都确定了支持复杂视觉推理问题答案的特定视觉原理。除了文本 CoT 之外，物联网还同时利用视觉和文本原理来帮助 MLLM 理解复杂的多模式信息。 IoT 提示提高了不同 MLLM 中各种视觉理解任务的零样本视觉推理性能。此外，物联网提示生成的逐步视觉特征解释阐明了视觉推理过程，有助于分析大型多模态模型的认知过程]]></description>
      <guid>https://arxiv.org/abs/2405.13872</guid>
      <pubDate>Fri, 24 May 2024 06:26:33 GMT</pubDate>
    </item>
    <item>
      <title>COTET：知识图实体类型的跨视图最佳传输</title>
      <link>https://arxiv.org/abs/2405.13602</link>
      <description><![CDATA[arXiv:2405.13602v1 公告类型：新 
摘要：知识图实体类型（KGET）旨在推断知识图中缺失的实体类型实例。以前的研究主要集中在利用与实体相关的上下文信息，这为推理提供了有价值的线索。然而，他们长期以来忽视了实体固有的信息的双重性，既包含高级粗粒度集群知识，又包含细粒度类型知识。本文介绍了知识图实体类型的跨视图最优传输（COTET），这是一种有效地将类型如何聚类的信息合并到实体和类型的表示中的方法。 COTET 包含三个模块：i）多视图生成和编码器，通过实体类型、实体集群和类型集群类型视角捕获不同粒度级别的结构化知识； ii) 跨视图最优传输，通过从分布对齐的角度最小化 Wasserstein 距离，将视图特定的嵌入传输到统一空间； iii) 基于池的实体类型预测，采用混合池机制来聚合来自实体的不同邻居的预测分数。此外，我们引入了基于分布的损失函数，以减少训练期间漏报的发生。大量实验证明了 COTET 与现有基线相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.13602</guid>
      <pubDate>Fri, 24 May 2024 06:26:32 GMT</pubDate>
    </item>
    <item>
      <title>ConcertoRL：一种创新的时间交错强化学习方法，用于增强直驱串联翼车辆的控制</title>
      <link>https://arxiv.org/abs/2405.13651</link>
      <description><![CDATA[arXiv:2405.13651v1 公告类型：新 
摘要： 在串联翼影响下的昆虫规模直驱实验平台的控制问题中，现有强化学习模型面临的首要挑战是其探索过程中有限的安全性和连续训练过程的稳定性。我们引入了 ConcertoRL 算法来提高控制精度并稳定在线训练过程，该算法包括两个主要创新：将经典控制器与基于强化学习的控制器交织在一起的时间交织机制，旨在提高初始阶段的控制精度；策略Composer整理了之前学习的经验，保证在线培训过程的稳定性。本文进行了一系列实验。首先，结合时间交错机制的实验表明，与没有强化学习增强的场景相比，性能大幅提升约 70%，与控制频率加倍的参考控制器相比，效率提高了 50%。这些结果凸显了该算法产生超过各部分总和的协同效应的能力。]]></description>
      <guid>https://arxiv.org/abs/2405.13651</guid>
      <pubDate>Fri, 24 May 2024 06:26:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能科学家的“图灵测试”</title>
      <link>https://arxiv.org/abs/2405.13352</link>
      <description><![CDATA[arXiv:2405.13352v1 公告类型：新 
摘要：虽然法学硕士在解决数学或编码问题方面表现出了令人印象深刻的能力，但做出科学发现的能力仍然是一个明显的挑战。本文提出了“人工智能科学家的图灵测试”，以评估人工智能代理是否可以独立进行科学研究，而不依赖于人类生成的知识。从科学的历史发展中汲取灵感，我们提出了七项基准测试，用于评估人工智能代理在各个科学领域做出突破性发现的能力。这些测试包括从天体观测中推断日心模型，发现模拟环境中的运动定律，推导控制振动弦的微分方程，从电动力学模拟中推断麦克斯韦方程，发明初始值问题的数值方法，发现用于数据压缩的霍夫曼编码，并开发高效的排序算法。为了确保这些测试的有效性，人工智能代理提供了针对每个问题的交互式库或数据集，而无需访问可能包含有关目标发现的信息的人类知识。最终目标是创造一名人工智能科学家，能够做出新颖且有影响力的科学发现，超越各自领域最优秀的人类专家。这些“图灵测试”充当中间里程碑，评估人工智能代理做出当时开创性发现的能力。如果人工智能代理能够通过这七项测试中的大部分，这将表明在培养人工智能科学家方面取得了重大进展，为未来自主科学发现的进步铺平了道路。本文旨在为人工智能在科学研究中的能力建立一个基准，并促进这一令人兴奋的领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2405.13352</guid>
      <pubDate>Fri, 24 May 2024 06:26:31 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型 (LLM) 辅助城市环境中的无线网络部署</title>
      <link>https://arxiv.org/abs/2405.13356</link>
      <description><![CDATA[arXiv:2405.13356v1 公告类型：新 
摘要：大型语言模型 (LLM) 的出现彻底改变了语言理解和类人文本生成，引起了许多其他领域的兴趣，并牢记这个问题：LLM 还能做什么？尽管它们被广泛采用，但正在进行的研究仍在继续探索将法学硕士集成到不同系统中的新方法。
  本文探讨了利用法学硕士力量实现 6G（第六代）无线通信技术的新技术，这是一个自动化和智能系统至关重要的领域。法学硕士对特定领域任务的固有适应性使它们成为增强 6G 环境中无线系统的主要候选人。
  我们引入了一种新颖的基于强化学习 (RL) 的框架，该框架利用 LLM 进行无线通信中的网络部署。我们的方法包括在城市环境中以法学硕士为核心培训 RL 代理，以最大限度地扩大覆盖范围。该代理的目标是驾驭复杂的城市环境并确定最佳区域覆盖的网络参数。此外，我们将法学硕士与卷积神经网络（CNN）相结合，以利用它们的优势，同时减轻它们的局限性。采用深度确定性策略梯度 (DDPG) 算法进行训练。结果表明，LLM 辅助模型在某些情况下可以优于基于 CNN 的模型，而在其他情况下至少表现同样好。]]></description>
      <guid>https://arxiv.org/abs/2405.13356</guid>
      <pubDate>Fri, 24 May 2024 06:26:31 GMT</pubDate>
    </item>
    <item>
      <title>区块链和人工智能：协同与冲突</title>
      <link>https://arxiv.org/abs/2405.13462</link>
      <description><![CDATA[arXiv:2405.13462v1 公告类型：新
摘要：区块链技术和人工智能 (AI) 已成为各自领域的变革力量。本文探讨了这两种技术之间的协同作用和挑战。我们的研究根据市值分析了结合区块链和人工智能的最大项目，并得出了一个新颖的框架来对当代和未来的用例进行分类。尽管理论上兼容，但目前结合区块链和人工智能的现实世界应用仍处于起步阶段。]]></description>
      <guid>https://arxiv.org/abs/2405.13462</guid>
      <pubDate>Fri, 24 May 2024 06:26:31 GMT</pubDate>
    </item>
    <item>
      <title>多重可实现性和深度学习的兴起</title>
      <link>https://arxiv.org/abs/2405.13231</link>
      <description><![CDATA[arXiv:2405.13231v1 公告类型：新 
摘要：多重可实现性理论认为，心理状态可以在多种物理系统中实现。深度学习革命似乎正在将这种可能性变为现实，提供迄今为止最合理的人造实现复杂认知功能的例子。本文探讨了深度学习模型对多重可实现性论文的影响。除其他外，它挑战了广泛持有的观点，即多重可实现性意味着对心灵的研究可以而且必须独立于对其在大脑或人工类似物中的实现的研究进行。尽管其核心贡献是哲学性的，但这篇论文对当代认知科学具有实质性的方法论成果，表明深度神经网络可能在制定和评估认知假设方面发挥着至关重要的作用，即使它们被解释为实现级模型。在深度学习时代，多重可实现性具有新的意义。]]></description>
      <guid>https://arxiv.org/abs/2405.13231</guid>
      <pubDate>Fri, 24 May 2024 06:26:30 GMT</pubDate>
    </item>
    <item>
      <title>目标作为奖励计划</title>
      <link>https://arxiv.org/abs/2405.13242</link>
      <description><![CDATA[arXiv:2405.13242v1 公告类型：新 
摘要：人们非常有能力制定自己的目标，从儿童游戏开始一直持续到成年。尽管对目标和目标导向行为进行了大量的实证和计算工作，但模型仍然远未捕捉到人类日常目标的丰富性。在这里，我们通过收集人类生成的有趣目标的数据集，将它们建模为产生奖励的程序，并通过程序合成生成新颖的类人目标来弥补这一差距。产生奖励的程序通过组合符号操作来捕获目标的丰富语义，添加时间约束，并允许程序在行为跟踪上执行以评估进度。为了构建目标的生成模型，我们在无限可能的目标程序集上学习适应度函数，并使用质量多样性算法对新目标进行采样。人类评估者发现，当从人类示例占用的程序空间分区中采样时，模型生成的目标与人类创建的游戏没有区别。我们还发现，我们模型的内部适应度分数可以预测被评估为更有趣且更人性化的游戏。]]></description>
      <guid>https://arxiv.org/abs/2405.13242</guid>
      <pubDate>Fri, 24 May 2024 06:26:30 GMT</pubDate>
    </item>
    <item>
      <title>Mamo：带有求解器的数学建模基准</title>
      <link>https://arxiv.org/abs/2405.13144</link>
      <description><![CDATA[arXiv:2405.13144v1 公告类型：新 
摘要：数学建模涉及使用数学表达式和方程来表示现实世界的现象、系统或问题，以分析、理解和预测其行为。鉴于此过程通常需要经验丰富的专家，因此人们有兴趣探索大型语言模型（LLM）是否可以进行数学建模以潜在地减少人力。为了评估数学建模方面的法学硕士，我们引入了一个新的基准 Mamo，它超越了传统的以结果为导向的评估。与主要根据数学问题解决方案的准确性来评估法学硕士的传统方法不同，我们的方法提供了对建模过程本身的更深入的了解。通过关注法学硕士所采取的过程而不是最终解决方案的正确性，Mamo 开创了一种新颖的评估范式。这一转变强调了理解法学硕士固有建模能力的重要性，为更细致、更全面地分析其解决问题策略铺平了道路。我们的工作标志着该领域的重大进步，通过强调法学硕士建模过程的评估而不是单纯答案的正确性，为未来的研究提出了新的方向。该基准不仅有助于更好地理解法学硕士的数学建模能力，还为评估其在复杂问题解决场景中的表现设立了新标准。]]></description>
      <guid>https://arxiv.org/abs/2405.13144</guid>
      <pubDate>Fri, 24 May 2024 06:26:29 GMT</pubDate>
    </item>
    <item>
      <title>人工智能聊天机器人根据患者投诉预测疾病的可靠性如何？</title>
      <link>https://arxiv.org/abs/2405.13219</link>
      <description><![CDATA[arXiv:2405.13219v1 公告类型：新 
摘要：利用大型语言模型 (LLM) 的人工智能 (AI) 聊天机器人因其在自动化患者交互和辅助临床决策方面的潜力而在医疗保健领域受到关注。本研究检验了人工智能聊天机器人（特别是 GPT 4.0、Claude 3 Opus 和 Gemini Ultra 1.0）在根据急诊科患者投诉预测疾病方面的可靠性。该方法包括少量学习技术，用于评估聊天机器人在疾病预测方面的有效性。我们还对基于 Transformer 的模型 BERT 进行了微调，并将其性能与 AI 聊天机器人进行了比较。结果表明，GPT 4.0 通过增加少量样本数据实现了高精度，而 Gemini Ultra 1.0 在示例较少的情况下表现良好，而 Claude 3 Opus 保持了一致的性能。然而，BERT 的性能低于所有聊天机器人，这表明由于标记数据有限而存在局限性。尽管聊天机器人的准确性各不相同，但对于关键的医疗决策来说，它们都不够可靠，这凸显了严格验证和人工监督的必要性。这项研究表明，虽然人工智能聊天机器人在医疗保健领域具有潜力，但它们应该补充而不是取代人类专业知识，以确保患者安全。需要进一步完善和研究来提高基于人工智能的医疗保健应用程序的疾病预测可靠性。]]></description>
      <guid>https://arxiv.org/abs/2405.13219</guid>
      <pubDate>Fri, 24 May 2024 06:26:29 GMT</pubDate>
    </item>
    <item>
      <title>CausalPlayground：解决前沿因果关系研究中的数据生成要求</title>
      <link>https://arxiv.org/abs/2405.13092</link>
      <description><![CDATA[arXiv:2405.13092v1 公告类型：新 
摘要：由于缺乏具有真实效果的现实世界数据集，因果效应的研究通常依赖于合成数据。由于当前的数据生成工具并不总能满足最先进研究的所有要求，因此通常采用临时方法。这导致数据集之间的异质性并延迟研究进展。我们通过引入 CausalPlayground 来解决当前数据生成库的缺点，CausalPlayground 是一个 Python 库，它提供了用于生成、采样和共享结构因果模型 (SCM) 的标准化平台。 CausalPlayground 提供对 SCM、干预以及用于学习和定量研究的 SCM 数据集生成的细粒度控制。此外，通过与强化学习 (RL) 环境的标准框架 Gymnasium 集成，我们可以实现与 SCM 的在线交互。总的来说，通过引入 CausalPlayground，我们的目标是促进该领域更高效、更具可比性的研究。所有代码和 API 文档均可在 https://github.com/sa-and/CausalPlayground 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.13092</guid>
      <pubDate>Fri, 24 May 2024 06:26:28 GMT</pubDate>
    </item>
    <item>
      <title>情绪在在线健康社区信息支持问答对中的作用：多模态深度学习方法</title>
      <link>https://arxiv.org/abs/2405.13099</link>
      <description><![CDATA[arXiv:2405.13099v1 公告类型：新 
摘要：本研究探讨了在线健康社区中寻求信息支持的问题、答复和帮助评级之间的关系。我们创建了问题-响应对的标记数据集，并开发了多模式机器学习和深度学习模型，以可靠地预测信息支持问题和响应。我们采用可解释的人工智能来揭示信息支持交流中嵌入的情感，证明情感在提供信息支持中的重要性。此前尚未研究过情感支持和信息支持之间复杂的相互作用。该研究完善了社会支持理论，为用户决策辅助工具的开发奠定了基础。讨论了进一步的影响。]]></description>
      <guid>https://arxiv.org/abs/2405.13099</guid>
      <pubDate>Fri, 24 May 2024 06:26:28 GMT</pubDate>
    </item>
    </channel>
</rss>