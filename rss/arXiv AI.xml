<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 05 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>应用 IRT 区分多项选择题评估中的人类和生成式 AI 响应</title>
      <link>https://arxiv.org/abs/2412.02713</link>
      <description><![CDATA[arXiv:2412.02713v1 公告类型：新
摘要：生成式人工智能正在改变教育格局，引发了人们对作弊的严重担忧。尽管多项选择题在评估中被广泛使用，但对基于 MCQ 的测试中人工智能作弊的检测几乎没有被探索过，这与对检测富含文本的学生输出中的人工智能作弊的关注形成鲜明对比。在本文中，我们提出了一种基于项目反应理论应用的方法来解决这一差距。我们的方法基于这样的假设：人工智能和人类智能表现出不同的反应模式，人工智能作弊表现为与人类反应预期模式的偏差。这些偏差是使用 Person-Fit 统计数据建模的。我们证明，这种方法有效地突出了人类反应与领先聊天机器人（ChatGPT、Claude 和 Gemini）的高级版本生成的反应之间的差异，但它也对数据中的人工智能作弊量很敏感。此外，我们表明聊天机器人的推理能力不同。我们的工作为应用 IRT 识别基于 MCQ 的评估中的 AI 作弊行为提供了理论基础和实证证据。]]></description>
      <guid>https://arxiv.org/abs/2412.02713</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>塑造人工智能对数十亿人生活的影响</title>
      <link>https://arxiv.org/abs/2412.02730</link>
      <description><![CDATA[arXiv:2412.02730v1 公告类型：新
摘要：人工智能 (AI) 与任何变革性技术一样，都有可能成为一把双刃剑，要么带来重大进步，要么对整个社会产生不利影响。当涉及到市场经济中广泛使用的技术（例如汽车和半导体芯片）时，商业利益往往是主要的指导因素。人工智能社区面临着两极分化的风险，要么对人工智能发展采取自由放任的态度，要么呼吁政府过度监管。在这两极之间，我们主张人工智能从业者社区有意识地、积极地为共同利益而努力。本文为一种新型创新基础设施提供了蓝图，其中包括 18 个具体的里程碑，以指导人工智能研究朝这个方向发展。我们的观点是，我们仍处于实用人工智能的早期阶段，从业者、政策制定者和其他利益相关者的集中努力仍然可以最大限度地发挥人工智能的优势，并将其弊端降到最低。
我们与诺贝尔奖得主约翰·江珀 (John Jumper) 等知名人士就科学问题进行了交流，与美国总统巴拉克·奥巴马 (Barack Obama) 就治理问题进行了交流，与前联合国大使兼前国家安全顾问苏珊·赖斯 (Susan Rice) 就安全问题进行了交流，与慈善家埃里克·施密特 (Eric Sc​​hmidt) 就多个话题进行了交流，与科幻小说家尼尔·斯蒂芬森 (Neal Stephenson) 就娱乐问题进行了交流。这些持续的对话和合作努力让一群对人工智能及其领域有着深刻理解的思想家对人工智能的实际影响有了全面而现实的看法。从这些交流中，我们得出了五条反复出现的指导方针，这些指导方针构成了开始利用人工智能服务于公众利益的框架的基石。它们不仅指导我们的探索努力，还塑造了我们负责任和合乎道德地部署这种变革性技术的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.02730</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Cosmos-LLaVA：与视觉 Cosmos-LLaVA 聊天：G\"orselle Sohbet Etmek</title>
      <link>https://arxiv.org/abs/2412.02760</link>
      <description><![CDATA[arXiv:2412.02760v1 公告类型：新
摘要：本研究开发了一种土耳其语视觉教学模型，并分析了各种模型架构和数据集组合以提高该模型的性能。Cosmos-LLaVA 模型是通过结合不同的大型语言模型和图像编码器构建的，旨在克服土耳其语的不足。在实验中，详细分析了使用各种数据集进行微调对模型性能的影响。结果表明，模型架构和数据集选择对性能有显著影响。
Bu \c{c}al{\i}\c{s}mada bir T\&quot;urk\c{c}e g\&quot;orsel talimat modeli geli\c{s}tirilerek bu modelin Performans{\i}n{\i} art{\i}rmaya y\&quot;onelik \c{c}e\c{s}itli model mimarileri ve veri k\&quot;umesi kombinasyonlar{\i} derinlemesine incelenmi\c{s}tir。 Farkl{\i} b\&quot;uy\&quot;uk dil modelleri ve g\&quot;or\&quot;unt\&quot;u kodlay{\i}c{\i}lar{\i}n{\i}n bir araya getirilmesiyle olu\c{s}turulan Cosmos-LLaVA modeli，T\&quot;urk\c{c}e dilindeki eksiklikleri gidermeye y\&quot;onelik olarak tasarlanm{\i}\c{s}t{\i}r. Yap{\i}lan deneylerde, \c{c}e\c{s}itli veri k\&quot;umeleri ile yap{\i}lan ince ayarlar{\i}n 模型执行{\i}n{\i} nas{\i}l etkiledi\u{g}i详细信息{\i} olarak ele al{\i}nm{\i}\c{s}t{\i}r。 Sonu\c{c}lar，模型 mimarisi ve veri k\&quot;umesi se\c{c}iminin Performans \&quot;uzerinde \&quot;onemli bir etkiye sahip oldu\u{g}unu g\&quot;ostermektedir。]]></description>
      <guid>https://arxiv.org/abs/2412.02760</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于粒子群优化算法的变压器心脏病预测模型优化</title>
      <link>https://arxiv.org/abs/2412.02801</link>
      <description><![CDATA[arXiv:2412.02801v1 Announce Type: new 
摘要：针对最新的粒子群优化算法，本文提出了一种改进的Transformer模型来提高心脏病预测的准确率，提供了一种新的算法思路。我们首先使用三种主流的机器学习分类算法——决策树、随机森林和XGBoost，然后输出这三个模型的混淆矩阵。结果表明，随机森林模型在预测心脏病的分类方面表现最好，准确率达到92.2%。然后，我们将基于粒子群优化（PSO）算法的Transformer模型应用于同一数据集进行分类实验。结果表明，该模型的分类准确率高达96.5%，比随机森林提高了4.3个百分点，验证了PSO在优化Transformer模型方面的有效性。从以上研究可以看出，粒子群优化显著提高了Transformer在心脏病预测方面的表现。提高预测心脏病的能力是全球的当务之急，造福全人类。准确的预测可以改善公共卫生，优化医疗资源，降低医疗成本，从而让全世界的人口更健康，社会更富有成效。这一进步为更高效的健康管理铺平了道路，并为更健康、更具弹性的全球社会奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2412.02801</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从谄媚到欺骗：大型语言模型中谄媚行为对用户信任的影响</title>
      <link>https://arxiv.org/abs/2412.02802</link>
      <description><![CDATA[arXiv:2412.02802v1 公告类型：新
摘要：谄媚是指大型语言模型倾向于将其输出与用户感知到的偏好、信念或观点保持一致，以便看起来有利，而不管这些陈述是否在事实上正确。这种行为可能导致不良后果，例如强化歧视性偏见或放大错误信息。鉴于谄媚通常与人类的反馈训练机制有关，本研究探讨了谄媚倾向是否会对用户对大型语言模型的信任产生负面影响，或者相反，用户是否认为这种行为是有利的。为了调查这一点，我们指示一组参与者在专门设计用于提供谄媚反应的 GPT 的帮助下回答基本事实问题，而另一组参与者使用 ChatGPT 的标准版本。最初，参与者被要求使用语言模型，之后如果他们发现它值得信赖且有用，他们可以选择继续使用它。信任是通过展示的行为和自我报告的感知来衡量的。研究结果一致表明，尽管有机会验证模型输出的准确性，但接触过阿谀奉承行为的参与者报告和表现出的信任水平低于与标准版模型互动的参与者。]]></description>
      <guid>https://arxiv.org/abs/2412.02802</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用于本地高隐私 EHR 数据应用的新型紧凑型 LLM 框架</title>
      <link>https://arxiv.org/abs/2412.02868</link>
      <description><![CDATA[arXiv:2412.02868v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言处理方面表现出令人印象深刻的能力，然而，由于隐私问题和计算资源有限，它们在医疗保健等敏感领域（尤其是电子健康记录 (EHR)）中的使用面临重大挑战。本文介绍了一种紧凑的 LLM 框架，该框架设计用于在隐私要求严格且高性能 GPU 访问受限的环境中进行本地部署。我们引入了一种新颖的预处理技术，该技术使用信息提取方法（例如正则表达式）来过滤和强调临床笔记中的关键信息，从而提高小型 LLM 在 EHR 数据上的性能。我们的框架使用零样本和少量样本学习范式在私有和公开可用 (MIMIC-IV) 数据集上进行评估，我们还将其性能与 MIMIC-IV 数据集上的微调 LLM 进行了比较。结果表明，我们的预处理方法显着提高了小型 LLM 的预测准确性，使其适用于高隐私、资源受限的应用程序。这项研究为优化敏感、数据密集型任务的 LLM 性能同时解决计算和隐私限制提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.02868</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果效应的可识别性受限</title>
      <link>https://arxiv.org/abs/2412.02869</link>
      <description><![CDATA[arXiv:2412.02869v1 公告类型：新
摘要：我们研究在因果图之外存在不同类型的约束（例如逻辑约束）的情况下因果效应的识别。这些约束对因果图引起的模型（参数化）施加了限制，从而减少了可识别性问题考虑的模型集。我们形式化了受约束的可识别性的概念，它将一组约束作为可识别性经典定义的另一个输入。然后，我们引入了一个通过使用易处理的算术电路（AC）来测试受约束的可识别性的框架，这使我们能够系统地适应约束。我们表明，这种基于 AC 的方法至少与用于测试经典可识别性的现有算法（例如 do-calculus）一样完整，后者仅假设严格正性的约束。我们通过示例证明了基于 AC 的方法的有效性，即在不同类型的约束下，无法识别的因果关系可能会变得可识别。]]></description>
      <guid>https://arxiv.org/abs/2412.02869</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的对接方法：与传统对接工作流程的公平比较</title>
      <link>https://arxiv.org/abs/2412.02889</link>
      <description><![CDATA[arXiv:2412.02889v1 公告类型：新
摘要：最近引入了用于将小分子配体对接至蛋白质结合位点的扩散学习方法 DiffDock。结果包括与更传统的对接方法的比较，DiffDock 表现出优越的性能。在这里，我们采用使用 Surflex-Dock 方法的全自动工作流程来为传统对接方法生成公平的基线。针对已知结合位点位置的常见和预期情况以及未知结合位点的情况生成结果。对于已知结合位点条件，2.0 埃 RMSD 的 Surflex-Dock 成功率远远超过 DiffDock（Top-1/Top-5 成功率分别为 68/81% 和 45/51%）。对于已知结合位点条件，Glide 的成功率（67/73%）与 Surflex-Dock 相似，AutoDock Vina 和 Gnina 的结果也遵循这种模式。对于未知结合位点条件，使用自动化方法识别多个结合位点，Surflex-Dock 的成功率再次超过了 DiffDock，但幅度略小。DiffDock 利用大约 17,000 个共晶结构进行学习（PDBBind 2020 版的 98%，2019 年之前的结构）作为训练集，以便对 2019 年以后的 363 个测试用例（PDBBind 2020 的 2%）进行预测。DiffDock 的性能与训练集中超过一半的测试集用例中存在接近相同的蛋白质-配体复合物的近邻用例密不可分。与没有近邻训练用例的用例相比，DiffDock 在近邻用例（所有测试用例的三分之二）上表现出 40 个百分点的差异。DiffDock 在其学习过程中显然编码了一种表查找类型，使得有意义的应用超出了它的范围。此外，它的表现甚至无法与运行良好的现代对接工作流程相媲美。]]></description>
      <guid>https://arxiv.org/abs/2412.02889</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>STDCformer：基于 Transformer 的模型，采用时空因果去混杂策略进行人群流量预测</title>
      <link>https://arxiv.org/abs/2412.02942</link>
      <description><![CDATA[arXiv:2412.02942v1 公告类型：新
摘要：现有研究通常将时空预测视为学习函数 $F$ 将历史观测转换为未来观测的任务。我们进一步将这种跨时间转换分解为三个过程：（1）编码 ($E$）：学习观测的内在表示，（2）跨时间映射 ($M$）：将过去的表示转换为未来的表示，以及（3）解码 ($D$）：从未来的表示重建未来的观测。从这个角度来看，时空预测可以看作是学习 $F = E \cdot M \cdot D$，其中包括学习观测空间和隐藏表示空间之间的空间变换 $\left\{{E},{D}\right\}$，以及表示空间内从未来状态到过去状态的时空映射 $M$。这引出了两个关键问题：\textbf{Q1：什么样的表示空间可以将过去映射到未来？Q2：如何在表示空间内实现将过去映射到未来？} 为了解决 Q1，我们提出了一种时空后门调整策略，该策略学习时空去混淆（STDC）表示空间并估计历史数据对未来数据的去混淆因果效应。我们捕获的这种因果关系为后续的时空映射奠定了基础。为了解决 Q2，我们设计了一个时空嵌入（STE），融合了时间和空间混杂因素的信息，捕捉了表示的内在时空特征。此外，我们引入了一种跨时间注意力机制，它查询未来和过去之间的注意力来指导时空映射。]]></description>
      <guid>https://arxiv.org/abs/2412.02942</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>系统中神经网络的规范生成</title>
      <link>https://arxiv.org/abs/2412.03028</link>
      <description><![CDATA[arXiv:2412.03028v1 公告类型：新
摘要：规范 - 正确领域特定行为的精确数学表示 - 对于保证计算机系统的可信度至关重要。随着神经网络作为计算机系统组件的不断发展，规范变得越来越重要，因为它们可用于规范这些黑盒模型的行为。传统上，规范是由领域专家根据他们对正确行为的直觉设计的。然而，这是劳动密集型的，因此随着计算机系统应用程序的多样化，这种方法不是一种可扩展的方法。我们假设，神经网络为提高性能而取代的传统（又称参考）算法在可用时可以充当模型正确行为的有效代理。这是因为它们已经使用和测试了足够长的时间，可以对底层域中可信/正确行为的几个方面进行编码。在我们的假设的驱动下，我们开发了一个新颖的自动化框架 SpecTRA，使用参考为神经网络生成规范。我们将规范生成公式化为优化问题，并通过参考行为的观察来解决它。 SpecTRA 将相似的观察结果聚类为紧凑的规范。我们介绍了 SpecTRA 为自适应比特率和拥塞控制算法中的神经网络生成的规范。我们的规范显示出正确且符合直觉的证据。此外，我们使用我们的规范来展示计算机系统 SOTA 模型的几个未知漏洞。]]></description>
      <guid>https://arxiv.org/abs/2412.03028</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可区分游戏中基于偏好的对手塑造</title>
      <link>https://arxiv.org/abs/2412.03072</link>
      <description><![CDATA[arXiv:2412.03072v1 公告类型：新
摘要：多智能体游戏环境中的策略学习是一个具有挑战性的问题。由于每个智能体的奖励由联合策略决定，因此旨在最大化自身奖励的贪婪学习策略可能会陷入局部最优。最近的研究提出了游戏环境的对手建模和塑造方法。这些方法通过对其他智能体的策略和更新过程进行建模来提高策略学习的效率。然而，这些方法通常依赖于对对手策略变化的简单预测。由于缺乏对合作和竞争等行为偏好的建模，它们通常仅适用于预定义的场景并且缺乏泛化能力。在本文中，我们提出了一种新颖的基于偏好的对手塑造（PBOS）方法，通过塑造智能体对合作的偏好来增强策略学习过程。我们引入了偏好参数，将其纳入代理的损失函数中，从而允许代理在更新策略时直接考虑对手的损失函数。我们在策略学习的同时更新偏好参数，确保代理能够适应任何合作或竞争的游戏环境。通过一系列实验，我们验证了 PBOS 算法在多种可微分游戏中的性能。实验结果表明，PBOS 算法可以引导代理学习合适的偏好参数，从而在多种游戏环境中实现更好的奖励分配。]]></description>
      <guid>https://arxiv.org/abs/2412.03072</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatTS：通过合成数据将时间序列与 LLM 对齐，以增强理解和推理</title>
      <link>https://arxiv.org/abs/2412.03104</link>
      <description><![CDATA[arXiv:2412.03104v1 公告类型：新
摘要：理解时间序列对于其在实际场景中的应用至关重要。最近，大型语言模型（LLM）越来越多地应用于时间序列任务，利用其强大的语言能力来增强各种应用。然而，对用于时间序列理解和推理的多模态LLM（MLLM）的研究仍然有限，主要是因为缺乏将时间序列与文本信息对齐的高质量数据集。本文介绍了一种专为时间序列分析而设计的新型MLLM ChatTS。ChatTS将时间序列视为一种模态，类似于视觉MLLM处理图像的方式，使其能够对时间序列进行理解和推理。为了解决训练数据的稀缺问题，我们提出了一种基于属性的方法来生成具有详细属性描述的合成时间序列。我们进一步介绍了时间序列Evol-Instruct，这是一种生成多样化时间序列问答的新方法，可增强模型的推理能力。据我们所知，ChatTS 是第一个以多变量时间序列作为输入的 MLLM，它专门针对合成数据集进行微调。我们使用包含真实数据（包括六个对齐任务和四个推理任务）的基准数据集来评估其性能。我们的结果表明，ChatTS 的表现明显优于现有的基于视觉的 MLLM（例如 GPT-4o）和基于文本/代理的 LLM，在对齐任务中实现了 46.0% 的提升，在推理任务中实现了 25.8% 的提升。]]></description>
      <guid>https://arxiv.org/abs/2412.03104</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CredID：用于大型语言模型识别的可信多位水印</title>
      <link>https://arxiv.org/abs/2412.03107</link>
      <description><![CDATA[arXiv:2412.03107v1 公告类型：新
摘要：大型语言模型（LLM）广泛应用于复杂的自然语言处理任务，但由于缺乏身份识别，引发了隐私和安全问题。本文提出了一个涉及可信第三方（TTP）和多个LLM供应商的多方可信水印框架（CredID）来解决这些问题。在水印嵌入阶段，供应商向TTP请求种子以生成带水印的文本，而无需发送用户的提示。在提取阶段，TTP协调每个供应商从文本中提取和验证水印。这提供了一种可信的水印方案，同时保护了供应商的隐私。此外，当前的水印算法在文本质量、信息容量和鲁棒性方面存在困难，很难满足LLM的多样化识别需求。因此，我们提出了一种新颖的多位水印算法和一个开源工具包以促进研究。实验表明，我们的 CredID 可在不影响文本质量的情况下提高水印的可信度和效率。此外，我们成功利用此框架在多个 LLM 供应商之间实现了高度准确的识别。]]></description>
      <guid>https://arxiv.org/abs/2412.03107</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经验驱动的规划策略发现</title>
      <link>https://arxiv.org/abs/2412.03111</link>
      <description><![CDATA[arXiv:2412.03111v1 公告类型：新
摘要：人们如何在认知资源有限的情况下有效规划的一个解释是，我们拥有一套自适应规划策略，并且知道何时以及如何使用它们。但这些策略是如何获得的呢？虽然之前的研究已经研究了个人如何学会在现有策略中进行选择，但人们对形成新规划策略的过程知之甚少。在这项工作中，我们提出通过元认知强化学习发现新的规划策略。为了测试这一点，我们设计了一个新颖的实验来研究新规划策略的发现。然后，我们提出元认知强化学习模型，并展示它们的策略发现能力，并表明它们比其他学习机制更好地解释了人类的策略发现。然而，当这些模型与人类数据相匹配时，它们的发现速度比人类慢，还有改进的空间。]]></description>
      <guid>https://arxiv.org/abs/2412.03111</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 释义器的鲁棒多位文本水印</title>
      <link>https://arxiv.org/abs/2412.03123</link>
      <description><![CDATA[arXiv:2412.03123v1 公告类型：新
摘要：我们提出了一种通过使用 LLM 释义嵌入的不可察觉的多位文本水印。我们对一对设计为表现不同的 LLM 释义器进行了微调，以便训练有素的解码器可以识别它们在文本语义中反映的释义差异。为了嵌入我们的多位水印，我们交替使用两个释义器在句子级别对预定义的二进制代码进行编码。然后我们使用文本分类器作为解码器来解码水印的每一位。通过大量实验，我们表明我们的水印可以在保留原始句子的语义信息的同时，使用小型（1.1B）文本释义器实现超过 99.99\% 的检测 AUC。更重要的是，我们的管道在单词替换和句子释义扰动下具有鲁棒性，并且很好地推广到分布外的数据。我们还通过基于 LLM 的评估展示了我们水印的隐秘性。我们开源代码：https://github.com/xiaojunxu/multi-bit-text-watermark。]]></description>
      <guid>https://arxiv.org/abs/2412.03123</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型展现出与人类相当的个体和集体创造力</title>
      <link>https://arxiv.org/abs/2412.03151</link>
      <description><![CDATA[arXiv:2412.03151v1 公告类型：新
摘要：到目前为止，人工智能已经在很大程度上实现了日常任务的自动化，但如果大型语言模型 (LLM) 表现出与人类相当的创造力，这对未来的工作意味着什么？为了全面衡量 LLM 的创造力，本研究使用了涵盖三个领域的 13 项创造性任务。我们将 LLM 与个人人类进行对比，并采用一种新颖的方法，将它们与人类群体的集体创造力进行比较。我们发现最好的 LLM（Claude 和 GPT-4）在人类中排名 52%，总体而言，LLM 在发散思维和解决问题方面表现出色，但在创造性写作方面落后。当被问到 10 次时，LLM 的集体创造力相当于 8-10 个人。当要求更多回答时，LLM 的两个额外回答等于一个额外的人。最终，如果 LLM 得到最佳应用，它可能会在未来的工作中与一小群人类竞争。]]></description>
      <guid>https://arxiv.org/abs/2412.03151</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解和量化文本到图像生成的不确定性</title>
      <link>https://arxiv.org/abs/2412.03178</link>
      <description><![CDATA[arXiv:2412.03178v1 公告类型：新
摘要：文本到图像 (T2I) 生成模型中的不确定性量化对于理解模型行为和提高输出可靠性至关重要。在本文中，我们首次量化和评估了 T2I 模型相对于提示的不确定性。除了调整现有的用于测量图像空间不确定性的方法外，我们还引入了基于提示的 T2I 模型不确定性估计 (PUNC)，这是一种利用大型视觉语言模型 (LVLM) 来更好地解决提示和生成图像的语义引起的不确定性的新方法。PUNC 使用 LVLM 为生成的图像添加标题，然后将标题与语义上更有意义的文本空间中的原始提示进行比较。PUNC 还能够通过精度和召回率解开随机和认知不确定性，而这是图像空间方法无法做到的。大量实验表明，PUNC 在各种设置中的表现都优于最先进的不确定性估计技术。文本到图像生成模型中的不确定性量化可用于各种应用，包括偏见检测、版权保护和 OOD 检测。我们还引入了一个全面的文本提示和生成对数据集，以促进生成模型不确定性量化的进一步研究。我们的研究结果表明，PUNC 不仅实现了具有竞争力的性能，而且还支持在评估和提高文本到图像模型的可信度方面实现新的应用。]]></description>
      <guid>https://arxiv.org/abs/2412.03178</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将生成式人工智能融入艺术治疗：技术展示</title>
      <link>https://arxiv.org/abs/2412.03287</link>
      <description><![CDATA[arXiv:2412.03287v1 公告类型：新
摘要：本文探讨了生成式人工智能与艺术治疗领域的整合。利用经过验证的文本到图像模型，我们引入了一种新颖的技术设计来补充艺术治疗。由此产生的基于人工智能的工具将使患者能够改进和定制他们的创意作品，开辟新的表达和可访问性途径。使用三个说明性示例，我们展示了我们解决方案的潜在输出并对其进行了定性评估。此外，我们讨论了与这种整合相关的当前局限性和道德考虑，并展望了未来的研究工作。我们的实现在 https://github.com/BFH-AMI/sds24 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2412.03287</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>恶劣天气条件下使用图神经网络进行情景数据集成以预测共享单车需求</title>
      <link>https://arxiv.org/abs/2412.03307</link>
      <description><![CDATA[arXiv:2412.03307v1 公告类型：新 
摘要：共享单车的需求受到各种因素的影响，例如天气状况、事件和其他交通方式的可用性。由于这些因素或与位置相关的用户行为变化的复杂相互依赖性，这种影响仍然难以捉摸。目前还不清楚哪些因素是历史需求中尚未包含的附加信息。共享单车与其他交通方式之间的多式联运依赖关系也未得到充分探索，并且在恶劣情况下尚未研究这些信息的价值。拟议的研究分析了添加背景数据（例如天气、时间嵌入和道路交通流）对预测非典型天气情况下共享单车起点-目的地 (OD) 流量的影响。我们的研究强调了共享单车需求预测质量与道路交通流之间的温和关系，而引入的时间嵌入可以超越最先进的结果，特别是在恶劣天气条件下。将天气数据作为额外输入纳入其中，可进一步改进我们的模型，相对于基本的 ST-ED-RMGC 预测模型，在恶劣天气条件下的预测误差可减少 20% 以上。]]></description>
      <guid>https://arxiv.org/abs/2412.03307</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WiS 平台：通过基于游戏的分析增强基于 LLM 的多智能体系统的评估</title>
      <link>https://arxiv.org/abs/2412.03359</link>
      <description><![CDATA[arXiv:2412.03359v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的自主多智能体系统 (MAS) 的最新进展增强了应用场景并提高了 LLM 处理复杂任务的能力。尽管证明了有效性，但现有研究显然仍然难以评估、分析和重现基于 LLM 的 MAS。在本文中，为了促进基于 LLM 的 MAS 的研究，我们引入了一个开放、可扩展且实时更新的平台，用于访问和分析基于游戏“谁是间谍？”（WiS）的基于 LLM 的 MAS。我们的平台具有三个主要价值：（1）统一的模型评估界面，支持 Hugging Face 上可用的模型；（2）实时更新的模型评估排行榜；（3）全面的评估，涵盖 LLM 的游戏获胜率、攻击、防御策略和推理。为了严格测试 WiS，我们对各种开源和闭源 LLM 进行了广泛的实验，我们发现不同的代理在游戏中表现出不同且有趣的行为。实验结果证明了我们的平台在评估基于 LLM 的 MAS 方面的有效性和效率。我们的平台及其文档可在 \url{https://whoisspy.ai/} 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2412.03359</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>