<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过最优传输从长尾数据的噪声标签中学习</title>
      <link>https://arxiv.org/abs/2408.03977</link>
      <description><![CDATA[arXiv:2408.03977v1 公告类型：交叉 
摘要：噪声标签在现实世界的数据集中很常见，它会严重损害深度学习模型的训练。然而，最近的对抗性抗噪方法忽略了真实数据的长尾分布，这会严重损害去噪策略的效果。同时，噪声标签的管理不善进一步损害了模型处理长尾数据的能力。为了解决这个问题，我们提出了一种新方法来管理同时具有长尾分布和噪声标签的数据。首先，我们引入了一个损失距离交叉选择模块，它集成了类预测和特征分布来过滤干净的样本，有效地解决了噪声标签和长尾分布引入的不确定性。随后，我们采用最优传输策略以半监督训练的方式为噪声集生成伪标签，提高伪标签质量，同时减轻长尾分布导致的样本稀缺性的影响。我们在合成数据集和真实数据集上进行了实验，综合实验结果表明我们的方法超越了目前最先进的方法。我们的代码将在未来提供。]]></description>
      <guid>https://arxiv.org/abs/2408.03977</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>电信基础模型：应用、挑战和未来趋势</title>
      <link>https://arxiv.org/abs/2408.03964</link>
      <description><![CDATA[arXiv:2408.03964v1 公告类型：交叉 
摘要：电信网络正变得越来越复杂，具有多样化的部署场景、多标准和多供应商支持。电信网络生态系统的复杂性对有效管理、运营和优化网络提出了挑战。为了解决这些障碍，人工智能 (AI) 已被广泛用于解决电信网络中的不同任务。然而，这些传统的 AI 模型通常是为特定任务而设计的，依赖于大量且成本高昂的标记数据，这些数据需要专业的电信专业知识来开发和维护。AI 模型通常无法概括和支持不同的部署场景和应用程序。相比之下，基础模型 (FM) 在语言、视觉和决策任务的各个领域表现出有效的泛化能力。FM 可以在电信生态系统生成的多种数据模态上进行训练，并利用专业领域知识。此外，FM 可以进行微调，以使用最少的任务特定标记数据来解决许多专门的任务，并且在某些情况下，能够利用上下文来解决以前未见过的问题。在 6G 的曙光中，本文探讨了使用 FM 塑造电信技术和标准未来的潜在机会。特别是，本文概述了开发电信 FM (TFM) 的概念过程，并讨论了为网络配置、操作和维护协调专用 TFM 的新兴机会。最后，本文讨论了开发和部署 TFM 的局限性和挑战。]]></description>
      <guid>https://arxiv.org/abs/2408.03964</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:12 GMT</pubDate>
    </item>
    <item>
      <title>增强输出多样性可改善基于共轭梯度的对抗性攻击</title>
      <link>https://arxiv.org/abs/2408.03972</link>
      <description><![CDATA[arXiv:2408.03972v1 公告类型：交叉 
摘要：深度神经网络容易受到对抗性示例的攻击，并且在此背景下研究了生成对抗性示例的对抗性攻击。现有研究表明，增加模型输出的多样性有助于提高攻击性能。本研究重点关注自共轭梯度 (ACG) 攻击，该攻击受共轭梯度法启发，具有很高的多样化性能。我们假设增加两个连续搜索点之间的距离会增强输出多样性。为了检验我们的假设，我们提出了 Rescaling-ACG (ReACG)，它自动修改显着影响两个连续搜索点之间距离的两个组件，包括搜索方向和步长。ReACG 表现出比 ACG 更高的攻击性能，并且对于具有多个分类类别的 ImageNet 模型特别有效。实验结果表明，两个连续搜索点之间的距离增强了输出多样性，可能有助于开发新的强大攻击。代码可在 \url{https://github.com/yamamura-k/ReACG} 获取]]></description>
      <guid>https://arxiv.org/abs/2408.03972</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能依赖程度调查</title>
      <link>https://arxiv.org/abs/2408.03948</link>
      <description><![CDATA[arXiv:2408.03948v1 公告类型：交叉 
摘要：人工智能 (AI) 系统已成为现代技术不可或缺的组成部分。然而，对人类行为反应的研究却落后了，即对人类对人工智能建议的依赖 (AI 依赖) 的研究。目前文献中的不足包括对人工智能依赖的影响不明确、缺乏外​​部有效性、衡量依赖的方法相互矛盾以及忽视依赖随时间的变化。未来研究的有希望的途径包括对生成性人工智能输出的依赖和多用户情况下的依赖。最后，我们提出了一个形态学框，作为对人工智能依赖性研究的指导。]]></description>
      <guid>https://arxiv.org/abs/2408.03948</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:11 GMT</pubDate>
    </item>
    <item>
      <title>EcoFollower：一种考虑燃油消耗的环保跟车模型</title>
      <link>https://arxiv.org/abs/2408.03950</link>
      <description><![CDATA[arXiv:2408.03950v1 公告类型：交叉 
摘要：为了缓解交通运输造成的能源短缺和环境影响，本研究引入了 EcoFollower，这是一种使用强化学习 (RL) 开发的新型生态跟车模型，用于优化跟车场景中的燃料消耗。利用 NGSIM 数据集，与成熟的智能驾驶员模型 (IDM) 相比，对 EcoFollower 的性能进行了评估。研究结果表明，EcoFollower 在模拟真实的驾驶行为、保持车辆平稳运行以及紧密匹配碰撞时间 (TTC)、车头时距和舒适度等地面真实指标方面表现出色。值得注意的是，该模型显著降低了油耗，与实际驾驶场景相比降低了 10.42%。这些结果强调了像 EcoFollower 这样的基于 RL 的模型能够增强自动驾驶汽车算法，促进更安全、更节能的驾驶策略。]]></description>
      <guid>https://arxiv.org/abs/2408.03950</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:11 GMT</pubDate>
    </item>
    <item>
      <title>自适应系统架构，实现其临时可扩展性：无人驾驶汽车车队——任务控制中心案例研究</title>
      <link>https://arxiv.org/abs/2408.03963</link>
      <description><![CDATA[arXiv:2408.03963v1 公告类型：交叉 
摘要：系统系统 (SoS) 由组成系统 (CS) 组成，这些组成系统相互作用以提供超越任何单个 CS 的独特功能。SoS 中的一个关键挑战是临时可扩展性，这意味着系统大小在运行过程中会通过添加或删除 CS 而发生变化。本研究以无人驾驶车辆车队 (UVF) 为实际 SoS 示例，解决任务变化、范围扩展和 UV 故障等不确定性问题。提出的解决方案涉及一个自适应系统，该系统可动态调整 UVF 架构，允许任务控制中心 (MCC) 根据性能标准自动扩展 UVF 大小或根据操作员决定手动扩展 UVF 大小。实施了多代理环境和规则管理引擎来模拟和验证这种方法。]]></description>
      <guid>https://arxiv.org/abs/2408.03963</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:11 GMT</pubDate>
    </item>
    <item>
      <title>拟人化大型语言模型在学习环境中的影响</title>
      <link>https://arxiv.org/abs/2408.03945</link>
      <description><![CDATA[arXiv:2408.03945v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 越来越多地用于学习环境中以支持教学 - 无论是作为学习伙伴还是导师。通过我们的贡献，我们旨在讨论学习环境中 LLM 拟人化对教育理论的影响，为更有效的学习成果奠定基础，并了解其对学习者的情感影响。根据媒体方程，人们倾向于以与回应他人相同的方式回应媒体。佐治亚理工学院进行的一项研究表明，聊天机器人可以在学习环境中成功实施。在这项研究中，选定的在线课程的学习者无法区分聊天机器人和“真正的”老师。随着基于 LLM 的聊天机器人（例如 OpenAI 的 GPT 系列）越来越多地用于教育工具，了解拟人化方面对基于 LLM 的聊天机器人的归因过程如何影响学习者的情绪非常重要。]]></description>
      <guid>https://arxiv.org/abs/2408.03945</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:10 GMT</pubDate>
    </item>
    <item>
      <title>提示产品：研究文本到图像生成模型的设计空间探索策略</title>
      <link>https://arxiv.org/abs/2408.03946</link>
      <description><![CDATA[arXiv:2408.03946v1 公告类型：交叉 
摘要：文本到图像模型可以实现高效的设计空间探索，快速从文本提示生成图像。然而，许多生成式人工智能工具对于产品设计应用来说并不完美，因为它们不是为产品设计的目标和要求而构建的。文本输入和图像输出之间不明确的联系进一步复杂化了它们的应用。这项工作实证研究了设计空间探索策略，这些策略可以成功地产生可行、新颖和美观的产品图像，这是产品设计的三个共同目标。具体来说，分析了全局和局部编辑模式中的用户操作，包括他们花费的时间、提示长度、单一标准与多标准提示以及提示的目标导向。主要发现揭示了单一标准与多标准以及提示的目标导向在实现特定设计目标方面的关键作用，这些设计目标随着时间和提示长度而变化。该研究建议在全局编辑期间优先使用多标准提示，以提高可行性和新颖性，而在局部编辑期间则优先使用单一标准提示，以提高美观性。总体而言，本文强调了人工智能驱动的文本转图像模型与其在产品设计中的有效性之间的微妙关系，敦促设计师在不同的编辑模式下仔细构建提示，以更好地满足产品设计的独特需求。]]></description>
      <guid>https://arxiv.org/abs/2408.03946</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:10 GMT</pubDate>
    </item>
    <item>
      <title>用于评估多目标优化中的进化过程的比较可视化分析框架</title>
      <link>https://arxiv.org/abs/2308.05640</link>
      <description><![CDATA[arXiv:2308.05640v1 公告类型：交叉 
摘要：进化多目标优化 (EMO) 算法已被证明可有效解决多标准决策问题。在实际应用中，分析师经常同时使用几种算法并比较它们的解决方案集，以深入了解不同算法的特点并探索更广泛的可行解决方案。然而，EMO 算法通常被视为黑匣子，导致难以对内部进化过程进行详细分析和比较。受可视化分析工具在可解释人工智能中的成功应用的启发，我们认为交互式可视化可以显著增强多种 EMO 算法之间的比较分析。在本文中，我们提出了一个可视化分析框架，可以探索和比较 EMO 算法中的进化过程。在文献综述和专家访谈的指导下，提出的框架解决了各种分析任务，并建立了一个多方面的可视化设计，以支持进化中的中间代以及解决方案集的比较分析。我们通过基准测试和现实世界的多目标优化问题的案例研究证明了我们框架的有效性，以阐明分析师如何利用我们的框架来检查和比较不同的算法。]]></description>
      <guid>https://arxiv.org/abs/2308.05640</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:09 GMT</pubDate>
    </item>
    <item>
      <title>HOAA：用于增强性能处理引擎的混合高估近似加法器</title>
      <link>https://arxiv.org/abs/2408.00806</link>
      <description><![CDATA[arXiv:2408.00806v1 公告类型：交叉 
摘要：本文介绍了一种混合高估近似加法器，旨在提高处理引擎的性能，特别是针对边缘 AI 应用。提出了一种新颖的 Plus One Adder 设计作为 RCA 链中的增量加法器，将一个带有过量 1 的全加法器与输入 A、B 和 Cin 结合在一起。该设计将输出近似为 2 位值，以降低硬件复杂性并提高资源效率。Plus One Adder 集成到动态可重构 HOAA 中，允许在运行时在准确和近似高估模式之间进行互换。所提出的设计已针对多种应用进行了演示，例如二进制补码减法和四舍五入到偶数，以及可配置激活函数，它们是处理引擎的关键组件。与最先进的设计相比，我们的方法面积效率提高了 21%，功耗降低了 33%，同时精度损失最小。因此，提出的 HOAA 可能成为资源受限环境的一个有前途的解决方案，在硬件效率和计算精度之间提供理想的权衡。]]></description>
      <guid>https://arxiv.org/abs/2408.00806</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:09 GMT</pubDate>
    </item>
    <item>
      <title>构建能够与人类一起学习和思考的机器</title>
      <link>https://arxiv.org/abs/2408.03943</link>
      <description><![CDATA[arXiv:2408.03943v1 公告类型：交叉 
摘要：我们想从机器智能中得到什么？我们设想的机器不仅仅是思考的工具，而且是思考的伙伴：与我们一起思考的合理、有洞察力、知识渊博、可靠和值得信赖的系统。当前的人工智能 (AI) 系统有时满足其中一些标准。在本观点中，我们展示了如何利用协作认知科学来设计真正可以称为“思想伙伴”的系统，这些系统旨在满足我们的期望并补充我们的局限性。我们列出了几种人类和人工智能思想伙伴可以参与的协作思维模式，并提出了与人类兼容的思想伙伴关系的要求。借鉴计算认知科学的主题，我们通过贝叶斯视角激发了一条替代的扩展路径，用于设计思想伙伴及其使用的生态系统，我们构建的伙伴可以积极地构建和推理人类和世界的模型。]]></description>
      <guid>https://arxiv.org/abs/2408.03943</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:09 GMT</pubDate>
    </item>
    <item>
      <title>SCENE：使用软反事实评估可解释的 AI 技术</title>
      <link>https://arxiv.org/abs/2408.04575</link>
      <description><![CDATA[arXiv:2408.04575v1 公告类型：新 
摘要：可解释人工智能 (XAI) 对于增强 AI 模型的透明度和可问责性至关重要，尤其是在自然语言处理 (NLP) 任务中。本文介绍了 SCENE（自然语言可解释性的软反事实评估），这是一种新颖的评估方法，它利用大型语言模型 (LLM) 以零样本方式生成软反事实解释。通过专注于基于标记的替换，SCENE 无需进行大量微调即可创建上下文适当且语义上有意义的软反事实。SCENE 采用 Validitysoft 和 Csoft 指标来评估与模型无关的 XAI 方法在文本分类任务中的有效性。应用于 CNN、RNN 和 BERT 架构，SCENE 提供了有关各种 XAI 技术的优势和局限性的宝贵见解。]]></description>
      <guid>https://arxiv.org/abs/2408.04575</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:08 GMT</pubDate>
    </item>
    <item>
      <title>满足多准则期望的非最大化策略</title>
      <link>https://arxiv.org/abs/2408.04385</link>
      <description><![CDATA[arXiv:2408.04385v1 公告类型：新
摘要：在动态规划和强化学习中，代理在随机环境中进行顺序决策的策略通常通过将目标表示为标量奖励函数并寻求最大化预期总奖励的策略来确定。然而，人类关心的许多目标自然涉及世界的多个方面，如何将它们浓缩为单个奖励函数可能并不明显。此外，最大化受到规范游戏的影响，其中获得的策略以非预期的方式实现较高的预期总奖励，通常采取极端或荒谬的行动。
在这里，我们考虑具有多个不同评估指标的有限非循环马尔可夫决策过程，这些指标不一定代表用户希望最大化的数量。我们假设代理的任务是确保评估指标的预期总数向量落入某个给定的凸集，称为期望集。我们的算法通过使用单纯形来近似可行性集并向前传播愿望，同时确保愿望仍然可行，从而保证完成此任务。它的复杂度与可能的状态-动作-后继三元组的数量呈线性关系，与评估指标的数量呈多项式关系。此外，所选策略和目标的明确非最大化性质产生了额外的自由度，可用于将启发式安全标准应用于动作的选择。我们讨论了几种这样的安全标准，旨在引导代理采取更保守的行为。]]></description>
      <guid>https://arxiv.org/abs/2408.04385</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:07 GMT</pubDate>
    </item>
    <item>
      <title>RiskAwareBench：面向 LLM 实体代理高级规划的物理风险意识评估</title>
      <link>https://arxiv.org/abs/2408.04449</link>
      <description><![CDATA[arXiv:2408.04449v1 公告类型：新
摘要：大型语言模型 (LLM) 与机器人技术的集成显著增强了具身代理理解和执行复杂自然语言指令的能力。然而，在现实环境中不加节制地部署基于 LLM 的具身系统可能会带来潜在的物理风险，例如财产损失和人身伤害。现有的 LLM 安全基准忽视了基于 LLM 的具身代理的风险意识。为了解决这一差距，我们提出了 RiskAwareBench，这是一个自动化框架，旨在评估基于 LLM 的具身代理的物理风险意识。RiskAwareBench 包含四个模块：安全提示生成、风险场景生成、计划生成和评估，以最少的人工干预实现全面的风险评估。利用这个框架，我们编译了 PhysicalRisk 数据集，涵盖了各种场景以及相关的安全提示、观察和说明。大量实验表明，大多数LLM表现出不足的物理风险意识，而基线风险缓解策略的增强效果有限，这强调了未来提高基于LLM的具身代理的风险意识的紧迫性和关键性。]]></description>
      <guid>https://arxiv.org/abs/2408.04449</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:07 GMT</pubDate>
    </item>
    <item>
      <title>答案集编程中的学习规则推理</title>
      <link>https://arxiv.org/abs/2408.04528</link>
      <description><![CDATA[arXiv:2408.04528v1 公告类型：新
摘要：我们感兴趣的是自动化推理学习规定，以满足各种利益相关者的需求，从管理人员到教师，再到不同阶段的学生。我们的工作建立在对波茨坦大学各种学习计划的广泛分析之上。基本原则的概念化为我们提供了学习规定的正式说明。特别是，形式化揭示了可接受的学习计划的属性。最后，我们提出了一种在答案集编程中对学习规定进行编码的方法，以生成相应的学习计划。最后，我们展示了如何将这种方法扩展到用于探索学习计划的通用用户界面。]]></description>
      <guid>https://arxiv.org/abs/2408.04528</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:07 GMT</pubDate>
    </item>
    <item>
      <title>MMRole：开发和评估多模式角色扮演代理的综合框架</title>
      <link>https://arxiv.org/abs/2408.04203</link>
      <description><![CDATA[arXiv:2408.04203v1 公告类型：新
摘要：最近，角色扮演代理 (RPA) 因其传递情感价值和促进社会学研究的潜力而受到越来越多的关注。然而，现有的研究主要局限于文本模态，无法模拟人类的多模态感知能力。为了弥补这一差距，我们引入了多模态角色扮演代理 (MRPA) 的概念，并提出了一个全面的框架 MMRole，用于它们的开发和评估，其中包括个性化的多模态数据集和稳健的评估方法。具体来说，我们构建了一个大规模、高质量的数据集 MMRole-Data，包括 85 个角色、11K 幅图像和 14K 个单轮或多轮对话。此外，我们提出了一种稳健的评估方法 MMRole-Eval，涵盖三个维度的八个指标，其中训练了一个奖励模型来对 MRPA 进行评分，并使用构建的真实数据进行比较。此外，我们还开发了第一个专门的 MRPA，即 MMRole-Agent。广泛的评估结果表明 MMRole-Agent 的性能有所提高，并突出了开发 MRPA 的主要挑战，强调需要增强多模态理解和角色扮演一致性。数据、代码和模型将在 https://github.com/YanqiDai/MMRole 上提供。]]></description>
      <guid>https://arxiv.org/abs/2408.04203</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:06 GMT</pubDate>
    </item>
    <item>
      <title>KnowPC：面向零样本协调的知识驱动程序化强化学习</title>
      <link>https://arxiv.org/abs/2408.04336</link>
      <description><![CDATA[arXiv:2408.04336v1 公告类型：新
摘要：零样本协调（ZSC）仍然是合作 AI 领域的一大挑战，其目的是让代理在训练环境甚至新环境中与看不见的伙伴合作。近年来，一种流行的 ZSC 解决方案范式是深度强化学习（DRL）与高级自我对弈或基于种群的方法相结合，以增强神经策略处理看不见的伙伴的能力。尽管取得了一些成功，但这些方法通常依赖黑盒神经网络作为策略函数。然而，神经网络通常缺乏可解释性和逻辑性，使得学习到的策略难以被伙伴（例如人类）理解，并限制了它们的泛化能力。这些缺点阻碍了强化学习方法在各种合作场景中的应用。我们建议用可解释的程序来表示代理的策略。与神经网络不同，程序包含稳定的逻辑，但它们不可微分且难以优化。为了自动学习此类程序，我们引入了零样本协调的知识驱动程序强化学习 (KnowPC)。我们首先定义一个基础领域特定语言 (DSL)，包括程序结构、条件基元和动作基元。一个重大挑战是程序搜索空间巨大，难以有效地找到高性能程序。为了解决这个问题，KnowPC 集成了一个提取器和一个推理器。提取器从多智能体交互轨迹中发现环境转换知识，而推理器则根据转换知识推断出每个动作基元的先决条件。]]></description>
      <guid>https://arxiv.org/abs/2408.04336</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:06 GMT</pubDate>
    </item>
    <item>
      <title>NAVINACT：结合导航和模仿学习，实现引导式强化学习</title>
      <link>https://arxiv.org/abs/2408.04054</link>
      <description><![CDATA[arXiv:2408.04054v1 公告类型：新
摘要：强化学习 (RL) 在模拟环境中取得了显著进展，但由于探索和泛化方面的挑战，其在现实世界机器人任务中的应用仍然有限。为了解决这些问题，我们引入了 NAVINACT，这是一个框架，它选择机器人何时使用基于经典运动规划的导航以及何时学习策略。为了进一步提高探索效率，我们使用模仿数据来引导探索。NAVINACT 在两种操作模式之间动态切换：远离物体时使用经典技术导航到航点，即将与物体交互时使用强化学习进行细粒度操作控制。NAVINACT 由多头架构组成，由用于模式分类的 ModeNet、用于航点预测的 NavNet 和用于精确操作的 InteractNet 组成。通过结合 RL 和模仿学习 (IL) 的优势，NAVINACT 提高了样本效率并减轻了分布偏移，确保了任务的稳健执行。我们在多个具有挑战性的模拟环境和真实任务中评估了我们的方法，与现有方法相比，它在适应性、效率和泛化方面表现出色。在模拟和真实环境中，NAVINACT 都表现出了强大的性能。在模拟中，NAVINACT 在 30k 个样本的训练成功率上比基线方法高出 10-15%，在评估阶段则高出 30-40%。在真实场景中，与基线相比，它在简单任务上的成功率高出 30-40%，并且在复杂的两阶段操作任务中取得了独特的成功。
数据集和补充材料可以在我们的网站上找到：{https://raaslab.org/projects/NAVINACT/}。]]></description>
      <guid>https://arxiv.org/abs/2408.04054</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:05 GMT</pubDate>
    </item>
    <item>
      <title>数字化身：框架开发及其评估</title>
      <link>https://arxiv.org/abs/2408.04068</link>
      <description><![CDATA[arXiv:2408.04068v1 公告类型：新
摘要：我们提出了一种用于人工智能驱动数字化身的新型提示策略。为了更好地量化我们的提示策略如何影响幽默、真实性和好感度等拟人化特征，我们提出了 Crowd Vote - Crowd Score 的改编版，允许评委从回答相同或类似提示的竞争对手中选出大型语言模型 (LLM) 候选人。为了可视化我们的 LLM 的响应以及我们的提示策略的有效性，我们提出了一个端到端框架来创建高保真人工智能 (AI) 驱动的数字化身。该管道有效地捕捉了个人的互动本质，我们的流式传输算法通过从服务器到移动设备的实时音频视频流提供高质量的数字化身。我们的可视化工具和我们的 Crowd Vote 指标都表明我们的 AI 驱动数字化身具有最先进的幽默、真实性和好感度，优于所有竞争对手和基线。就我们的唐纳德·特朗普和乔·拜登头像而言，他们的真实性和好感度甚至比现实世界中的头像还要高。]]></description>
      <guid>https://arxiv.org/abs/2408.04068</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:05 GMT</pubDate>
    </item>
    <item>
      <title>感知、反思和规划：设计无需指令即可实现目标导向城市导航的 LLM 代理</title>
      <link>https://arxiv.org/abs/2408.04168</link>
      <description><![CDATA[arXiv:2408.04168v1 公告类型：新
摘要：本文考虑了城市导航中的一个场景：为 AI 代理提供了目标位置相对于一些知名地标的语言描述；通过仅观察周围的场景，包括识别地标和道路网络连接，代理必须在没有指令的情况下做出导航到目标位置的决策。这个问题非常具有挑战性，因为它需要代理建立自我位置并获得复杂城市环境的空间表征，其中地标通常是不可见的。在没有导航指令的情况下，这种能力对于代理在远程城市导航中做出高质量决策至关重要。随着大型语言模型 (LLM) 的新兴推理能力，一个诱人的基线是促使 LLM 对每次观察做出“反应”并做出相应的决策。然而，这个基线的性能非常差，代理经常重复访问相同的位置并做出短视、不一致的决策。为了解决这些问题，本文介绍了一种具有感知、反思和规划能力的新型代理工作流程。具体来说，我们发现 LLaVA-7B 可以进行微调，以足够精确地感知地标的方向和距离，以实现城市导航。此外，反思是通过记忆机制实现的，过去的经验被存储起来，并可以通过当前感知进行检索，以进行有效的决策论证。规划使用反思结果来制定长期计划，这可以避免在远程导航中做出短视决策。我们表明，与最先进的基线相比，设计的工作流显著提高了 LLM 代理的导航能力。]]></description>
      <guid>https://arxiv.org/abs/2408.04168</guid>
      <pubDate>Fri, 09 Aug 2024 06:30:05 GMT</pubDate>
    </item>
    </channel>
</rss>