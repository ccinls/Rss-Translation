<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 04 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于地标的任务分解的 LLM 增强符号强化学习</title>
      <link>https://arxiv.org/abs/2410.01929</link>
      <description><![CDATA[arXiv:2410.01929v1 公告类型：新
摘要：强化学习 (RL) 的基本挑战之一是将复杂的任务分解为更易于 RL 代理学习的子任务。在本文中，我们报告了我们的工作，该工作将通过使用一些给定的正向和负向轨迹来解决复杂任务来识别子任务。我们假设状态由一阶谓词逻辑表示，我们利用该逻辑设计了一种新算法来识别子任务。然后，我们使用大型语言模型 (LLM) 来生成用于实现每个子任务的一阶逻辑规则模板。然后，通过基于归纳逻辑编程 (ILP) 的 RL 代理将这些规则进一步微调为基于规则的策略。通过实验，我们验证了我们的算法在检测子任务方面的准确性，该算法成功地正确检测了所有子任务。我们还调查了语言模型为实现子任务而生成的常识性规则的质量。我们的实验表明，我们的 LLM 指导规则模板生成可以生成解决子任务所需的规则，从而可以用更少的关于环境预定义的一阶逻辑谓词的假设来解决复杂任务。]]></description>
      <guid>https://arxiv.org/abs/2410.01929</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>距离迷失：上下文接近度对图形任务中 LLM 性能的影响</title>
      <link>https://arxiv.org/abs/2410.01985</link>
      <description><![CDATA[arXiv:2410.01985v1 公告类型：新
摘要：尽管取得了重大进展，但大型语言模型 (LLM) 仍存在盲点，削弱了它们检索和有效处理相关上下文数据的能力。我们证明，LLM 在图形任务中的表现超出了“大海捞针”的场景——解决问题需要跨多个子问题进行交叉引用和推理——受到上下文中相关信息的接近度的影响，我们称这种现象为“距离丢失”。我们研究了两个基本的图形任务：识别两个节点之间的共同连接和评估三个节点之间的相似性，并表明模型在这些任务中的性能显著取决于公共边的相对定位。我们使用各种图形编码技术评估了三个公开可用的 LLM - Llama-3-8B、Llama-3-70B 和 GPT-4，这些技术表示 LLM 输入的图形结构。我们提出了一种关于“距离迷失”现象的公式，并证明“距离迷失”和“中间迷失”现象是独立发生的。结果表明，随着节点连接距离的增加，模型准确率可能会下降高达 6 倍，与图编码和模型大小无关。]]></description>
      <guid>https://arxiv.org/abs/2410.01985</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zodiac：用于多智能体诊断的心脏病专家级 LLM 框架</title>
      <link>https://arxiv.org/abs/2410.02026</link>
      <description><![CDATA[arXiv:2410.02026v1 公告类型：新
摘要：大型语言模型 (LLM) 在医疗保健领域取得了显著进展。然而，LLM 在特定领域临床实践中的专业性仍然存在很大差距，限制了它们在现实世界诊断中的应用。在这项工作中，我们介绍了 ZODIAC，这是一个由 LLM 驱动的框架，具有心脏病专家级别的专业性，旨在让 LLM 参与心脏病诊断。ZODIAC 通过从患者数据中提取临床相关特征、检测显著的心律失常以及生成初步报告供心脏病专家审查和改进来协助心脏病专家。为了实现心脏病专家级别的专业性，ZODIAC 建立在多智能体协作框架上，能够跨多种模式处理患者数据。每个 LLM 代理都使用心脏病专家裁定的真实患者数据进行微调，从而增强了模型的专业性。 ZODIAC 经过独立心脏病专家的严格临床验证，通过八项指标进行评估，以衡量临床有效性并解决安全问题。结果表明，ZODIAC 的表现优于行业领先的模型，包括 OpenAI 的 GPT-4o、Meta 的 Llama-3.1-405B 和 Google 的 Gemini-pro，以及 Microsoft 的 BioGPT 等医学专家 LLM。ZODIAC 通过提供满足医疗实践严格要求的领域特定解决方案，展示了专业 LLM 在医疗保健领域的变革潜力。值得注意的是，ZODIAC 已成功集成到心电图 (ECG) 设备中，体现了将 LLM 嵌入软件即医疗设备 (SaMD) 的日益增长的趋势。]]></description>
      <guid>https://arxiv.org/abs/2410.02026</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跟踪外观以相位同步变化的物体</title>
      <link>https://arxiv.org/abs/2410.02094</link>
      <description><![CDATA[arXiv:2410.02094v1 公告类型：新
摘要：我们遇到的物体在与它们互动时经常会改变外观。照明（阴影）、物体姿势或非刚性物体的移动的变化会极大地改变可用的图像特征。生物视觉系统如何跟踪变化中的物体？它可能涉及特定的注意力机制，用于独立于物体外观推断物体的位置——一种著名的神经科学理论与通过神经同步进行计算相关的能力。我们通过计算测试了以下假设：通过神经同步实现视觉注意力是生物视觉系统跟踪外观随时间变化的物体的能力的基础。我们首先介绍一种新颖的深度学习电路，它可以通过神经同步学习精确控制对特征的注意力，而不受其在世界上的位置的影响：复值循环神经网络 (CV-RNN)。接下来，我们使用 FeatureTracker 比较人类、CV-RNN 和其他深度神经网络 (DNN) 中的物体跟踪：这是一项大规模挑战，要求观察者在物体的位置和外观以精确控制的方式发生变化时跟踪它们。虽然人类毫不费力地解决了 FeatureTracker，但最先进的 DNN 却没有。相比之下，我们的 CV-RNN 在挑战中的表现与人类相似，为相位同步作为跟踪移动时外观变化的物体的神经基础的作用提供了计算概念验证。]]></description>
      <guid>https://arxiv.org/abs/2410.02094</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能否可靠地模拟人类学习者的行为？开放式学习环境的模拟创作框架</title>
      <link>https://arxiv.org/abs/2410.02110</link>
      <description><![CDATA[arXiv:2410.02110v1 公告类型：新
摘要：模拟学习者的行为有助于在部署之前对开放式交互式学习环境进行压力测试和原型设计。虽然最近的研究表明使用大型语言模型 (LLM) 模拟人类行为很有前景，但由于关键限制，这种方法尚未超越基本的概念验证阶段。首先，LLM 对微小的提示变化高度敏感，这让人怀疑它们在没有大量提示工程的情况下能否推广到新的场景。此外，看似成功的结果往往是不可靠的，要么是因为领域专家无意中引导 LLM 产生预期结果，导致自我实现的预言；要么是因为 LLM 在其训练数据中遇到了高度相似的场景，这意味着模型可能不是在模拟行为，而是在复述记忆的内容。为了应对这些挑战，我们提出了 Hyp-Mix，这是一个模拟创作框架，允许专家通过结合关于学习者行为的可测试假设来开发和评估模拟。在物理学习环境中测试该框架后，我们发现即使底层学习者模型发生变化，GPT-4 Turbo 也能保持校准的行为，这首次证明 LLM 可用于在开放式交互式学习环境中模拟现实行为，这是实现有用的 LLM 行为模拟的必要先决条件。]]></description>
      <guid>https://arxiv.org/abs/2410.02110</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从像素到标记：量化视觉模态的字节对编码</title>
      <link>https://arxiv.org/abs/2410.02155</link>
      <description><![CDATA[arXiv:2410.02155v1 公告类型：新
摘要：多模态大型语言模型在整合视觉和文本信息方面取得了重大进展，但它们往往难以有效地协调这些模态。我们引入了一种新颖的图像标记器，通过将字节对编码 (BPE) 的原理应用于视觉数据来弥补这一差距。与依赖单独视觉编码器的传统方法不同，我们的方法直接将结构先验信息合并到图像标记中，反映了纯文本大型语言模型中使用的成功标记策略。这种创新方法使 Transformer 模型能够更有效地跨模态学习和推理。通过理论分析和大量实验，我们证明我们的 BPE 图像标记器显着增强了 MLLM 的多模态理解能力，即使在训练数据有限的情况下也是如此。我们的方法不仅提高了各种基准的性能，而且还显示出良好的可扩展性，有可能为更高效、更强大的多模态基础模型铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2410.02155</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>草莓园规划：评估和改进 LRM o1 的规划和调度能力</title>
      <link>https://arxiv.org/abs/2410.02162</link>
      <description><![CDATA[arXiv:2410.02162v1 公告类型：新 
摘要：规划实现期望状态的行动方案的能力长期以来一直被认为是智能代理的核心能力，并且自诞生以来一直是人工智能研究不可或缺的一部分。随着大型语言模型 (LLM) 的出现，人们对它们是否具有这种规划能力产生了浓厚的兴趣，但是——尽管自 GPT3 以来出现了大量新的私有和开源 LLM——但进展仍然缓慢。OpenAI 声称他们最近的 o1（Strawberry）模型是专门构建和训练的，以摆脱自回归 LLM 的正常限制——使其成为一种新型模型：大型推理模型 (LRM)。在本文中，我们在规划和调度基准上评估了两个 LRM（o1-preview 和 o1-mini）的规划能力。我们发现，虽然 o1 似乎确实比自回归 LLM 有显著的改进，但这是以高昂的推理成本为代价的，而且仍然无法对其生成的内容提供任何保证。我们还表明，将 o1 模型与外部验证器相结合（在所谓的 LRM-Modulo 系统中）可以保证组合系统输出的正确性，同时进一步提高性能。]]></description>
      <guid>https://arxiv.org/abs/2410.02162</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有人类水平指南优化的 LLM 驱动自动评分框架</title>
      <link>https://arxiv.org/abs/2410.02165</link>
      <description><![CDATA[arXiv:2410.02165v1 公告类型：新
摘要：开放式简答题 (SAG) 已被广泛认为是在学习分析 (LA) 背景下深入了解学习者反应的有力工具。然而，由于评分工作量大以及对评估不一致的担忧，SAG 在实践中经常带来挑战。随着自然语言处理 (NLP) 的最新进展，自动简答评分 (ASAG) 为这些挑战提供了一个有希望的解决方案。尽管如此，当前的 ASAG 算法通常在通用性方面受到限制，并且倾向于针对特定问题进行量身定制。在本文中，我们提出了一个统一的多智能体 ASAG 框架 GradeOpt，它利用大型语言模型 (LLM) 作为 SAG 的评分器。更重要的是，GradeOpt 将两个额外的基于 LLM 的代理 - 反射器和精炼器 - 合并到多智能体系统中。这使 GradeOpt 能够通过对其错误进行自我反思来自动优化原始评分指南。通过对一项具有挑战性的 ASAG 任务（即对教学内容知识 (PCK) 和内容知识 (CK) 问题进行评分）进行实验，GradeOpt 在评分准确性和与人类评分员的行为一致性方面表现出优于代表性基线的性能。最后，全面的消融研究证实了 GradeOpt 中设计的各个组件的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.02165</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体系统中面向智能体的规划</title>
      <link>https://arxiv.org/abs/2410.02189</link>
      <description><![CDATA[arXiv:2410.02189v1 公告类型：新
摘要：通过拥有不同专业知识和工具的多个代理的协作，多代理系统在解决实际问题方面取得了令人瞩目的进展。给定用户查询，作为这些系统中的大脑的元代理需要将查询分解为多个子任务，这些子任务可以分配给能够解决它们的合适代理，即所谓的面向代理的规划。在本研究中，我们确定了面向代理的规划的三个关键设计原则，包括可解性、完整性和非冗余性，以确保每个子任务都得到有效解决，从而对原始查询做出令人满意的响应。这些原则进一步启发我们提出一种用于多代理系统中面向代理的规划的新框架，利用快速的任务分解和分配过程，然后通过奖励模型进行有效和高效的评估。在规划过程中，元代理还负责评估专家代理的表现，及时调整子任务并根据需要进行安排。此外，我们将反馈回路集成到所提出的框架中，以进一步增强此类问题解决过程的有效性和稳健性。大量实验表明，与单智能体系统和现有的多智能体系统规划策略相比，所提出的框架在解决实际问题方面具有进步性。]]></description>
      <guid>https://arxiv.org/abs/2410.02189</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于对齐语言模型的具有偏好表示的通用偏好建模</title>
      <link>https://arxiv.org/abs/2410.02197</link>
      <description><![CDATA[arXiv:2410.02197v1 公告类型：新
摘要：对人类偏好进行建模对于将基础模型与人类价值观相结合至关重要。传统的奖励建模方法，例如 Bradley-Terry (BT) 奖励模型，在表达能力方面存在不足，特别是在解决不及物偏好方面。虽然监督配对偏好模型 (PairPM) 可以表达一般偏好，但它们的实现是高度临时的，不能保证比较配对的偏好概率一致。此外，由于它们在比较多个响应时具有二次查询复杂度，因此计算成本很高。在本文中，我们引入了偏好表示学习，这是一种将响应嵌入潜在空间以有效捕获复杂偏好结构的方法，可实现线性查询复杂度。此外，我们提出了基于偏好分数的一般偏好优化 (GPO)，它从人类反馈中推广了基于奖励的强化学习。实验结果表明，我们的一般偏好表示模型 (GPM) 在 RewardBench 基准上的表现优于 BT 奖励模型，幅度高达 5.6%，并且有效地模拟了周期性偏好，而任何 BT 奖励模型的行为都像随机猜测一样。此外，在使用 GPO 和我们的一般偏好模型对语言模型进行后期训练后，对 AlpacaEval2.0 和 MT-Bench 等下游任务进行评估，结果显示性能显著提升，幅度高达 9.3%。这些发现表明，我们的方法可以增强基础模型与细微的人类价值观的一致性。代码可在 https://github.com/general-preference/general-preference-model 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.02197</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphIC：基于图的多步推理上下文示例检索模型</title>
      <link>https://arxiv.org/abs/2410.02203</link>
      <description><![CDATA[arXiv:2410.02203v1 公告类型：新
摘要：上下文学习 (ICL) 使大型语言模型 (LLM) 能够通过在输入中直接合并一些上下文示例 (ICE) 来推广到新任务，而无需更新参数。然而，ICL 的有效性在很大程度上依赖于 ICE 的选择，而传统的基于文本的嵌入方法通常不足以完成需要多步推理的任务，例如数学和逻辑问题解决。这是由于浅层语义相似性引入的偏差无法捕捉这些任务所需的更深层的推理结构。我们提出了 GraphIC，这是一种利用基于图的推理过程表示的新方法，结合贝叶斯网络 (BN) 来选择 ICE。图结构本质上会过滤掉浅层语义，同时保留核心推理结构。重要的是，BN 可以捕获节点属性对其父节点的依赖性，这与人类认知的层次性非常相似，即每个想法都由前面的想法塑造而成。这使得 BN 特别适合多步骤推理任务，使该过程更接近人类推理。对三种推理任务（数学推理、代码生成和逻辑推理）进行的大量实验表明，GraphIC 在选择 ICE 方面优于无训练和基于训练的模型，在有效性和效率方面均表现出色。我们表明，GraphIC 增强了 ICL 的性能和互操作性，显著提高了多步骤推理任务的 ICE 选择。]]></description>
      <guid>https://arxiv.org/abs/2410.02203</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CodePMP：用于大型语言模型推理的可扩展偏好模型预训练</title>
      <link>https://arxiv.org/abs/2410.02229</link>
      <description><![CDATA[arXiv:2410.02229v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言理解和生成方面取得了重大进展，这得益于可扩展的预训练和高级微调。然而，由于高质量偏好数据的稀缺，增强 LLM 的推理能力，特别是通过从人类反馈中强化学习 (RLHF)，仍然具有挑战性，而这些数据的注释需要大量劳动力，对奖励模型 (RM) 微调至关重要。为了缓解这个问题，我们引入了 CodePMP，这是一种可扩展的偏好模型预训练 (PMP) 管道，它利用来自公开可用的高质量源代码的大量合成代码偏好对语料库。CodePMP 通过在大规模合成代码偏好对上预训练偏好模型来提高 RM 微调效率。我们在数学推理任务（GSM8K、MATH）和逻辑推理任务（ReClor、LogiQA2.0）上对 CodePMP 进行了评估，结果一致显示 LLM 的推理性能有显著提升，并强调了可扩展偏好模型预训练对于有效奖励建模的重要性。]]></description>
      <guid>https://arxiv.org/abs/2410.02229</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEAL：通过语言模型进行语义增强模仿学习</title>
      <link>https://arxiv.org/abs/2410.02231</link>
      <description><![CDATA[arXiv:2410.02231v1 公告类型：新
摘要：分层模仿学习 (HIL) 是一种有前途的方法，可用于解决长期决策任务。然而，由于缺乏详细的子目标学习监督标签，并且依赖数百到数千个专家演示，因此这是一项具有挑战性的任务。在这项工作中，我们引入了 SEAL，这是一个新颖的框架，它利用大型语言模型 (LLM) 强大的语义和世界知识来指定子目标空间和预标记状态，以表示语义上有意义的子目标，而无需事先了解任务层次结构。SEAL 采用双编码器结构，将监督的 LLM 引导子目标学习与无监督的矢量量化 (VQ) 相结合，以获得更稳健的子目标表示。此外，SEAL 还结合了转换增强的低级规划器，以提高对子目标转换的适应性。我们的实验表明，SEAL 的表现优于最先进的 HIL 方法和基于 LLM 的规划方法，特别是在专家数据集较小和复杂的长期任务环境中。]]></description>
      <guid>https://arxiv.org/abs/2410.02231</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用强化学习实现高交互交通场景中的端到端驾驶</title>
      <link>https://arxiv.org/abs/2410.02253</link>
      <description><![CDATA[arXiv:2410.02253v1 公告类型：新
摘要：动态和交互式交通场景对自动驾驶系统提出了重大挑战。强化学习 (RL) 提供了一种有前途的方法，它能够探索超出预先收集的数据集和预定义条件限制的驾驶策略，尤其是在复杂环境中。然而，一个关键的挑战在于有效地从高维、多模态观测序列中提取空间和时间特征，同时最大限度地减少误差随时间的积累。此外，有效地引导大规模 RL 模型在训练过程中收敛到最佳驾驶策略而不频繁失败仍然很棘手。
我们提出了一种基于端到端模型的 RL 算法 Ramble 来解决这些问题。Ramble 将多视图 RGB 图像和 LiDAR 点云处理成低维潜在特征，以捕捉每个时间步骤的交通场景背景。然后采用基于 Transformer 的架构来建模时间依赖性并预测未来状态。通过学习环境的动态模型，Ramble 可以预测即将发生的交通事件并做出更明智的战略决策。我们的实施表明，特征提取和决策方面的先前经验在加速 RL 模型向最佳驾驶策略的收敛方面起着关键作用。Ramble 在 CARLA Leaderboard 2.0 上的路线完成率和驾驶得分方面取得了最先进的表现，展示了其在管理复杂和动态交通状况方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.02253</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IoT-LLM：利用大型语言模型增强现实世界的物联网任务推理</title>
      <link>https://arxiv.org/abs/2410.02429</link>
      <description><![CDATA[arXiv:2410.02429v1 公告类型：新
摘要：大型语言模型 (LLM) 在文本和视觉领域表现出卓越的能力，但经常产生违反物理定律的输出，揭示了它们对物理世界的理解存在差距。受人类认知的启发，感知是推理的基础，我们探索使用物联网 (IoT) 传感器数据和相关知识增强 LLM 的感知能力，以便在物理世界中进行物联网任务推理。在这项工作中，我们系统地研究了 LLM 通过增强其感知和知识库来解决现实世界物联网任务的能力，然后提出了一个统一的框架 IoT-LLM 来增强这种能力。在 IoT-LLM 中，我们为 LLM 定制了三个步骤：将物联网数据预处理为适合 LLM 的格式，通过思路提示和专门的角色定义激活他们的常识性知识，并通过基于上下文学习的面向物联网的检索增强生成来扩展他们的理解。为了评估性能，我们设计了一个新的基准，其中包含五个具有不同数据类型和推理难度的真实物联网任务，并提供了六个开源和闭源 LLM 的基准测试结果。实验结果表明，现有 LLM 的局限性在于，它们使用简单的文本输入，无法有效地执行这些任务。我们表明，IoT-LLM 显著提高了 LLM（如 GPT-4）的物联网任务推理性能，与以前的方法相比，在各种任务中平均提高了 65%。结果还展示了 LLM 通过提供推理过程来理解物联网数据和数据背后的物理定律的能力。我们工作的局限性旨在激发这个新时代的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2410.02429</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测吸引子模型</title>
      <link>https://arxiv.org/abs/2410.02430</link>
      <description><![CDATA[arXiv:2410.02430v1 公告类型：新
摘要：顺序记忆，即以正确的顺序形成并准确回忆一系列事件或刺激的能力，是生物和人工智能的基本先决条件，因为它支撑着许多认知功能（例如语言理解、规划、情景记忆形成等）。然而，现有的顺序记忆方法存在灾难性遗忘、容量有限、迭代学习过程缓慢、低阶马尔可夫记忆，最重要的是，无法表示和生成源自同一上下文的多个有效未来可能性。受生物学上合理的神经科学认知理论的启发，我们提出了 \textit{预测吸引子模型 (PAM)}，这是一种具有理想生成特性的新型序列记忆架构。PAM 是一种流式模型，通过仅观察每个输入 \textit{一次} 以在线、连续的方式学习序列。此外，我们发现 PAM 通过在皮质微柱中通过侧向抑制来唯一地表示过去的背景，从而避免灾难性遗忘，这可以防止新记忆覆盖以前学到的知识。PAM 通过从一组预测可能性的联合集合中采样来生成未来预测；这种生成能力是通过与预测器一起训练的吸引子模型实现的。我们表明，PAM 是在生物学上合理的框架中通过赫布可塑性规则使用局部计算进行训练的。本文讨论了其他理想特性（例如，噪声容忍度、基于 CPU 的学习、容量扩展）。我们的研究结果表明，PAM 代表了在追求生物学上合理且计算效率高的顺序记忆模型方面迈出的重要一步，对认知科学和人工智能研究具有广泛的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.02430</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强烈的偏好影响价值一致性的稳健性</title>
      <link>https://arxiv.org/abs/2410.02451</link>
      <description><![CDATA[arXiv:2410.02451v1 公告类型：新
摘要：价值对齐旨在确保大型语言模型 (LLM) 和其他 AI 代理的行为符合人类价值观，这对于确保这些系统的安全性和可信度至关重要。价值对齐的一个关键组成部分是将人类偏好建模为人类价值观的代表。在本文中，我们通过检查偏好模型的敏感性来研究价值对齐的稳健性。具体来说，我们问：某些偏好概率的变化如何影响这些模型对其他偏好的预测？为了回答这个问题，我们从理论上分析了广泛使用的偏好模型的稳健性，通过检查它们对它们建模的偏好的微小变化的敏感性。我们的研究结果表明，在 Bradley-Terry 和 Placket-Luce 模型中，随着其他偏好的变化，偏好的概率可能会发生显着变化，尤其是当这些偏好占主导地位时（即概率接近 0 或 1）。我们确定了这些模型中这种敏感性变得重要的具体条件，并讨论了对人工智能系统中价值一致的稳健性和安全性的实际意义。]]></description>
      <guid>https://arxiv.org/abs/2410.02451</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能掌握法律理论吗？利用多智能体协作的洞察力增强法律推理</title>
      <link>https://arxiv.org/abs/2410.02507</link>
      <description><![CDATA[arXiv:2410.02507v1 公告类型：新
摘要：大型语言模型（LLM）可能难以完全理解法律理论并执行复杂的法律推理任务。在本研究中，我们引入了一项具有挑战性的任务（混淆指控预测），以更好地评估LLM对法律理论的理解和推理能力。我们还提出了一个新颖的框架：用于提高复杂法律推理能力（MALR）的多智能体框架。MALR采用非参数学习，鼓励LLM自动分解复杂的法律任务并模仿人类的学习过程从法律规则中提取见解，帮助LLM更好地理解法律理论并提高他们的法律推理能力。在多个真实世界数据集上进行的大量实验表明，所提出的框架有效地解决了实际场景中的复杂推理问题，为法律领域更可靠的应用铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.02507</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>选择比努力更重要：法学硕士 (LLM) 助力高效多智能体探索</title>
      <link>https://arxiv.org/abs/2410.02511</link>
      <description><![CDATA[arXiv:2410.02511v1 公告类型：新
摘要：随着状态-动作空间的扩大，有效的多智能体探索仍然是强化学习中长期存在的挑战。尽管追求新颖性、多样性或不确定性越来越受到关注，但如果没有适当的指导选择，探索所带来的冗余努力对社区来说是一个实际问题。本文介绍了一种称为 LEMAE 的系统方法，该方法选择从知识丰富的大型语言模型 (LLM) 中引导信息丰富的任务相关指导，以实现高效的多智能体探索。具体来说，我们将来自 LLM 的语言知识以低 LLM 推理成本的判别方式转化为对任务完成至关重要的符号关键状态。为了释放关键状态的力量，我们设计了基于子空间的后见内在奖励 (SHIR)，通过增加奖励密度来引导代理走向关键状态。此外，我们构建了关键状态记忆树 (KSMT) 来跟踪特定任务中关键状态之间的转换，以进行有组织的探索。得益于减少冗余探索，LEMAE 在具有挑战性的基准（例如 SMAC 和 MPE）上的表现远远优于现有的 SOTA 方法，在某些情况下实现了 10 倍的加速。]]></description>
      <guid>https://arxiv.org/abs/2410.02511</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图可达性的模式感知逻辑重构</title>
      <link>https://arxiv.org/abs/2410.02533</link>
      <description><![CDATA[arXiv:2410.02533v1 公告类型：新
摘要：图可达性是理解图中两个不同点是否通过通常附加语义的弧相互连接的任务。可达性有很多应用，从运动规划到路由。提高可达性需要关系的结构知识，以避免逻辑语言中实现的传统深度优先和广度优先策略的复杂性。在某些情况下，图通过其模式定义得到丰富，为每个弧建立了域和范围。引入模式感知形式化来指导搜索可能会带来敏感的改进，通过删除无用的路径并优先考虑那些原则上更早到达目标的路径。在这项工作中，我们提出了一种策略，通过利用实例的高级概念化来自动排除和排序某些图路径。目的是获得图可达性场景的新一阶逻辑重构，能够在时间、空间要求和回溯次数方面改进传统算法。实验表明该方法具有预期的优势，减少了搜索策略中的回溯次数，从而节省了时间和空间。]]></description>
      <guid>https://arxiv.org/abs/2410.02533</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>