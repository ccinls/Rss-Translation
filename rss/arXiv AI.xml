<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 16 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>代理人作为法官：用代理人评估代理人</title>
      <link>https://arxiv.org/abs/2410.10934</link>
      <description><![CDATA[arXiv:2410.10934v1 公告类型：新
摘要：当代评估技术不适用于代理系统。这些方法要么只关注最终结果——忽略代理系统的逐步性质，要么需要过多的人工劳动。为了解决这个问题，我们引入了 Agent-as-a-Judge 框架，其中使用代理系统来评估代理系统。这是 LLM-as-a-Judge 框架的有机扩展，结合了代理功能，可为整个任务解决过程提供中间反馈。我们将 Agent-as-a-Judge 应用于代码生成任务。为了克服现有基准的问题并为 Agent-as-a-Judge 提供概念验证测试平台，我们提出了 DevAI，这是一个包含 55 个现实自动化 AI 开发任务的新基准。它包括丰富的手动注释，例如总共 365 个分层用户需求。我们使用 Agent-as-a-Judge 对三种流行的代理系统进行了基准测试，发现它的表现远远优于 LLM-as-a-Judge，并且与我们的人工评估基线一样可靠。总之，我们认为 Agent-as-a-Judge 标志着现代代理系统向前迈出了坚实的一步——通过提供动态和可扩展的自我改进所必需的丰富而可靠的奖励信号。]]></description>
      <guid>https://arxiv.org/abs/2410.10934</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WILT：面向法学硕士的多轮记忆稳健归纳逻辑基准</title>
      <link>https://arxiv.org/abs/2410.10998</link>
      <description><![CDATA[arXiv:2410.10998v1 公告类型：新
摘要：虽然大型语言模型在广泛领域中表现出令人印象深刻的能力，但它们在需要在多个回合中收集证据并得出合乎逻辑的结论的推理任务中仍然面临重大挑战。这些挑战给 LLM 聊天用户界面带来了重大障碍，因为 LLM 聊天用户界面依赖多回合交互来促进有效协作。这种限制导致了现实世界的问题；例如，服务聊天机器人必须在多个回合中从客户那里收集必要的信息，才能有效地诊断和解决问题。尽管许多现实世界的 LLM 用例具有多回合性质，但大多数现有基准测试都依赖于精心策划的单回合测试，这通常会模糊记忆和真正推理之间的界限。为了解决这个问题，我们引入了 Wason 归纳逻辑测试 (WILT)，这是一个简单但具有挑战性的多回合推理基准测试，旨在抵制记忆。 WILT 的灵感来自 Wason 2-4-6 任务，参与者必须通过提出测试用例（例如 $(2, 4, 6)$）来推断涉及三个变量的布尔函数（例如 $x &lt; y &lt; z$）。在 WILT 中，每次测试都从一张白纸开始，只提供初始指令，以防止模型依赖预先学习到的反应。经过几轮测试，模型必须通过提出测试用例与环境进行交互，以缩小可能的假设范围，并最终根据结果推断出隐藏函数。我们的研究结果表明，LLM 在完成这项任务时举步维艰，表现出明显的优势和劣势：有些模型更擅长通过提出有价值的测试用例来缩小假设空间，而另一些模型更擅长从观察到的案例中推断出隐藏函数。尽管存在这些差异，但表现最佳的模型也只实现了 28% 的准确率，凸显了 LLM 在复杂的多轮推理任务中的表现存在显著差距。]]></description>
      <guid>https://arxiv.org/abs/2410.10998</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过答案集编程为树集成学习方法生成全局和局部解释</title>
      <link>https://arxiv.org/abs/2410.11000</link>
      <description><![CDATA[arXiv:2410.11000v1 公告类型：新
摘要：我们提出了一种使用答案集编程 (ASP) 为树集成学习方法生成规则集作为全局和局部解释的方法。为此，我们采用分解方法，在规则构建中利用基础决策树的分割结构，然后使用 ASP 中编码的模式挖掘方法评估规则以提取解释规则。对于全局解释，从整个训练的树集成模型中选择候选规则，而对于局部解释，仅考虑与特定预测实例相关的规则来选择候选规则。我们展示了如何在 ASP 中以声明方式表示用户定义的约束和偏好，以允许透明和灵活的规则集生成，以及如何将规则用作解释以帮助用户更好地理解模型。使用真实数据集和流行的树集成算法进行的实验评估表明，我们的方法适用于广泛的分类任务。正在逻辑编程理论与实践 (TPLP) 中考虑。]]></description>
      <guid>https://arxiv.org/abs/2410.11000</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>3D-Prover：利用行列式点过程进行多样性驱动的定理证明</title>
      <link>https://arxiv.org/abs/2410.11133</link>
      <description><![CDATA[arXiv:2410.11133v1 公告类型：新
摘要：自动形式推理的一个关键挑战是难以处理的搜索空间，该空间随着证明的深度而呈指数增长。这种分支是由可应用于给定目标的大量候选证明策略引起的。尽管如此，这些策略中的许多在语义上相似或导致执行错误，在这两种情况下都浪费了宝贵的资源。我们解决了有效修剪此搜索的问题，仅使用从以前的证明尝试生成的合成数据。我们首先证明可以生成语义感知的策略表示，以捕捉对证明环境、成功可能性和执行时间的影响。然后，我们提出了一种新颖的过滤机制，该机制利用这些表示来选择语义多样且高质量的策略，使用行列式点过程。我们的方法 3D-Prover 旨在通用，并增强任何底层策略生成器。我们通过增强 ReProver LLM 证明了 3D-Prover 在 miniF2F-valid 和 miniF2F-test 基准上的有效性。我们表明，我们的方法可以提高整体证明率，并显著提高策略成功率、执行时间和多样性。]]></description>
      <guid>https://arxiv.org/abs/2410.11133</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结构化数据可以减少认知不确定性吗？</title>
      <link>https://arxiv.org/abs/2410.11141</link>
      <description><![CDATA[arXiv:2410.11141v1 公告类型：新
摘要：在这项工作中，我们提出了一个利用本体对齐来改进深度学习模型学习过程的框架。通过这种方法，我们表明，与模型的原生版本相比，使用本体进行微调的模型可以以更高的速度学习下游任务，并且在顺序分类任务上具有更好的性能。此外，我们扩展了我们的工作，以展示在本体对齐过程中检索到的包容映射如何帮助增强大型语言模型中的检索增强生成。结果表明，使用包容映射获得的响应显示上下文相似度增加了 8.97%，事实准确性增加了 1%。我们还使用这些分数来定义我们的幻觉指数，并表明这种方法将 LLM 中的幻觉降低了 4.847%。]]></description>
      <guid>https://arxiv.org/abs/2410.11141</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>潜在预测赋权：无需模拟器即可测量赋权</title>
      <link>https://arxiv.org/abs/2410.11155</link>
      <description><![CDATA[arXiv:2410.11155v1 公告类型：新
摘要：赋权有潜力帮助代理学习大型技能，但目前还不是训练通用代理的可扩展解决方案。最近的赋权方法通过最大化技能和状态之间的相互信息来学习不同的技能；然而，这些方法需要一个转换动态模型，这在具有高维和随机观测的现实环境中学习起来可能具有挑战性。我们提出了潜在预测赋权 (LPE)，这是一种可以以更实用的方式计算赋权的算法。LPE 通过最大化一个目标来学习大型技能，该目标是技能和状态之间相互信息的原则性替代品，并且只需要一个更简单的潜在预测模型，而不是一个完整的环境模拟器。我们在各种环境中（包括具有高维观测和高度随机转换动态的环境）通过实证研究证明，我们的赋权目标 (i) 学习与领先的赋权算法相似大小的技能组合，该算法假设可以访问转换动态模型，并且 (ii) 优于其他基于模型的赋权方法。]]></description>
      <guid>https://arxiv.org/abs/2410.11155</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在连续状态和动作空间中学习具有优先级和参数噪声的代理</title>
      <link>https://arxiv.org/abs/2410.11250</link>
      <description><![CDATA[arXiv:2410.11250v1 公告类型：新
摘要：在 RL 的众多变体中，一个重要的问题是状态和动作空间是连续的——自主机器人、自动驾驶汽车、最优控制都是此类问题的例子，这些问题可以自然地适用于基于强化的算法，并且具有连续的状态和动作空间。在本文中，我们引入了一种优先形式，结合了深度 Q 学习 (DQN) 和深度确定性策略梯度 (DDPG) 等最先进的方法，以超越早期的连续状态和动作空间问题结果。我们的实验还涉及在训练期间使用参数噪声，从而产生更强大的深度 RL 模型，其性能显著优于早期结果。我们相信这些结果对于连续状态和动作空间问题是一个有价值的补充。]]></description>
      <guid>https://arxiv.org/abs/2410.11250</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的离线 RL 用于改善增强 ARC 任务中的决策</title>
      <link>https://arxiv.org/abs/2410.11324</link>
      <description><![CDATA[arXiv:2410.11324v1 公告类型：新
摘要：有效的长期策略使 AI 系统能够通过在扩展范围内做出连续决策来驾驭复杂环境。同样，强化学习 (RL) 代理可以跨序列优化决策以最大化奖励，即使没有即时反馈也是如此。为了验证潜在扩散约束 Q 学习 (LDCQ)（一种著名的基于扩散的离线 RL 方法）在多步决策中表现出强大的推理能力，我们旨在评估其在抽象和推理语料库 (ARC) 上的表现。然而，由于 ARC 训练集中缺乏足够的经验数据，应用离线 RL 方法来增强 AI 中的战略推理以解决 ARC 中的任务具有挑战性。为了解决这一限制，我们为 ARC 引入了一个增强的离线 RL 数据集，称为用于抽象和推理的合成离线学习数据 (SOLAR)，以及 SOLAR-Generator，它根据预定义的规则生成不同的轨迹数据。 SOLAR 通过提供足够的经验数据来实现离线 RL 方法的应用。我们为一个简单的任务合成了 SOLAR，并用它来训练使用 LDCQ 方法的代理。我们的实验证明了离线 RL 方法在简单的 ARC 任务上的有效性，展示了代理能够做出多步顺序决策并正确识别答案状态的能力。这些结果凸显了离线 RL 方法在增强 AI 战略推理能力方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.11324</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用自注意力网络实现确定性逻辑程序的推导</title>
      <link>https://arxiv.org/abs/2410.11396</link>
      <description><![CDATA[arXiv:2410.11396v1 公告类型：新
摘要：在本文中，我们提出可以使用自注意网络实现逻辑推理的受限版本。我们的目的是展示用变压器网络构建的LLM（大型语言模型）可以进行逻辑推理。我们将通过分析自注意网络（变压器网络的主要组成部分）来揭示LLM的潜力。我们的方法不是基于自然语言的语义，而是基于逻辑推理的操作。%观点。我们表明，具有前馈网络（FFN）的自注意网络的分层构造可以为一类逻辑公式实现自上而下的推导。我们还展示了自下而上的推导也适用于同一类。我们相信我们的结果表明LLM隐含地具有逻辑推理的能力。]]></description>
      <guid>https://arxiv.org/abs/2410.11396</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能意识案例：语言代理和全局工作区理论</title>
      <link>https://arxiv.org/abs/2410.11407</link>
      <description><![CDATA[arXiv:2410.11407v1 公告类型：新
摘要：人们普遍认为，现有的人工系统不具备现象意识，而构建具有现象意识的人工系统需要重大的技术进步，如果这是可能的。我们通过以下论点来挑战这一假设：如果全局工作空间理论 (GWT)（一种领先的现象意识科学理论）是正确的，那么一种广泛实施的人工智能架构的实例，即人工语言代理，如果它们还没有具备现象意识，就很容易具备现象意识。在此过程中，我们阐明了一种明确的方法来思考如何将意识的科学理论应用于人工系统，并利用这种方法根据 GWT 得出一组现象意识的必要和充分条件。]]></description>
      <guid>https://arxiv.org/abs/2410.11407</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新审视基准和评估：基于代理的法学硕士探索性动态评估框架</title>
      <link>https://arxiv.org/abs/2410.11507</link>
      <description><![CDATA[arXiv:2410.11507v2 公告类型：新
摘要：虽然已经开发了各种垂直领域大型语言模型 (LLM)，但自动评估它们在不同领域的性能的挑战仍然很大。当前基于基准的评估方法表现出僵化、无目的的交互，并且依赖于预先收集的静态数据集，这些数据集构建成本高、跨领域不灵活且与实际用户需求不一致。为了解决这个问题，我们重新审视评估组件并引入两个概念：Benchmark+，它将传统的问答基准扩展为更灵活的“策略标准”格式；Assessment+，它增强了交互过程，使更深入的探索成为可能，并支持定量指标和定性见解。这些概念通过更丰富的多轮交互捕捉 LLM 的细微行为。我们提出了一个基于代理的评估框架 TestAgent，它通过检索增强生成和强化学习来实现这些概念。从构建垂直领域评估到激活现有基准等任务的实验证明了 TestAgent 在各种场景中的有效性。我们相信这项工作为 LLM 的自动评估提供了一个有趣的视角。]]></description>
      <guid>https://arxiv.org/abs/2410.11507</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AGENTiGraph：利用私人数据的 LLM 聊天机器人交互式知识图谱平台</title>
      <link>https://arxiv.org/abs/2410.11531</link>
      <description><![CDATA[arXiv:2410.11531v1 公告类型：新
摘要：大型语言模型（LLM）已在各种应用中展示了其能力，但面临着幻觉、有限的推理能力和事实不一致等挑战，尤其是在处理复杂的特定领域任务（如问答）时。虽然知识图谱（KG）已被证明有助于缓解这些问题，但关于 LLM 与背景 KG 集成的研究仍然有限。特别是，用户可访问性和底层 KG 的灵活性尚未得到彻底探索。我们引入了 AGENTiGraph（基于任务的交互和图形表示的自适应生成引擎），这是一个通过自然语言交互进行知识管理的平台。它集成了知识提取、集成和实时可视化。AGENTiGraph 采用多代理架构来动态解释用户意图、管理任务和集成新知识，确保适应不断变化的用户需求和数据环境。我们的方法在知识图谱交互方面表现出色，尤其是对于复杂的特定领域任务。在 3,500 个测试用例的数据集上进行的实验结果表明，AGENTiGraph 的表现明显优于最先进的零样本基线，在任务分类中实现了 95.12% 的准确率，在任务执行中实现了 90.45% 的成功率。用户研究证实了它在现实场景中的有效性。为了展示多功能性，我们将 AGENTiGraph 扩展到立法和医疗保健领域，构建了能够回答法律和医疗背景下的复杂查询的专用 KG。]]></description>
      <guid>https://arxiv.org/abs/2410.11531</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Y-Mol：一种用于药物开发的多尺度生物医学知识引导的大型语言模型</title>
      <link>https://arxiv.org/abs/2410.11550</link>
      <description><![CDATA[arXiv:2410.11550v1 公告类型：新
摘要：大型语言模型 (LLM) 最近在各个领域的一般任务中表现出色。然而，它们在药物开发等特定领域的有效性仍然存在挑战。为了解决这些挑战，我们引入了 \textbf{Y-Mol}，为药物开发流程形成了完善的 LLM 范式。Y-Mol 是一种多尺度生物医学知识引导的 LLM，旨在完成先导化合物发现、临床前和临床预测等任务。通过整合数百万个多尺度生物医学知识并使用 LLaMA2 作为基础 LLM，Y-Mol 通过从出版物语料库、知识图谱和专家设计的合成数据中学习，增强了生物医学领域的推理能力。该功能通过三种面向药物的指令得到进一步丰富：来自已处理出版物的基于描述的提示、用于从知识图中提取关联的基于语义的提示以及用于理解来自生物医学工具的专家知识的基于模板的提示。此外，Y-Mol 提供了一套 LLM 范例，可以自主执行整个药物开发过程中的下游任务，包括虚拟筛选、药物设计、药理特性预测和药物相关相互作用预测。我们对各种生物医学来源的广泛评估表明，Y-Mol 在发现先导化合物、预测分子特性和识别药物相互作用事件方面明显优于通用 LLM。]]></description>
      <guid>https://arxiv.org/abs/2410.11550</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UFO 是否推动了创新？大型语言模型中的因果关系错觉</title>
      <link>https://arxiv.org/abs/2410.11684</link>
      <description><![CDATA[arXiv:2410.11684v1 公告类型：新
摘要：当人们在没有支持证据的情况下相信两个变量之间存在因果关系时，就会产生因果错觉。这种认知偏见被认为是许多社会问题的根源，包括社会偏见、刻板印象形成、错误信息和迷信思想。在这项研究中，我们调查了大型语言模型是否会在现实世界中产生因果错觉。我们评估并比较了 GPT-4o-Mini、Claude-3.5-Sonnet 和 Gemini-1.5-Pro 生成的新闻标题，以确定这些模型是否错误地将相关性定义为因果关系。为了衡量阿谀奉承行为（当模型与用户的信念保持一致以使其看起来有利时发生，即使它不是客观正确的），我们还将偏见纳入提示中，观察这种操纵是否会增加模型表现出因果错觉的可能性。我们发现，与人工撰写的新闻稿中因果关系夸大实验的结果一致，Claude-3.5-Sonnet 模型表现出的因果错觉程度最低。另一方面，我们的研究结果表明，虽然模仿谄媚会增加这些模型中因果错觉的可能性，尤其是在 GPT-4o-Mini 中，但 Claude-3.5-Sonnet 仍然是抵御这种认知偏见最强大的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.11684</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>认知缺陷的证据和生成式人工智能的发展进步：钟表绘图测试分析</title>
      <link>https://arxiv.org/abs/2410.11756</link>
      <description><![CDATA[arXiv:2410.11756v1 公告类型：新
摘要：生成式人工智能的快速发展激发了人们对其认知能力的兴趣，尤其是考虑到它能够完成语言理解和代码生成等任务。这项研究探讨了几个最近的 GenAI 模型在时钟绘图测试 (CDT) 中的表现，这是一种对视觉空间规划和组织的神经心理学评估。虽然模型可以创建类似时钟的绘图，但它们在准确的时间表示方面存在困难，显示出与轻度至重度认知障碍 (Wechsler, 2009) 类似的缺陷。尽管准确呈现了时钟特征，但错误包括数字排序问题、错误的时钟时间和不相关的添加。只有 GPT 4 Turbo 和 Gemini Pro 1.5 产生了正确的时间，得分与健康人 (4/4) 一样。后续的时钟读数测试显示只有 Sonnet 3.5 成功，这表明绘画缺陷源于数字概念的困难。这些发现可能反映了视觉空间理解、工作记忆或计算方面的弱点，凸显了学习知识的优势，但推理能力较弱。比较人类和机器的表现对于理解人工智能的认知能力和指导向类似人类的认知功能发展至关重要。]]></description>
      <guid>https://arxiv.org/abs/2410.11756</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线客户端调度和资源分配，实现高效的联邦边缘学习</title>
      <link>https://arxiv.org/abs/2410.10833</link>
      <description><![CDATA[arXiv:2410.10833v1 公告类型：交叉 
摘要：联邦学习 (FL) 使边缘设备能够协作训练机器学习模型，而无需共享其原始数据。由于其隐私保护优势，FL 已部署在许多实际应用中。然而，在具有功率、带宽和计算等受限资源的移动边缘网络上部署 FL 会导致高训练延迟和低模型精度，尤其是在数据和系统异构的情况下。在本文中，我们研究了在资源受限和不确定性下移动边缘网络上 FL 的最佳客户端调度和资源分配，以最大限度地减少训练延迟，同时保持模型精度。具体来说，我们首先分析客户端采样对 FL 中模型收敛的影响，并制定一个随机优化问题，该问题捕捉了异构和不确定系统资源下运行时间和模型性能之间的权衡。为了解决这个公式化的问题，我们进一步开发了一种基于 Lyapunov 优化的在线控制方案，用于客户端采样和资源分配，而无需了解 FL 系统中的未来动态。大量实验结果表明，与现有方案相比，提出的方案可以提高训练延迟和资源效率。]]></description>
      <guid>https://arxiv.org/abs/2410.10833</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关注重要的事情：基于视觉的强化学习泛化的分离模型</title>
      <link>https://arxiv.org/abs/2410.10834</link>
      <description><![CDATA[arXiv:2410.10834v1 公告类型：交叉 
摘要：基于视觉的强化学习 (RL) 面临的主要挑战是在看不见的环境中有效地进行泛化。尽管先前的研究已经探索了不同的辅助任务来增强泛化，但很少有研究采用图像重建，因为担心在训练过程中加剧对与任务无关的特征的过度拟合。认识到图像重建在表示学习中的卓越地位，我们提出了 SMG（用于泛化的分离模型），这是一种利用图像重建进行泛化的新方法。SMG 引入了两个模型分支，通过协作重建分别从视觉观察中提取与任务相关和与任务无关的表示。在此架构的基础上，我们进一步强调了与任务相关的特征对于泛化的重要性。具体而言，SMG 结合了两个额外的一致性损失，以引导代理在不同场景中的注意力转向与任务相关的区域，从而实现避免过度拟合。 DMC 中的大量实验证明了 SMG 在泛化方面的 SOTA 性能，尤其是在视频背景设置中表现出色。对机器人操作任务的评估进一步证实了 SMG 在实际应用中的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.10834</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>精心设计叙事结尾：使用 SSM Mamba 进行零样本学习以生成短篇故事结尾</title>
      <link>https://arxiv.org/abs/2410.10848</link>
      <description><![CDATA[arXiv:2410.10848v1 公告类型：交叉 
摘要：写故事是一项引人入胜但又充满挑战性的工作。作者经常会遇到创作瓶颈，他们的叙述前进的道路变得模糊不清。本文旨在通过提供一种创新的解决方案来解决此类问题：一种根据给定提示完成故事的工具。通过输入一个短篇故事提示，用户可以收到他们的故事的结论，用一句话或多句话表达出来，从而通过人工智能驱动的创造力增强讲故事的过程。这个工具不仅旨在帮助作者克服写作瓶颈，而且还为任何人提供一种有趣且互动的方式，让他们自发地扩展故事创意。通过这篇论文，我们探索了人工智能与创意写作的交集，突破了故事创作和结局的界限。为了创建最终的文本生成模型，我们使用了预先训练的 GPT-3.5 模型和新创建的微调 SSM-Mamba 模型，这两个模型在包括 BERT 分数、METEOR、BLEU、ROUGE 和 Perplexity 在内的一系列指标上均表现良好。SSM 模型也已作为开源贡献向 HuggingFace 模型上的 NLP 社区公开，这暂时是 HuggingFace 上故事生成任务中首个此类状态空间模型。]]></description>
      <guid>https://arxiv.org/abs/2410.10848</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续近似法用于改进 LLM 的量化感知训练</title>
      <link>https://arxiv.org/abs/2410.10849</link>
      <description><![CDATA[arXiv:2410.10849v1 公告类型：交叉 
摘要：模型压缩方法用于减少大型语言模型 (LLM) 的计算和能量需求。量化感知训练 (QAT) 是一种有效的模型压缩方法，旨在减少量化后的性能下降。为了进一步减少这种性能下降，我们在舍入函数（传统上由直通估计器 (STE) 近似）和夹紧函数上对 QAT 过程引入了两个连续近似。通过应用这两种方法，量化模型在 WikiText-v2 数据集上的困惑度 (PPL) 达到 9.0815，优于基线的 9.9621。此外，我们在 BoolQ 上实现了 2.76% 的改进，在 MMLU 上实现了 5.47% 的改进，证明了使用我们的方法可以更准确地学习步长和权重。我们的方法在相同的精度、模型大小和训练设置下实现了更好的性能，有助于开发符合全球可持续发展目标的更节能的 LLM 技术。]]></description>
      <guid>https://arxiv.org/abs/2410.10849</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对错误提示和人口统计学提示的可靠性</title>
      <link>https://arxiv.org/abs/2410.10850</link>
      <description><![CDATA[arXiv:2410.10850v1 公告类型：交叉 
摘要：我们调查并观察了大型语言模型 (LLM) 支持的聊天机器人在气候变化和心理健康领域中处理带有人口统计信息的错误提示和问题的行为和性能。通过定量和定性方法的结合，我们评估了聊天机器人辨别陈述真实性、对事实的遵守以及其回答中是否存在偏见或错误信息的能力。我们使用真/假问题进行的定量分析表明，这些聊天机器人可以依靠这些封闭式问题给出正确的答案。然而，从领域专家那里收集到的定性见解表明，人们仍然担心隐私、道德影响以及聊天机器人引导用户获得专业服务的必要性。我们得出的结论是，虽然这些聊天机器人具有巨大的前景，但它们在敏感领域的部署需要仔细考虑、道德监督和严格改进，以确保它们能够有益地增强人类的专业知识，而不是一个自主的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.10850</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>