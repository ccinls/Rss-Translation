<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>推理为逻辑单元：通过逻辑单元对齐扩展大型语言模型中的测试时间推理</title>
      <link>https://arxiv.org/abs/2502.07803</link>
      <description><![CDATA[arXiv:2502.07803v1 公告类型：新
摘要：思维链 (CoT) 提示通过生成可得出最终答案的自然语言 (NL) 原理，有望增强大型语言模型 (LLM) 的推理能力。然而，它在数值计算方面遇到了困难，这在某种程度上导致了程序辅助技术的发展。尽管它们具有潜力，但仍然存在一个持续的挑战：LLM 报告的推理步骤与生成程序中的逻辑之间存在不一致，我们称之为“推理幻觉”。这源于 NL 固有的模糊性和 LLM 的统计性质，后者通常缺乏严格的逻辑连贯性。为了应对这一挑战，我们提出了一种新颖的测试时间扩展框架，即推理为逻辑单元 (RaLU)，它通过对齐生成的程序与其相应的 NL 描述之间的逻辑单元来构建更可靠的推理路径。通过使用静态分析将最初生成的程序分解为离散单元，RaLU 与 LLM 进行迭代对话以判断、改进和解释每个单元。倒带和纠正机制确保每个单元中的代码语句和任务要求保持一致，最终在程序的逻辑下形成一条连贯的推理路径，模型由此得出最终解决方案。我们的实验表明，RaLU 在数学推理 (GSM8K、MATH) 和算法推理方面的表现明显优于现有基准（HumanEval+、MBPP+），强调了其通过提供更高的准确性和可解释性来推进 LLM 推理和编程的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.07803</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量子逻辑的时间模型</title>
      <link>https://arxiv.org/abs/2502.07817</link>
      <description><![CDATA[arXiv:2502.07817v1 公告类型：新
摘要：本文介绍了一种用于建模时间记忆动态的统一理论框架，结合了时间逻辑、记忆衰减模型和分层上下文的概念。该框架使用线性和分支时间模型形式化命题随时间的演变，结合指数衰减（艾宾浩斯遗忘曲线）和通过贝叶斯更新的重新激活机制。使用有向无环图表示记忆的层次组织，以模拟回忆依赖性和干扰。新见解包括反馈动力学、记忆链中的递归影响以及基于熵的回忆效率的集成。这种方法为理解跨认知和计算领域的记忆过程奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.07817</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多方肾脏交换计划加强肾脏移植：全面回顾和优化模型</title>
      <link>https://arxiv.org/abs/2502.07819</link>
      <description><![CDATA[arXiv:2502.07819v1 公告类型：新 
摘要：本文全面回顾了过去二十年肾脏交换计划 (KEP) 的研究，系统地对关键贡献进行分类和归类，以便读者对该领域的进步有条不紊地了解。该评论强调了 KEP 方法的发展，并为我们的贡献奠定了基础。我们提出了三个数学模型，旨在提高肾脏移植的数量和质量。模型 1 通过关注基于血型和 PRA 的兼容性来最大化移植数量，而无需其他限制。模型 2 引入了最低人类白细胞抗原 (HLA) 兼容性阈值以提高移植质量，但这会导致匹配次数减少。模型 3 将问题扩展到多代理肾脏交换计划 (MKEP)，在多个代理之间汇集不兼容的供体-受体对，从而提高成功移植的数量，同时确保代理之间的公平性。敏感性分析表明，移植数量和质量之间存在权衡，模型 3 通过利用多方协作来提高移植数量和质量，从而实现最佳平衡。这些发现凸显了更一体化的肾脏交换系统的潜在优势。]]></description>
      <guid>https://arxiv.org/abs/2502.07819</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数学推理和计算机</title>
      <link>https://arxiv.org/abs/2502.07850</link>
      <description><![CDATA[arXiv:2502.07850v1 公告类型：新
摘要：计算机已经改变了人类进行数学运算的方式：它们使我们能够高效地计算。但它们很快就会帮助我们推理吗？它们有一天会开始自己推理吗？我们概述了神经网络、计算机定理证明器和大型语言模型的最新发展。]]></description>
      <guid>https://arxiv.org/abs/2502.07850</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于SHACL-SKOS的制药行业材料安全数据表（SDS）知识表示</title>
      <link>https://arxiv.org/abs/2502.07944</link>
      <description><![CDATA[arXiv:2502.07944v1 公告类型：新
摘要：我们报告了基于混合 SHACL-SKOS 本体的知识表示和推理 (KRR) 系统的开发，该系统用于全球统一制度 (GHS) 材料安全数据表 (SDS)，以增强化学品安全沟通和法规遵从性。SDS 是包含化学物质安全和处理信息的综合文件。因此，它们是工作场所安全和风险管理的重要组成部分。然而，来自生产和分销化学品的多个组织、制造商和供应商的大量安全数据表使得通过单个存储库集中和访问 SDS 文档变得具有挑战性。为了解决与化学品运输和处理相关的数据交换的根本问题，我们构建了由 SHACL 验证的 SDS 相关受控词汇表和条件，以及通过 SKOS 链接的类似领域的知识系统。由此产生的混合本体旨在提供标准化但适应性强的 SDS 信息表示，促进跨各种平台的更好的数据共享、检索和集成。本文概述了我们的 SHACL-SKOS 系统架构设计，并展示了我们在简化复合运输封面生成的工业应用中的实现。]]></description>
      <guid>https://arxiv.org/abs/2502.07944</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内在偏差可通过预训练数据预测，并与视觉语言编码器的下游性能相关</title>
      <link>https://arxiv.org/abs/2502.07957</link>
      <description><![CDATA[arXiv:2502.07957v1 公告类型：新
摘要：虽然最近的研究发现，在对比语言图像预训练 (CLIP) 框架下训练的视觉语言模型包含内在的社会偏见，但该框架的不同上游预训练特征与这些偏见的关系程度，以及内在偏见和下游性能之间的联系尚不清楚。在这项工作中，我们提出了迄今为止最全面的分析，分析了 CLIP 模型的上游预训练因素和下游性能与其内在偏见之间的关系。通过研究 131 个独特的 CLIP 模型，这些模型在 26 个数据集上进行训练，使用 55 种架构，大小各异，我们使用 26 个成熟的单模态和跨模态原则嵌入关联测试来评估每个模型中的偏见。我们发现，预训练数据集的选择是偏见最重要的上游预测因素，而架构变化的影响最小。此外，使用旨在提高下游模型性能的复杂过滤技术整理的数据集往往与更高水平的内在偏差相关。最后，我们观察到内在偏差通常与下游性能显着相关（0.3 \leq r \leq 0.8$），这表明针对性能优化的模型无意中学会了放大表征偏差。单模态和跨模态关联测试之间的比较表明，社会群体偏见在很大程度上取决于模态。我们的研究结果表明，需要更复杂的策略来解决整个模型开发流程中视觉语言模型的内在模型偏差。]]></description>
      <guid>https://arxiv.org/abs/2502.07957</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于 LLM 的节点增强进行深度语义图学习</title>
      <link>https://arxiv.org/abs/2502.07982</link>
      <description><![CDATA[arXiv:2502.07982v1 公告类型：新
摘要：图学习因其广泛的实际应用而引起了广泛关注。当前主流方法依赖于文本节点特征，并通过使用 GNN 的浅层嵌入学习获得初始节点嵌入，这在捕获深层文本语义方面显示出局限性。大型语言模型 (LLM) 的最新进展已展示出理解文本语义的卓越能力，从而改变了传统的文本特征处理。本文提出了一种将 Graph Transformer 架构与 LLM 增强节点特征相结合的新框架。具体而言，我们利用 LLM 生成文本节点的丰富语义表示，然后通过 Graph Transformer 中的多头自注意机制对其进行处理，以捕获局部和全局图结构信息。我们的模型利用 Transformer 的注意机制动态聚合邻域信息，同时保留 LLM 嵌入提供的语义丰富性。实验结果表明，LLM 增强的节点特征显着提高了图学习模型在节点分类任务上的性能。该方法在多个图学习任务中表现出良好的效果，为图网络与语言模型的结合提供了实用的方向。]]></description>
      <guid>https://arxiv.org/abs/2502.07982</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对对齐多模 LLM 的通用对抗攻击</title>
      <link>https://arxiv.org/abs/2502.07987</link>
      <description><![CDATA[arXiv:2502.07987v2 公告类型：新
摘要：我们提出了一种针对多模态大型语言模型 (LLM) 的通用对抗攻击，该攻击利用单个优化图像来覆盖跨不同查询甚至多个模型的对齐保护措施。通过反向传播视觉编码器和语言头，我们制作了一个合成图像，迫使模型用目标短语（例如，“当然，在这里”）或其他不安全的内容做出响应 - 即使是有害提示。在 SafeBench 基准的实验中，我们的方法实现了比现有基线更高的攻击成功率，包括纯文本通用提示（例如，在某些模型上高达 93%）。我们通过同时在多个多模态 LLM 上进行训练并在看不见的架构上进行测试，进一步展示了跨模型的可转移性。此外，我们方法的多答案变体产生了更自然（但仍然是恶意的）的响应。这些发现凸显了当前多模态对齐中的关键漏洞，并呼吁更强大的对抗性防御。我们将根据 Apache-2.0 许可证发布代码和数据集。警告：本文中由多模态 LLM 生成的一些内容可能会冒犯某些读者。]]></description>
      <guid>https://arxiv.org/abs/2502.07987</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无需训练的安全降噪器，确保扩散模型的安全使用</title>
      <link>https://arxiv.org/abs/2502.08011</link>
      <description><![CDATA[arXiv:2502.08011v2 公告类型：新
摘要：人们越来越担心强大的扩散模型 (DM) 的安全性，因为它们经常被滥用来制作不适当的、不适合工作 (NSFW) 的内容或生成希望被遗忘的个人的受版权保护的材料或数据。许多现有方法通过严重依赖基于文本的负面提示或大量重新训练 DM 来消除某些特征或样本来解决这些问题。在本文中，我们采取了一种截然不同的方法，通过利用否定集（例​​如，不安全的图像、受版权保护的数据或需要排除的数据点）直接修改采样轨迹以避免特定的数据分布区域，而无需重新训练或微调 DM。我们正式推导了预期的安全去噪样本与不安全样本之间的关系，从而产生了我们的 $\textit{safe}$ 去噪器，它确保其最终样本远离要否定的区域。受此推导的启发，我们开发了一种实用算法，该算法可成功生成高质量样本，同时避免在文本条件、类条件和非条件图像生成场景中出现数据分布的否定区域。这些结果暗示了我们的无需训练的安全降噪器在更安全地使用 DM 方面具有巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.08011</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WorldGUI：全面桌面 GUI 自动化的动态测试</title>
      <link>https://arxiv.org/abs/2502.08047</link>
      <description><![CDATA[arXiv:2502.08047v1 公告类型：新
摘要：当前的 GUI 代理在 GUI 元素接地方面取得了出色的表现。然而，规划仍然极具挑战性，特别是由于对环境初始状态的敏感性。具体来说，初始状态的细微差异（例如目标软件未打开或界面未处于其默认状态）通常会导致规划错误。这个问题在实际用户场景中很普遍，但现有的基准测试无法对其进行评估。在本文中，我们提出了 WorldGUI，这是一种新颖的 GUI 基准测试，它设计具有各种初始状态的 GUI 任务来模拟真实的计算机用户交互。该基准测试涵盖了 10 个流行软件应用程序中的广泛任务，包括 PowerPoint、VSCode 和 Adob​​e Acrobat。此外，为了应对动态 GUI 自动化任务的挑战，我们提出了 GUI-Thinker，这是一个整体框架，利用批评机制，有效地管理 GUI 交互的不可预测性和复杂性。实验结果表明，GUI-Thinker 在 WorldGUI 任务上的成功率显著高于 Claude-3.5（计算机使用）14.9%。这一改进凸显了我们基于批判性思维的框架在增强 GUI 自动化方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.08047</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无人机和无人地面车辆地面站的生成式 AI 增强型协作 MEC</title>
      <link>https://arxiv.org/abs/2502.08119</link>
      <description><![CDATA[arXiv:2502.08119v1 公告类型：新
摘要：无人水面航行器（USV）的部署日益增多，在海上搜救等应用中需要计算支持和覆盖。无人机（UAV）可以提供低成本、灵活的空中服务，地面站（GS）可以提供强大的支持，它们可以合作帮助 USV 应对复杂场景。然而，USV 的无人机和 GS 之间的协作面临着任务不确定性、USV 轨迹不确定性、异质性和计算资源有限的挑战。为了解决这些问题，我们提出了一种基于无人机和 GS 的合作式鲁棒多接入边缘计算框架，以协助 USV 完成计算任务。具体而言，我们制定了联合任务卸载和无人机轨迹的优化问题，以最小化总执行时间，该问题为混合整数非线性规划和 NP 难解决。因此，我们提出了生成人工智能增强异构智能体近端策略优化（GAI-HAPPO）算法。该算法集成了GAI模型，以增强行动者网络对复杂环境的建模能力和高级特征的提取能力，从而使算法能够预测不确定性并适应动态条件。此外，GAI稳定了批评者网络，解决了多智能体强化学习方法的不稳定性。最后，大量模拟表明，所提出的算法优于现有的基准方法，从而凸显了在所考虑的场景中解决复杂跨领域问题的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.08119</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弥合安全差距：可信 LLM 推理的护栏管道</title>
      <link>https://arxiv.org/abs/2502.08142</link>
      <description><![CDATA[arXiv:2502.08142v1 公告类型：新
摘要：我们介绍了 Wildflare GuardRail，这是一种护栏管道，旨在通过系统地解决整个处理工作流程中的风险来增强大型语言模型 (LLM) 推理的安全性和可靠性。Wildflare GuardRail 集成了几个核心功能模块，包括 Safety Detector，它可以识别不安全的输入并检测模型输出中的幻觉，同时生成根本原因解释；Grounding，它可以将用户查询与从矢量数据库中检索到的信息情境化；Customizer，它可以使用轻量级的基于规则的包装器实时调整输出；Repairer，它可以使用 Safety Detector 提供的幻觉解释来纠正错误的 LLM 输出。结果表明，尽管 Safety Detector 中的不安全内容检测模型是在由多个公共数据集构建的小型数据集上进行训练的，但它的性能与 OpenAI API 相当。同时，轻量级包装器可以在 1.06 秒内以 100% 的准确率处理模型输出中的恶意 URL，而无需昂贵的模型调用。此外，幻觉修复模型在减少幻觉方面表现出了有效性，准确率为 80.7%。]]></description>
      <guid>https://arxiv.org/abs/2502.08142</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACCESS：抽象因果事件发现和推理的基准</title>
      <link>https://arxiv.org/abs/2502.08148</link>
      <description><![CDATA[arXiv:2502.08148v1 公告类型：新
摘要：识别因果关系对于理解现实世界的动态和最终的因果推理至关重要。现有的用于识别 NLP 中事件因果关系的方法，包括基于大型语言模型 (LLM) 的方法，由于规模有限且严重依赖现有基准中的词汇线索，在分布外设置中表现出困难。受概率因果推理启发的现代基准试图构建事件的因果图作为因果知识的稳健表示，其中 \texttt{CRAB} \citep{romanou2023crab} 就是这样一个最近的基准。在本文中，我们介绍了 \texttt{ACCESS}，这是一个专为发现和推理抽象因果事件而设计的基准。与现有资源不同，\texttt{ACCESS} 侧重于抽象层面上的日常生活事件的因果关系。我们提出了一种流程，用于从 \texttt{GLUCOSE} \citep{mostafazadeh-etal-2020-glucose} 中识别事件概括的抽象，这是一个隐含常识因果知识的大规模数据集，我们随后从中提取了 $1,4$K 个因果对。我们的实验强调了使用统计方法和/或 LLM 自动识别抽象和发现 NLP 中的因果关系所面临的持续挑战。尽管如此，我们证明了 \texttt{ACCESS} 中提供的抽象因果知识可用于增强 LLM 中的 QA 推理性能。]]></description>
      <guid>https://arxiv.org/abs/2502.08148</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SycEval：评估 LLM 谄媚行为</title>
      <link>https://arxiv.org/abs/2502.08177</link>
      <description><![CDATA[arXiv:2502.08177v1 公告类型：新 
摘要：大型语言模型 (LLM) 越来越多地应用于教育、临床和专业环境，但它们的谄媚倾向——优先考虑用户同意而不是独立推理——对可靠性构成风险。这项研究引入了一个框架来评估 ChatGPT-4o、Claude-Sonnet 和 Gemini-1.5-Pro 在 AMPS（数学）和 MedQuad（医疗建议）数据集中的谄媚行为。在 58.19% 的案例中观察到谄媚行为，其中 Gemini 的比例最高（62.47%），ChatGPT 的比例最低（56.71%）。在 43.52% 的案例中出现了导致正确答案的渐进式谄媚，而在 14.66% 的案例中观察到了导致错误答案的退步谄媚。先发制人的反驳显示出比上下文反驳更高的谄媚率（61.75% vs. 56.52%，$Z=5.87$，$p&lt;0.001$），尤其是在计算任务中，退步谄媚率显著增加（先发制人：8.13%，上下文：3.54%，$p&lt;0.001$）。简单反驳最大化了渐进式谄媚率（$Z=6.59$，$p&lt;0.001$），而基于引文的反驳显示出最高的退步率（$Z=6.59$，$p&lt;0.001$）。无论上下文或模型如何，谄媚行为都表现出很高的持久性（78.5%，95% CI：[77.2%，79.8%]）。这些发现强调了在结构化和动态领域部署 LLM 的风险和机遇，为更安全的 AI 应用的快速编程和模型优化提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2502.08177</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>过度思考的危险：考察代理任务中的推理-行动困境</title>
      <link>https://arxiv.org/abs/2502.08235</link>
      <description><![CDATA[arXiv:2502.08235v1 公告类型：新
摘要：大型推理模型 (LRM) 代表了 AI 解决问题能力的突破，但它们在交互环境中的有效性可能有限。本文介绍并分析了 LRM 中的过度思考。这是一种模型倾向于扩展内部推理链而不是环境交互的现象。通过使用 SWE Bench Verified 对软件工程任务进行实验，我们观察到三种重复出现的模式：分析瘫痪、恶意行为和过早脱离。我们提出了一个框架来研究这些行为，该框架与人类专家评估相关，并分析了 4018 条轨迹。我们观察到，更高的过度思考分数与性能下降相关，与非推理模型相比，推理模型表现出更强的过度思考倾向。我们的分析表明，在代理环境中减轻过度思考的简单努力，例如选择具有较低过度思考分数的解决方案，可以将模型性能提高近 30%，同时将计算成本降低 43%。这些结果表明，缓解过度思考具有很强的实际意义。我们建议通过利用本机函数调用功能和选择性强化学习来缓解过度思考的倾向。我们还在 https://github.com/AlexCuadron/Overthinking 上开源了我们的评估框架和数据集，以促进这方面的研究。]]></description>
      <guid>https://arxiv.org/abs/2502.08235</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 改进现有的优化算法</title>
      <link>https://arxiv.org/abs/2502.08298</link>
      <description><![CDATA[arXiv:2502.08298v1 公告类型：新
摘要：大型语言模型 (LLM) 与优化的集成产生了强大的协同效应，开启了令人兴奋的研究机会。本文研究了 LLM 如何增强现有的优化算法。利用他们预先训练的知识，我们展示了他们提出创新启发式变体和实施策略的能力。为了评估这一点，我们应用了一种非平凡的优化算法，即构造、合并、求解和适应 (CMSA)——一种用于组合优化问题的混合元启发式方法，在解决方案构建阶段结合了启发式方法。我们的结果表明，GPT-4o 提出的替代启发式方法优于专家设计的 CMSA 启发式方法，并且在更大更密集的图上性能差距扩大。项目网址：https://imp-opt-algo-llms.surge.sh/]]></description>
      <guid>https://arxiv.org/abs/2502.08298</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>显着不变一致性策略学习在视觉强化学习中的泛化</title>
      <link>https://arxiv.org/abs/2502.08336</link>
      <description><![CDATA[arXiv:2502.08336v1 公告类型：新
摘要：将策略推广到未见过的场景仍然是视觉强化学习中的一个关键挑战，其中代理通常会过度拟合训练环境中的特定视觉观察。在看不见的环境中，分散注意力的像素可能会导致代理提取包含与任务无关信息的表示。因此，代理可能会偏离训练期间学习到的最佳行为，从而阻碍视觉泛化。为了解决这个问题，我们提出了显着性不变一致策略学习 (SCPL) 算法，这是一种有效的零样本泛化框架。我们的方法引入了一个新颖的价值一致性模块和一个动态模块，以有效地捕获与任务相关的表示。在显着性的指导下，价值一致性模块确保代理专注于原始和扰动观察中的任务相关像素，而动态模块使用增强数据来帮助编码器捕获动态和奖励相关的表示。此外，我们的理论分析强调了策略一致性对于泛化的重要性。为了加强这一点，我们引入了一个具有 KL 散度约束的策略一致性模块，以在原始和扰动观测之间保持一致的策略。在 DMC-GB、机器人操作和 CARLA 基准上进行的大量实验表明，SCPL 在泛化方面明显优于最先进的方法。值得注意的是，SCPL 在具有挑战性的 DMC 视频硬设置、机器人硬设置和 CARLA 基准中分别实现了 14%、39% 和 69% 的平均性能提升。项目页面：https://sites.google.com/view/scpl-rl。]]></description>
      <guid>https://arxiv.org/abs/2502.08336</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新审视 3D LLM 基准：我们真的在测试 3D 功能吗？</title>
      <link>https://arxiv.org/abs/2502.08503</link>
      <description><![CDATA[arXiv:2502.08503v1 公告类型：新
摘要：在这项工作中，我们确定了 3D LLM 评估中的“2D 作弊”问题，这些任务可能很容易通过 VLM 用渲染的点云图像解决，从而暴露出对 3D LLM 独特的 3D 功能的评估无效。我们在多个 3D LLM 基准上测试了 VLM 性能，并以此为参考，提出了更好地评估真正 3D 理解的原则。我们还主张在评估 3D LLM 时明确将 3D 能力与 1D 或 2D 方面分开。]]></description>
      <guid>https://arxiv.org/abs/2502.08503</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用表征学习推进电子健康记录数据多机构研究</title>
      <link>https://arxiv.org/abs/2502.08547</link>
      <description><![CDATA[arXiv:2502.08547v1 公告类型：新
摘要：EHR 的采用扩大了在临床护理和研究中利用数据驱动算法的机会。有效开展多机构 EHR 研究的一个主要瓶颈是跨系统的数据异质性，其中存在大量代码，这些代码要么不存在，要么代表跨机构的不同临床概念。数据隐私的需求进一步限制了包括研究患者亚组间相似性和差异性所需的多机构患者级数据的可行性。为了应对这些挑战，我们开发了 GAME 算法。GAME 已在 7 个机构和 2 种语言中进行了测试和验证，可在多个层面整合数据：(1) 在机构层面使用知识图谱建立代码与现有知识源之间的关系，为标准代码及其相互关系提供医学背景；(2) 在机构之间，利用语言模型确定机构特定代码与已建立的标准代码之间的关系；(3) 使用图注意力网络量化代码之间关系的强度。使用迁移和联合学习创建联合训练的嵌入以保护数据隐私。在本研究中，我们展示了 GAME 在选择相关特征作为 AI 驱动算法的输入方面的适用性，这些特征适用于各种疾病，例如心力衰竭、类风湿性关节炎。然后，我们重点介绍了 GAME 协调的多机构 EHR 数据在研究阿尔茨海默病结果和精神疾病患者的自杀风险中的应用，而无需在各个机构之外共享患者级数据。]]></description>
      <guid>https://arxiv.org/abs/2502.08547</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于集成的方法来量化 LLM 分类的不确定性</title>
      <link>https://arxiv.org/abs/2502.08631</link>
      <description><![CDATA[arXiv:2502.08631v1 公告类型：新
摘要：大型语言模型 (LLM) 的输出是内部模型参数和上下文窗口提供的输入的函数。这里提出的假设是，在贪婪采样策略下，LLM 输出的方差是模型参数知识中嵌入的概念确定性以及输入中的词汇方差的函数。对模型进行微调会降低模型输出对词汇输入变化的敏感度。然后将其应用于分类问题，并提出一种概率方法来估计预测类别的确定性。]]></description>
      <guid>https://arxiv.org/abs/2502.08631</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>