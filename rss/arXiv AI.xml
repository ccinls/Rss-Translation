<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>概率人工智能</title>
      <link>https://arxiv.org/abs/2502.05244</link>
      <description><![CDATA[ARXIV：2502.05244V1公告类型：新 
摘要：人工智能通常是指人造系统的科学和工程，这些系统通常可以执行与需要人类智能方面的方面有关的任务，例如玩游戏，翻译语言和驾驶汽车。近年来，在基于学习的，以数据为基础的AI方法的方法中取得了令人兴奋的进步，机器学习和深度学习使计算机系统能够以前所未有的方式感知世界。强化学习使得在复杂的游戏（例如GO和挑战机器人）任务（例如四足动力）中取得了突破。
  智力的一个关键方面不仅是做出预测，而且是关于这些预测中不确定性的原因，并在做出决策时考虑这种不确定性。这就是“概率人工智能”上的手稿的内容。第一部分涵盖了机器学习的概率方法。我们讨论由于缺乏数据而导致的“认知”不确定性之间的区别，这是不可约束的，例如，词干，例如噪声观察和结果。我们讨论了概率推断和现代方法的具体方法，以进行有效的近似推断。
  手稿的第二部分是关于在顺序决策任务中考虑不确定性。我们考虑主动学习和贝叶斯优化 - 通过提出实验来降低认知不确定性的实验来收集数据的方法。然后，我们考虑使用神经网络功能近似的强化学习和现代深度RL方法。我们通过讨论基于模型的RL中的现代方法来结束，这些方法利用了认识论和态度的不确定性来指导探索，同时也推理了安全性。]]></description>
      <guid>https://arxiv.org/abs/2502.05244</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ITBench：评估各种现实世界中IT自动化任务的AI代理</title>
      <link>https://arxiv.org/abs/2502.05352</link>
      <description><![CDATA[ARXIV：2502.05352V1公告类型：新 
摘要：实现使用AI代理来自动化关键IT任务的愿景取决于衡量和理解拟议解决方案有效性的能力。我们介绍了ITBench，该框架提供了一种系统的方法，用于基于AI代理来解决现实世界中的IT自动化任务。我们的最初发布针对三个关键领域：站点可靠性工程（SRE），合规性和安全操作（CISO）和金融业务（Finops）。该设计使AI研究人员能够通过按钮工作流和可解释的指标来了解AI代理的挑战和机遇。 ITBench包括一组最初的94个现实世界情景，可以通过社区贡献轻松扩展。我们的结果表明，由最先进模型提供动力的代理只能解决SRE方案的13.8％，25.2％的CISO方案和0％的Finops方案。我们希望ITBench成为正确，安全和快速的AI驱动IT自动化的关键推动器。]]></description>
      <guid>https://arxiv.org/abs/2502.05352</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过混合ai元认知的概率基础</title>
      <link>https://arxiv.org/abs/2502.05398</link>
      <description><![CDATA[ARXIV：2502.05398V1公告类型：新 
摘要：元认知是有关代理商自己内部过程的推理的概念，并且最近在人工智能（AI）以及更具体地说，是机器学习系统的重新关注。本文回顾了一种混合ai方法，称为“错误检测和纠正规则”（EDCR），该方法允许学习规则以纠正感知（例如，神经）模型。此外，我们引入了一个概率框架，为先前的经验研究增加了严格的框架，并使用此框架来证明结果的结果和充分的元认知改进条件，并限制了该方法。一组未来]]></description>
      <guid>https://arxiv.org/abs/2502.05398</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用于金融服务任务的代理AI系统：建模和模型风险管理人员</title>
      <link>https://arxiv.org/abs/2502.05439</link>
      <description><![CDATA[ARXIV：2502.05439V1公告类型：新 
摘要：大语言模型的出现已经迎来了代理系统的新时代，在该时代，人工智能计划在各种领域都表现出显着的自主决策能力。本文探讨了金融服务行业的代理系统工作流程。特别是，我们建立了可以有效协作以执行复杂建模和模型风险管理（MRM）任务的代理工作人员。建模人员由经理和多个代理人组成，他们执行特定任务，例如探索性数据分析，功能工程，模型选择，超参数调整，模型培训，模型评估和写作文档。 MRM工作人员由经理和专业代理人组成，他们执行任务，例如检查建模文档，模型复制，概念性声音，结果分析和写作文档的合规性。我们通过提供一系列用于信用卡欺诈检测，信用卡批准和投资组合信用风险建模数据集的数值示例，来证明建模和MRM工作人员的有效性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2502.05439</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优胜党的奥德赛：特工可以生存并仍然是好人吗？</title>
      <link>https://arxiv.org/abs/2502.05442</link>
      <description><![CDATA[ARXIV：2502.05442V1公告类型：新 
摘要：随着AI模型在权力和通用性上的增长，了解代理在复杂环境中学习和做出决策的方式对于促进道德行为至关重要。本文研究了将生物学驱动器（特别是自我保护）实施到三种不同的代理中的道德含义。用整洁的贝叶斯代理，用随机变异推理优化的贝叶斯代理，而GPT 4O代理播放模拟的，LLM生成的基于文本的冒险游戏。代理商在每种情况下选择行动以生存，适应越来越具有挑战性的情况。模拟后分析评估了代理商决定的道德得分，发现了他们导航以生存的权衡。具体而言，分析发现，当危险增加时，代理人会忽略道德考虑，而是选择不道德行为。代理人的集体行为，将道德的贸易伦理换成生存，表明优先级生存会增加不道德行为的风险。在AGI的背景下，设计代理人优先考虑生存，可能会扩大不道德决策的可能性和意外的紧急行为，从而提出了有关AI安全研究中目标设计的基本问题。]]></description>
      <guid>https://arxiv.org/abs/2502.05442</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有自适应分层知识图的LLM驱动分散生成代理用于合作计划</title>
      <link>https://arxiv.org/abs/2502.05453</link>
      <description><![CDATA[ARXIV：2502.05453V1公告类型：新 
摘要：在动态开放世界情景中开发长期合作的智能代理是多代理系统的主要挑战。传统的多代理增强学习（MARL）框架等集中式培训分散执行（CTDE）挣扎着可伸缩性和灵活性。他们需要集中的长期计划，这在没有自定义奖励功能的情况下很难，并且在处理多模式数据时面临挑战。 CTDE方法还采用固定的合作策略，使其在代理需要独立适应和计划的动态环境中不切实际。为了解决分散的多代理合作，我们建议在新型的多代理手工艺环境中分散的自适应知识记忆和结构化通信系统（DAMC）。通过大型语言模型（LLM）驱动的我们的生成代理，通过利用外部知识和语言来长期计划和推理，比传统的MARL代理更可扩展。 DAMC并没有完全共享所有过去经验的信息，而是引入了一个多模式的内存系统，该系统作为层次知识图和结构化通信协议组织，以优化代理合作。这使代理可以从过去的交互中推理并有效地共享相关信息。关于新型多代理开放世界任务的实验表明，在任务效率和协作方面，DAMC在任务效率和协作方面的表现都优于MAL和LLM基准。与单一代理方案相比，两种代理的方案以少63％的步骤实现了相同的目标，而六个代理情景却少了74％，突出了自适应记忆和结构化沟通在实现长期目标方面的重要性。我们在以下网址公开发布我们的项目：https：//happyeureka.github.io/damcs。]]></description>
      <guid>https://arxiv.org/abs/2502.05453</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分层增强学习的顺序随机组合优化</title>
      <link>https://arxiv.org/abs/2502.05537</link>
      <description><![CDATA[ARXIV：2502.05537V1公告类型：新 
摘要：强化学习（RL）已成为合并优化（CO）问题的有前途的工具，因为它的能力快速，有效和可推广的解决方案。尽管如此，现有作品主要集中于单发确定性CO，而顺序随机CO（SSCO）很少研究其广泛的应用，例如适应性影响最大化（IM）和感染性疾病干预。在本文中，我们研究了SSCO问题，在该问题中，我们首先决定了所有时间步骤的预算（例如，自适应IM中的种子节点数量），然后为每个时间步骤选择一组节点。关于SSCO的少数现有研究通过假设在时间范围内假设均匀分布的预算分配来简化问题，从而产生了次优的解决方案。我们提出了一个称为Wake-Sleep选项（WS-OPTION）的通用分层RL（HRL）框架，这是一个基于两层选项的框架，同时决定在下层的较高层和节点选择上选择自适应预算分配。 WS-Option从两层马尔可夫决策过程（MDP）的连贯表述开始，从而捕获了两层决策之间的相互依存关系。在此基础上，WS-Option采用了几种创新的设计来平衡模型的训练稳定性和计算效率，从而阻止了两层之间的恶性循环干扰问题。经验结果表明，与传统方法相比，WS-Option具有显着提高的有效性和概括性。此外，可以将学习的模型推广到较大的图表，从而大大减少了计算资源的开销。]]></description>
      <guid>https://arxiv.org/abs/2502.05537</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识是力量：利用大型语言模型来增强认知诊断</title>
      <link>https://arxiv.org/abs/2502.05556</link>
      <description><![CDATA[ARXIV：2502.05556V1公告类型：新 
摘要：认知诊断模型（CDM）旨在通过一系列练习来分析他们的表现来评估学生的认知状态。但是，由于缺乏丰富的先验知识，现有的CDM经常在诊断不经常的学生和练习方面遇到困难。随着具有广泛领域知识的大型语言模型（LLM）的进步，它们融入认知诊断的融合带来了一个有前途的机会。尽管存在这种潜力，但将LLM与CDMS相结合仍然带来了重大挑战。 LLM不适合捕获学生与练习之间的细粒度协作互动，以及LLM的语义空间与CDMS的行为空间之间的差异。为了解决这些问题，我们提出了一种新颖的知识增强认知诊断（KCD）框架，该框架是使用LLMS增强CDM并与各种CDM体系结构兼容的模型不合时宜的框架。 KCD框架分为两个阶段：LLM诊断和认知水平比对。在LLM诊断阶段，学生和练习都被诊断为实现全面和详细的建模。在认知水平的对准阶段，我们使用对比度学习和面具重构方法弥合了CDM的行为空间与LLMS语义空间之间的差距。几个现实世界数据集的实验证明了我们提出的框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.05556</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缩小基于AI的网络管理中的责任差距：智能审计系统方法</title>
      <link>https://arxiv.org/abs/2502.05608</link>
      <description><![CDATA[ARXIV：2502.05608V1公告类型：新 
摘要：现有的网络范例通过使用人工智能（AI）基于基于人工智能的网络管理工具，实现了较低的停机时间以及更高的经验（QOE）。这些AI管理系统可以自动响应网络条件变化，降低操作员的运营成本并提高整体性能。在采用基于AI的管理工具可以增强整体网络性能的同时，它也引入了挑战，例如消除人类监督，侵犯隐私，算法偏见和模型不准确。此外，无法解决这些挑战的基于AI的代理人应该是自身的罪魁祸首，而不是整个网络。为了解决此责任差距，提出了一个由深入增强学习（DRL）模型和机器学习（ML）模型组成的框架，以识别并分配责任的数值网络条件最终会影响最终用户。为使用模拟网络操作参数训练框架创建了模拟环境。在测试过程中，DRL模型的精度为96％，以识别基于AI的管理代理，而使用梯度下降的ML模型在测试过程中以83％的精度学习了网络条件。]]></description>
      <guid>https://arxiv.org/abs/2502.05608</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无定形的堡垒在线：协作设计开放式多代理AI和游戏环境</title>
      <link>https://arxiv.org/abs/2502.05632</link>
      <description><![CDATA[ARXIV：2502.05632V1公告类型：新 
摘要：这项工作介绍了在线的无定形堡垒 - 一个基于网络的平台，用户可以在该平台上设计由培养皿般的环境和由多代理AI字符组成的游戏。用户可以通过微观但透明的有限状态机构代理组成，互动，创建和共享人造生活和游戏环境。该网站具有多个交互式编辑器和可访问的设置，可直接从浏览器查看多代理交互。该系统提供了使用简单AI代理的新兴行为的主题不同的AI和游戏环境的数据库。]]></description>
      <guid>https://arxiv.org/abs/2502.05632</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>管理关键矿产供应链中的地质不确定性：适用于美国锂资源的POMDP方法</title>
      <link>https://arxiv.org/abs/2502.05690</link>
      <description><![CDATA[ARXIV：2502.05690V1公告类型：新 
摘要：全球向可再生能源技术和电动汽车的过渡驱动的世界正在进入空前的关键矿物需求时期。这种过渡提出了矿产资源开发的独特挑战，特别是由于地质不确定性 - 传统供应链优化方法无法充分解决的关键特征。为了应对这一挑战，我们提出了一种新的可观察到的马尔可夫决策过程（POMDP）的新颖应用，该过程优化了关键的矿物采购决策，同时明确考虑了地质不确定性的动态性质。通过对美国锂供应链的案例研究，我们证明了与传统方法相比，基于POMDP的政策获得了卓越的结果，尤其是在初始储备估计不完善的情况下。我们的框架为将国内资源开发与国际供应多样化平衡的定量见解提供了定量见解，为决策者提供了一种系统的方法，用于关键矿产供应链中的战略决策。]]></description>
      <guid>https://arxiv.org/abs/2502.05690</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类对齐的障碍和途径：游戏理论方法</title>
      <link>https://arxiv.org/abs/2502.05934</link>
      <description><![CDATA[ARXIV：2502.05934V1公告类型：新 
摘要：在什么条件下，AI代理可以有效地将其行为与人类的偏好保持一致？更具体地说，当他们足够熟练地与我们合作时，协调需要多长时间，什么时候可以在计算上可行？这些AI一致性的基本问题有助于定义是什么使AI代理``足够安全&#39;&#39;且对人类很有价值。由于尚不存在这样一般有能力的系统，因此需要进行理论分析以确定保证时以及它们是什么。
  我们介绍了一个游戏理论框架，该框架以更少的假设概括了先前的对齐方式，从而使我们能够分析跨$ m $目标和$ n $代理的对齐的计算复杂性，从而提供上限和下限。与以前的工作通常假设普通先验，理想化的交流或隐式障碍性不同，我们的框架正式表征了在最小假设下的一致性难度。
  我们的主要结果表明，即使代理是完全合理的，并且在计算上\ emph {nocked}，在任务空间大小中，可以在时间\ emph {lineare}中实现对齐。因此，在实际设置中，在输入长度中，任务空间通常是\ emph {指数}，这仍然是不切实际的。更引人注目的是，我们的下限表明，在缩放到指数的许多任务或试剂时，对齐是\ emph {nosper}，突出了基本的计算屏障到可扩展的对齐。
  Relaxing these idealized assumptions, we study \emph{computationally bounded} agents with noisy messages (representing obfuscated intent), showing that while alignment can still succeed with high probability, it incurs additional \emph{exponential} slowdowns in the task space size, number代理和任务数量。
  我们通过确定使一致性更可行的条件结束。]]></description>
      <guid>https://arxiv.org/abs/2502.05934</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MEDACHAIN：LLM代理的完全自动化和零代码框架</title>
      <link>https://arxiv.org/abs/2502.05957</link>
      <description><![CDATA[ARXIV：2502.05957V1公告类型：新 
摘要：大型语言模型（LLM）代理在任务自动化和智能决策中表现出了显着的功能，推动了诸如Langchain和Autogen等代理开发框架的广泛采用。但是，这些框架主要为开发人员提供广泛的技术专业知识的服务 - 考虑到只有0.03％的全球人口具有必要的编程技能，这一重大局限性。这个鲜明的可访问性差距提出了一个基本的问题：无论技术背景如何，我们都可以单独使用自然语言来构建自己的LLM代理？为了应对这一挑战，我们介绍了Metachain-A完全自动化且高度自我开发的框架，使用户仅通过自然语言创建和部署LLM代理。 Metachain作为自主代理操作系统运行，包括四个关键组件：i）代理系统实用程序，ii）llm驱动的可操作发动机，iii）自我管理文件系统，iv）iv）自我播放剂自定义模块。这种轻巧但功能强大的系统可以在没有编码要求或手动干预的情况下对工具，代理和工作流进行有效而动态的创建和修改。除了其无代码的代理开发功能之外，Metachain还可以作为通用AI助手的多功能多代理系统。对GAIA基准的全面评估表明，Metachain在通用多代理任务中的有效性，超过了现有的最新方法。此外，与许多基于LLM的替代解决方案相比，Metachain的检索结果（RAG）相关的功能始终如一。]]></description>
      <guid>https://arxiv.org/abs/2502.05957</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>培训语言模型，用于通过多代理强化学习的社会扣除</title>
      <link>https://arxiv.org/abs/2502.06060</link>
      <description><![CDATA[ARXIV：2502.06060V1公告类型：新 
摘要：以自然语言进行交流是多代理设置中的强大工具，因为它使独立代理能够在可观察到的部分设置中共享信息，并允许与人类零拍摄的协调。但是，大多数先前的作品都受到限制，因为它们要么依靠大量的人类示范培训，要么缺乏产生自然和有用的沟通策略的能力。在这项工作中，我们训练语言模型以对其自然语言的环境进行有效的讨论，而没有任何人类的示威。我们将沟通问题分解为聆听和说话。我们的关键思想是利用代理商的目标，将有关世界的有用信息预测为指导沟通的密集奖励信号。具体来说，我们通过训练他们的聆听技巧来提高模型的听力技能，以根据讨论来预测有关环境的信息，并且我们同时通过基于对其他代理的影响来奖励消息，通过奖励消息来提高模型的口语技巧。为了调查复杂社会环境中沟通的作用和必要性，我们根据我们中间研究一个具体的社会演绎游戏，在这里回答的关键问题是对抗性冒名顶替者的身份。我们分析了由于我们的技术而进行的新兴行为，例如指责嫌疑犯并提供证据，并发现它可以进行强有力的讨论，与标准RL相比，获胜率翻了一番。我们在https://socialdeductionllm.github.io/上发布代码和模型]]></description>
      <guid>https://arxiv.org/abs/2502.06060</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息在人类决策中的价值</title>
      <link>https://arxiv.org/abs/2502.06152</link>
      <description><![CDATA[ARXIV：2502.06152V1公告类型：新 
摘要：人类和AIS经常与决策任务配对，并期望达到互补的表现，在这种情况下，人类和AI的组合均优于单独的一个。但是，如果不知道每个代理商采用哪些特定信息和策略，则通常不清楚如何提高人类团队的绩效。我们提供了一个决策理论框架，用于表征信息的价值 - 因此，代理商在AI辅助决策工作流程中提供了更好地利用可用信息的机会。我们证明了将框架用于模型选择，人类绩效的经验评估以及解释设计。我们提出了一种基于信息的新颖实例级解释技术，该技术适应了基于传统显着性的解释，以解释决策中的信息价值。]]></description>
      <guid>https://arxiv.org/abs/2502.06152</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调节性和类似AGM的信念变化在可取性 - 差异框架中</title>
      <link>https://arxiv.org/abs/2502.06235</link>
      <description><![CDATA[ARXIV：2502.06235V1公告类型：新 
摘要：我们展示了如何扩展信念变化的AGM框架（扩展，修订，收缩），以根据接受和拒绝选项的抽象概念以及抽象的概念来处理所谓的可寻求诱因框架中的条件事件的概念。这种抽象水平使我们能够同时处理经典和量子概率理论。]]></description>
      <guid>https://arxiv.org/abs/2502.06235</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AppVLM：一种用于在线应用程序控制的轻巧视觉语言模型</title>
      <link>https://arxiv.org/abs/2502.06395</link>
      <description><![CDATA[ARXIV：2502.06395V1公告类型：新 
摘要：将基础模型作为智能手机助手（称为应用程序代理）的利用是一项关键的研究挑战。这些代理商的目的是通过解释文本说明并通过设备的界面执行操作来执行人类的说明。在有希望的同时，当前的方法面临着重大局限性。使用大型专有模型（例如GPT-4O）的方法在计算上很昂贵，而使用较小的微调模型的方法通常缺乏对分发任务的适应性。在这项工作中，我们介绍了AppVLM，这是一种轻巧的视觉语言模型（VLM）。首先，我们在AndroidControl数据集上脱机微调。然后，我们通过从Androidworld环境中收集数据并进行进一步的培训迭代来完善其政策。我们的结果表明，与所有评估的基线相比，APPVLM在AndroidControl数据集上的离线评估中达到了最高的动作预测准确性，并且在AndroidWorld环境中在线任务完成成功率中的GPT-4O匹配，而最多十倍。这使APPVLM成为现实部署的实用和高效解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.06395</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>POMDP的更紧密的价值功能近似</title>
      <link>https://arxiv.org/abs/2502.06523</link>
      <description><![CDATA[ARXIV：2502.06523V1公告类型：新 
摘要：解决部分可观察到的马尔可夫决策过程（POMDP）通常需要对指数的许多状态信念的价值进行推理。为了实践绩效，最先进的求解器使用价值范围来指导这种推理。但是，声音上值范围通常在计算上是昂贵的，并且这种界限的紧密度与它们的计算成本之间存在权衡。本文引入了与常用的快速知情界相比，引入了新的且更紧密的上值边界。我们的经验评估表明，尽管它们额外的计算开销，但新的上限仍在各种基准测试中加速了最新的POMDP求解器。]]></description>
      <guid>https://arxiv.org/abs/2502.06523</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们可以信任AI基准吗？ AI评估中当前问题的跨学科审查</title>
      <link>https://arxiv.org/abs/2502.06559</link>
      <description><![CDATA[ARXIV：2502.06559V1公告类型：新 
摘要：定量人工智能（AI）基准已成为评估AI模型和系统的性能，能力和安全性的基本工具。目前，它们塑造了AI开发的方向，并在监管框架中起着越来越重要的作用。然而，随着影响力的增长，他们对如何以及对他们评估高度敏感主题（包括高影响力能力，安全性和系统性风险）等影响的影响也感到担忧。本文介绍了大约100项研究的跨学科元评估，讨论了过去10年中发表的定量基准测试实践中的缺点。它在基准的设计和应用中汇集了许多细粒度问题（例如，数据集创建，文档不足，数据污染以及将信号与噪声区分开的偏见）具有更广泛的社会技术问题（例如评估评估的过度关注点基于文本的AI模型根据一次性测试逻辑无法说明AI模型越来越多模式并与人类和其他技术系统相互作用）。我们的审查还重点介绍了当前基准测试实践中的一系列系统缺陷，例如未对准激励措施，构建有效性问题，未知的未知数以及基准结果游戏的问题。此外，它强调了基准实践从根本上是由文化，商业和竞争性动态来塑造的，这些动态通常以更广泛的社会关注为代价来优先考虑最先进的表现。通过提供与现有基准测试程序相关的风险概述，我们将基准中的不成比例信任提出问题，并为改善现实世界情景复杂性中定量AI基准的责任感和相关性的持续努力做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2502.06559</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于在基于半半数的数据评估中实用程序的影响</title>
      <link>https://arxiv.org/abs/2502.06574</link>
      <description><![CDATA[ARXIV：2502.06574V1公告类型：新 
摘要：基于半个性的机器学习数据评估（ML）通过利用合作游戏理论和实用程序概念的原理来量化单个数据指向下游ML任务的贡献。尽管该框架已用于评估数据质量，但我们的实验揭示了不同公用事业之间的估值不一致，尽管这与ML性能有关。除了提出对数据评估可靠性的担忧之外，这种不一致的解释是挑战性的，因为它源于该实用程序与数据点和半权重的复杂相互作用，这在先前的工作中几乎没有研究。在本文中，我们朝着阐明对基于半数的数据评估的实用性影响的第一步。具体而言，我们对这种影响的几何解释对广泛的分类公用事业系列，其中包括准确性和算术平均值。我们介绍了空间签名的概念：给定半符号，数据点可以嵌入二维空间中，并将实用程序函数映射到该空间的双重上。这种几何透视图将数据集和半公用事业的影响分开，为实验观察到的估值结果对实用程序选择的敏感性提供了理论上的解释。]]></description>
      <guid>https://arxiv.org/abs/2502.06574</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>