<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 04 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于期望最大化算法的模糊作业车间调度问题自回归模型</title>
      <link>https://arxiv.org/abs/2502.00018</link>
      <description><![CDATA[arXiv:2502.00018v1 公告类型：新
摘要：模糊车间作业调度问题 (FJSSP) 是车间作业调度问题 (JSSP) 的创新扩展，它包含一层不确定性，使问题更接近真实制造环境的复杂性。这种改进增加了推导解决方案的计算复杂性，同时提高了其适用性。在确定性调度领域，神经组合优化 (NCO) 最近表现出显着的功效。然而，它在模糊调度领域的应用相对未被探索。本文旨在通过研究使用神经网络吸收和处理模糊信息以解决 FJSSP 的可行性来弥补这一差距，从而利用 NCO 的进步来增强模糊调度方法。为了实现这一目标，我们将 FJSSP 作为一项生成任务，并引入基于期望最大化算法的自回归模型 (EMARM) 来解决它。在训练过程中，我们的模型交替从给定实例生成调度方案（E 步）和根据这些生成的方案调整自回归模型权重（M 步）。这种新颖的方法有效地解决了获取真实标签的巨大障碍，这是 NCO 框架中普遍存在的问题。在测试中，实验结果证明了 EMARM 在解决 FJSSP 方面的卓越能力，展示了其在模糊调度中的有效性和实际应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.00018</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理的增长模式</title>
      <link>https://arxiv.org/abs/2502.00019</link>
      <description><![CDATA[arXiv:2502.00019v1 公告类型：新 
摘要：一阶搜索空间的哪些属性支持/阻碍推理？学习哪些类型的事实最有效？回答这些问题对于理解演绎推理的动态和创建支持有效推理的大规模知识型学习系统至关重要。我们通过开发一个模型来解决这些问题，该模型说明了基本事实的分布如何影响搜索空间中的推理性能。实验表明，均匀的搜索空间适用于较大的知识库，而度分布不均的搜索空间在较小的知识库中表现出更好的性能。在某些情况下，问答性能会出现急剧转变，这表明应该使用现有知识对搜索空间结构的分析来指导学习系统中新基本事实的获取。]]></description>
      <guid>https://arxiv.org/abs/2502.00019</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能系统中的时间推理</title>
      <link>https://arxiv.org/abs/2502.00020</link>
      <description><![CDATA[arXiv:2502.00020v1 公告类型：新
摘要：大规模常识时间推理是认知系统的核心问题。许多任务都需要正确推断流利度的持续时间，包括自然语言理解和规划。许多人工智能系统的演绎闭包有限，因为它们无法正确推断有关现有流利度和事件的信息。在本研究中，我们讨论了 Cyc 知识库中稳健时间投影所需的知识表示和推理方案。我们讨论了事件如何开始和结束流利度的风险期。然后，我们使用离散生存函数（表示事实持久性的知识）来推断给定的流利度。推断的间隔可以通过时间约束和其他类型的常识知识截断。最后，我们展示了实验结果，以证明这些方法在问答性能方面取得了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2502.00020</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 驱动的多智能体协作环境下基于场景的动态高精度 HRA 合成数据采集方法</title>
      <link>https://arxiv.org/abs/2502.00022</link>
      <description><![CDATA[arXiv:2502.00022v1 公告类型：新
摘要：HRA（人因可靠性分析）数据对于推进 HRA 方法至关重要。然而，现有的数据收集方法缺乏必要的粒度，大多数方法都无法捕捉动态特征。此外，许多方法需要专家知识作为输入，这使得它们耗时且劳动密集。为了应对这些挑战，我们提出了一种自动收集 HRA 数据的新范例。我们的方法侧重于人为错误背后的关键指标，特别是在协作环境中测量工作量。本研究利用微调的大型语言模型 (LLM)，介绍了一种新颖的、场景驱动的工作量估计方法。通过对高温气冷反应堆 (HTGR) 的实际运行数据训练 LLM，我们可以在各种协作场景中实时模拟人类行为和认知负荷。该方法可动态适应操作员工作量的变化，提供更准确、灵活和可扩展的工作量估计。结果表明，所提出的 WELLA（使用 LLM 和代理进行工作量评估）在预测准确性方面优于现有的基于 LLM 的商业方法。]]></description>
      <guid>https://arxiv.org/abs/2502.00022</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向实际电网拓扑控制的高效多目标优化</title>
      <link>https://arxiv.org/abs/2502.00034</link>
      <description><![CDATA[arXiv:2502.00034v1 公告类型：新
摘要：随着能源需求的增加和向可再生能源的转变，电网运营商在控制室面临越来越多的困难，这为管理拥塞和维持稳定供应带来了新的复杂性。有效的电网拓扑控制需要能够处理多目标权衡的高级工具。虽然强化学习 (RL) 为应对此类挑战提供了一个有前途的框架，但现有的多目标强化学习 (MORL) 方法无法扩展到现实世界电网运营中固有的大型状态和动作空间。在这里，我们提出了一种专为电网拓扑控制而设计的两阶段、高效且可扩展的多目标优化 (MOO) 方法，将高效的 RL 学习阶段与快速规划阶段相结合，为未见过的场景生成日前计划。我们使用来自欧洲输电系统运营商 (TSO) TenneT 的历史数据验证了我们的方法，展示了最短的部署时间，在 4-7 分钟内以强大的性能生成日前计划。这些结果凸显了我们的可扩展方法在支持实际电网管理方面的潜力，为运营规划提供了一种实用、计算高效且省时的工具。根据目前的拥堵成本和电网运营效率低下的情况，TSO 采用我们的方法每年可节省数百万欧元，为将其集成到控制室提供了极具吸引力的经济激励。]]></description>
      <guid>https://arxiv.org/abs/2502.00034</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用计划进行计数和推理</title>
      <link>https://arxiv.org/abs/2502.00145</link>
      <description><![CDATA[arXiv:2502.00145v1 公告类型：新
摘要：经典规划要求一系列运算符达到给定目标。虽然最常见的情况是计算计划，但许多场景需要的不止于此。然而，计划空间的定量推理仍然大多未被探索。一个基本问题是计算计划，这与计划空间的条件概率有关。事实上，定性和定量方法在自动推理的其他各个领域都已得到很好的确立。我们提出了第一项关于计划空间定量和定性推理的研究。特别是，我们关注多项式有界计划。在理论方面，我们研究它的复杂性，这产生了丰富的推理模式。由于计数通常很难，我们引入了更简单的方面概念，这使得我们能够理解运算符的重要性。在实践方面，我们为规划实施定量推理。因此，我们将规划任务转化为命题公式，并使用知识汇编来计算不同的计划。该框架可以很好地扩展到大型计划空间，同时支持丰富的推理能力，例如学习修剪函数和可解释的规划。]]></description>
      <guid>https://arxiv.org/abs/2502.00145</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>位置编码在 ARC 基准中的作用</title>
      <link>https://arxiv.org/abs/2502.00174</link>
      <description><![CDATA[arXiv:2502.00174v1 公告类型：新
摘要：抽象和推理语料库挑战人工智能系统使用最少的训练数据进行抽象推理，这是一项对人类来说很直观的任务，但对机器学习模型来说却要求很高。以 CodeT5+ 为例，我们展示了位置编码的局限性如何阻碍推理并影响性能。这项工作进一步研究了位置编码在变压器架构中的作用，强调了它对不同大小和配置的模型的关键影响。通过比较几种策略，我们发现虽然 2D 位置编码和旋转位置嵌入提供了具有竞争力的性能，但 2D 编码在数据受限的场景中表现出色，强调了其对 ARC 任务的有效性]]></description>
      <guid>https://arxiv.org/abs/2502.00174</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于强化学习的多车辆协作决策算法的差异化奖励方法</title>
      <link>https://arxiv.org/abs/2502.00352</link>
      <description><![CDATA[arXiv:2502.00352v1 公告类型：新
摘要：强化学习（RL）通过状态-动作-奖励反馈回路在优化多车辆协作驾驶策略方面表现出巨大潜力，但仍面临样本效率低等挑战。本文提出了一种基于稳态转移系统的差异化奖励方法，通过分析交通流特性，将状态转移梯度信息纳入奖励设计，旨在优化多车辆协作决策中的动作选择和策略学习。在不同自动驾驶汽车渗透率下，所提方法在 MAPPO、MADQN 和 QMIX 等 RL 算法中得到了性能验证。结果表明，差异化奖励方法显著加速了训练收敛，并且在交通效率、安全性和行动合理性方面优于中心化奖励等。此外，该方法还表现出很强的可扩展性和环境适应性，为复杂交通场景中的多智能体协作决策提供了一种新方法。]]></description>
      <guid>https://arxiv.org/abs/2502.00352</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ALU：Agentic LLM 忘却学习</title>
      <link>https://arxiv.org/abs/2502.00406</link>
      <description><![CDATA[arXiv:2502.00406v1 公告类型：新
摘要：大型语言模型 (LLM) 中的信息删除或抑制是一种理想的功能，在 AI 监管、法律合规、安全和隐私方面很有用。LLM 反学习方法旨在从 LLM 中删除所需信息。由于这些目标的竞争性质，当前的 LLM 反学习方法难以平衡反学习的有效性和实用性。在不假设访问模型权重的情况下保持反学习过程在计算上可行是一个被忽视的领域。我们提出了第一个代理 LLM 反学习 (ALU) 方法，这是一种多代理、无需再训练、与模型无关的 LLM 反学习方法，可在保留实用性的同时实现有效的反学习。我们的 ALU 框架通过涉及多个 LLM 代理来进行反学习，每个代理都为反学习过程中的特定步骤而设计，而无需更新框架中任何代理的模型权重。用户可以轻松以任意顺序请求任意一组反学习实例，ALU 可以实时无缝适应。这无需对底层 LLM 模型进行任何更改即可实现。通过对已建立的基准（TOFU、WMDP、WPU）和越狱技术（多次拍摄、目标掩蔽、其他语言）进行大量实验，我们证明 ALU 始终是当前最先进方法中最强大的 LLM 反学习框架，同时具有较低的恒定时间成本。我们进一步强调了 ALU 在大规模评估时与现有方法相比的卓越性能。具体而言，ALU 在多达 1000 个反学习目标上进行评估，超出了所有先前提出的 LLM 反学习方法的评估范围。]]></description>
      <guid>https://arxiv.org/abs/2502.00406</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>事半功倍——在基于大型语言模型的系统中实施路由策略：一项扩展调查</title>
      <link>https://arxiv.org/abs/2502.00409</link>
      <description><![CDATA[arXiv:2502.00409v2 公告类型：新 
摘要：基于大型语言模型 (LLM) 的系统，即包含 LLM 作为中心组件的互连元素（例如，对话代理），通常是单片静态架构，依赖于单个 LLM 来处理所有用户查询。但是，它们通常需要不同的预处理策略、推理水平或知识。在非常大的多主题语料库上训练的通用 LLM（例如 GPT-4）可以在各种任务中表现良好。它们需要大量的财务、能源和硬件资源，而这些资源对于基本任务来说可能不合理。这意味着可能会为给定的查询投资不必要的成本。为了解决这个问题，路由机制将用户查询路由到最合适的组件，例如较小的 LLM 或特定主题的专家。这种方法可以提高响应质量，同时最大限度地降低成本。路由可以扩展到对话代理架构的其他组件，例如选择最佳嵌入策略。本文探讨了将路由集成到基于 LLM 的系统中的关键考虑因素，重点关注资源管理、成本定义和策略选择。我们的主要贡献包括问题的形式化、强调相关性和资源效率的现有方法的新分类法，以及这些策略与行业实践的比较分析。最后，我们确定了未来研究的关键挑战和方向。]]></description>
      <guid>https://arxiv.org/abs/2502.00409</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MetaOpenFOAM 2.0：大型语言模型驱动的自动化 CFD 模拟和后处理思路链</title>
      <link>https://arxiv.org/abs/2502.00498</link>
      <description><![CDATA[arXiv:2502.00498v1 公告类型：新
摘要：计算流体动力学 (CFD) 广泛应用于航空航天、能源和生物学，以模拟流体流动、传热和化学反应。虽然大型语言模型 (LLM) 已经改变了各个领域，但它们在 CFD 中的应用仍然有限，特别是对于后处理等复杂任务。为了弥补这一差距，我们推出了 MetaOpenFOAM 2.0，它利用思路链 (COT) 分解和迭代验证，通过自然语言输入增强非专家用户的可访问性。在涵盖模拟（流体流动、传热、燃烧）和后处理（提取、可视化）的新基准上进行测试，MetaOpenFOAM 2.0 的可执行性得分为 6.3/7，通过率为 86.9%，明显优于 MetaOpenFOAM 1.0（2.1/7，0%）。此外，事实证明该方法具有成本效益，平均每例成本为 0.15 美元。一项消融研究证实，COT 驱动的分解和迭代细化显著提高了任务性能。此外，缩放定律表明，增加 COT 步骤可提高准确性，同时提高令牌使用率，这与 LLM 训练后缩放趋势一致。这些结果凸显了 LLM 在自动化工业和研究应用的 CFD 工作流程方面的变革潜力。代码可在 https://github.com/Terry-cyx/MetaOpenFOAM 上找到]]></description>
      <guid>https://arxiv.org/abs/2502.00498</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>发现非循环过程的直接跟随图模型</title>
      <link>https://arxiv.org/abs/2502.00499</link>
      <description><![CDATA[arXiv:2502.00499v1 公告类型：新
摘要：流程挖掘是一系列旨在分析和改进流程的方法和方法的通用名称。具体而言，旨在从事件日志中得出流程模型的方法属于流程发现类别。在流程范围内，非循环流程形成一个独特的类别。在这样的过程中，先前执行的操作不会重复，形成独特的操作链。然而，由于操作顺序的差异，现有的流程发现方法可以提供包含循环的模型，即使流程是非循环的。本文提出了一种新的流程发现算法，该算法可以发现非循环流程的非循环 DFG 模型。通过将事件日志划分为提供非循环 DFG 模型的部分并合并它们同时避免形成循环，可以发现模型。在真实和人工事件日志上测试了生成的算法。没有循环可以提高模型的视觉清晰度和精度，还允许将循环敏感方法或可视化应用于模型。]]></description>
      <guid>https://arxiv.org/abs/2502.00499</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>谁是 MVP？LLM 代理模块化归因的博弈论评估基准</title>
      <link>https://arxiv.org/abs/2502.00510</link>
      <description><![CDATA[arXiv:2502.00510v1 公告类型：新 
摘要：大型语言模型 (LLM) 代理框架通常采用模块化架构，结合规划、推理、动作执行和反射等组件来处理复杂任务。然而，量化每个模块对整体系统性能的贡献仍然是一项重大挑战，阻碍了优化和可解释性。为了解决这个问题，我们引入了 CapaBench（能力级评估基准），这是一个基于合作博弈论的 Shapley 值的评估框架，它系统地衡量代理架构中各个模块及其交互的边际影响。通过在所有可能的组合中用测试变体替换默认模块，CapaBench 提供了一种归因性能贡献的主要方法。主要贡献包括：（1）我们第一个提出了一种基于 Shapley 值的方法来量化 LLM 代理中能力的贡献；（2）具有高 Shapley 值的模块在组合时始终会带来可预测的性能提升，从而实现有针对性的优化； （3）我们构建了一个包含 1,000 多个条目的多轮数据集，涵盖不同的领域和实际任务场景，从而能够全面评估代理能力。CapaBench 弥合了组件级评估和整体系统评估之间的差距，为优化模块化 LLM 代理和推进其在复杂的现实场景中的部署提供了可行的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.00510</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解分布变化下的多模态法学硕士：一种信息论方法</title>
      <link>https://arxiv.org/abs/2502.00577</link>
      <description><![CDATA[arXiv:2502.00577v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 已显示出良好的性能，但在分布变化下会遇到困难，因为评估数据与指令调整分布不同。尽管之前的研究提供了实证评估，但我们认为，建立一个可以表征和量化 MLLM 风险的正式框架对于确保 MLLM 在现实世界中的安全可靠应用是必要的。从信息论的角度，我们提出了第一个能够量化分布变化下 MLLM 最大风险的理论框架。我们框架的核心是引入有效互信息 (EMI)，这是一种量化输入查询和模型响应之间相关性的原则性指标。我们推导出分布内 (ID) 和分布外 (OOD) 数据之间 EMI 差异的上限，并将其与视觉和文本分布差异联系起来。在涵盖 61 个转变场景的真实基准数据集上进行的大量实验从经验上验证了我们的理论见解。]]></description>
      <guid>https://arxiv.org/abs/2502.00577</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于神经符号数学推理的高级弱监督公式探索</title>
      <link>https://arxiv.org/abs/2502.00629</link>
      <description><![CDATA[arXiv:2502.00629v1 公告类型：新
摘要：近年来，神经符号方法已成为一种流行且强大的方法，它增强了人工智能系统执行抽象、逻辑和定量推理的能力，提高了精度和可控性。最近的研究通过利用各种机器学习模型显式或隐式地预测提供符号指令的中间标签，成功地进行了符号推理。然而，这些中间标签并不总是作为训练数据的一部分为每个任务准备的，以大型语言模型 (LLM) 为代表的预训练模型也不能利用其内在知识始终如一地生成有效的符号指令。另一方面，现有的工作开发了替代的学习技术，使学习系统能够自主发现最佳的符号指令。然而，当面对相对巨大的搜索空间或更具挑战性的推理问题时，它们的性能也表现出局限性。鉴于此，在这项工作中，我们提出了一种神经符号推理系统的高级实践，即从问题输入和最终输出中探索具有弱监督的中间标签。我们在数学数据集上的实验从多个方面证明了我们提案的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.00629</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lipschitz 终身蒙特卡洛树搜索用于掌握非平稳任务</title>
      <link>https://arxiv.org/abs/2502.00633</link>
      <description><![CDATA[arXiv:2502.00633v1 公告类型：新
摘要：蒙特卡洛树搜索 (MCTS) 已被证明在解决复杂规划任务方面非常有效，它通过使用树的置信上限 (UCT) 来平衡探索和开发。然而，现有的工作还没有考虑基于 MCTS 的终身规划，其中代理面临一系列非平稳的任务——例如，具有不同的转换概率和奖励——这些任务在整个操作生命周期内按顺序绘制。本文介绍了使用 MCTS 进行 Lipschitz 终身规划的 LiZero。我们提出了一种新的自适应 UCT (aUCT) 概念，将知识从源任务转移到新任务的探索/开发，这取决于任务之间的 Lipschitz 连续性和蒙特卡洛动作采样中知识的置信度。我们从提高采样效率的角度分析了 LiZero 的加速因子，并开发了有效的算法，通过数据驱动和基于模型的方法以在线方式计算 aUCT，其采样复杂性和误差界限也具有特征。实验结果表明，LiZero 的表现明显优于现有的 MCTS 和终身学习基线，其收敛速度更快（3$\sim$4x）达到最佳奖励。我们的结果凸显了 LiZero 在动态现实环境中推进决策和规划的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.00633</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CollabLLM：从被动响应者到主动合作者</title>
      <link>https://arxiv.org/abs/2502.00640</link>
      <description><![CDATA[arXiv:2502.00640v1 公告类型：新
摘要：大型语言模型通常使用下一轮奖励进行训练，这限制了它们优化长期交互的能力。因此，它们通常会被动地响应模棱两可或开放式的用户请求，无法帮助用户实现最终意图并导致对话效率低下。为了解决这些限制，我们引入了 CollabLLM，这是一种新颖的通用训练框架，可增强多轮人机 LLM 协作。它的关键创新是一种协作模拟，它使用多轮感知奖励来估计响​​应的长期贡献。通过强化微调这些奖励，CollabLLM 超越了响应用户请求，并积极发现用户意图并提供有见地的建议 - 这是迈向更加以人为本的 AI 的关键一步。我们还设计了一个多轮交互基准，其中包含三个具有挑战性的任务，例如文档创建。 CollabLLM 的表现明显优于我们的基准，LLM 评委的任务表现平均提高了 18.5%，互动性提高了 46.3%。最后，我们对 201 名评委进行了一项大型用户研究，其中 CollabLLM 使用户满意度提高了 17.6%，用户花费时间减少了 10.4%。]]></description>
      <guid>https://arxiv.org/abs/2502.00640</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的代理</title>
      <link>https://arxiv.org/abs/2502.00648</link>
      <description><![CDATA[arXiv:2502.00648v1 公告类型：新
摘要：人们对生成式人工智能对社会的影响非常担忧。现代人工智能工具能够从最少的提示中生成更逼真的文本、图像、视频和功能代码。随着能力和可用性的提高，人们越来越担心这些工具的滥用，以及可能对个人和社会造成的有意和无意的伤害。在本文中，我们认为 \emph{agency} 是研究这些危害和好处的合适视角，但这样做需要代理理论的进步，以及该理论在（基于代理的）模型中的应用方式的进步。]]></description>
      <guid>https://arxiv.org/abs/2502.00648</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的事件日志分析技术：一项调查</title>
      <link>https://arxiv.org/abs/2502.00677</link>
      <description><![CDATA[arXiv:2502.00677v1 公告类型：新
摘要：事件日志分析是安全专业人员承担的一项重要任务。事件日志记录了计算设备上发生的活动的关键信息，由于生成的事件数量庞大，因此需要花费大量时间和资源进行分析。这项要求高且重复的任务也容易出错。为了解决这些问题，研究人员开发了自动化技术来改进事件日志分析过程。大型语言模型 (LLM) 最近展示了成功执行个人通常会参与的广泛任务的能力，并且达到高标准，并且速度和复杂程度都超过人类。因此，研究人员正在迅速研究 LLM 在事件日志分析中的应用。这包括微调、检索增强生成 (RAG) 和上下文学习，这些都会影响性能。这些工作取得了良好的进展，但仍需要了解知识的发展体系，找出工作之间的共同点，并确定该领域进一步发展的关键挑战和潜在解决方案。本文旨在概述基于 LLM 的事件日志分析技术，为读者提供该领域的深入概述、先前研究中发现的差距，并总结未来探索的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2502.00677</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习数学语言模型的自主代码集成</title>
      <link>https://arxiv.org/abs/2502.00691</link>
      <description><![CDATA[arXiv:2502.00691v1 公告类型：新
摘要：数学大型语言模型 (LLM) 工具集成的最新研究旨在结合思路链 (CoT) 推理和代码执行的互补优势。然而，我们发现了一个关键的限制：当前工具集成的数学 LLM 依赖外部指令来决定是否使用 CoT 或代码，缺乏独立选择最合适方法的自主权。这促使我们研究数学 LLM 的 \emph{自主代码集成}，这使模型能够在没有可靠监督的情况下 \emph{独立} 开发自己的方法选择策略。为了应对这一挑战，我们提出了一种创新的期望最大化 (EM) 公式，通过探索模型的功能来改进模型的决策。这个框架在 (a) 计算参考策略之间交替，通过自我探索来提高模型对其能力的信念，以及 (b) 根据改进的信念更新模型。我们通过高效的实现进一步增强了此框架，结合了新颖的数据合成策略和离线策略强化学习。大量实验表明，我们的方法仅使用公共查询集，就显著提高了现有数学 LLM 的性能，在具有挑战性的 MATH 基准上将准确率提高了近 20\% 至 65.28\%，同时将代码执行量减少了高达 65\%。]]></description>
      <guid>https://arxiv.org/abs/2502.00691</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>