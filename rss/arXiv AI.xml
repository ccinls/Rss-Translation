<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 05 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>零成本基准上异步多保真度优化的快速基准测试</title>
      <link>https://arxiv.org/abs/2403.01888</link>
      <description><![CDATA[arXiv:2403.01888v1 公告类型：新
摘要：虽然深度学习取得了许多成功，但其结果往往取决于超参数（HP）的精心选择。然而，深度学习训练的耗时特性使得 HP 优化 (HPO) 成为一项成本高昂的工作，从而减慢了高效 HPO 工具的开发速度。虽然零成本基准无需实际训练即可提供性能和运行时间，为非并行设置提供了解决方案，但它们在并行设置方面存在不足，因为每个工作线程必须传达其查询的运行时间以按确切的顺序返回其评估。这项工作通过引入一个用户友好的 Python 包来解决这一挑战，该包通过零成本基准促进高效的并行 HPO。我们的方法根据文件系统中存储的信息计算准确的退货单，从而消除了长时间等待的需要，并实现更快的 HPO 评估。我们首先通过广泛的测试来验证我们的方法的正确性，并且对 6 个流行的 HPO 库进行的实验表明了它对不同库的适用性以及与传统方法相比能够实现超过 1000 倍的加速。我们的软件包可以通过 pip install mfhpo-simulator 安装。]]></description>
      <guid>https://arxiv.org/abs/2403.01888</guid>
      <pubDate>Tue, 05 Mar 2024 15:19:01 GMT</pubDate>
    </item>
    <item>
      <title>SMAUG：基于滑动多维任务窗口的 MARL 框架，用于自适应实时子任务识别</title>
      <link>https://arxiv.org/abs/2403.01816</link>
      <description><![CDATA[arXiv:2403.01816v1 公告类型：新
摘要：基于子任务的多智能体强化学习（MARL）方法不是直接从指数扩展的联合观察行动空间中做出行为决策，而是使智能体能够学习如何处理不同的子任务。大多数现有的基于子任务的 MARL 方法都是基于分层强化学习 (HRL)。然而，这些方法往往限制子任务的数量，周期性地执行子任务识别，并且只能在预定义的固定时间段内识别并执行特定的子任务，这使得它们不灵活，不适合子任务不断变化的多样化和动态场景。为了突破上述限制，提出了一种基于\textbf{S}liding \textbf{M}多维t\textbf{A}sk窗口的m\textbf{U}ti-agent强化学习框架（SMAUG）用于自适应实时子任务识别。它利用滑动多维任务窗口从基于不同长度的观察和预测轨迹连接的轨迹段中提取子任务的基本信息。推理网络旨在通过面向子任务的策略网络迭代预测未来轨迹。此外，定义内在动机奖励以促进子任务探索和行为多样性。 SMAUG 可以与任何基于 Q-learning 的方法集成。在《星际争霸 II》上的实验表明，SMAUG 不仅表现出与所有基线相比的性能优势，而且在初始训练阶段的奖励增长也更加突出和迅速。]]></description>
      <guid>https://arxiv.org/abs/2403.01816</guid>
      <pubDate>Tue, 05 Mar 2024 15:19:00 GMT</pubDate>
    </item>
    <item>
      <title>基于模型、以数据为中心的人工智能：弥合学术理想与工业实用主义之间的鸿沟</title>
      <link>https://arxiv.org/abs/2403.01832</link>
      <description><![CDATA[arXiv:2403.01832v1 公告类型：新
摘要：本文深入研究了数据在学术和工业领域中的对比作用，强调了以数据为中心的人工智能和与模型无关的人工智能方法之间的差异。我们认为，虽然以数据为中心的人工智能注重高质量数据对模型性能的首要作用，但与模型无关的人工智能优先考虑算法的灵活性，通常会牺牲数据质量的考虑。这种区别表明，数据质量的学术标准常常不能满足工业应用的严格要求，导致在现实环境中部署学术模型时存在潜在的陷阱。通过全面分析，我们解决了这些差异，提出了它们带来的挑战以及弥合差距的策略。此外，我们提出了一种新的范式：基于模型的以数据为中心的人工智能，旨在通过将模型考虑因素集成到数据优化过程中来协调这些差异。这种方法强调了不断发展对学术研究和工业部署的细微差别敏感的数据要求的必要性。通过探索这些差异，我们的目标是更深入地了解数据在人工智能开发中的作用，并鼓励学术和工业标准的融合，以增强人工智能在现实世界的适用性。]]></description>
      <guid>https://arxiv.org/abs/2403.01832</guid>
      <pubDate>Tue, 05 Mar 2024 15:19:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态集成如何提高 LLM 的优化性能：容量车辆路径问题的案例研究</title>
      <link>https://arxiv.org/abs/2403.01757</link>
      <description><![CDATA[arXiv:2403.01757v1 公告类型：新
摘要：最近，大型语言模型（LLM）将其定位为解决复杂优化挑战的有力工具。尽管认识到这一点，现有基于法学硕士的优化方法的一个主要限制是，当完全依赖数字文本提示时，尤其是在高维问题中，它们很难捕获决策变量之间的关系。考虑到这一点，我们首先建议使用能够处理文本和视觉提示的多模态 LLM 来增强优化性能，以便更深入地了解已处理的优化问题。这种集成可以更全面地理解优化问题，类似于人类的认知过程。我们开发了一个基于 LLM 的多模式优化框架，可以模拟人类解决问题的工作流程，从而提供更细致、更有效的分析。该方法的有效性是通过针对众所周知的组合优化问题（即有能力车辆路径问题）的广泛实证研究来评估的。将结果与仅依赖文本提示的基于 LLM 的优化算法获得的结果进行比较，证明了我们的多模式方法的显着优势。]]></description>
      <guid>https://arxiv.org/abs/2403.01757</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:59 GMT</pubDate>
    </item>
    <item>
      <title>CatCode：代码与文本混合的法学硕士综合评估框架</title>
      <link>https://arxiv.org/abs/2403.01784</link>
      <description><![CDATA[arXiv:2403.01784v1 公告类型：新
摘要：诸如 ChatGPT 之类的大型语言模型 (LLM) 在理解和生成代码和文本的混合方面越来越熟练。基于这样的$\textit{mixture}$的评估可以更全面地了解模型解决编码问题的能力。然而，在这种情况下，当前的评估方法要么任务覆盖范围有限，要么缺乏标准化。为了解决这个问题，我们建议使用范畴论作为评估框架。具体来说，代码类别内的态射可以表示代码调试和转换，两个类别之间的函子表示代码翻译，代码类别和自然语言类别之间的函子表示代码生成、解释和再现。我们提出了一个名为 $\textbf{CatCode}$ ($\textbf{Cat}$egory $\textbf{Code}$) 的自动评估框架，可以全面评估 LLM 的编码能力，包括 ChatGPT、Text-Davinci 和 CodeGeeX 。]]></description>
      <guid>https://arxiv.org/abs/2403.01784</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:59 GMT</pubDate>
    </item>
    <item>
      <title>假设中的假设：最好的半事实解释是使用反事实作为指导找到的吗？</title>
      <link>https://arxiv.org/abs/2403.00980</link>
      <description><![CDATA[arXiv:2403.00980v1 公告类型：新
摘要：最近，使用“仅当”解释的反事实在可解释人工智能（XAI）中变得非常流行，因为它们描述了黑盒人工智能系统的特征输入的哪些变化会导致（通常是负面的）决策的变化——结果。甚至最近，使用“即使”解释的半事实也获得了更多关注。他们阐明了特征输入的变化，但这些变化并没有改变人工智能系统的决策结果，并有可能提出更有益的资源。一些半事实方法使用查询实例的反事实来指导半事实产生（所谓的反事实引导方法），而其他方法则不使用（所谓的无反事实方法）。在这项工作中，我们使用 5 个关键指标对 7 个数据集上的 8 种半事实方法进行了全面测试，以确定是否需要反事实指导来找到最佳的半事实。这些测试的结果表明并非如此，而是计算决策空间的其他方面会带来更好的半事实 XAI。]]></description>
      <guid>https://arxiv.org/abs/2403.00980</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:58 GMT</pubDate>
    </item>
    <item>
      <title>动物友好型人工智能案例</title>
      <link>https://arxiv.org/abs/2403.01199</link>
      <description><![CDATA[arXiv:2403.01199v1 公告类型：新
摘要：人工智能被认为越来越重要，并且可能会产生深远的影响，但人工智能伦理和人工智能工程领域尚未完全认识到这些技术，包括大语言模型（LLM）将对动物产生巨大影响。我们认为这种影响很重要，因为动物在道德上很重要。
  作为评估法学硕士中动物考虑的第一个实验，我们构建了一个概念验证评估系统，该系统从多个角度评估法学硕士的反应和偏见。该系统通过两个标准评估法学硕士的输出：其真实性以及对动物利益的考虑程度。我们使用一组结构化查询和预定义的规范视角测试了 OpenAI ChatGPT 4 和 Anthropic Claude 2.1。初步结果表明，测试模型的结果可以根据它们对动物的考虑进行基准测试，并且可以通过更发达和经过验证的系统来解决和减轻所产生的立场和偏见。
  我们的研究为将动物伦理融入人工智能提供了一种可能的方法，为涉及动物和社会或与动物和社会相关的各个领域的未来研究和实际应用开辟了道路，包括教育、公共政策和监管。总的来说，这项研究是迈向更有用、更负责任的人工智能系统的一步，可以更好地认识和尊重所有众生的切身利益和观点。]]></description>
      <guid>https://arxiv.org/abs/2403.01199</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:58 GMT</pubDate>
    </item>
    <item>
      <title>不确定知识图上的软推理</title>
      <link>https://arxiv.org/abs/2403.01508</link>
      <description><![CDATA[arXiv:2403.01508v1 公告类型：新
摘要：基于机器学习的逻辑查询回答研究使得能够利用大规模且不完整的知识图谱进行推理。本文通过考虑知识的不确定性进一步推进了这一研究方向。知识的不确定性在现实世界中被广泛观察到，但 \textit{并不}与支撑现有研究的一阶逻辑无缝地一致。为了弥补这一差距，我们研究了对不确定知识的软查询的设置，这是由软约束规划的建立所激发的。我们进一步提出了一种基于机器学习的方法，具有前向推理和后向校准功能，可以回答大规模、不完整和不确定的知识图谱上的软查询。理论讨论表明，我们的方法与一阶查询的最先进的推理算法具有相同的复杂性。实证结果证明我们的方法相对于之前基于数字嵌入扩展的基于机器学习的方法具有优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.01508</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:58 GMT</pubDate>
    </item>
    <item>
      <title>利用深层生成技术推动零售供应链：分类、调查和见解</title>
      <link>https://arxiv.org/abs/2403.00861</link>
      <description><![CDATA[arXiv:2403.00861v1 公告类型：新
摘要：生成式人工智能应用程序，例如 ChatGPT 或 DALL-E，已经向世界展示了它们在生成类人文本或图像方面的令人印象深刻的能力。更深入地说，这些人工智能应用程序的科学利益相关者是深度生成模型，又名 DGM，其旨在学习数据的底层分布并生成在统计上与原始数据集相似的新数据点。提出了一个关键问题：我们如何将 DGM 应用于现代零售供应链领域？为了解决这个问题，本文希望对 DGM 进行全面的回顾，并讨论它们在零售供应链中现有和潜在的用例，方法是 (1) 提供最先进的 DGM 及其变体的分类和概述，( 2）从端到端的角度回顾零售供应链中现有的 DGM 应用程序，以及（3）讨论如何进一步利用 DGM 来解决零售供应链问题的见解和潜在方向。]]></description>
      <guid>https://arxiv.org/abs/2403.00861</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:57 GMT</pubDate>
    </item>
    <item>
      <title>算法配置问题</title>
      <link>https://arxiv.org/abs/2403.00898</link>
      <description><![CDATA[arXiv:2403.00898v1 公告类型：新
摘要：随着算法参数自动配置方法的发展，算法优化领域取得了显着的进步。本文深入研究了算法配置问题，重点是优化参数化算法以解决决策/优化问题的特定实例。我们提出了一个全面的框架，不仅形式化了算法配置问题，而且还概述了利用机器学习模型和启发式策略解决其问题的不同方法。本文将现有方法分为按实例方法和按问题方法，区分模型构建和部署的离线和在线策略。通过综合这些方法，我们的目标是为理解和解决算法配置固有的复杂性提供一条清晰的途径。]]></description>
      <guid>https://arxiv.org/abs/2403.00898</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:57 GMT</pubDate>
    </item>
    <item>
      <title>ToolNet：通过工具图连接大型语言模型和海量工具</title>
      <link>https://arxiv.org/abs/2403.00839</link>
      <description><![CDATA[arXiv:2403.00839v1 公告类型：新
摘要：虽然在广泛的任务中取得了显着的进展，但大型语言模型（LLM）在正确使用大量外部工具方面仍然受到严重限制。现有的情境学习方法只是将工具格式化为纯文本描述列表，并将其输入到法学硕士，法学硕士从中生成一系列工具调用来逐步解决问题。这种范式忽略了工具之间的内在依赖性，并将所有推理负载卸载给法学硕士，使它们仅限于有限数量的专门设计的工具。因此，对于法学硕士来说，使用大量工具库仍然具有挑战性，在面对现实场景时会产生很大的限制。本文提出了 ToolNet，这是一个即插即用的框架，可以将工具的数量扩展到数千个，同时适度增加代币消耗。 ToolNet 将工具组织成有向图。每个节点代表一个工具，加权边表示工具转换。从初始工具节点开始，LLM 通过从其后继节点中迭代选择下一个工具节点在图中进行导航，直到任务得到解决。大量实验表明，ToolNet 在具有挑战性的多跳工具学习数据集上可以取得令人印象深刻的结果，并且对工具故障具有弹性。]]></description>
      <guid>https://arxiv.org/abs/2403.00839</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:56 GMT</pubDate>
    </item>
    <item>
      <title>冲突中的团队组建</title>
      <link>https://arxiv.org/abs/2403.00859</link>
      <description><![CDATA[arXiv:2403.00859v1 公告类型：新
摘要：在这项工作中，我们提出了冲突中的团队组建问题。目标是将个人分配给具有给定能力的任务，同时考虑到个人的任务偏好以及它们之间的冲突。使用相关舍入方案作为我们的主要工具箱，我们提供有效的近似算法。我们的框架非常通用，可以模拟教育环境和人力资源管理中出现的许多不同的现实场景。我们在现实世界的数据集上测试和部署我们的算法，并表明我们的算法找到的分配比自然基线找到的分配更好。在教育环境中，我们还展示了我们的作业如何远远优于人类专家手动完成的作业。在人力资源管理应用程序中，我们展示了我们的任务如何增加团队的多样性。最后，使用合成数据集，我们证明我们的算法在实践中可以很好地扩展。]]></description>
      <guid>https://arxiv.org/abs/2403.00859</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:56 GMT</pubDate>
    </item>
    <item>
      <title>TroubleLLM：与红队专家结盟</title>
      <link>https://arxiv.org/abs/2403.00829</link>
      <description><![CDATA[arXiv:2403.00829v1 公告类型：新
摘要：大型语言模型（LLM）成为各种自然语言任务的最先进的解决方案，并集成到现实世界的应用程序中。然而，法学硕士可能会在表现出不良安全问题（例如社会偏见和有毒内容）方面产生潜在危害。在部署之前必须评估其安全问题。然而，现有方法生成的测试提示的质量和多样性仍远不能令人满意。这些方法不仅劳动密集型、需要大量预算成本，而且对于LLM申请的特定测试领域缺乏测试提示生成的可控性。借助LLM进行LLM测试的想法，我们提出了第一个LLM，称为TroubleLLM，用于针对LLM安全问题生成可控的测试提示。大量的实验和人工评估证明了TroubleLLM在发电质量和发电可控性方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.00829</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:55 GMT</pubDate>
    </item>
    <item>
      <title>MedAide：利用大型语言模型在边缘设备上提供本地医疗援助</title>
      <link>https://arxiv.org/abs/2403.00830</link>
      <description><![CDATA[arXiv:2403.00830v1 公告类型：新
摘要：大型语言模型（LLM）以其卓越的自然语言处理（NLP）能力正在给各个领域带来革命性的变化。然而，在资源有限的边缘计算和嵌入式系统中部署法学硕士面临着巨大的挑战。另一个挑战在于在医疗设施和基础设施有限的偏远地区提供医疗援助。为了解决这个问题，我们推出了 MedAide，一个本地医疗保健聊天机器人。它利用与LangChain集成的微型法学硕士，提供高效的基于边缘的初步医疗诊断和支持。 MedAide 采用模型优化，在没有服务器基础设施的嵌入式边缘设备上实现最小的内存占用和延迟。使用低秩适应（LoRA）优化训练过程。此外，该模型还根据不同的医疗数据集进行训练，利用人类反馈的强化学习 (RLHF) 来增强其特定领域的能力。该系统在各种消费级 GPU 和 Nvidia Jetson 开发板上实现。 MedAide 在医疗咨询方面实现了 77% 的准确率，在 USMLE 基准中得分为 56，实现了一个节能的医疗保健援助平台，减轻了基于边缘的部署带来的隐私问题，从而为社区赋能。]]></description>
      <guid>https://arxiv.org/abs/2403.00830</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:55 GMT</pubDate>
    </item>
    <item>
      <title>立场文件：人工智能代理迈向整体智能</title>
      <link>https://arxiv.org/abs/2403.00833</link>
      <description><![CDATA[arXiv:2403.00833v1 公告类型：新
摘要：大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发代理人工智能——一种将大型基础模型集成到代理操作中的具体系统。 Agent AI 的新兴领域涵盖了广泛的现有体现和基于代理的多模态交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型来实现体现的智能行为，Agent基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论人工智能代理的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。]]></description>
      <guid>https://arxiv.org/abs/2403.00833</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:55 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士高风险决策中的认知偏差</title>
      <link>https://arxiv.org/abs/2403.00811</link>
      <description><![CDATA[arXiv:2403.00811v1 公告类型：新
摘要：大型语言模型（LLM）作为支持不断扩大的决策任务范围的工具具有巨大的潜力。然而，鉴于他们对人类（创建的）数据的培训，法学硕士可能会继承针对受保护群体的社会偏见，并受到认知偏见的影响。这种类似人类的偏见可能会妨碍在法学硕士的协助下做出公平且可解释的决策。我们的工作引入了 BiasBuster，这是一个旨在发现、评估和减轻法学硕士认知偏差的框架，特别是在高风险决策任务中。受心理学和认知科学先前研究的启发，我们开发了一个包含 16,800 个提示的数据集，用于评估不同的认知偏差（例如，提示引起的、顺序的、固有的）。我们测试了各种偏见缓解策略，同时提出了一种使用法学硕士来消除他们自己的提示偏见的新方法。我们的分析提供了关于不同商业和开源模型中认知偏差的存在和影响的全面图景。我们证明，我们的自助消除偏见可以有效地减轻认知偏见，而无需为每种偏见类型手动制作示例。]]></description>
      <guid>https://arxiv.org/abs/2403.00811</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:54 GMT</pubDate>
    </item>
    <item>
      <title>在合作语言游戏中适应队友</title>
      <link>https://arxiv.org/abs/2403.00823</link>
      <description><![CDATA[arXiv:2403.00823v1 公告类型：新
摘要：Codenames 游戏最近成为智能代理设计的一个感兴趣的领域。该游戏的独特之处在于队友之间的语言和协调发挥着重要作用。以前为该游戏设计代理的方法使用单一内部语言模型来确定动作选择。这通常会导致某些队友的表现良好，而其他队友的表现较差，因为代理无法适应任何特定的队友。在本文中，我们提出了第一个用于播放 Codenames 的自适应代理。我们采用集成方法，其目标是在与特定队友交互的过程中确定我们的内部专家代理（每个代理可能都有自己的语言模型）是最佳匹配。这种方法面临的一个困难是缺乏能够准确捕捉 Codenames 团队绩效的单一数字指标。之前的 Codenames 研究利用了一些不同的指标来评估代理团队。我们提出了一种新颖的单一指标来评估 Codenames 团队的表现，无论是玩单团队（纸牌）游戏，还是与另一个团队进行竞争性游戏。然后，我们提出并分析一个集成代理，该代理在每轮选择一名内部专家，以最大化该建议指标。实验分析表明，这种集成方法适用于单个队友，并且通常与最好的内部专家与队友的表现几乎一样好。至关重要的是，这种成功并不依赖于之前对队友、整体特工或他们的兼容性的了解。这项研究代表了使基于语言的代理（例如代号）更适合单个队友的合作语言设置的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2403.00823</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:54 GMT</pubDate>
    </item>
    <item>
      <title>一种新的动态分布式规划方法：在 DPDP 问题中的应用</title>
      <link>https://arxiv.org/abs/2403.00805</link>
      <description><![CDATA[arXiv:2403.00805v1 公告类型：新
摘要：在这项工作中，我们提出了一种新的动态分布式规划方法，该方法能够考虑代理对其要计划的操作集引入的变化，以便考虑其环境中发生的变化。我们的方法适合分布式计划的分布式规划环境，其中每个代理都可以生成自己的计划。根据我们的方法，计划的生成基于使用遗传算法对约束的满足。我们的方法是，每当要计划的行动集发生变化时，每个代理都会生成一个新计划。这是为了考虑到新计划中引入的新行动。在这个新计划中，智能体每次都将旧计划中所有未执行的旧动作以及变化产生的新动作作为一个新的动作集，并作为新的初始状态；主体的动作集发生变化的状态。在我们的工作中，我们使用了一个具体案例来说明和展示我们方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2403.00805</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:53 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型引导认知代理</title>
      <link>https://arxiv.org/abs/2403.00810</link>
      <description><![CDATA[arXiv:2403.00810v1 公告类型：新
摘要：大型语言模型包含关于世界的嘈杂的常识，但很难训练或微调。另一方面，认知架构具有出色的可解释性，并且可以灵活更新，但需要大量的手动工作来实例化。在这项工作中，我们结合了两方面的优点：利用大型语言模型中编码的噪声知识引导基于认知的模型。通过执行厨房任务的具体代理，我们表明，与完全基于大型语言模型的代理相比，我们提出的框架具有更高的效率。我们的实验表明，大型语言模型是认知架构的良好信息来源，而认知架构反过来可以验证大型语言模型的知识并将其更新到特定领域。]]></description>
      <guid>https://arxiv.org/abs/2403.00810</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:53 GMT</pubDate>
    </item>
    <item>
      <title>关于法学硕士在规划中的作用：将法学硕士嵌入规划图中</title>
      <link>https://arxiv.org/abs/2403.00783</link>
      <description><![CDATA[arXiv:2403.00783v1 公告类型：新
摘要：计划综合旨在生成一系列行动或政策，将给定的初始状态转变为目标状态，提供可由专家设计或从训练数据或与世界交互中学习的领域模型。出于对大型语言模型（LLM）中的紧急规划能力的兴趣，人们提出了研究 LLM 规划有效性的工作，而不考虑在 LLM 中使用任何现成的规划技术。在本文中，我们旨在通过调查法学硕士在现成规划框架中的作用，进一步研究法学硕士规划能力的洞察力。为此，我们研究了将 LLM 嵌入到著名的规划框架之一（基于图的规划）中的有效性，提出了一种新颖的基于 LLM 的规划框架，其中 LLM 嵌入了两个级别的规划图（即相互约束生成级别）和约束解决水平。我们凭经验展示了我们提出的框架在各个规划领域的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.00783</guid>
      <pubDate>Tue, 05 Mar 2024 15:18:52 GMT</pubDate>
    </item>
    </channel>
</rss>