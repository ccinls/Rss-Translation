<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 14 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在深度增强学习中，稳定性与可塑性之间的神经元水平平衡</title>
      <link>https://arxiv.org/abs/2504.08000</link>
      <description><![CDATA[ARXIV：2504.08000V1公告类型：新 
摘要：与人类持续获取知识的能力相反，代理商在深度加强学习中与稳定性困境（DRL）斗争，这是指保留现有技能（稳定）和学习新知识（可塑性）之间的权衡。当前的方法着重于在网络级别平衡这两个方面，缺乏对单个神经元的足够的分化和细粒度的控制。为了克服这一限制，我们提出了稳定性和可塑性（NBSP）方法之间的神经元水平平衡，从观察到特定神经元与与任务相关的技能密切相关的观察中，我们提出了灵感。具体而言，NBSP First（1）定义和识别RL技能神经元，这些神经元对于通过目标方法保留知识至关重要，然后（2）通过采用针对这些神经元的梯度掩盖和经验重播技术来引入一个框架，以保护编码的现有技能，同时使适应新任务适应新任务。关于元世界和Atari基准的许多实验结果表明，NBSP在平衡稳定性和可塑性方面的现有方法显着优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2504.08000</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于处理本体论图的Python工具包</title>
      <link>https://arxiv.org/abs/2504.08006</link>
      <description><![CDATA[ARXIV：2504.08006V1公告类型：新 
摘要：我们在本体论图上介绍了培养皿网的理论基础，以及设计和实施用于处理此类网络的Python工具包。在培养皿网上的本体论图中，域知识以本体论形式封闭。这样，可以将一些有价值的知识（尤其是在语义关系方面）添加到通过培养皿网模型和控制过程中的模型。在实现的方法中，本体论图是从根据OWL 2 Web本体语言构建的本体学获得的。实现的工具使用户能够在本体论图上定义培养皿网的结构和动力学。]]></description>
      <guid>https://arxiv.org/abs/2504.08006</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>公用事业启发了Topsis的概括</title>
      <link>https://arxiv.org/abs/2504.08014</link>
      <description><![CDATA[ARXIV：2504.08014V1公告类型：新 
摘要：Topsis，一种对替代方案进行排名的流行方法是基于与理想和反理想点的汇总距离。因此，它被认为与广泛流行和公认的“基于公用事业的方法”本质上有所不同，这些方法从重量平均的公用事业值中建立排名。尽管如此，最近已证明TOPSI是这些“基于公用事业的方法”的自然概括，理由是可以将其使用的距离分解为所谓的重量量表平均值（WM）和权重尺度标准偏差（WSD）。但是，这两个组成部分对最终排名的影响不能以任何影响在标准上的影响下。这就是为什么在我们先前的结果的基础上，在本文中，我们提出了对WM和WSD响应的Topsis聚集的修改，从而对WM和WSD的排名如何影响了一定的可解释性控制。修改构成了标准TOPSIS方法的自然概括，因为多亏了它们，普遍的Topsis可能会变成原始的TOPSIS，或者遵循决策者的偏好，可以将WM与WSD或WSD交易。在后一种情况下，TOPSIS逐渐减少到常规的“基于实用性的方法”。总而言之，我们认为所提出的概括构成了一种有趣的实用工具，可以通过受控新形式的决策者偏好来影响排名。]]></description>
      <guid>https://arxiv.org/abs/2504.08014</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI科学家V2：通过代理树搜索的车间级自动化科学发现</title>
      <link>https://arxiv.org/abs/2504.08066</link>
      <description><![CDATA[ARXIV：2504.08066V1公告类型：新 
摘要：AI越来越多地在改变科学发现的方式中发挥关键作用。我们介绍了AI Scientist-V2，这是一种端到端的代理系统，该系统能够生产第一个完全AI生成的同行评审工作室论文。该系统迭代地制定了科学假设，设计和执行实验，分析和可视化数据，并自主撰写科学手稿。与其前身（V1，Lu等，2024 Arxiv：2408.06292）相比，AI Scientist-V2消除了对人为撰写的代码模板的依赖，可以有效地跨越多样化的机器学习域，并利用了一种新颖的渐进式搜索方法，由专门的实验经理管理。此外，我们通过整合视觉模型（VLM）反馈回路来增强AI审阅者的组件，以迭代内容的迭代细化和数字美学。我们通过将三个完全自主的手稿提交给同行评审的ICLR研讨会来评估AI科学家V2。值得注意的是，一个手稿的得分足够高，超过了人类的平均验收阈值，这标志着完全AI生成的纸的第一例成功地浏览了同行评审。这一成就凸显了AI在进行科学研究方面的不断增长的能力。我们预计，自主科学发现技术的进一步进步将对人类知识的产生产生深远的影响，从而在研究生产力中实现了前所未有的可扩展性，并显着加快了科学的突破，从而使整个社会受益匪浅。我们已经在https://github.com/sakanaai/ai-scientist-v2上开源了代码，以促进这种变革性技术的未来发展。我们还讨论了AI在科学中的作用，包括AI安全。]]></description>
      <guid>https://arxiv.org/abs/2504.08066</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>编排企业的代理和数据：化合物AI的蓝图体系结构</title>
      <link>https://arxiv.org/abs/2504.08148</link>
      <description><![CDATA[ARXIV：2504.08148V1公告类型：新 
摘要：大型语言模型（LLM）由于在各种任务中令人印象深刻的能力而引起了人们对行业的重大兴趣。但是，LLMS的广泛采用提出了一些挑战，例如集成到现有应用程序和基础架构中，公司专有数据，模型和API以及会议成本，质量，响应能力和其他要求。为了应对这些挑战，从整体模型转变为复合AI系统，其前提是更强大，多功能和可靠的应用程序。但是，到目前为止，进步是零散的，提出了有关代理工作流程，编程模型和扩展LLM功能的建议，而没有清晰的整体体系结构愿景。在本文中，我们为复合AI系统提出了一个“蓝图体系结构”，用于协调企业应用程序的代理和数据。在我们提出的架构中，关键的编排概念是“流”，以协调代理之间的数据和指示流。企业中现有的专有模型和API被映射到“代理”中定义的“代理注册表”，该代理为代理元数据提供服务，并学习了用于搜索和计划的表示。代理可以通过“数据注册表”使用专有数据，该数据类似地注册了各种模式的企业数据。将所有这些都捆绑在一起，数据和任务“计划者”分解，映射并优化给定服务质量（QoS）要求（例如成本，准确性和延迟）的任务和查询。我们说明了人力资源领域中用例的体系结构的实现，并讨论了企业中“代理AI”的机会和挑战。]]></description>
      <guid>https://arxiv.org/abs/2504.08148</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MEDREP：通用电子健康记录基础模型的医学概念表示</title>
      <link>https://arxiv.org/abs/2504.08329</link>
      <description><![CDATA[ARXIV：2504.08329V1公告类型：新 
摘要：电子健康记录（EHR）基础模型已成为探索的领域，其在各种医疗任务中的表现都提高了。尽管取得了迅速的进步，但仍存在一个基本限制：处理词汇中未见的医疗法规。这个问题限制了EHR基础模型的一般性和通过不同词汇训练的模型的集成。为了解决这个问题，我们根据观察性医学结果伙伴关系（OMOP）共同数据模型（CDM）提出了EHR基础模型的MEDREP，提供了综合的医疗概念表示和患者轨迹的基本数据增强策略。对于概念表示学习，我们通过大型语言模型（LLM）提示并通过OMOP词汇的图形本体论提示并增强基于文本的表示形式，从而丰富了每个概念的信息。轨迹增强将所选概念随机替换为具有密切相关表示形式的其他类似概念，使模型实践具有概念的概念。最后，我们证明了经过MEDREP训练的EHR基础模型可以更好地维护外部数据集中的预测性能。我们的代码实现可在https://github.com/kicarussays/medrep上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2504.08329</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在部分可观察性下对合作多机构增强学习的信念状态</title>
      <link>https://arxiv.org/abs/2504.08417</link>
      <description><![CDATA[ARXIV：2504.08417V1公告类型：新 
摘要：在部分可观察到的环境中学习的强化学习通常具有挑战性，因为它要求代理学习基础系统状态的估计。这些挑战在多代理的环境中加剧了，在这些环境中，代理人同时学习并影响了基本状态以及彼此的观察结果。我们提出在系统基本状态上使用学识的信念来克服这些挑战，并通过完全分散的培训和执行来强化学习。我们的方法利用国家信息以一种自我监督的方式预先培训概率的信念模型。随后，在基于州的强化学习算法中使用了捕获推断的状态信息以及对该信息的不确定性的信念状态，以在部分观察性下为合作多代理增强学习的端到端模型创建端到端模型。通过将信念和强化学习任务分开，我们能够显着简化政策和价值功能学习任务，并提高收敛速度和最终表现。我们对旨在展示部分可观察性变异的多种部分可观察到的多个多代理任务评估了我们提出的方法。]]></description>
      <guid>https://arxiv.org/abs/2504.08417</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>任务存储器引擎（TME）：增强对多步LLM代理任务的状态意识</title>
      <link>https://arxiv.org/abs/2504.08525</link>
      <description><![CDATA[ARXIV：2504.08525V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地用作多步任务的自主代理。但是，大多数现有的框架无法维持对任务状态的结构化理解，通常依靠线性提示串联或浅内存缓冲区。这会导致脆弱的性能，频繁的幻觉和远距离连贯性。在这项工作中，我们提出了任务存储器引擎（TME），这是一个轻巧且结构化的内存模块，该模块使用层次任务存储树（TMT）跟踪任务执行。树中的每个节点都对应于任务步骤，并存储相关的输入，输出，状态和子任务关系。我们引入了一种及时的合成方法，该方法基于活动节点路径动态生成LLM提示，从而显着提高了执行一致性和上下文接地。通过案例研究和对多步代理任务的比较实验，我们证明了TME可以提高任务完成精度，并以最小的实施开销来提高任务完成精度和更可解释的行为。 TME的完整实现可在https://github.com/biubiutomato/tme-agent上获得。]]></description>
      <guid>https://arxiv.org/abs/2504.08525</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立可解释的人工智能系统的评估框架</title>
      <link>https://arxiv.org/abs/2504.08552</link>
      <description><![CDATA[ARXIV：2504.08552V1公告类型：新 
摘要：人工智能在计算机系统开发中的整合提出了一个新的挑战：使人类可以解释的智能系统。这在健康和福祉领域尤其重要，在这种情况下，决策支持系统的透明度使医疗保健专业人员能够理解和信任自动化的决策和预测。为了满足这一需求，需要工具来指导可解释的AI系统的开发。在本文中，我们介绍了一个评估框架，旨在支持可解释的健康和福祉系统的开发。此外，我们提出了一个案例研究，以说明框架在实践中的应用。我们认为，我们的框架不仅可以作为开发医疗保健中可解释的AI系统的宝贵工具，而且还可以作为对个人产生重大影响的任何AI系统的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2504.08552</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMS是否信任AI法规？游戏理论LLM代理的新兴行为</title>
      <link>https://arxiv.org/abs/2504.08640</link>
      <description><![CDATA[ARXIV：2504.08640V1公告类型：新 
摘要：普遍同意，在AI开发生态系统中促进信任与合作对于促进可信赖的AI系统的采用至关重要。通过将大语言模型（LLM）代理嵌入进化游戏理论框架中，本文研究了AI开发人员，监管机构和用户之间的复杂相互作用，并在不同的监管场景下对其战略选择进行了建模。进化游戏理论（EGT）用于定量地模拟每个演员所面临的困境，而LLMS提供了额外的复杂性和细微差别，并实现重复的游戏并结合了人格特质。我们的研究确定了战略AI代理的新兴行为，这些行为往往比纯游戏理论代理人采用更多的“悲观”（不信任和有缺陷）的立场。我们观察到，如果用户完全信任，激励措施是有效促进有效法规的有效措施。但是，有条件的信任可能会恶化“社会公约”。因此，建立用户信任和监管机构声誉之间的良性反馈似乎是推动开发人员创建安全AI的关键。但是，这种信任的出现水平可能取决于用于测试的特定LLM。因此，我们的结果为AI调节系统提供了指导，并有助于预测战略LLM代理的结果，如果它们被用来帮助调节本身。]]></description>
      <guid>https://arxiv.org/abs/2504.08640</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sphere：人类系统的评估卡</title>
      <link>https://arxiv.org/abs/2504.07971</link>
      <description><![CDATA[ARXIV：2504.07971V1公告类型：交叉 
摘要：在大型语言模型（LLMS）的时代，建立有效的人类互动系统的有效评估方法和标准越来越具有挑战性。为了鼓励更多透明的文档并促进有关人类系统系统评估设计选项的讨论，我们提出了一个评估卡领域，其中包括五个关键的维度：1）正在评估什么？ 2）评估是如何进行的？ 3）谁参加评估？ 4）何时进行评估？ 5）如何验证评估？我们使用球体对39个人类系统进行了审查，概述了当前的评估实践和改进领域。我们提供了三个建议，以提高评估实践的有效性和严格性。]]></description>
      <guid>https://arxiv.org/abs/2504.07971</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中公平评估的变质测试：识别骆驼和GPT中的交叉偏见</title>
      <link>https://arxiv.org/abs/2504.07982</link>
      <description><![CDATA[ARXIV：2504.07982V1公告类型：交叉 
摘要：大型语言模型（LLM）在自然语言处理方面取得了长足的进步，但仍然容易受到与公平相关的问题的影响，通常反映了其培训数据中固有的偏见。这些偏见会带来风险，特别是当LLM部署在敏感地区，例如医疗保健，金融和法律时。本文介绍了一种变质​​测试方法，以系统地识别LLMS中的公平性错误。我们定义并应用了一组面向公平的变质关系（MRS），以评估各种人口统计学输入中的最先进的LLM Llama和GPT模型。我们的方法包括为每个MR生成源和后续测试案例，并分析违反公平的模型响应。结果表明，MT在暴露偏见模式中的有效性，尤其是与语调和情感有关，并突出显示了经常揭示公平性故障的敏感属性的特定交集。这项研究改善了LLMS中的公平测试，提供了一种结构化方法来检测和减轻偏见并改善对公平敏感应用中的模型鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2504.07982</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>心理健康知识增强LLM的社会网络危机干预文本转移识别方法</title>
      <link>https://arxiv.org/abs/2504.07983</link>
      <description><![CDATA[ARXIV：2504.07983V1公告类型：交叉 
摘要：随着社交媒体平台上心理健康危机的普遍性的增加，识别和预防潜在伤害已成为紧迫的挑战。这项研究介绍了一个大型语言模型（LLM）基于社交网络危机干预的文本转移识别方法，并通过特定领域的心理健康知识增强了。我们提出了一个多层框架，该框架结合了使用BERT的转移学习，并整合了心理健康知识，情感分析和行为预测技术。该框架包括一个在现实世界中的社交媒体数据集中训练的危机注释工具，使该模型能够检测细微的情感线索并确定心理危机。实验结果表明，该提出的方法在危机检测准确性中的表现优于传统模型，并表现出对微妙的情感和上下文变化的更高敏感性。]]></description>
      <guid>https://arxiv.org/abs/2504.07983</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>密封：免费的大语言模型的通知推理校准</title>
      <link>https://arxiv.org/abs/2504.07986</link>
      <description><![CDATA[ARXIV：2504.07986V1公告类型：交叉 
摘要：大型语言模型（LLMS），例如OpenAI的O1系列，通过扩展的思维链（COT）推理机制证明了对复杂推理任务的引人注目的功能。但是，最近的研究揭示了COT推理轨迹的大量冗余，这不仅增加了推理潜伏期，而且还通过将注意力转移到不必要的推理路径上对模型性能产生负面影响。为了解决这个问题，我们研究了LLM的内部推理结构，并将它们分为三种主要思想类型：执行，反思和过渡思想。此外，我们的分析表明，过度反思和过渡思想与失败案例密切相关，这些思想类别在潜在空间中表现出明显的分离。基于这些，我们引入了密封件（可通行的推理校准），这是一种无训练的方法，可以无缝校准COT工艺，提高准确性，同时显示出显着的效率提高。密封由一个离线阶段组成，用于在潜在空间中提取推理转向向量，然后通过使用转向向量的表示干预对推理轨迹进行直通校准。值得注意的是，转向矢量在各种任务中表现出强大的可传递性。多种模型（DeepSeek-R1-Distill和QWQ-32B-Preigiew）和基准测试（Math500，GSM8K，LiveCodeBench）之间进行了广泛的实验，可验证密封的有效性，而准确性提高了11％，而将其降低了11.8％至50.4％。我们的代码可在https://github.com/vita-group/seal上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2504.07986</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>区域小故事：使用小型模型比较语言学习和代币功能</title>
      <link>https://arxiv.org/abs/2504.07989</link>
      <description><![CDATA[ARXIV：2504.07989V1公告类型：交叉 
摘要：小语言模型（SLM）为特定域提供了有效的LLMS替代方案。 2023年的小故事研究开发了一个英语数据集，该数据集允许具有1至1000万参数的SLM产生连贯的输出。我们的研究通过将原始数据集转换为印度语言并使用LLM创建合成数据来扩展此框架。我们专注于印地语，马拉地语和孟加拉语，评估SLM的区域语言处理和理解语言复杂性。我们表明，SLM的参数比LLMS有效地处理区域语言，为``代币化策略&#39;&#39;和语言复杂性提供了一个互补的框架。我们的分析表明，语言特异性的表达者表明，该语言的特定于印度语言的通用效果超过了仿效的效果，并提供了信息分析。印地语模型和孟加拉语，我们表明，合成数据集超过了训练SLM的内容。]]></description>
      <guid>https://arxiv.org/abs/2504.07989</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有限和无限神经网络对低密度传感器网络的现实EMF暴露估算的比较分析</title>
      <link>https://arxiv.org/abs/2504.07990</link>
      <description><![CDATA[ARXIV：2504.07990V1公告类型：交叉 
摘要：了解环境暴露于无线电电磁场（RF-EMF）的空间和时间模式对于进行风险评估至关重要。这些评估旨在探索RF-EMF暴露与其对人类健康以及野生动植物和植物生命的影响之间的潜在联系。现有研究使用了不同的机器学习工具来估算电动势暴露。但是，需要对这些技术进行比较分析，以更好地了解其对现实数据集的性能。在这项工作中，我们介绍了基于有限和无限宽度卷积网络的方法，以估算和评估法国里尔70个现实世界传感器的EMF暴露水平。已经进行了比较分析来分析方法的执行时间和估计精度的性能。为了提高高分辨率网格的估计精度，我们利用了一种预处理的梯度下降方法来进行核估计。均方根误差（RMSE）用作比较这些深度学习模型的性能的评估标准。]]></description>
      <guid>https://arxiv.org/abs/2504.07990</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的“神经how叫”：一种自我增强的偏见现象和动态衰减解决方案</title>
      <link>https://arxiv.org/abs/2504.07992</link>
      <description><![CDATA[ARXIV：2504.07992V1公告类型：交叉 
摘要：大语言模型（LLM）驱动的AI系统可能表现出推理故障模式，我们称其为“神经ho叫”，这是一种自我增强的认知环路，其中某些高度加权的输入成为主导，从而导致抗矫正的根深蒂固的响应模式。本文探讨了这种现象的基础机制，该机制不同于模型崩溃和偏见的显着性加权。我们提出了一种基于衰减的校正机制，即使在“锁定” AI系统中，也可以动态引入平衡调整并可以恢复适应性推理。此外，我们讨论了由不当管理的强化产生的其他相关效果。最后，我们概述了这种缓解策略的潜在应用，以改善现实世界决策任务中的AI鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2504.07992</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估本体论在问题产生的任务中的适应性</title>
      <link>https://arxiv.org/abs/2504.07994</link>
      <description><![CDATA[ARXIV：2504.07994V1公告类型：交叉 
摘要：基于本体的问题生成是语义感知系统的重要应用，它可以为各种学习环境创建大型问题库。这些系统的有效性，无论是在产生问题的能力和认知难度方面，都在很大程度上取决于基本本体论的质量和建模方法，因此评估其对此任务的适合度至关重要。迄今为止，还没有对影响问题产生过程的特定本体方面或特征进行全面调查。因此，本文提出了一组要求和特定于任务的指标，以评估教学环境中问题生成任务的适应性。使用Romeo方法论，一种用于得出特定任务指标的结构化框架，采用了一种基于专家的方法来评估自动问题生成（AQG）任务中各种本体学的性能，然后在一组本体论中进行评估。我们的结果表明，本体特征显着影响问题产生的有效性，不同的本体论表现出不同的绩效水平。这突出了评估本体质量在AQG任务方面的重要性。]]></description>
      <guid>https://arxiv.org/abs/2504.07994</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CDM-QTA：量化的训练加速度，以进行扩散模型的有效洛拉微调</title>
      <link>https://arxiv.org/abs/2504.07998</link>
      <description><![CDATA[ARXIV：2504.07998V1公告类型：交叉 
摘要：定制应用程序的微调大扩散模型需要大量的功率和时间，这对在移动设备上有效实施构成了重大挑战。在本文中，我们开发了一种专门针对扩散模型的低级适应（LORA）的新型培训加速器，旨在简化过程并降低计算复杂性。通过利用完全量化的培训方案进行洛拉微调，我们在保持高模型保真度的同时，实现了记忆使用和功耗的大量降低。所提出的加速器具有灵活的数据流，可在洛拉过程中高利用不规则和可变张量的形状。与基线相比，实验结果最高可达1.81倍训练的速度和5.50倍能效的提高，对图像产生质量的影响最小。]]></description>
      <guid>https://arxiv.org/abs/2504.07998</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DGFAMBA：学习流量分解的视觉域概括状态空间</title>
      <link>https://arxiv.org/abs/2504.08019</link>
      <description><![CDATA[ARXIV：2504.08019V1公告类型：交叉 
摘要：域的概括旨在从源域中学习表示形式，可以将其推广到任意看不见的目标域。视觉领域概括的基本挑战是由戏剧性风格变化引起的域间隙，而图像内容稳定。由Vmamba举例说明的选择性状态空间的领域展示了其代表内容时的全球接受领域。但是，很少探索为选择性状态空间开发域不变属性的方式。在本文中，我们提出了一种新型的流量分解状态空间模型，称为DG-Famba，用于视觉领域的概括。为了维持域的一致性，我们通过流量分解来创新地绘制样式增强和原始状态嵌入。在这个潜在的流动空间中，每个样式嵌入的每个状态均由潜在概率路径指定。通过在潜在空间中对齐这些概率路径，无论样式差异如何，状态嵌入能够表示相同的内容分布。在各种视觉域概括设置上进行的广泛实验表明其最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2504.08019</guid>
      <pubDate>Mon, 14 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>