<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 27 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>解释美德的简要概述</title>
      <link>https://arxiv.org/abs/2411.16709</link>
      <description><![CDATA[arXiv:2411.16709v1 公告类型：新 
摘要：在本报告中，我简要总结了哲学、心理学和认知科学中关于解释美德的文献，并将这些概念与可解释的人工智能联系起来。]]></description>
      <guid>https://arxiv.org/abs/2411.16709</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人体运动指令调整</title>
      <link>https://arxiv.org/abs/2411.16805</link>
      <description><![CDATA[arXiv:2411.16805v1 公告类型：新
摘要：本文介绍了 LLaMo（大型语言和人体运动助手），这是一种用于人体运动指令调整的多模态框架。与将非语言输入（例如视频或运动序列）转换为语言标记的传统指令调整方法相比，LLaMo 保留了运动的原始形式以进行指令调整。此方法保留了在标记化过程中经常被忽略的运动特定细节，从而提高了模型解释复杂人类行为的能力。通过处理视频和运动数据以及文本输入，LLaMo 实现了灵活的以人为本的分析。在包括人类行为和专业活动在内的高复杂度领域进行的实验评估表明，LLaMo 可以有效捕获特定领域的知识，从而增强对运动密集型场景的理解和预测。我们希望 LLaMo 为未来具有广泛应用的多模态 AI 系统奠定基础，从体育分析到行为预测。我们的代码和模型可在项目网站上找到：https://github.com/ILGLJ/LLaMo。]]></description>
      <guid>https://arxiv.org/abs/2411.16805</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语言游戏进行无限制的苏格拉底式学习</title>
      <link>https://arxiv.org/abs/2411.16905</link>
      <description><![CDATA[arXiv:2411.16905v1 公告类型：新
摘要：在封闭系统中训练的代理可以掌握任何所需的能力，只要满足以下三个条件：（a）它收到足够信息和一致的反馈，（b）它的经验/数据覆盖范围足够广，（c）它具有足够的容量和资源。在这篇立场文件中，我们证明了这些条件的合理性，并考虑了在假设（c）不是瓶颈的情况下，封闭系统中（a）和（b）会产生哪些限制。考虑到具有匹配输入和输出空间（即语言）的代理的特殊情况，我们认为这种纯粹的递归自我改进，称为“苏格拉底式学习”，可以大大提高其初始数据或知识中存在的性能，并且仅受时间以及逐渐错位问题的限制。此外，我们提出了一个基于语言游戏概念的建设性框架来实现它。]]></description>
      <guid>https://arxiv.org/abs/2411.16905</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的一致性引导奖励集成离线学习</title>
      <link>https://arxiv.org/abs/2411.17135</link>
      <description><![CDATA[arXiv:2411.17135v1 公告类型：新
摘要：使用大型语言模型 (LLM) 来实现具身代理已经变得很流行，但在实践中它存在一些局限性。在这项工作中，我们不是直接使用 LLM 作为代理，而是探索将其用作具身代理学习的工具。具体来说，为了通过离线强化学习 (RL) 训练单独的代理，LLM 用于在训练数据集中为各个动作提供密集的奖励反馈。为此，我们提出了一个一致性引导的奖励集成框架 (CoREN)，旨在解决将 LLM 生成的估计值应用到目标环境域的困难。该框架采用时空一致的奖励的自适应集成来在训练数据集中获得基于领域的奖励，从而实现在不同环境领域中具身代理的有效离线学习。使用 VirtualHome 基准进行的实验表明，CoREN 的表现明显优于其他离线 RL 代理，并且尽管 CoREN 的代理策略网络只有 117M 个参数，并且仅使用 LLM 进行训练，但它的性能仍与具有 8B 参数的最先进的基于 LLM 的代理相当。]]></description>
      <guid>https://arxiv.org/abs/2411.17135</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过在线 POMDP 规划实现机器人助手的意图识别</title>
      <link>https://arxiv.org/abs/2411.17326</link>
      <description><![CDATA[arXiv:2411.17326v1 公告类型：新
摘要：意图识别，或预测另一个代理的行为的能力，在设计和开发能够支持人类日常任务的自动化助手中起着至关重要的作用。特别是，工业环境带来了有趣的挑战，包括决策者的潜在干扰以及嘈杂或不完整的观察。在这样的环境中，负责帮助和支持人类工人的机器人助手必须将信息收集行动与自己的主动任务交织在一起，这种方法被称为主动目标识别。在本文中，我们描述了一个用于在线意图识别的部分可观察模型，展示了一些初步的实验结果，并讨论了这类问题中存在的一些挑战。]]></description>
      <guid>https://arxiv.org/abs/2411.17326</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BPP-Search：增强思维树推理能力以解决数学建模问题</title>
      <link>https://arxiv.org/abs/2411.17404</link>
      <description><![CDATA[arXiv:2411.17404v1 公告类型：新
摘要：LLM 具有高级推理能力，可以将自然语言问题转化为数学模型。然而，现有的开源运筹学数据集缺乏对建模过程的详细注释，例如变量定义，仅关注目标值，这阻碍了强化学习的应用。为了解决这个问题，我们发布了 StructuredOR 数据集，该数据集带有全面的标签，可以捕获完整的数学建模过程。我们进一步提出了 BPP-Search，这是一种使用 Beam 搜索、过程奖励模型和成对偏好算法将强化学习集成到思维树结构中的算法。这种方法可以有效地探索树结构，避免穷举搜索，同时提高准确性。在 StructuredOR、NL4OPT 和 MAMO-ComplexLP 数据集上进行的大量实验表明，BPP-Search 明显优于最先进的方法，包括思维链、自洽和思维树。在基于树的推理中，BPP-Search 也超越了与贪婪搜索或束搜索相结合的过程奖励模型，表现出更高的准确性和效率，并能够更快地检索到正确的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.17404</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过图形化、超化和不确定性推进不确定组合学：模糊、中智、软、粗糙及其他</title>
      <link>https://arxiv.org/abs/2411.17411</link>
      <description><![CDATA[arXiv:2411.17411v1 公告类型：新
摘要：为了更好地处理现实世界的不确定性，引入了模糊集、中智集、粗糙集和软集等概念。例如，中智集同时表示真值、不确定性和假值，已被证明是复杂系统中建模不确定性的宝贵工具。这些集合概念越来越多地以图形形式进行研究，广义图形概念现在涵盖了超图和超超图等众所周知的结构。此外，超概念和超超概念正在图论以外的领域得到积极研究。
组合学、不确定集（包括模糊集、中智集、粗糙集、软集和多石集）、不确定图以及超和超超概念是活跃的研究领域，具有重要的数学和实践意义。认识到它们的重要性，本文探讨了新的图形和集合概念以及超和超超概念，详见“论文结构”的“结果”部分。此外，这项工作旨在整合最近的发现，提供类似调查的资源来告知和吸引读者。
例如，我们通过引入中性智集、中性智集、中性偏移和非标准实集来扩展几个图形概念。本文定义了各种概念，旨在激发新想法并为研究人员的学术追求提供宝贵的资源。]]></description>
      <guid>https://arxiv.org/abs/2411.17411</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以像素为中心进行对象中心的原符号行为推理</title>
      <link>https://arxiv.org/abs/2411.17438</link>
      <description><![CDATA[arXiv:2411.17438v1 公告类型：新
摘要：自主智能代理必须解决不同抽象层次上的计算挑战，从低级感官输入和运动命令空间到高级抽象推理和规划领域。设计此类代理的一个关键问题是如何最好地实例化将在这两个层次之间交互的表示空间——理想情况下不需要以昂贵的数据注释的形式进行监督。这些目标可以通过用对象（基于感知和动作）来表示世界来有效地实现。在这项工作中，我们提出了一种新颖的、受大脑启发的深度学习架构，它使用以对象为中心的表示，从像素中学习解释、控制和推理其环境。我们通过需要结合（高级）逻辑推理和（低级）连续控制的合成环境中的任务展示了我们方法的实用性。结果表明，代理可以学习突发条件行为推理，例如 $(A \to B) \land (\neg A \to C)$，以及逻辑组合 $(A \to B) \land (A \to C) \vdash A \to (B \land C)$ 和 XOR 运算，并成功控制其环境以满足从这些逻辑规则中推导出的目标。由于动态的内部期望目标生成，代理可以在线适应其环境中的意外变化，并且对其世界模型的轻微违反具有很强的鲁棒性。虽然目前的结果仅限于合成设置（dSprites 的 2D 和 3D 激活版本），这达不到现实世界的复杂程度，但所提出的架构展示了如何操纵接地对象表示，作为无监督学习的关键归纳偏差，以实现行为推理。]]></description>
      <guid>https://arxiv.org/abs/2411.17438</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 ChatGPT4 作为计算机科学专业学生教学助理的好处和风险</title>
      <link>https://arxiv.org/abs/2411.16690</link>
      <description><![CDATA[arXiv:2411.16690v1 公告类型：交叉 
摘要：ChatGPT3.5 发布后，因其能够生成有关编码的专业问题的答案而震惊了软件工程界。许多教育工作者立即想知道是否有可能将聊天机器人用作帮助学生回答编程问题的支持工具。本文从三个层面评估了这种可能性：基础计算机科学知识（基本算法和数据结构）、核心能力（设计模式）和高级知识（量子计算）。在每种情况下，我们都会向 ChatGPT3.5 提出几次规范化的问题，然后查看答案的正确性，最后检查是否会产生问题。主要结果是，随着领域的专业化程度的提高，ChatGPT3.5 的性能急剧下降：对于基本算法，它返回的答案几乎总是正确的，对于设计模式，生成的代码包含许多代码异味并且通常质量较差，但有时仍然能够修复它（如果被要求的话），而对于量子计算，它通常是明显的错误。]]></description>
      <guid>https://arxiv.org/abs/2411.16690</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GENzyme 进行反应调节的从头酶设计</title>
      <link>https://arxiv.org/abs/2411.16694</link>
      <description><![CDATA[arXiv:2411.16694v1 公告类型：交叉 
摘要：RFDiffusionAA、AlphaFold3、AlphaProteo 和 Chai1 等模型的引入彻底改变了蛋白质结构建模和相互作用预测，主要从结合角度来看，专注于创建理想的锁和钥匙模型。然而，这些方法对于酶-底物相互作用可能不够，因为完美的结合模型很少见，而诱导契合状态更常见。为了解决这个问题，我们转向酶设计的功能视角，其中酶功能由其催化的反应定义。在这里，我们引入了 \textsc{GENzyme}，这是一种 \textit{de novo} 酶设计模型，它将催化反应作为输入并生成催化口袋、完整酶结构和酶-底物结合复合物。 \textsc{GENzyme} 是一个端到端的三阶段模型，集成了 (1) 催化口袋生成和序列协同设计模块、(2) 口袋修复和酶逆折叠模块，以及 (3) 结合和筛选模块，用于优化和预测酶-底物复合物。整个设计过程由目标催化反应驱动。这种反应优先方法可以实现更准确、更具有生物相关性的酶设计，在创建能够催化特定反应的酶方面可能超越基于结构和结合的模型。我们在 https://github.com/WillHua127/GENzyme 提供 \textsc{GENzyme} 代码。]]></description>
      <guid>https://arxiv.org/abs/2411.16694</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强电力系统仿真的 LLM：反馈驱动的多智能体框架</title>
      <link>https://arxiv.org/abs/2411.16707</link>
      <description><![CDATA[arXiv:2411.16707v1 公告类型：交叉 
摘要：实验技术与大型语言模型 (LLM) 的结合正在改变科学研究，将 AI 定位为多功能研究助手，而不仅仅是解决问题的工具。然而，在电力系统领域，管理模拟——一项必不可少的实验技术——对于 LLM 来说仍然是一个挑战，因为它们的领域特定知识有限、推理能力受限以及对模拟参数的处理不精确。为了解决这些限制，我们提出了一个反馈驱动的多代理框架，该框架包含三个提议的模块：增强检索增强生成 (RAG) 模块、改进的推理模块和具有错误反馈机制的动态环境代理模块。该框架在 Daline 和 MATPOWER 的 69 个不同任务上进行了验证，成功率分别达到 93.13% 和 96.85%，显著优于最新的 LLM（ChatGPT 4o 和 o1-preview），后者在标准模拟任务上的成功率为 27.77%，在复杂任务上的成功率为 0%。此外，我们的框架还支持快速、经济高效的任务执行，每次模拟大约在 30 秒内完成，平均代币成本为 0.014 美元。总体而言，这个适应性强的框架为开发基于 LLM 的智能助手奠定了基础，供人类研究人员使用，促进电力系统研究及其他研究。]]></description>
      <guid>https://arxiv.org/abs/2411.16707</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用形式化验证对文本转视频模型进行神经符号评估</title>
      <link>https://arxiv.org/abs/2411.16718</link>
      <description><![CDATA[arXiv:2411.16718v1 公告类型：交叉 
摘要：Sora、Gen-3、MovieGen 和 CogVideoX 等文本到视频模型的最新进展正在突破合成视频生成的界限，并在机器人、自动驾驶和娱乐等领域得到应用。随着这些模型的普及，出现了各种指标和基准来评估生成的视频的质量。然而，这些指标强调视觉质量和流畅度，忽略了时间保真度和文本到视频对齐，而这对于安全关键型应用至关重要。为了解决这一差距，我们引入了 NeuS-V，这是一种新颖的合成视频评估指标，它使用神经符号形式验证技术严格评估文本到视频的对齐。我们的方法首先将提示转换为正式定义的时间逻辑 (TL) 规范，并将生成的视频转换为自动机表示。然后，它通过根据 TL 规范正式检查视频自动机来评估文本到视频的对齐。此外，我们提供了一个时间扩展提示的数据集，以根据我们的基准评估最先进的视频生成模型。我们发现，与现有指标相比，NeuS-V 与人工评估的相关性高出 5 倍以上。我们的评估进一步表明，当前的视频生成模型在这些时间复杂的提示上表现不佳，这凸显了未来需要改进文本到视频的生成能力。]]></description>
      <guid>https://arxiv.org/abs/2411.16718</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>避免危害：一种保护视觉语言模型免遭越狱的自适应方法</title>
      <link>https://arxiv.org/abs/2411.16721</link>
      <description><![CDATA[arXiv:2411.16721v1 公告类型：交叉 
摘要：视觉语言模型 (VLM) 在受到对抗性攻击时会产生意外和有害的内容，特别是因为它们的视觉功能会产生新的漏洞。现有的防御措施，例如输入预处理、对抗性训练和基于响应评估的方法，由于成本高昂，通常不适合实际部署。为了应对这一挑战，我们提出了 ASTRA，这是一种高效且有效的防御措施，它通过自适应地引导模型远离对抗性特征方向来抵御 VLM 攻击。我们的关键程序包括找到代表有害响应方向的可转移转向向量，并应用自适应激活转向在推理时消除这些方向。为了创建有效的转向向量，我们随机从对抗性图像中消融视觉标记，并识别与越狱最密切相关的标记。然后使用这些标记来构建转向向量。在推理过程中，我们执行自适应转向方法，该方法涉及转向向量和校准激活之间的投影，从而导致良性输入的性能下降很小，同时在对抗性输入下强烈避免有害输出。跨多个模型和基线的大量实验证明了我们在减轻越狱风险方面的最先进性能和高效率。此外，ASTRA 表现出良好的可迁移性，既能防御设计时看不见的攻击（即基于结构化的攻击），也能防御来自不同分布的对抗性图像。]]></description>
      <guid>https://arxiv.org/abs/2411.16721</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三个臭皮匠顶个诸葛亮：人机交互的协作式 LLM 实体代理</title>
      <link>https://arxiv.org/abs/2411.16723</link>
      <description><![CDATA[arXiv:2411.16723v1 公告类型：交叉 
摘要：随着自然语言生成模型（称为大型语言模型 (LLM)）的最新发展，一个潜在的用例已经打开，可以改善人类与机器人助手的交互方式。这些 LLM 应该能够利用其广泛的理解将自然语言命令解释为有效、适合任务和安全的机器人任务执行。然而，实际上，这些模型存在幻觉，这可能会导致安全问题或偏离任务。在其他领域，这些问题已经通过使用协作 AI 系统得到改善，其中多个 LLM 代理可以协同工作以共同规划、编码和自我检查输出。在这项研究中，针对单个独立 AI 代理测试了多个协作 AI 系统，以确定其他领域的成功是否会转化为人机交互性能的提高。结果表明，代理数量与模型成功之间没有明确的趋势。然而，很明显一些协作式人工智能代理架构可以表现出大大提高的生成无错误代码和解决抽象问题的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.16723</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EmotiveTalk：通过音频信息解耦和情感视频传播生成富有表现力的说话头部</title>
      <link>https://arxiv.org/abs/2411.16726</link>
      <description><![CDATA[arXiv:2411.16726v1 公告类型：交叉 
摘要：扩散模型彻底改变了说话头部生成领域，但在长时间生成中仍然面临表现力、可控性和稳定性方面的挑战。在本研究中，我们提出了一个 EmotiveTalk 框架来解决这些问题。首先，为了更好地控制唇部运动和面部表情的生成，设计了一种视觉引导音频信息解耦 (V-AID) 方法来生成与唇部运动和表情一致的基于音频的解耦表示。具体而言，为了实现音频和面部表情表示空间之间的对齐，我们在 V-AID 中提出了一个基于扩散的共语音时间扩展 (Di-CTE) 模块，以在多源情绪条件约束下生成与表情相关的表示。然后，我们提出了一个精心设计的情绪头部扩散 (ETHD) 主干，以高效生成富有表现力的头部视频，其中包含一个表情解耦注入 (EDI) 模块，可自动将表情与参考肖像解耦，同时整合目标表情信息，实现更具表现力的生成性能。实验结果表明，EmotiveTalk 可以生成富有表现力的头部视频，确保承诺的情绪可控性和长时间生成过程中的稳定性，与现有方法相比取得了最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2411.16726</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最大限度地发挥深度学习对亚季节至季节气候预报的影响：优化的重要作用</title>
      <link>https://arxiv.org/abs/2411.16728</link>
      <description><![CDATA[arXiv:2411.16728v1 公告类型：交叉 
摘要：天气和气候预报对于农业和灾害管理等部门至关重要。尽管数值天气预报 (NWP) 系统已经取得了进展，但由于此间隔内的大气信号混乱且稀疏，跨度为 2 至 6 周的亚季节到季节 (S2S) 尺度的预报仍然具有挑战性。即使是最先进的深度学习模型也难以超越该领域的简单气候学模型。本文指出，优化而不是网络结构可能是造成这种性能差距的根本原因，然后我们开发了一种新颖的多阶段优化策略来缩小差距。大量的实证研究表明，我们的多阶段优化方法在使用相同主干结构的同时显着提高了关键技能指标 PCC 和 TCC，超越了最先进的 NWP 系统 (ECMWF-S2S) 超过 \textbf{19-91\%}。我们的研究反驳了最近的一项研究，即在 S2S 任务中直接预测优于滚动预测。通过理论分析，我们提出滚动预测表现不佳可能是由于训练过程中雅可比矩阵乘积的积累所致。我们的多阶段框架可以看作是解决这个问题的一种教师强制形式。代码可在 \url{https://anonymous.4open.science/r/Baguan-S2S-23E7/} 获得]]></description>
      <guid>https://arxiv.org/abs/2411.16728</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiM-Gestor：使用自适应层规范化 Mamba-2 生成语音手势</title>
      <link>https://arxiv.org/abs/2411.16729</link>
      <description><![CDATA[arXiv:2411.16729v1 公告类型：交叉 
摘要：使用基于 Transformer 的生成模型进行语音驱动的手势生成是虚拟人类创造中一个快速发展的领域。然而，现有模型由于其二次时间和空间复杂性而面临重大挑战，限制了可扩展性和效率。为了解决这些限制，我们引入了 DiM-Gestor，这是一种利用 Mamba-2 架构的创新端到端生成模型。DiM-Gestor 具有双组件框架：（1）模糊特征提取器和（2）语音到手势映射模块，均基于 Mamba-2 构建。模糊特征提取器与中文预训练模型和 Mamba-2 集成，可自主提取隐式、连续的语音特征。这些特征被合成为统一的潜在表示，然后由语音到手势映射模块进行处理。该模块采用自适应层规范化 (AdaLN) 增强型 Mamba-2 机制，在所有序列标记上统一应用转换。这可以精确建模语音特征和手势动态之间的细微相互作用。我们利用扩散模型来训练和推断各种手势输出。对新发布的中文同声传译手势数据集进行的大量主观和客观评估证实了我们提出的模型的有效性。与基于 Transformer 的架构相比，评估表明我们的方法提供了具有竞争力的结果，并显着降低了内存使用量（约 2.4 倍），并将推理速度提高了 2 到 4 倍。此外，我们发布了 CCG 数据集，这是一个中文同声传译手势数据集，包含 15.97 小时（五种场景中的六种风格）的中国专业电视广播员表演的 3D 全身骨架手势动作。]]></description>
      <guid>https://arxiv.org/abs/2411.16729</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“道德化”多步骤越狱提示：大型语言模型中针对口头攻击的护栏黑盒测试</title>
      <link>https://arxiv.org/abs/2411.16730</link>
      <description><![CDATA[arXiv:2411.16730v1 Announce Type: cross 
摘要：随着大型语言模型在各个领域的应用不断拓展，对识别有害内容生成和护栏机制的有效性提出了更高的挑战。本研究旨在通过对看似道德的提示模拟进行黑盒测试，评估护栏在面对多步骤越狱提示生成的言语攻击时的有效性。实验对象选取了GPT-4o、Grok-2 Beta、Llama 3.1 (405B)、Gemini 1.5和Claude 3.5 Sonnet。研究者通过设计“企业中层管理者竞相晋升”的场景，使用同样的多步骤提示模拟道德攻击，并观察模型在每一步的响应。实验过程中，上述模型的护栏在本实验中均被绕过，生成言语攻击的内容。数据结果显示，Claude 3.5 Sonnet 在识别越狱提示倾向性方面表现优于其他模型。研究者希望借此提醒开发者和未来的研究，护栏不仅不宜充当内容过滤器的角色，还应具备预防功能。为了保证实验的客观性和普适性，研究者已将实验过程、黑盒测试代码以及​​增强护栏代码上传至 GitHub，以促进开发社区的合作：https://github.com/brucewang123456789/GeniusTrail.git。]]></description>
      <guid>https://arxiv.org/abs/2411.16730</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChemSafetyBench：对化学领域的法学硕士安全性进行基准测试</title>
      <link>https://arxiv.org/abs/2411.16736</link>
      <description><![CDATA[arXiv:2411.16736v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的进步和广泛应用令人瞩目，包括它们在科学研究援助中的应用。然而，这些模型通常会产生科学上不正确或不安全的响应，在某些情况下，它们可能会鼓励用户从事危险行为。为了解决化学领域的这个问题，我们引入了 ChemSafetyBench，这是一个旨在评估 LLM 响应准确性和安全性的基准。ChemSafetyBench 包含三个关键任务：查询化学性质、评估化学用途的合法性以及描述合成方法，每个任务都需要越来越深入的化学知识。我们的数据集包含各种化学材料的 30K 多个样本。我们结合手工制作的模板和高级越狱场景来增强任务多样性。我们的自动评估框架全面评估了 LLM 响应的安全性、准确性和适当性。对最先进的 LLM 进行的大量实验揭示了显着的优势和关键的漏洞，强调了采取强有力的安全措施的必要性。 ChemSafetyBench 旨在成为开发更安全的化学 AI 技术的关键工具。我们的代码和数据集可在 https://github.com/HaochenZhao/SafeAgent4Chem 上找到。警告：本文包含使用 AI 模型合成受控化学品的讨论。]]></description>
      <guid>https://arxiv.org/abs/2411.16736</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>吸引力盆地内的无分类器引导可能会导致记忆</title>
      <link>https://arxiv.org/abs/2411.16738</link>
      <description><![CDATA[arXiv:2411.16738v1 公告类型：交叉 
摘要：扩散模型倾向于精确地从训练数据中重现图像。这种对训练数据的精确复制令人担忧，因为它可能导致侵犯版权和/或泄露隐私敏感信息。在本文中，我们提出了一种理解记忆现象的新方法，并提出了一种简单而有效的方法来缓解它。我们认为记忆的发生是因为去噪过程中的吸引盆地将扩散轨迹引向记忆图像。然而，这可以通过引导扩散轨迹远离吸引盆地来缓解，即不应用无分类器引导，直到出现应用无分类器引导的理想过渡点。这导致生成图像质量高且与调节机制一致非记忆图像。为了进一步改进这一点，我们提出了一种新的引导技术，\emph{相反引导}，它可以在去噪过程中更快地逃离吸引盆地。我们证明了在发生记忆的各种场景中吸引盆地的存在，并且我们表明我们提出的方法成功地减轻了记忆。]]></description>
      <guid>https://arxiv.org/abs/2411.16738</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>