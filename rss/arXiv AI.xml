<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于雷达手势感应的可解释规则系统：增强人工智能的透明度和个性化</title>
      <link>https://arxiv.org/abs/2410.12806</link>
      <description><![CDATA[arXiv:2410.12806v1 公告类型：新
摘要：在安全和信任至关重要的领域，人工智能 (AI) 对有效且可解释的模型的需求日益增长。在这项研究中，我们介绍了 MIRA，这是一种透明且可解释的多类规则算法，专为基于雷达的手势检测而设计。MIRA 满足了对可理解 AI 的关键需求，通过提供对其决策过程的洞察来增强用户信任。我们通过个性化规则集展示系统的适应性，这些规则集可根据个人用户行为进行校准，提供以用户为中心的 AI 体验。除了展示一种新颖的多类分类架构外，我们还通过比较分析分享了一个广泛的调频连续波雷达手势数据集和我们系统卓越可解释性的证据。我们的研究强调了 MIRA 提供高可解释性和性能的能力，并强调了在安全关键应用中更广泛采用可解释 AI 的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.12806</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IMAS：农村医疗保健服务的综合代理方法</title>
      <link>https://arxiv.org/abs/2410.12868</link>
      <description><![CDATA[arXiv:2410.12868v1 公告类型：新 
摘要：自 COVID-19 爆发以来，由于经验丰富的医疗专业人员迁移到城市中心，世界各地的农村社区在获得医疗保健方面面临重大挑战。半训练有素的护理人员，例如社区卫生工作者 (CHW) 和注册执业医师 (RMP)，已经介入填补这一空白，但往往缺乏正规培训。本文提出了一种先进的代理医疗助理系统，旨在通过利用大型语言模型 (LLM) 和代理方法改善农村地区的医疗保健服务。该系统由五个关键组件组成：翻译、医疗复杂性评估、专家网络集成、最终医疗建议生成和响应简化。我们的创新框架确保了上下文敏感、适应性强和可靠的医疗援助，能够进行临床分类、诊断和识别需要专家干预的病例。该系统旨在处理文化细微差别和不同的识字水平，以当地语言提供清晰且可操作的医疗建议。使用 MedQA、PubMedQA 和 JAMA 数据集的评估结果表明，这种综合方法显著提高了农村医护人员的效率，使医疗服务不足的人群更容易获得和理解医疗保健。与本文和 IMAS 相关的所有代码和补充材料均可在 https://github.com/uheal/imas 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.12868</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIND：面向法学硕士预培训的数学综合对话</title>
      <link>https://arxiv.org/abs/2410.12881</link>
      <description><![CDATA[arXiv:2410.12881v1 公告类型：新
摘要：合成数据在提高预训练数据质量从而提高下游任务准确性方面的效用在最近的大型语言模型 (LLM) 中得到了广泛探索。然而，这些方法在复杂、多跳和数学推理任务中不足，因为合成数据通常无法为现有的原始语料库添加补充知识。在这项工作中，我们提出了一种新颖的大规模和多样化的数学信息合成对话 (MIND) 生成方法，以提高 LLM 的数学推理能力。具体来说，使用 MIND，我们基于 OpenWebMath (OWM) 生成合成对话，从而产生了一个新的数学语料库 MIND-OWM。我们对不同对话设置的实验表明，结合对话参与者之间的知识差距对于生成高质量的数学数据至关重要。我们进一步确定了一种在预训练期间格式化和整合合成数据和原始数据的有效方法，以最大限度地提高数学推理能力，强调需要重新构造原始数据，而不是按原样使用。与仅使用原始数据进行预训练相比，在 MIND-OWM 上进行预训练的模型在数学推理方面表现出显著提升（GSM8K：+13.42%，MATH：+2.30%），包括在专业知识（MMLU：+4.55%，MMLU-STEM：+4.28%）和通用推理任务（GENERAL REASONING：+2.51%）方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2410.12881</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为挖掘对象知识的工具</title>
      <link>https://arxiv.org/abs/2410.12959</link>
      <description><![CDATA[arXiv:2410.12959v1 公告类型：新
摘要：常识知识对于机器推理世界至关重要。大型语言模型 (LLM) 已证明其能够执行几乎像人类一样的文本生成。尽管取得了成功，但它们仍不足以成为值得信赖的智能系统，因为它们的答案基础不透明，并且在被问及晦涩难懂的实体或技术领域时倾向于捏造事实。然而，我们假设它们对日常世界中物体的一般知识在很大程度上是合理的。基于这一假设，本文研究了 LLM 形成有关常见物理制品的明确知识的能力，重点关注它们的部件和材料。我们的工作区分了构成整个物体的物质和构成其部件的物质$\unicode{x2014}$这是知识库构建中以前未被充分探索的区别。我们使用包含五个上下文示例的少样本和零样本多步骤提示，生成了约 2,300 个对象及其子类型的零件和材料数据存储库。我们的评估证明了 LLM 在提取知识方面的覆盖范围和可靠性。这种对知识挖掘的贡献应该对 AI 研究关于对象结构和成分的推理有用，并可作为执行多跳问答的 LLM 的显性知识来源（类似于知识图谱）。]]></description>
      <guid>https://arxiv.org/abs/2410.12959</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习推理表征：跨不同结构进行概括</title>
      <link>https://arxiv.org/abs/2410.13018</link>
      <description><![CDATA[arXiv:2410.13018v1 公告类型：新
摘要：推理，即从现有知识中逻辑地得出结论的能力，是人类的标志。它们与感知一起构成了人工智能的两大主题。虽然深度学习已经将感知的极限推向了人类水平的表现之外，但推理领域的进展却远远落后。一个根本原因是推理问题通常对知识和查询都有灵活的结构，许多现有模型仅在训练期间看到的结构上表现良好。在这里，我们旨在通过设计跨知识和查询结构泛化的算法以及加速结构化数据开发的系统来突破推理模型的界限。这篇论文由三部分组成。在第一部分中，我们研究了可以归纳推广到具有新实体和关系词汇的看不见的知识图谱的模型。对于新实体，我们提出了一个框架，该框架在计算路径表示的动态规划算法中学习神经算子。对于关系，我们构建一个关系图来捕获关系之间的交互，从而将新关系转换为新实体。在第二部分中，我们分别提出了两种解决方案，用于在知识图谱和文本上泛化多步骤查询。对于知识图谱，我们表明多步骤查询可以通过多次调用图神经网络和模糊逻辑运算来解决。对于文本，我们设计了一种算法，将显性知识作为文本规则进行学习，以改进多步骤查询的大型语言模型。在第三部分中，我们提出了两个系统来促进结构化数据的机器学习开发。我们的库将结构化数据视为一等公民，并消除了在结构化数据上开发算法的障碍。我们的节点嵌入系统解决了嵌入矩阵的 GPU 内存瓶颈，并扩展到具有十亿个节点的图。]]></description>
      <guid>https://arxiv.org/abs/2410.13018</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士中的电路假设检验</title>
      <link>https://arxiv.org/abs/2410.13032</link>
      <description><![CDATA[arXiv:2410.13032v1 公告类型：新
摘要：大型语言模型 (LLM) 展示了令人惊讶的能力，但我们不了解它们是如何实现的。一种假设表明，这些能力主要由 LLM 内的小型子网络（称为电路）执行。但我们如何评估这个假设呢？在本文中，我们形式化了一组假设电路满足的标准，并开发了一套假设检验来评估电路满足这些标准的程度。这些标准侧重于 LLM 行为的保留程度、这种行为的局部化程度以及电路是否最小。我们将这些测试应用于研究文献中描述的六个电路。我们发现合成电路（模型中硬编码的电路）与理想化的属性一致。在 Transformer 模型中发现的电路在不同程度上满足标准。为了方便将来对电路进行实证研究，我们创建了 \textit{circuitry} 包，它是 \textit{TransformerLens} 库的包装器，它抽象了钩子和激活的低级操作。该软件可在 \url{https://github.com/blei-lab/circuitry} 上获取。]]></description>
      <guid>https://arxiv.org/abs/2410.13032</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率电路的最优传输</title>
      <link>https://arxiv.org/abs/2410.13061</link>
      <description><![CDATA[arXiv:2410.13061v1 公告类型：新
摘要：我们引入了一种用于概率电路 (PC) 的新型最优传输框架。虽然最近已经证明，可以计算表示为某些类别的 PC 的分布之间的差异，但据我们所知，目前还没有计算 PC 给出的概率分布之间的 Wasserstein 距离的方法。我们考虑一种 Wasserstein 型距离，它将相关最优传输问题的耦合度量限制为概率电路。然后，我们通过求解一系列小的线性程序来开发一种计算该距离的算法，并推导出可处理的电路条件。此外，我们表明我们还可以从这些线性规划问题的解中检索 PC 之间的最优传输计划。然后，我们考虑 PC 和数据集之间的经验 Wasserstein 距离，并表明我们可以通过有效的迭代算法估计 PC 参数以最小化该距离。]]></description>
      <guid>https://arxiv.org/abs/2410.13061</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型作为符号机器：通过结构主义和后结构主义语言理论重新概念化人工智能语言系统</title>
      <link>https://arxiv.org/abs/2410.13065</link>
      <description><![CDATA[arXiv:2410.13065v1 公告类型：新
摘要：本文提出了一种理解大型语言模型 (LLM) 的新框架，将其重新概念化为符号机器，而不是人类认知的模仿。借鉴结构主义和后结构主义语言理论（特别是费迪南德·德·索绪尔和雅克·德里达的作品），我认为 LLM 应该被理解为语言本身的模型，与德里达的“写作”概念（l&#39;ecriture）保持一致。本文分为三个部分。首先，我通过解释 word2vec 嵌入算法如何在索绪尔的语言框架内作为符号的关系系统运行来奠定理论基础。其次，我运用德里达对索绪尔的批评将“写作”定位为 LLM 建模的对象，将机器的“思维”视为符号行为的统计近似值。最后，第三部分探讨了现代法学硕士如何反映后结构主义的不固定意义概念，并认为“下一代标记生成”机制有效地捕捉了意义的动态性质。通过将法学硕士重新概念化为符号机器而不是认知模型，该框架提供了一种评估法学硕士优势和局限性的替代视角，为未来的研究提供了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2410.13065</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思想链：通过 LLM 代理革新新创意开发研究</title>
      <link>https://arxiv.org/abs/2410.13185</link>
      <description><![CDATA[arXiv:2410.13185v1 公告类型：新
摘要：有效的研究构思是科学研究的关键步骤。然而，科学文献的急剧增加使得研究人员很难跟上最新进展并确定有意义的研究方向。大型语言模型（LLM）的最新发展为自动生成新颖的研究想法提供了一种有希望的途径。然而，现有的创意生成方法要么轻而易举地提示 LLM，要么直接将 LLM 暴露于大量文献中而没有提供有用的信息。受人类研究人员的研究过程的启发，我们提出了一个基于 LLM 的创意链（CoI）代理，它将相关文献组织成链式结构，以有效地反映研究领域的进步发展。这种组织有助于 LLM 捕捉当前研究的进展，从而增强他们的创意能力。此外，我们提出了 Idea Arena，这是一种评估协议，可以从不同角度全面评估创意生成方法，与人类研究人员的偏好紧密结合。实验结果表明，CoI 代理始终优于其他方法，并且在研究创意生成方面表现出与人类相当的质量。此外，我们的 CoI 代理价格低廉，最低成本为 \0.50 美元即可生成候选创意及其相应的实验设计。]]></description>
      <guid>https://arxiv.org/abs/2410.13185</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文增强的多视图轨迹表征学习：通过自监督模型弥合差距</title>
      <link>https://arxiv.org/abs/2410.13196</link>
      <description><![CDATA[arXiv:2410.13196v1 公告类型：新
摘要：使用通用密集表示对轨迹数据进行建模已成为各种下游应用的流行范例，例如轨迹分类、行程时间估计和相似性计算。然而，现有方法通常依赖于单一空间视图中的轨迹，限制了它们捕获丰富上下文信息的能力，而这些信息对于深入了解不同地理空间环境中的运动模式至关重要。为此，我们提出了 MVTraj，一种用于轨迹表示学习的新型多视图建模方法。MVTraj 整合了从 GPS 到道路网络和兴趣点的各种上下文知识，以提供对轨迹数据的更全面理解。为了使学习过程在多个视图之间保持一致，我们利用 GPS 轨迹作为桥梁，并采用自监督借口任务来捕获和区分不同空间视图中的运动模式。随后，我们将不同视角的轨迹视为不同的模态，并应用分层跨模态交互模块来融合这些表示，从而丰富来自多个来源的知识。对现实世界数据集的大量实验表明，MVTraj 在与各种空间视图相关的任务中的表现明显优于现有基线，从而验证了其在时空建模中的有效性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2410.13196</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMOPT：从头开始学习定义和解决一般优化问题</title>
      <link>https://arxiv.org/abs/2410.13213</link>
      <description><![CDATA[arXiv:2410.13213v1 公告类型：新
摘要：优化问题普遍存在于各种场景中。制定并解决用自然语言描述的优化问题通常需要高度专业的人类专业知识，这可能会阻碍基于优化的决策的广泛应用。为了使问题制定和解决自动化，利用大型语言模型 (LLM) 已成为一种潜在的方法。然而，这种方法存在优化泛化的问题。也就是说，目前大多数基于 LLM 的方法的准确性和它们可以建模的优化问题类型的通用性仍然有限。在本文中，我们提出了一个统一的基于学习的框架 LLMOPT 来促进优化泛化。从优化问题的自然语言描述和预先训练的 LLM 开始，LLMOPT 构建了引入的五元素公式作为学习定义各种优化问题类型的通用模型。然后，LLMOPT 采用多指令调优来增强问题形式化和求解器代码生成的准确性和通用性。之后，为了防止 LLM 中的幻觉，例如牺牲求解精度来避免执行错误，LLMOPT 采用了模型对齐和自校正机制。我们评估了 LLMOPT 的优化泛化能力，并在六个真实世界数据集上比较了各种方法，这些数据集涵盖了健康、环境、能源和制造业等大约 20 个领域。大量实验结果表明，LLMOPT 能够对各种优化问题类型进行建模，例如线性/非线性规划、混合整数规划和组合优化，并且与最先进的方法相比，平均求解精度显著提高了 11.08%。代码可在 https://github.com/caigaojiang/LLMOPT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.13213</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>锚定对齐以增强自我解释</title>
      <link>https://arxiv.org/abs/2410.13216</link>
      <description><![CDATA[arXiv:2410.13216v1 公告类型：新
摘要：在这项工作中，我们引入了一种对齐方法，旨在增强大型语言模型 (LLM) 即使在没有注释的合理解释的情况下也能表达其推理（自我解释）的能力。我们的对齐方法包括三个关键部分：解释质量评估、自我指导数据集生成和模型对齐。此外，我们提出了一种称为“锚点偏好对对齐”的新技术，该技术通过将模型输出分为三类来改进偏好对的选择：始终正确、始终不正确和可变。通过对每个类别应用量身定制的策略，我们提高了直接偏好优化 (DPO) 的有效性。我们的实验结果表明，与其他微调策略相比，这种方法在保持准确性的同时显着提高了解释质量。]]></description>
      <guid>https://arxiv.org/abs/2410.13216</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于贪婪算法的旅游路线规划问题研究</title>
      <link>https://arxiv.org/abs/2410.13226</link>
      <description><![CDATA[arXiv:2410.13226v1 Announce Type: new 
摘要：基于贪婪算法的路线规划问题是寻找给定起点和终点之间最优或接近最优路线的方法。本文首先利用PCA方法对城市评价指标进行降维，提取关键主成分，利用KMO和TOPSIS算法对数据进行降维。其次，对于未通过KMO检验的数据集，将使用熵权法和TOPSIS法进行综合评价。最后，基于贪婪算法提出并优化了路线规划算法，根据游客的不同需求提供个性化的路线定制。我们还考虑了当地的出行效率、游览旅游景点所需的时间以及必要的每日休息时间，以降低成本并避免陷入局部最优解。]]></description>
      <guid>https://arxiv.org/abs/2410.13226</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于无监督知识图谱对齐的简化且可学习的图卷积注意力网络</title>
      <link>https://arxiv.org/abs/2410.13263</link>
      <description><![CDATA[arXiv:2410.13263v1 公告类型：新
摘要：当前实体对齐（EA）任务的成功很大程度上取决于标记数据提供的监督信息。考虑到标记数据的成本，大多数监督方法难以应用于实际场景。因此，越来越多基于对比学习、主动学习或其他深度学习技术的工作被开发出来，以解决标记数据不足造成的性能瓶颈。然而，现有的无监督 EA 方法仍然存在一些局限性，要么建模复杂度高，要么无法平衡对齐的有效性和实用性。为了克服这些问题，我们提出了一种简化和可学习的图卷积注意网络，用于无监督知识图谱对齐方法（SLU）。具体而言，我们首先引入一个新的简单框架 LCAT 作为主干网络来建模两个 KG 的图结构。然后设计一种基于潜在匹配关系的关系结构重构方法，高效过滤对齐实体的无效邻域信息，提高SLU的易用性和可扩展性。令人印象深刻的是，提出了一种基于一致性的相似度函数，可以更好地度量候选实体对的相似性。最后，我们在三个不同规模（15K和100K）和不同类型的数据集（跨语言和单语）上进行了广泛的实验，验证了SLU的优越性。实验结果表明，SLU显著提高了对齐准确率，优于25种有监督或无监督方法，最佳情况下的Hits@1比最佳基线提高了6.4%。]]></description>
      <guid>https://arxiv.org/abs/2410.13263</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过摘要引导解码减轻大型视觉语言模型中的幻觉</title>
      <link>https://arxiv.org/abs/2410.13321</link>
      <description><![CDATA[arXiv:2410.13321v1 公告类型：新
摘要：大型视觉语言模型 (LVLM) 表现出令人印象深刻的能力，能够从视觉输入生成详细且连贯的响应。然而，由于过度依赖语言先验，它们容易产生幻觉。为了解决这个问题，我们研究了 LVLM 中的语言先验，并做出了两个关键观察：(1) 即使在预测与图像相关的词性 (POS) 相关的标记时，随着标记序列的增长，模型也越来越依赖语言先验，从而放大幻觉。(2) 直接校准 LVLM 的输出分布以减轻语言先验的方法可能会导致文本质量下降甚至加剧幻觉。基于这些发现，我们提出了一种新方法，即摘要引导解码 (SGD)。该方法通过摘要减少文本上下文，自然而然地鼓励模型更多地关注图像信息，同时仅控制与图像相关的 POS 标记以保持文本质量。通过实验，我们证明了 SGD 在对象幻觉基准上实现了最先进的性能。此外，在准确率和召回率之间的权衡方面，SGD 在现有方法中实现了帕累托最优。最后，我们观察到，尽管现有方法难以在减少对象幻觉与保持文本质量之间取得平衡，但 SGD 在应对这一挑战方面表现出了稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.13321</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指令驱动的游戏引擎：扑克案例研究</title>
      <link>https://arxiv.org/abs/2410.13441</link>
      <description><![CDATA[arXiv:2410.13441v1 公告类型：新
摘要：指令驱动游戏引擎 (IDGE) 项目旨在通过使大型语言模型 (LLM) 遵循自由形式的游戏描述并生成游戏过程来实现游戏开发的民主化。IDGE 允许用户仅通过自然语言指令创建游戏，这大大降低了游戏开发的门槛。我们将 IDGE 的学习过程作为下一状态预测任务，其中模型根据玩家动作自回归预测游戏状态。游戏状态的计算必须精确；否则，轻微的错误可能会破坏游戏体验。由于稳定性和多样性之间的差距，这具有挑战性。为了解决这个问题，我们以课程方式训练 IDGE，逐步增加其在复杂场景中的曝光率。我们最初的进展在于开发扑克 IDGE，它不仅支持广泛的扑克变体，还允许通过自然语言输入实现高度个性化的新扑克游戏。这项工作为未来改变游戏的创建和玩法奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.13441</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MeNTi：通过嵌套工具调用桥接医学计算器和 LLM 代理</title>
      <link>https://arxiv.org/abs/2410.13610</link>
      <description><![CDATA[arXiv:2410.13610v1 公告类型：新
摘要：将工具集成到大型语言模型（LLM）中促进了其广泛应用。尽管如此，在专门的下游任务环境中，仅依靠工具不足以完全解决现实世界的复杂性。这尤其限制了 LLM 在医学等领域的有效部署。在本文中，我们专注于医疗计算器的下游任务，该任务使用标准化测试来评估个人的健康状况。我们介绍了一种用于 LLM 的通用代理架构 MeNTi。MeNTi 集成了专门的医疗工具包，并使用元工具和嵌套调用机制来提高 LLM 工具的利用率。具体而言，它实现了灵活的工具选择和嵌套工具调用，以解决复杂医疗场景中面临的实际问题，包括计算器选择、槽填充和单位转换。为了评估 LLM 在计算器场景的整个临床过程中进行定量评估的能力，我们引入了 CalcQA。该基准测试要求 LLM 使用医学计算器进行计算并评估患者的健康状况。CalcQA 由专业医生构建，包含 100 个病例计算器对，并辅以 281 个医学工具工具包。实验结果表明，我们的框架显著提高了性能。这项研究为 LLM 在医学苛刻场景中的应用开辟了新的方向。]]></description>
      <guid>https://arxiv.org/abs/2410.13610</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>维基数据中的不相交性违规</title>
      <link>https://arxiv.org/abs/2410.13707</link>
      <description><![CDATA[arXiv:2410.13707v1 公告类型：新
摘要：不相交性检查是知识库中最重要的约束检查之一，可用于帮助检测和纠正不正确的陈述和内部矛盾。Wikidata 是一个非常庞大的社区管理知识库。由于其规模和结构，Wikidata 包含许多不正确的陈述和内部矛盾。我们分析了 Wikidata 上当前的不相交性建模，确定了导致这些不相交性违规的模式并对其进行分类。我们使用 SPARQL 查询来识别导致不相交性违规的每个“罪魁祸首”，并制定公式来识别和修复冲突信息。我们最后讨论了如何在 Wikidata 中更好地建模和扩展不相交信息。]]></description>
      <guid>https://arxiv.org/abs/2410.13707</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MixEval-X：基于真实世界数据混合的任意评估</title>
      <link>https://arxiv.org/abs/2410.13754</link>
      <description><![CDATA[arXiv:2410.13754v1 公告类型：新
摘要：感知和生成多种模态对于 AI 模型有效地从现实世界信号中学习和参与至关重要，因此需要对它们的开发进行可靠的评估。我们发现当前评估中存在两个主要问题：（1）标准不一致，由具有不同协议和成熟度级别的不同社区塑造；（2）查询、评分和泛化偏差显著。为了解决这些问题，我们引入了 MixEval-X，这是第一个任意对任意现实世界基准，旨在优化和标准化输入和输出模态的评估。我们提出了多模态基准混合和自适应校正管道来重建现实世界的任务分布，确保评估有效地推广到现实世界的用例。广泛的元评估表明，我们的方法有效地将基准样本与现实世界的任务分布对齐，并且模型排名与众包现实世界评估的排名高度相关（高达 0.98）。我们提供全面的排行榜来重新排名现有的模型和组织，并提供见解以增进对多模式评估的理解并为未来的研究提供信息。]]></description>
      <guid>https://arxiv.org/abs/2410.13754</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 引导的协同进化：改进多智能体对抗游戏中的团队组建</title>
      <link>https://arxiv.org/abs/2410.13769</link>
      <description><![CDATA[arXiv:2410.13769v1 公告类型：新
摘要：我们考虑多智能体对抗游戏中的团队组建问题。我们提出了一种新颖的算法 BERTeam，它使用基于 Transformer 的深度神经网络和掩码语言模型训练从训练有素的群体中选择最佳玩家团队。我们将其与共同进化深度强化学习相结合，后者训练了一组多样化的个体玩家来选择团队。我们在多智能体对抗游戏 Marine Capture-The-Flag 中测试了我们的算法，我们发现 BERTeam 学习了非平凡的团队组成，在与看不见的对手对抗时表现良好。对于这款游戏，我们发现 BERTeam 的表现优于 MCAA，后者是一种同样优化团队组建的算法。]]></description>
      <guid>https://arxiv.org/abs/2410.13769</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>