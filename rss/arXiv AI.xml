<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 21 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>对话式医疗 AI：准备投入实践</title>
      <link>https://arxiv.org/abs/2411.12808</link>
      <description><![CDATA[arXiv:2411.12808v1 公告类型：新
摘要：医生短缺导致医疗专业知识的获取受到严重限制。虽然对话式人工智能 (AI) 有望解决这一问题，但在现实世界的医疗环境中，其在面向患者的角色中的安全部署仍未得到充分探索。我们首次在现实世界的医疗环境中对医生监督的 LLM 对话代理进行了大规模评估。
我们的代理 Mo 被集成到现有的医疗建议聊天服务中。在三周的时间里，我们对 926 个病例进行了随机对照实验，以评估患者的体验和满意度。其中，Mo 处理了 298 次完整的患者互动，我们报告了医生评估的安全性和医疗准确性指标。
与标准护理相比，患者报告的 AI 辅助对话信息清晰度更高（3.73 vs 3.62 分（满分 4 分），p &lt; 0.05），总体满意度更高（4.58 vs 4.42 分（满分 5 分），p &lt; 0.05），同时表现出同等水平的信任度和感知同理心。高选择率（受访者中为 81%）超过了人工智能在医疗保健领域接受度的先前基准。医生监督确保了安全，有经验运营医疗咨询聊天服务的全科医生将 95% 的对话评为“良好”或“优秀”。
我们的研究结果表明，精心实施的 AI 医疗助理可以增强患者体验，同时通过医生监督保持安全标准。这项工作为人工智能在医疗保健沟通中的部署可行性提供了实证证据，并深入了解了成功融入现有医疗保健服务的要求。]]></description>
      <guid>https://arxiv.org/abs/2411.12808</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>声明与证明：人工智能评估中的明确假设对于有效监管是必要的</title>
      <link>https://arxiv.org/abs/2411.12820</link>
      <description><![CDATA[arXiv:2411.12820v1 公告类型：新
摘要：随着人工智能系统的进步，人工智能评估正成为确保安全法规的重要支柱。我们认为，这种法规应该要求开发人员明确识别和证明评估的关键基本假设，作为其安全案例的一部分。我们确定了人工智能评估中的核心假设（用于评估现有模型和预测未来模型），例如全面的威胁建模、代理任务有效性和充分的能力引出。其中许多假设目前无法得到很好的证明。如果监管要以评估为基础，那么如果评估显示出不可接受的危险或这些假设没有得到充分证明，就应该要求停止人工智能开发。我们提出的方法旨在提高人工智能开发的透明度，为更有效地治理先进的人工智能系统提供一条切实可行的道路。]]></description>
      <guid>https://arxiv.org/abs/2411.12820</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络系统中信任与人工智能的博弈论共生</title>
      <link>https://arxiv.org/abs/2411.12859</link>
      <description><![CDATA[arXiv:2411.12859v1 公告类型：新
摘要：本章探讨了人工智能 (AI) 与网络系统中信任之间的共生关系，重点关注这两个要素如何在战略网络安全环境中相互加强。人工智能在数据处理、学习和实时响应方面的能力为管理动态复杂网络中的信任提供了前所未有的支持。然而，人工智能的成功整合也取决于人工智能系统本身的可信度。本章使用博弈论框架，介绍了信任评估方法、人工智能在网络安全中的战略作用以及确保负责任的人工智能部署的治理框架。我们研究了当通过人工智能动态管理信任时，信任如何形成一个有弹性的安全生态系统。通过将信任视为人工智能的输出和人工智能的要求，本章为正反馈循环奠定了基础，其中人工智能增强了网络安全，而对人工智能系统的信任促进了它们的采用。]]></description>
      <guid>https://arxiv.org/abs/2411.12859</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KAAE：通过知识感知属性学习进行知识图谱的数值推理</title>
      <link>https://arxiv.org/abs/2411.12950</link>
      <description><![CDATA[arXiv:2411.12950v1 公告类型：新
摘要：数值推理在各种人工智能应用中都至关重要，例如自然语言处理和推荐系统，其中涉及使用实体、关系和属性值（例如，重量、长度）来推断新的事实关系（例如，尼罗河比亚马逊河长）。然而，现有的方法在建模中遇到两个关键挑战：（1）语义相关性 - 无法充分捕捉实体、关系和数值属性之间必要的上下文交互，通常导致推理不理想；（2）语义模糊性 - 难以准确区分数值推理过程中的序数关系，这会损害高质量样本的生成并限制对比学习的有效性。为了应对这些挑战，我们提出了一种新颖的知识感知属性嵌入模型（KAAE），用于数值推理中的知识图谱嵌入。具体来说，为了克服语义相关性的挑战，我们引入了混合专家知识感知 (MoEKA) 编码器，旨在将实体、关系和数值属性的语义集成到联合语义空间中。为了解决语义歧义问题，我们实施了一种新的序数知识对比学习 (OKCL) 策略，该策略借助序数关系从原始数据中生成高质量的序数样本，捕捉精确数值推理所必需的细粒度语义细微差别。在三个公共基准数据集上进行的实验证明了 KAAE 在各种属性值分布中的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2411.12950</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电动汽车实时能量最优路径规划</title>
      <link>https://arxiv.org/abs/2411.12964</link>
      <description><![CDATA[arXiv:2411.12964v1 公告类型：新 
摘要：电动汽车 (EV) 在现代交通系统中的迅速普及使得能量感知路由成为其成功整合的关键任务，尤其是在大型网络中。在电动汽车剩余能量有限且充电地点不易到达的情况下，某些目的地可能只能通过能量最优路径到达：该路径消耗的能量比所有其他替代方案都要少。这种节能路径的可行性在很大程度上取决于用于规划的能量模型的准确性，因此未能考虑车辆动力学可能导致能量估计不准确，从而导致某些计划路线在现实中不可行。本文探讨了车辆动力学对电动汽车能量最优路径规划的影响。我们开发了一个精确的能量模型，将关键的车辆动力学参数纳入能量计算中，从而降低了在电池限制下规划不可行路径的风险。本文还介绍了两种新颖的在线重新加权函数，它们可以在再生制动导致负能量成本的情况下实现更快、无需预处理的路径查找，使其成为实时应用的理想选择。通过在现实世界的交通网络上进行大量实验，我们证明了我们的方法在计算效率和能量估计准确性方面大大提高了电动汽车的能量最优路径查找。]]></description>
      <guid>https://arxiv.org/abs/2411.12964</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MindForge：利用心智理论为实体代理提供终身协作学习的能力</title>
      <link>https://arxiv.org/abs/2411.12977</link>
      <description><![CDATA[arXiv:2411.12977v1 公告类型：新
摘要：当代具身代理，例如 Minecraft 中的 Voyager，已在开放式个人学习中展现出良好的能力。然而，当使用开放式大型语言模型 (LLM) 时，这些代理通常会在基本任务上遇到困难，即使在对特定领域知识进行微调时也是如此。受人类文化学习的启发，我们提出了 \collabvoyager，这是一个新颖的框架，它通过明确的视角来增强 Voyager 的终身协作学习。 \collabvoyager 引入了三个关键创新：(1) 将感知、信念、愿望和行动联系起来的心理表征理论；(2) 代理之间的自然语言交流；(3) 任务和环境知识的语义记忆以及协作情节的情景记忆。这些进步使代理能够推理自己和他人的心理状态，从经验上解决了两种普遍存在的失败模式：错误信念和错误的任务执行。在混合专业知识的 Minecraft 实验中，\collabvoyager 代理的表现优于 Voyager 代理，收集一块泥土的任务完成率显著提高 $66.6\% (+39.4\%)$，收集一块木块的任务完成率显著提高 $70.8\% (+20.8\%)$。它们表现出新兴行为，例如从专家到新手代理的知识转移和协作代码更正。\collabvoyager 代理还展示了利用通过协作获得的先前经验和信念来适应分布外任务的能力。在这个开放式的社会学习范式中，\collabvoyager 为具身人工智能的民主发展铺平了道路，代理在部署过程中从同伴和环境反馈中学习。]]></description>
      <guid>https://arxiv.org/abs/2411.12977</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BetterBench：评估 AI 基准、发现问题并建立最佳实践</title>
      <link>https://arxiv.org/abs/2411.12990</link>
      <description><![CDATA[arXiv:2411.12990v1 公告类型：新
摘要：人工智能模型在高风险环境中越来越普遍，需要对其能力和风险进行彻底评估。基准测试通常用于衡量这些属性以及比较模型性能、跟踪进度以及识别基础和非基础模型中的弱点。它们可以为下游任务的模型选择提供信息并影响政策举措。然而，并非所有基准测试都是一样的：它们的质量取决于它们的设计和可用性。在本文中，我们开发了一个评估框架，考虑了人工智能基准测试生命周期中的 46 种最佳实践，并根据它评估了 24 个人工智能基准测试。我们发现存在很大的质量差异，常用的基准测试存在重大问题。我们进一步发现，大多数基准测试没有报告其结果的统计意义，也不允许轻易复制其结果。为了支持基准测试开发人员与最佳实践保持一致，我们根据我们的评估提供了最低质量保证清单。我们还开发了一个基准评估动态存储库来支持基准可比性，可通过 betterbench.stanford.edu 访问。]]></description>
      <guid>https://arxiv.org/abs/2411.12990</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>部分可观察马尔可夫决策过程的可解释有限内存策略</title>
      <link>https://arxiv.org/abs/2411.13365</link>
      <description><![CDATA[arXiv:2411.13365v1 公告类型：新
摘要：部分可观测马尔可夫决策过程 (POMDP) 是在不确定和部分可观测性下进行决策的基本框架。由于一般来说，最佳策略可能需要无限内存，因此它们很难实现，并且经常导致大多数问题无法判定。因此，人们大多考虑有限内存策略。然而，计算它们的算法通常非常复杂，由此产生的策略也是如此。面对对它们可解释性的需求，我们提供了此类策略的表示，(i) 以可解释的形式化，(ii) 通常尺寸较小，共同产生更高的可解释性。为此，我们结合了 Mealy 机和决策树的模型；后者描述策略的简单、固定部分，前者描述如何在它们之间切换。我们设计了标准文献中有限状态控制器 (FSC) 形式的策略的翻译，并展示了我们的方法如何顺利推广到有限内存策略的其他变体。此外，我们确定了最近使用的“基于吸引子的”策略的特定属性，这使我们能够构建更简单、更小的表示。最后，我们在几个案例研究中说明了更高的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2411.13365</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AdaptAgent：通过从人类演示中进行的小样本学习来适应多模式 Web 代理</title>
      <link>https://arxiv.org/abs/2411.13451</link>
      <description><![CDATA[arXiv:2411.13451v1 公告类型：新
摘要：由多模态大型语言模型 (MLLM) 提供支持的最先进的多模态 Web 代理可以通过处理用户指令和与图形用户界面 (GUI) 交互来自主执行许多 Web 任务。当前构建 Web 代理的策略依赖于 (i) 底层 MLLM 的通用性及其通过提示的可操纵性，以及 (ii) 对 Web 相关任务的 MLLM 进行大规模微调。然而，Web 代理仍然难以在看不见的网站和域上自动执行任务，从而限制了它们在企业特定和专有平台上的适用性。除了从大规模预训练和微调中进行泛化之外，我们还建议使用人工演示构建具有少量适应性的代理。我们引入了 AdaptAgent 框架，该框架使专有和开放权重的多模态 Web 代理能够使用少量人工演示（最多 2 次）适应新网站和域。我们在两个流行基准测试（Mind2Web 和 VisualWebArena）上进行的实验表明，使用上下文演示（针对专有模型）或元适应演示（针对元学习开放权重模型）可将任务成功率提高 3.36% 至 7.21%，而未适应的最先进的模型则相对提高了 21.03% 至 65.75%。此外，我们的附加分析（a）显示了多模态演示相对于纯文本演示的有效性，（b）揭示了元学习过程中不同数据选择策略对代理泛化的影响，以及（c）展示了少量样本示例数量对 Web 代理成功率的影响。总体而言，我们的结果为开发广泛适用的多模态 Web 代理开辟了一条互补轴，超越了大规模预训练和微调，强调了少量样本适应性。]]></description>
      <guid>https://arxiv.org/abs/2411.13451</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BALROG：对游戏上的 Agentic LLM 和 VLM 推理进行基准测试</title>
      <link>https://arxiv.org/abs/2411.13543</link>
      <description><![CDATA[arXiv:2411.13543v1 公告类型：新
摘要：大型语言模型 (LLM) 和视觉语言模型 (VLM) 拥有广泛的知识并表现出良好的推理能力；然而，它们在复杂、动态的环境中仍然难以表现良好。现实世界的任务需要处理复杂的交互、高级空间推理、长期规划和不断探索新策略——在这些领域，我们缺乏全面评估这些能力的有效方法。为了解决这一差距，我们引入了 BALROG，这是一种新颖的基准，旨在通过一系列具有挑战性的游戏来评估 LLM 和 VLM 的代理能力。我们的基准结合了一系列现有的不同难度级别的强化学习环境，包括非专家可以在几秒钟内解决的任务到可能需要数年才能掌握的极具挑战性的任务（例如，NetHack 学习环境）。我们设计了细粒度的指标来衡量性能，并对几种流行的开源和闭源 LLM 和 VLM 进行了广泛的评估。我们的研究结果表明，尽管目前的模型在较简单的游戏中取得了部分成功，但它们在更具挑战性的任务中却举步维艰。值得注意的是，我们观察到基于视觉的决策存在严重缺陷，因为当提供环境的视觉表示时，模型的表现会更差。我们发布 BALROG 作为开放且用户友好的基准，以促进代理社区未来的研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2411.13543</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SpatialDreamer：基于单目输入的自监督立体视频合成</title>
      <link>https://arxiv.org/abs/2411.11934</link>
      <description><![CDATA[arXiv:2411.11934v1 公告类型：交叉 
摘要：从单目输入合成立体视频是空间计算和虚拟现实领域的一项艰巨任务。这项任务的主要挑战在于缺乏用于训练的高质量配对立体视频以及难以保持帧之间的时空一致性。现有方法主要通过将新颖的视图合成 (NVS) 技术直接应用于视频来解决这些问题，同时面临着无法有效表示动态场景和需要大量训练数据等限制。在本文中，我们通过视频扩散模型引入了一种新颖的自监督立体视频合成范式，称为 SpatialDreamer，它正面应对了挑战。首先，为了解决立体视频数据不足的问题，我们提出了一个基于深度的视频生成模块 DVG，它采用前向后向渲染机制来生成具有几何和时间先验的配对视频。利用 DVG 生成的数据，我们提出了 RefinerNet 以及一个自监督合成框架，旨在促进高效而专注的训练。更重要的是，我们设计了一个一致性控制模块，该模块由立体偏差强度度量和时间交互学习模块 TIL 组成，分别用于确保几何和时间一致性。我们根据各种基准方法对所提出的方法进行了评估，结果显示了其卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.11934</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强化学习在金融应用中的回顾</title>
      <link>https://arxiv.org/abs/2411.12746</link>
      <description><![CDATA[arXiv:2411.12746v1 公告类型：交叉 
摘要：近年来，强化学习 (RL) 在金融应用中的应用趋势日益增长。
这种方法在解决金融决策任务方面显示出巨大的潜力。
在本次调查中，我们对 RL 在金融中的应用进行了全面的研究，并进行了一系列元分析，以调查文献中的共同主题，例如与传统方法相比，对 RL 性能影响最大的因素。
此外，我们确定了包括可解释性、马尔可夫决策过程 (MDP) 建模和稳健性在内的挑战，这些挑战阻碍了 RL 在金融行业的更广泛应用，并讨论了克服这些挑战的最新进展。
最后，我们提出了未来的研究方向，例如基准测试、上下文 RL、多智能体 RL 和基于模型的 RL，以应对这些挑战并进一步加强 RL 在金融中的实施。]]></description>
      <guid>https://arxiv.org/abs/2411.12746</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>金融人工智能调查：架构、进展和开放挑战</title>
      <link>https://arxiv.org/abs/2411.12747</link>
      <description><![CDATA[arXiv:2411.12747v1 公告类型：交叉 
摘要：金融人工智能为金融市场预测、投资组合优化和自动交易提供了复杂的方法。本调查从三个主要维度对这些发展进行了系统分析：捕捉复杂市场动态的预测模型、优化交易和投资策略的决策框架以及利用非结构化财务信息的知识增强系统。我们研究了重大创新，包括金融时间序列的基础模型、基于图形的市场关系建模架构和投资组合优化的分层框架。分析揭示了模型复杂性和实际约束之间的关键权衡，特别是在高频交易应用中。我们确定了理论进步与工业实施之间的关键差距和未解决的挑战，概述了提高模型性能和实际适用性的未解决的挑战和机遇。]]></description>
      <guid>https://arxiv.org/abs/2411.12747</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedCL-Ensemble Learning：一种联合持续学习框架，结合集成迁移学习，增强阿尔茨海默氏症 MRI 分类，同时保护隐私</title>
      <link>https://arxiv.org/abs/2411.12756</link>
      <description><![CDATA[arXiv:2411.12756v1 公告类型：交叉 
摘要：本研究工作介绍了一种利用先进的深度学习技术结合安全数据处理方法对阿尔茨海默病进行分类的新方法。本研究工作主要使用迁移学习模型（如 ResNet、ImageNet 和 VNet）从医学图像数据中提取高级特征。此后，这些预先训练的模型针对阿尔茨海默氏症相关的细微模式进行了微调，使得该模型能够对不同的数据源进行稳健的特征提取。此外，还结合了联邦学习方法来应对与分类相关的一些其他挑战，旨在提供更好的预测性能并保护数据隐私。所提出的模型是使用联邦学习构建的，无需共享敏感的患者数据。这样，分散式模型就可以从其训练的大型多样化数据集中受益，同时确保机密性。添加了基于密码的加密机制，使我们能够确保数据传输的安全，并进一步确保整个训练和分类过程中患者信息的隐私和完整性。实验结果不仅有助于提高阿尔茨海默病分类的准确性，同时还为医疗数据的安全和协作分析提供了一个框架。]]></description>
      <guid>https://arxiv.org/abs/2411.12756</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索量化对 StarCoder2 能耗和推理时间的影响</title>
      <link>https://arxiv.org/abs/2411.12758</link>
      <description><![CDATA[arXiv:2411.12758v1 公告类型：交叉 
摘要：本研究考察了量化和修剪策略，以减少代码大型语言模型 (LLM) 推理中的能耗。使用 StarCoder2，我们观察到由于吞吐量较低和一些准确性损失，量化带来的能源需求增加。相反，修剪减少了能源使用，但损害了性能。结果突出了 LLM 模型压缩中的挑战和权衡。我们建议未来研究硬件优化量化，以提高效率，同时将准确性损失降至最低。]]></description>
      <guid>https://arxiv.org/abs/2411.12758</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型辅助因果发现中消除幻觉的新方法</title>
      <link>https://arxiv.org/abs/2411.12759</link>
      <description><![CDATA[arXiv:2411.12759v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在因果发现中越来越多地被用来替代人类领域专家，这凸显了对最佳模型选择的需求。本文首次对流行的因果发现 LLM 进行了幻觉调查。我们表明，在因果发现中使用 LLM 时会出现幻觉，因此 LLM 的选择很重要。我们建议在有高质量数据可用时使用检索增强生成 (RAG) 来减少幻觉。此外，我们介绍了一种新方法，该方法在辩论中使用多个 LLM 和一个仲裁者来审核因果图中的边缘，从而实现与 RAG 相当的幻觉减少。]]></description>
      <guid>https://arxiv.org/abs/2411.12759</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能赋能人类研究，融合脑科学和社会科学见解</title>
      <link>https://arxiv.org/abs/2411.12761</link>
      <description><![CDATA[arXiv:2411.12761v1 公告类型：交叉 
摘要：本文探讨了人工智能（AI）在增强科学研究方面的变革性作用，特别是在脑科学和社会科学领域。我们分析了人类研究的基本方面，并认为现在是研究人员转向人机联合研究的时候了。在此基础上，我们提出了两种创新的人机联合研究研究范式：“AI-脑科学研究范式”和“AI-社会科学研究范式”。在这些范式中，我们介绍了三种人机协作模型：AI作为研究工具（ART），AI作为研究助手（ARA）和AI作为研究参与者（ARP）。此外，我们概述了进行人机联合研究的方法。本文旨在重新定义人类研究人员与AI系统之间的协作互动，为未来的研究方向奠定基础，并激发这一跨学科领域的创新。]]></description>
      <guid>https://arxiv.org/abs/2411.12761</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士玩语言游戏导致越狱</title>
      <link>https://arxiv.org/abs/2411.12762</link>
      <description><![CDATA[arXiv:2411.12762v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的出现刺激了众多越狱技术的发展，旨在绕过其针对恶意攻击的安全防御。一种有效的越狱方法是确定安全泛化失败的领域，这种现象称为不匹配泛化。在本文中，我们介绍了两种基于不匹配泛化的新型越狱方法：自然语言游戏和自定义语言游戏，这两种方法都能有效绕过 LLM 的安全机制，种类繁多，变体各异，使其难以防御并导致高攻击率。自然语言游戏涉及使用合成语言结构以及与这些结构交织在一起的动作，例如 Ubbi Dubbi 语言。基于这一现象，我们提出了自定义语言游戏方法：通过使用各种自定义规则与 LLM 互动，我们成功地在多个 LLM 平台上执行越狱攻击。大量实验证明了我们方法的有效性，在 GPT-4o 上的成功率为 93%，在 GPT-4o-mini 上的成功率为 89%，在 Claude-3.5-Sonnet 上的成功率为 83%。此外，为了研究安全对齐的可推广性，我们使用自定义语言游戏对 Llama-3.1-70B 进行了微调，以在我们的数据集中实现安全对齐，并发现当通过其他语言游戏进行交互时，微调后的模型仍然无法识别有害内容。这一发现表明，LLM 中嵌入的安全对齐知识无法推广到不同的语言格式，从而为该领域的未来研究开辟了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2411.12762</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能时代的教育</title>
      <link>https://arxiv.org/abs/2411.12763</link>
      <description><![CDATA[arXiv:2411.12763v1 公告类型：交叉 
摘要：随着神经符号人工智能 (NAI) 的出现，教育即将发生变革，这将重新定义我们如何支持深度自适应和个性化的学习体验。基于 NAI 的教育系统将能够解释复杂的人类概念和背景，同时采用先进的问题解决策略，所有这些都以既定的教学框架为基础。这将使学习系统实现迄今为止在规模上基本上无法实现的个性化水平，提供适合个人学习速度和可访问性需求的精细定制课程，包括对学生对科目的理解进行细粒度诊断，识别基础知识的差距，并相应地调整教学。在本文中，我们提出了一个系统，该系统利用教学代理的独特功能——旨在增强学习的具体角色——作为混合 NAI 架构的关键组件。为此，这些代理可以模拟细致入微的讨论、辩论和解决问题的练习，推动学习者超越死记硬背，走向深度理解。我们讨论了系统设计的理由和我们工作的初步结果。我们得出结论，NAI 时代的教育将使学习更加容易获得、更加公平，并与现实世界的技能保持一致。这是一个探索教育工具新深度理解的时代。]]></description>
      <guid>https://arxiv.org/abs/2411.12763</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEFD：用于检测 LLM 生成文本的语义增强框架</title>
      <link>https://arxiv.org/abs/2411.12764</link>
      <description><![CDATA[arXiv:2411.12764v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的广泛采用迫切需要强大的工具来检测 LLM 生成的文本，尤其是考虑到 \textit{释义} 技术通常会逃避现有的检测方法。为了应对这一挑战，我们提出了一种用于检测 LLM 生成的文本 (SEFD) 的新型语义增强框架，该框架利用基于检索的机制来充分利用文本语义。我们的框架通过系统地将基于检索的技术与传统检测器相结合，改进了现有的检测方法，采用了精心策划的检索机制，在全面覆盖和计算效率之间取得了平衡。我们展示了我们的方法在现实世界应用中常见的顺序文本场景中的有效性，例如在线论坛和问答平台。通过对各种 LLM 生成的文本和检测方法进行全面的实验，我们证明我们的框架在解释场景中显著提高了检测准确性，同时保持了标准 LLM 生成内容的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2411.12764</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>