<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 05 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>不确定环境中的元推理：元 BAMDP 框架</title>
      <link>https://arxiv.org/abs/2408.01253</link>
      <description><![CDATA[arXiv:2408.01253v1 公告类型：新
摘要：在决策场景中，\textit{推理} 可以被视为一种算法 $P$，该算法选择动作 $a^* \in \mathcal{A}$，旨在优化某些结果，例如最大化马尔可夫决策过程 (MDP) 的价值函数。然而，执行 $P$ 本身可能会产生一些成本（时间、精力、有限能力等），需要与在底层决策问题中做出选择所获得的明确效用一起考虑。为了准确地模拟人类行为以及优化人工智能规划，需要考虑这些成本，因为所有物理系统都必然面临资源限制。找到正确的 $P$ 本身可以构建为推理过程空间 $P$ 上的优化问题，通常称为 \textit{元推理}。传统上，人类元推理模型假设代理知道底层 MDP 的转换和奖励分布。本文通过提出一个元贝叶斯自适应 MDP (meta-BAMDP) 框架来处理奖励/转换分布未知的环境中元推理，从而概括了此类模型，该框架涵盖了人类和人工智能系统面临的更大、更现实的规划问题。作为第一步，我们将该框架应用于双臂伯努利老虎机 (TABB) 任务，该任务经常用于研究人类决策。由于元问题的复杂性，我们的解决方案必然是近似的，但在一系列对于人类决策场景来说可以说是现实的假设范围内仍然是稳健的。这些结果为理解认知约束下的人类探索提供了一个规范框架。贝叶斯自适应策略与元推理的结合丰富了决策研究的理论前景和在设计不确定性和资源约束下进行规划的人工智能系统的实际应用。]]></description>
      <guid>https://arxiv.org/abs/2408.01253</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:32 GMT</pubDate>
    </item>
    <item>
      <title>用于自主系统优化的多目标深度强化学习</title>
      <link>https://arxiv.org/abs/2408.01188</link>
      <description><![CDATA[arXiv:2408.01188v1 公告类型：新
摘要：强化学习 (RL) 广泛应用于自主系统 (AS)，因为它可以在运行时进行学习，而无需环境模型或预定义操作。然而，RL 在 AS 中的大多数应用，例如基于 Q 学习的应用，只能优化一个目标，因此在多目标系统中，有必要将多个目标组合在一个具有预定义权重的目标函数中。存在许多多目标强化学习 (MORL) 技术，但它们大多应用于 RL 基准测试，而不是现实世界的 AS 系统。在这项工作中，我们使用一种称为深度 W 学习 (DWN) 的 MORL 技术，并将其应用于 Emergent Web Servers 示例（一种自适应服务器），以找到运行时性能优化的最佳配置。我们将 DWN 与两个单目标优化实现进行比较：{\epsilon}-greedy 算法和深度 Q 网络。我们的初步评估表明，DWN 可以同时优化多个目标，其结果与 DQN 和 {\epsilon}-greedy 方法相似，并且在某些指标上具有更好的性能，并且避免了将多个目标组合成单个效用函数所带来的问题。]]></description>
      <guid>https://arxiv.org/abs/2408.01188</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:31 GMT</pubDate>
    </item>
    <item>
      <title>通过噪声门贝叶斯网络进行基于评分标准的学习者建模，以评估计算思维技能</title>
      <link>https://arxiv.org/abs/2408.01221</link>
      <description><![CDATA[arXiv:2408.01221v1 公告类型：新
摘要：在现代个性化教育中，人们越来越关注培养学习者的能力并对其进行准确评估。在之前的研究中，我们提出了一种从特定于任务的能力评估标准中推导出用于自动技能评估的学习者模型的程序，从而简化了自动评估工具的实施。然而，以前的方法有两个主要限制：（i）评估标准定义的能力之间的排序仅是间接建模的；（ii）模型中不包括未接受评估但完成任务所必需的补充技能。在这项工作中，我们通过引入虚拟观察节点来解决问题（i），严格执行技能排序而不改变网络结构。相反，对于点（ii），我们设计了一个具有两层门的网络，一层通过噪声或门执行分离运算，另一层通过逻辑与执行连接运算。这些变化提高了模型结果的一致性和建模工具的灵活性，同时又不损害模型的紧凑参数化、可解释性和简单的专家引出。我们使用这种方法开发了一个用于计算思维 (CT) 技能评估的学习者模型。CT-cube 技能评估框架和交叉阵列任务 (CAT) 用于举例说明并证明其可行性。]]></description>
      <guid>https://arxiv.org/abs/2408.01221</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:31 GMT</pubDate>
    </item>
    <item>
      <title>剖析不和谐：根据自相矛盾的指令对大型多模态模型进行基准测试</title>
      <link>https://arxiv.org/abs/2408.01091</link>
      <description><![CDATA[arXiv:2408.01091v1 公告类型：新
摘要：大型多模态模型 (LMM) 在遵循人类指令方面表现出色。然而，由于多模态交互和上下文长度的增加趋势，可能会出现自相矛盾的指令，这对语言初学者和弱势群体来说是一个挑战。我们引入了自相矛盾指令基准来评估 LMM 识别冲突命令的能力。它包含 20,000 个冲突，均匀分布在语言和视觉范式之间。它由一个新颖的自动数据集创建框架构建，该框架加快了流程并使我们能够涵盖广泛的指令形式。我们的全面评估表明，由于缺乏自我意识，当前的 LMM 始终难以识别多模态指令不一致。因此，我们提出了认知觉醒提示，以从外部注入认知，大大增强了不和谐检测。数据集和代码在这里：https://selfcontradiction.github.io/。]]></description>
      <guid>https://arxiv.org/abs/2408.01091</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:30 GMT</pubDate>
    </item>
    <item>
      <title>负责任才是明智之举：了解基于人工智能的电网服务的技术和监管环境</title>
      <link>https://arxiv.org/abs/2408.01121</link>
      <description><![CDATA[arXiv:2408.01121v1 公告类型：新
摘要：人工智能的出现和电网的数字化为智能电网的基于人工智能的服务引入了许多有效的应用场景。然而，由于法规不明确和缺乏风险量化技术，在关键基础设施中采用人工智能面临挑战。将基于人工智能的服务集成到智能电网的受监管和负责任的方法可以加速在日常实践中采用创新方法并解决社会普遍的安全问题。本文通过定义问责制并强调其对能源部门基于人工智能的服务的重要性，为实现这一目标做出了贡献。它强调了《人工智能法案》目前的缺点，并提出了一种在潜在的授权法案中解决这些问题的方法。提出的开发和运营负责任的基于人工智能的智能电网服务的技术方法允许评估不同的服务生命周期阶段并识别相关的问责风险。]]></description>
      <guid>https://arxiv.org/abs/2408.01121</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:30 GMT</pubDate>
    </item>
    <item>
      <title>使用公理谱重要性分解解释图像模型的全局扰动鲁棒性</title>
      <link>https://arxiv.org/abs/2408.01139</link>
      <description><![CDATA[arXiv:2408.01139v1 公告类型：新
摘要：扰动鲁棒性评估模型的脆弱性，这些脆弱性源于各种扰动，例如数据损坏和对抗性攻击。了解扰动鲁棒性的机制对于全局可解释性至关重要。我们提出了一种与模型无关的全局机械可解释性方法来解释图像模型的扰动鲁棒性。这项研究的动机有两个关键方面。首先，以前的全局可解释性工作与鲁棒性基准（例如平均损坏误差（mCE））相结合，并非旨在直接解释图像模型中的扰动鲁棒性机制。其次，我们注意到扰动自然图像的光谱信噪比（SNR）随频率呈指数衰减。这种幂律衰减意味着：低频信号通常比高频信号更稳健——但仅靠低频信号无法实现高分类精度。通过应用 Shapley 值理论，我们的方法在信息理论框架内公理化地量化了稳健特征和非稳健特征的预测能力。我们的方法被称为 \textbf{I-ASIDE}（\textbf{I}mage \textbf{A}xiomatic \textbf{S}pectral \textbf{I}mportance \textbf{D}ecomposition \textbf{E}xplanation），它为模型稳健性机制提供了独特的见解。我们对在 ImageNet 上预先训练的各种视觉模型进行了广泛的实验，以表明 \textbf{I-ASIDE} 不仅可以 \textbf{测量} 扰动稳健性，还可以 \textbf{提供对其机制的解释。]]></description>
      <guid>https://arxiv.org/abs/2408.01139</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:30 GMT</pubDate>
    </item>
    <item>
      <title>从头到尾：人工智能价值链上的可竞争性</title>
      <link>https://arxiv.org/abs/2408.01051</link>
      <description><![CDATA[arXiv:2408.01051v1 公告类型：新
摘要：本次研讨会将发展和巩固一个跨学科 CSCW 研究人员社区，重点关注可竞争人工智能主题。作为研讨会的成果，我们将以研究路线图的形式综合人工智能价值链上可竞争性最紧迫的机遇和挑战。该路线图将有助于塑造和激励该领域的紧迫工作。考虑到人工智能价值链的长度和深度，它将特别激发围绕此类链各个站点的人工智能系统可竞争性的讨论。研讨会将作为一个平台，展示（可能或应该）有争议的人工智能系统的具体、成功和不成功的例子，以确定在各种情况下设计和部署可竞争人工智能的要求、障碍和机会。这将主要以面对面研讨会的形式举行，并有一些混合住宿。当天将包括个人演讲和小组活动，以激发创意并激发对可竞争人工智能领域的广泛思考。我们的目标是通过聚集研究人员、从业人员和利益相关者来促进跨学科对话，以促进可竞争人工智能的设计和部署。]]></description>
      <guid>https://arxiv.org/abs/2408.01051</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:29 GMT</pubDate>
    </item>
    <item>
      <title>强化学习中的自我博弈方法综述</title>
      <link>https://arxiv.org/abs/2408.01072</link>
      <description><![CDATA[arXiv:2408.01072v1 公告类型：新
摘要：自我对弈的特点是代理与自身的副本或过去版本的交互，最近在强化学习中引起了人们的关注。本文首先阐明了自我对弈的初步知识，包括多代理强化学习框架和基本博弈论概念。然后，它提供了一个统一的框架，并在该框架内对现有的自我对弈算法进行分类。此外，本文通过说明自我对弈在不同场景中的作用，弥合了算法与其实际意义之间的差距。最后，调查强调了自我对弈中存在的挑战和未来的研究方向。本文是了解强化学习中自我对弈多面格局的重要指南。]]></description>
      <guid>https://arxiv.org/abs/2408.01072</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:29 GMT</pubDate>
    </item>
    <item>
      <title>跨域环境中具体化教学遵循的语义技能基础</title>
      <link>https://arxiv.org/abs/2408.01024</link>
      <description><![CDATA[arXiv:2408.01024v1 公告类型：新
摘要：在具身指令遵循 (EIF) 中，将预训练语言模型 (LM) 集成为任务规划器成为一个重要分支，其中通过使用预训练技能和用户指令提示 LM 来在技能级别规划任务。然而，将这些预训练技能应用到不同领域仍然具有挑战性，因为它们与特定领域的知识错综复杂地纠缠在一起。为了应对这一挑战，我们提出了一个语义技能基础 (SemGro) 框架，该框架利用语义技能的层次性。SemGro 认识到这些技能的广泛范围，从普遍适用于各个领域的短期低语义技能到高度专业化和针对特定领域量身定制的长期丰富语义技能。该框架采用迭代技能分解方法，从语义技能层次结构的较高级别开始，然后向下移动，以便将每个计划技能定位到目标域内的可执行级别。为此，我们使用 LM 的推理能力来组合和分解语义技能，并使用其多模态扩展来评估目标域中的技能可行性。我们在 VirtualHome 基准测试中的实验表明，SemGro 在 300 个跨域 EIF 场景中效果显著。]]></description>
      <guid>https://arxiv.org/abs/2408.01024</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:28 GMT</pubDate>
    </item>
    <item>
      <title>安全约束网格环境中无模型任务适应的安全探索策略</title>
      <link>https://arxiv.org/abs/2408.00997</link>
      <description><![CDATA[arXiv:2408.00997v1 公告类型：新
摘要：训练无模型强化学习代理需要允许代理充分探索环境以寻找最佳策略。在安全受限的环境中，利用无监督探索或非最优策略可能会导致代理处于不良状态，从而导致对代理和环境都可能代价高昂或危险的结果。在本文中，我们介绍了一种用于导航网格环境的新探索框架，使无模型代理能够在遵守安全约束的同时与环境交互。我们的框架包括一个预训练阶段，在此期间，代理学习根据环境中的可观察特征和指定的安全约束来识别潜在的不安全状态。随后，训练二元分类模型来预测表现出类似动态的新环境中的那些不安全状态。这种经过训练的分类器使无模型代理能够确定在哪些情况下采用随机探索或次优策略可能会带来安全风险，在这种情况下，我们的框架会提示代理遵循预定义的安全策略，以减轻潜在的危险后果。我们在三个随机生成的网格环境中评估了我们的框架，并展示了无模型代理如何安全地适应新任务并学习新环境的最佳策略。我们的结果表明，通过定义适当的安全策略并利用训练有素的模型来检测不安全状态，我们的框架使无模型代理能够适应新任务和环境，并且安全违规行为明显减少。]]></description>
      <guid>https://arxiv.org/abs/2408.00997</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:27 GMT</pubDate>
    </item>
    <item>
      <title>Piculet：专门的模型引导幻觉减少多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2408.01003</link>
      <description><![CDATA[arXiv:2408.01003v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 在弥合视觉和语言模态之间的差距方面取得了重大进展。然而，MLLM 中的幻觉，即生成的文本与图像内容不一致，仍然是一个重大挑战。现有的解决幻觉的方法通常依赖于指令调整，这需要使用特定数据重新训练模型，这增加了进一步利用 MLLM 的成本。在本文中，我们介绍了一种名为 Piculet 的新型无训练方法，用于增强 MLLM 的输入表示。Piculet 利用多个专门的模型从输入图像中提取视觉信息的描述，并将这些描述与原始图像和查询相结合作为 MLLM 的输入。我们从数量和质量上评估了我们的方法，结果表明 Piculet 大大减少了 MLLM 的幻觉。我们的方法可以轻松扩展到不同的 MLLM，同时具有通用性。]]></description>
      <guid>https://arxiv.org/abs/2408.01003</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:27 GMT</pubDate>
    </item>
    <item>
      <title>基于 SAT 的贝叶斯网络严格验证方法</title>
      <link>https://arxiv.org/abs/2408.00986</link>
      <description><![CDATA[arXiv:2408.00986v1 公告类型：新
摘要：机器学习的最新进展加速了其在各种实际应用中的广泛应用。然而，在安全关键领域，机器学习模型的部署充满了挑战，因为它们的复杂性、缺乏可解释性以及缺乏对其行为的正式保证。在本文中，我们介绍了一个针对贝叶斯网络量身定制的验证框架，旨在解决这些缺点。我们的框架包括两个关键组件：（1）将贝叶斯网络转换为布尔逻辑文字的两步编译和编码方案，以及（2）利用这些文字来验证编码为约束的各种属性的形式化验证查询。具体来说，我们引入了两个验证查询：if-then 规则 (ITR) 和特征单调性 (FMO)。我们对验证方案的效率进行了基准测试，并展示了其在现实场景中的实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.00986</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:26 GMT</pubDate>
    </item>
    <item>
      <title>论具有恶意代理的多代理系统的弹性</title>
      <link>https://arxiv.org/abs/2408.00989</link>
      <description><![CDATA[arXiv:2408.00989v1 公告类型：新
摘要：由大型语言模型驱动的多智能体系统由于专家智能体的协作而表现出在各种任务中的强大能力，每个智能体都专注于特定领域。然而，当智能体单独部署时，存在恶意用户引入恶意智能体的风险，这些恶意智能体会产生不正确或不相关的结果，而这些结果过于隐蔽，无法被其他非专业智能体识别。因此，本文研究了两个基本问题：（1）在恶意智能体的作用下，各种多智能体系统结构（例如，A$\rightarrow$B$\rightarrow$C、A$\leftrightarrow$B$\leftrightarrow$C）在不同下游任务上的弹性如何？（2）我们如何提高系统弹性以防御恶意智能体？为了模拟恶意智能体，我们设计了两种方法，AutoTransform 和 AutoInject，将任何智能体转换为恶意智能体，同时保持其功能完整性。我们对四个下游多智能体系统任务进行了全面的实验，即代码生成、数学问题、翻译和文本评估。结果表明，“分层”多智能体结构，即 A$\rightarrow$(B$\leftrightarrow$C)，表现出卓越的弹性，性能下降最低，为 $23.6\%$，而其他两种结构的下降幅度分别为 $46.4\%$ 和 $49.8\%$。此外，我们展示了改善多智能体系统弹性的前景，通过展示两种防御方法，即引入一个额外的智能体来审查和纠正消息或为每个智能体提供挑战其他智能体输出的机制，可以增强系统弹性。我们的代码和数据可在 https://github.com/CUHK-ARISE/MAS-Resilience 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.00989</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:26 GMT</pubDate>
    </item>
    <item>
      <title>授予 GPT-4 许可和机会：增强小样本事件检测的准确性和置信度估计</title>
      <link>https://arxiv.org/abs/2408.00914</link>
      <description><![CDATA[arXiv:2408.00914v1 公告类型：新
摘要：GPT-4 等大型语言模型 (LLM) 在小样本学习环境中显示出足够的前景，建议用于通过迭代应用和审查生成“银”数据和改进新本体。通过可靠的置信度估计，此类工作流程变得更加有效。不幸的是，置信度估计是 GPT-4 等模型的一个已知弱点，而现有的补偿方法需要大量额外的复杂性和计算。本研究探索使用 GPT-4 进行有效置信度估计的方法，并使用小样本学习作为载体，在 BETTER 本体中进行事件检测。关键创新是扩展向 GPT-4 呈现的提示和任务，以提供在不确定时进行推测的许可以及量化和解释其不确定性的机会 (L&amp;O)。这种方法提高了准确性，并提供了可用的置信度测量 (0.759 AUC)，无需额外的机制。]]></description>
      <guid>https://arxiv.org/abs/2408.00914</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:25 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中总体不确定性的概括：一项理论研究</title>
      <link>https://arxiv.org/abs/2408.00946</link>
      <description><![CDATA[arXiv:2408.00946v1 公告类型：新
摘要：人工智能一直在处理不确定性以获得高度准确的结果。当数据集相当小或数据集发生变化时，情况会变得更糟。这对决策、预测和学习机制产生了深远的影响。本研究旨在通过从既定的著作、最新发展和实际应用中汲取思想，揭示人工智能中存在的不确定性的本质，并为人工智能提供新颖的总体不确定性定义。
从初始理论到当前方法，本文提供了处理更好的总体不确定性以及人工智能中不确定性复杂性的综合观点，帮助我们理解其在不同领域的意义和价值。]]></description>
      <guid>https://arxiv.org/abs/2408.00946</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:25 GMT</pubDate>
    </item>
    <item>
      <title>整合 ESG 与 AI：全面、负责任的 AI 评估框架</title>
      <link>https://arxiv.org/abs/2408.00965</link>
      <description><![CDATA[arXiv:2408.00965v1 公告类型：新
摘要：人工智能 (AI) 是一种在整个行业领域广泛开发和采用的技术。将环境、社会和治理 (ESG) 考虑因素与 AI 投资相结合对于确保合乎道德和可持续的技术进步至关重要。特别是从投资者的角度来看，这种整合不仅可以降低风险，还可以通过将 AI 计划与更广泛的社会目标相结合来提高长期价值创造。然而，这一领域在学术界和工业界都探索较少。为了弥补这一差距，我们引入了一个新颖的 ESG-AI 框架，该框架是基于与 28 家公司的合作见解而开发的，包含三个关键组成部分。该框架为这种整合提供了一种结构化的方法，是与行业从业者合作开发的。ESG-AI 框架概述了 AI 应用对环境和社会的影响，帮助投资者等用户评估 AI 使用的重要性。此外，它使投资者能够通过结构化的参与和对特定风险领域的全面评估来评估公司对负责任的 AI 的承诺。我们已于 2024 年 4 月公开发布了该框架和工具包，并得到了投资界的广泛关注和积极反馈。本文详细介绍了该框架的每个组成部分，展示了其在现实世界中的适用性以及指导合乎道德的 AI 投资的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.00965</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:25 GMT</pubDate>
    </item>
    <item>
      <title>UlRe-NeRF：通过神经渲染和超声反射方向参数化实现 3D 超声成像</title>
      <link>https://arxiv.org/abs/2408.00860</link>
      <description><![CDATA[arXiv:2408.00860v1 公告类型：新
摘要：三维超声成像是医学诊断中广泛应用的关键技术。然而，传统的3D超声成像方法存在分辨率固定、存储效率低、上下文连通性不足等限制，导致在处理复杂伪影和反射特性时性能不佳。近年来，基于NeRF（神经辐射场）的技术在视图合成和3D重建方面取得了重大进展，但在高质量超声成像方面仍然存在研究空白。为了解决这些问题，我们提出了一个新模型UlRe-NeRF，它将隐式神经网络和显式超声体积渲染结合到超声神经渲染架构中。该模型结合了反射方向参数化和谐波编码，使用方向MLP模块生成视图相关的高频反射强度估计，使用空间MLP模块生成介质的物理特性参数。这些参数用于体积渲染过程，以准确再现超声波在介质中的传播和反射行为。实验结果表明，UlRe-NeRF模型显著提高了高保真超声图像重建的真实感和准确性，尤其是在处理复杂介质结构时。]]></description>
      <guid>https://arxiv.org/abs/2408.00860</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:24 GMT</pubDate>
    </item>
    <item>
      <title>具有可解释性的时间知识图谱异常在线检测</title>
      <link>https://arxiv.org/abs/2408.00872</link>
      <description><![CDATA[arXiv:2408.00872v1 公告类型：新
摘要：时间知识图谱 (TKG) 是捕捉实体之间不断发展的关系的宝贵资源，但它们经常受到噪音的困扰，因此需要强大的异常检测机制。现有的动态图异常检测方法难以捕捉 TKG 中节点和边缘类别引入的丰富语义，而 TKG 嵌入方法缺乏可解释性，从而破坏了异常检测的可信度。此外，这些方法无法适应知识更新导致的模式变化和语义漂移。为了应对这些挑战，我们引入了 AnoT，这是一种高效的 TKG 汇总方法，专为 TKG 中可解释的在线异常检测而设计。AnoT 首先将 TKG 汇总为一个新的规则图，从而能够灵活地推断 TKG 中的复杂模式。当新知识出现时，AnoT 将其映射到规则图中的一个节点上，并递归遍历规则图以得出知识的异常分数。遍历产生可达节点，这些节点为新知识的有效性或异常提供可解释的证据。总体而言，AnoT 体现了检测器-更新器-监视器架构，包括用于离线 TKG 汇总和在线评分的检测器、基于新知识的实时规则图更新更新器以及用于估计规则图近似误差的监视器。在四个真实数据集上的实验结果表明，AnoT 在准确性和互操作性方面显著超越了现有方法。所有原始数据集和 AnoT 的实现均在 https://github.com/zjs123/ANoT 中提供。]]></description>
      <guid>https://arxiv.org/abs/2408.00872</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:24 GMT</pubDate>
    </item>
    <item>
      <title>Y Social：基于法学硕士的社交媒体数字孪生</title>
      <link>https://arxiv.org/abs/2408.00818</link>
      <description><![CDATA[arXiv:2408.00818v1 公告类型：新
摘要：在本文中，我们介绍了 Y，一种旨在复制在线社交媒体平台的新一代数字孪生。数字孪生是物理系统的虚拟复制品，允许进行高级分析和实验。在社交媒体的情况下，像 Y 这样的数字孪生为研究人员提供了一个强大的工具来模拟和理解复杂的在线互动。{\tt Y} 利用最先进的大型语言模型 (LLM) 来复制复杂的代理行为，从而实现对用户交互、内容传播和网络动态的准确模拟。通过整合这些方面，Y 为用户参与度、信息传播和平台政策的影响提供了宝贵的见解。此外，LLM 的集成使 Y 能够生成细微的文本内容并预测用户响应，从而促进对在线环境中突发现象的研究。
为了更好地描述所提出的数字孪生，本文中我们描述了其实施背后的原理，提供了可以对其生成的数据执行的分析的示例，并讨论了其与多学科研究的相关性。]]></description>
      <guid>https://arxiv.org/abs/2408.00818</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:23 GMT</pubDate>
    </item>
    <item>
      <title>LICM：针对新闻推荐的有效且高效的长兴趣链建模</title>
      <link>https://arxiv.org/abs/2408.00859</link>
      <description><![CDATA[arXiv:2408.00859v1 公告类型：新
摘要：向用户精准推荐个性化的候选新闻文章一直是新闻推荐系统的核心挑战。新闻推荐通常需要对用户兴趣进行建模以匹配候选新闻。最近的努力主要集中在提取局部子图信息，缺乏全面的全局新闻图提取阻碍了相似用户之间协作利用全局新闻信息的能力。为了克服这些限制，我们提出了一种有效且高效的新闻推荐长兴趣链建模（LICM），它将邻居兴趣与基于相似用户协作的全局新闻点击图中提炼的长链兴趣相结合，以增强新闻推荐。对于基于所有用户点击历史的全局新闻图，从中生成的长链兴趣可以更好地利用其中的高维信息，从而提高协作推荐的有效性。因此，我们设计了一个全面的选择机制和兴趣编码器，以从全局图中获得长链兴趣。最后，我们使用门控网络将长链信息与邻居信息相结合以实现最终的用户表示。在真实数据集上的实验结果验证了我们的模型的有效性和效率，可以提高新闻推荐的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.00859</guid>
      <pubDate>Mon, 05 Aug 2024 09:22:23 GMT</pubDate>
    </item>
    </channel>
</rss>