<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过与集成LLM的自适应LMS个性化教育</title>
      <link>https://arxiv.org/abs/2502.08655</link>
      <description><![CDATA[ARXIV：2502.08655V1公告类型：新 
摘要：大型语言模型（LLM）的广泛采用标志着技术的变革时代，尤其是在教育领域内。本文探讨了LLM在学习管理系统（LMS）中的集成，以开发一种适应性学习管理系统（ALMS），以针对各个教育阶段的个体学习者个性化。传统的LMS在促进教育材料的分布时，无法满足不同学生人群的细微差别，尤其是在教师可用性有限的环境中。我们提出的系统利用AI的灵活性提供可自定义的学习环境，以适应每个用户不断发展的需求。通过整合一套通用和域特异性LLM的套件，该系统旨在最大程度地减少常见问题，例如事实上的不准确性和过时的信息，这是Openai的Chatgpt等一般LLM的特征。本文详细介绍了施舍的开发，该施舍不仅解决了现有教育工具的隐私问题和局限性，而且还通过通过个性化的教育内容来维持参与来增强学习经验。]]></description>
      <guid>https://arxiv.org/abs/2502.08655</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高通量SAT采样</title>
      <link>https://arxiv.org/abs/2502.08673</link>
      <description><![CDATA[ARXIV：2502.08673V1公告类型：新 
摘要：在这项工作中，我们提出了一种新型的GPU加速布尔可满足性（SAT）采样的技术。与直接以连词正常形式（CNF）运行的常规抽样算法不同，我们的方法通过将其CNF表示形式考虑到简化的多级，多出的Boolean函数来改变SAT问题的逻辑约束。然后，它利用基于梯度的优化来指导搜索各种有效解决方案。我们的方法直接在重构SAT实例的电路结构上运行，将SAT问题重新解释为监督的多输出回归任务。这种可区分的技术可以在每个张量元素上进行独立的位操作，从而可以并行执行学习过程。结果，我们实现了GPU加速采样，而运行时的大幅提高了$ 33.6 \ times $至523.6美元\ times $，而不是最先进的启发式采样器。我们通过对先前研究中使用的公共领域基准套件的60美元实例进行了广泛的评估，证明了采样方法的出色性能。]]></description>
      <guid>https://arxiv.org/abs/2502.08673</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从PowerPoint UI草图到基于Web的应用程序：使用知识增强的LLM，上下文感知的视觉提示和React框架的GIS仪表板开发的模式驱动的代码生成</title>
      <link>https://arxiv.org/abs/2502.08756</link>
      <description><![CDATA[ARXIV：2502.08756V1公告类型：新 
摘要：开发基于Web的GIS应用程序，通常称为Cyber​​gis仪表板，用于查询和可视化环境研究中的GIS数据通常需要重复和资源密集型的努力。尽管生成AI为代码生成提供了自动化潜力，但由于整合域知识，软件工程原理和UI设计最佳实践的挑战，它在复杂的科学应用中挣扎。本文介绍了一个知识增强的代码生成框架，该框架从专门的知识库中检索软件工程最佳实践，领域专业知识和先进的技术堆栈，以增强生成的预培训预培训的变压器（GPT），以进行前端开发。该框架是从用户定义的UI线框（例如PowerPoint或Adobe Illustrator）中勾勒出的用户定义的UI线框的基于GIS的Web应用程序（例如仪表板，接口）的创建。在Python中实现的一种新颖的上下文感知的视觉提示方法，从这些线框中提取布局和接口功能来指导代码生成。我们的方法利用大型语言模型（LLMS）通过集成结构化推理，软件工程原理和领域知识来生成前端代码，从促使和检索提升生成（RAG）中汲取灵感。一项案例研究表明，该框架能够生成模块化的，可维护的Web平台，该平台托管了多个仪表板，以可视化用户勾勒的线框，可视化环境和能量数据（例如，时间序列，Shapefiles，Shapefiles，rasters）。通过采用知识驱动的方法，该框架使用诸如模型视图 - 视频模型（MVVM）和React等框架等设计模式（例如Model-View-viewModel（MVVM））生成可扩展的行业标准前端代码。这大大减少了设计和编码方面的手动努力，开创了开发智能城市软件的自动化和高效方法。]]></description>
      <guid>https://arxiv.org/abs/2502.08756</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有基于熵的人类反馈的上下文强盗</title>
      <link>https://arxiv.org/abs/2502.08759</link>
      <description><![CDATA[ARXIV：2502.08759V1公告类型：新 
摘要：近年来，基于偏好的人类反馈机制对于增强各种应用程序（包括对话式AI系统（例如ChatGpt））的模型性能已经成为至关重要的。但是，现有方法通常会忽略关键方面，例如模型不确定性和反馈质量的可变性。为了应对这些挑战，我们引入了一个基于熵的人类反馈框架，用于上下文匪徒，该框架仅在模型熵超过预定义的阈值时才通过征求专家反馈来动态平衡探索和剥削。我们的方法是模型不合时宜的，可以与使用随机策略的任何上下文匪徒无缝集成。通过全面的实验，我们表明我们的方法在需要最少的人类反馈的同时，即使在次优质量的条件下也可以实现显着的绩效提高。这项工作不仅提出了反馈招标的新策略，而且还强调了将人类指导纳入机器学习系统的鲁棒性和功效。我们的代码公开可用：https：//github.com/borealisai/cbhf]]></description>
      <guid>https://arxiv.org/abs/2502.08759</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单个模型可以掌握多转交谈和工具的使用吗？镇定：统一的会话媒介语言模型</title>
      <link>https://arxiv.org/abs/2502.08820</link>
      <description><![CDATA[ARXIV：2502.08820V1公告类型：新 
摘要：具有API称呼功能的大型语言模型（LLM）启用了有效的语言代理（LA），同时还彻底改变了传统的面向任务的对话（TOD）范式。但是，当前的方法面临着关键的困境：TOD系统经常受到有限的目标API的培训，在与新服务接口时，需要新数据以保持其质量，而LAS则未接受培训以维持用户对多转向对话的意图。因为强大的多转弯管理和高级功能调用对于有效的对话剂都至关重要，所以我们在三个流行的基准上评估了这些技能：Multiwoz 2.4（TOD），BFCL V3（LA）和API-BANK（LA）以及我们的分析揭示专门的方法在一个领域中表现出色，但在另一个领域表现不佳。为了弥合这种鸿沟，我们引入了平静（对话式语言模型），这是一种统一的方法，既可以整合对话式和代理能力。我们创建了Calm-it，这是一个经过精心构造的多任务数据集，与复杂的API使用相结合，将多转化的反应推理。我们使用CALS-IT训练三种型号平静8B，平静的70B和平静的405B，它们在所有三个基准测试中都超过了包括GPT-4O在内的顶级域特异性型号。]]></description>
      <guid>https://arxiv.org/abs/2502.08820</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习模型估算因果关系的概率</title>
      <link>https://arxiv.org/abs/2502.08858</link>
      <description><![CDATA[ARXIV：2502.08858V1公告类型：新 
摘要：因果关系的概率在现代决策中起着至关重要的作用。本文解决了通过使用机器学习模型来预测通过数据不足的亚群来预测因果关系概率的挑战。田和珍珠首先定义并得出了三个基本因素的紧密界限：必要性和充分性的概率（PNS），足够的概率（PS）以及必要的概率（PN）。但是，估计这些概率需要针对每个亚群特有的实验和观察性分布，而这些分布通常不可用或不切实际，而人群级别的数据有限。我们假设每个亚群的因果关系的概率取决于其特征。为了估算数据的这些概率，数据不足，我们建议使用机器学习模型，这些模型从亚群中吸引了具有足够数据的洞察力。我们对多个机器学习模型的评估表明，鉴于足够的人口级数据以及机器学习模型和激活功能的适当选择，可以有效地预测PNS。通过模拟研究，我们表明，使用MISH激活函数的多层感知器（MLP）模型在预测32,768个亚种群的PNS中，使用来自2,000个亚种群的数据预测PNS的平均绝对误差（MAE）。]]></description>
      <guid>https://arxiv.org/abs/2502.08858</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Enigmaeval：长期多模式推理挑战的基准</title>
      <link>https://arxiv.org/abs/2502.08859</link>
      <description><![CDATA[ARXIV：2502.08859V1公告类型：新 
摘要：语言模型掌握了现有的推理基准，我们需要新的挑战来评估其认知前沿。解决难题的事件是富有挑战的多模式问题的丰富存储库，这些问题测试了广泛的高级推理和知识能力，使它们成为评估边境语言模型的独特测试。我们介绍了Enigmaeval，这是一个来自拼图竞争和事件的问题和解决方案的数据集，这些问题和解决方案探讨了模型执行隐式知识合成和多步推论推理的能力。与现有的推理和知识基准不同，难题解决挑战模型，以发现看似无关的信息之间的隐藏连接以发现解决方案路径。该基准包括1184个各种复杂性的难题 - 每个通常都需要熟练的求解器团队数小时到几天才能完成 - 具有明确的，可验证的解决方案，以实现有效的评估。最先进的语言模型在这些难题上的准确性极低，甚至比其他困难的基准（例如人类的最后考试）要低，在面对需要非结构化和横向推理的问题的挑战时揭示了模型的缺点。]]></description>
      <guid>https://arxiv.org/abs/2502.08859</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不保证转换</title>
      <link>https://arxiv.org/abs/2502.08864</link>
      <description><![CDATA[ARXIV：2502.08864V1公告类型：新 
摘要：Hadfield-Menell等。 （2017年）提出了偏离开关游戏，这是一种人类合作的模型，其中AI代理商总是向人类服从人类，因为他们不确定我们的偏好。我解释了AI代理可能不推迟的两个原因。首先，AI代理可能不重视学习。其次，即使AI代理重视学习，他们也可能不确定学习我们的实际偏好。]]></description>
      <guid>https://arxiv.org/abs/2502.08864</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数字双技术中的数据传感器融合，以增强家庭环境的功能</title>
      <link>https://arxiv.org/abs/2502.08874</link>
      <description><![CDATA[ARXIV：2502.08874V1公告类型：新 
摘要：本文研究了数字双技术中数据传感器融合以增强家庭环境能力的整合，尤其是在冠状病毒大流行带来的挑战的背景下。该研究强调了数字化转型在不仅适应的关键作用，还可以减轻第四次工业革命期间的干扰。使用机智的运动传感器，收集了数据，用于诸如步行，工作，坐姿和说谎之类的活动，并通过测量加速度计，陀螺仪和磁力计的传感器进行了数据。该研究集成了网络物理系统，物联网，AI和机器人技术，以增强数字双胞胎功能。
  本文将传感器融合方法（包括特征级融合，决策级融合和卡尔曼滤波器融合）与SVM，GBOOST和随机森林等机器学习模型进行比较，以评估模型有效性。结果表明，传感器融合显着提高了这些模型的准确性和可靠性，因为它可以补偿单个传感器弱点，尤其是使用磁力计。尽管在理想条件下的准确性更高，但来自多个传感器的数据仍能确保在现实世界中更加一致和可靠的结果，从而建立了一个可靠的系统，该系统可以在实际情况下自信地应用。]]></description>
      <guid>https://arxiv.org/abs/2502.08874</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIH-TCCT：通过事件驱动的文本代码循环训练缓解LLMS中不一致的幻觉</title>
      <link>https://arxiv.org/abs/2502.08904</link>
      <description><![CDATA[ARXIV：2502.08904V1公告类型：新 
摘要：使用合成数据集的最新方法旨在解决大语言模型（LLMS）中不一致的幻觉；但是，这些方法主要是针对特定任务量身定制的，从而限制了它们的普遍性。受到逻辑密集型域中代码训练模型的强劲性能的启发，我们提出了一个新颖的框架，该框架利用基于事件的文本生成相应的代码，并采用循环训练来将代码的逻辑一致性传递给自然语言。我们的方法大大减少了三个领先的LLM和两类自然语言任务的幻觉不一致，同时保持整体绩效。该框架有效地减轻了幻觉，而无需适应下游任务，证明普遍性并提供了新的观点来应对不一致的幻觉挑战。]]></description>
      <guid>https://arxiv.org/abs/2502.08904</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加强大语言模型是正式的定理权家</title>
      <link>https://arxiv.org/abs/2502.08908</link>
      <description><![CDATA[ARXIV：2502.08908V1公告类型：新 
摘要：为了利用定理形式化和证明中的大型语言模型，我们通过推出下一个策略并将其与预期的策略进行比较，提出一个增强学习框架，以迭代地迭代优化了验证的LLM。实验结果表明，与直接调整的LLM相比，它有助于实现更高的精度。]]></description>
      <guid>https://arxiv.org/abs/2502.08908</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内部奖励模型的自愿性改善了自我奖励的语言模型</title>
      <link>https://arxiv.org/abs/2502.08922</link>
      <description><![CDATA[ARXIV：2502.08922V1公告类型：新 
摘要：将大语言模型（LLM）与人类偏好保持一致，对于它们在现实世界应用中的部署至关重要。自我奖励语言模型的最新进展表明，LLM可以使用其内部奖励模型（例如LLM-AS-A-Gudge）\ Cite {Yuanself}来生成偏好数据，从而提高了不昂贵的人类注释而没有昂贵的对准性能。但是，我们发现同一LLM中不同的内部奖励模型通常会产生不一致的偏好。这种不一致引起了人们对自我生成的偏好数据可靠性，阻碍整体一致性绩效的关注，并强调需要进一步研究，以确保可靠和连贯的一致性与人类偏好。为了解决这一限制，我们提出了自洽的内部奖励（SCIR），这是一个新颖的框架，旨在在训练过程中增强内部奖励模型之间的一致性。在每个培训步骤中，我们都会从多个预定义的内部奖励模型中收集偏好预测，并通过不一致的惩罚机制来实现一致性和信心，从而提高了这些内部奖励模型的可靠性。我们有选择地使用具有一致预测的数据进行优化优化，从而确保了偏好数据的质量。通过采用自洽的内部奖励，我们的方法显着提高了LLM的一致性性能和奖励建模能力，优于基线方法的优于明显的差距。]]></description>
      <guid>https://arxiv.org/abs/2502.08922</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于确保可区分神经符号推理范式的承诺</title>
      <link>https://arxiv.org/abs/2502.08932</link>
      <description><![CDATA[ARXIV：2502.08932V1发布类型：新 
摘要：要创建可用且可部署的人工智能（AI）系统，在许多不同的条件下，性能需要一定程度的保证。很多时候，部署的机器学习系统将需要通过与人工神经网络传感共同通过神经肯定程序进行的更经典的逻辑和推理。尽管许多先前的作品仅使用神经网络或整个企业系统检查了系统的单个组成部分的保证，但很少有作品研究了对综合神经成像系统的保证。在这项工作中，我们评估了端到端完全可区分的神经符号系统的保证，这是一种创建数据效率和更容易解释模型的新兴方法。我们使用scallop（端到端神经符号库）进行了研究，并在图像和音频域中的分类和推理任务进行了研究。我们评估了对抗性鲁棒性，校准，用户性能奇偶校验以及解决未对准解决方案的解决方案的保证。我们发现，端到端的神经成像方法通过我们的经验结果提供了超越数据效率的独特机会，但并非全面。我们发现，在定义算术操作以及对输入空间具有很高维度的情况下，这类神经成像模型具有更高的保证，在这些情况下，完全神经对应物很难学习强大的推理操作。我们确定了神经肯定模型的解释性之间的关系，以捕获快捷方式，尽管表现平等，但后来导致对抗性脆弱性的增加。最后，我们发现数据效率的承诺通常仅在类不平衡的推理问题的情况下才是。]]></description>
      <guid>https://arxiv.org/abs/2502.08932</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变压器电路的机械揭幕：自我影响是建模推理的关键</title>
      <link>https://arxiv.org/abs/2502.09022</link>
      <description><![CDATA[ARXIV：2502.09022V1公告类型：新 
摘要：基于变压器的语言模型取得了显着的成功，但由于复杂的非线性相互作用和高维操作，它们的内部推理机制在很大程度上仍然不透明。尽管以前的研究表明这些模型隐含地编码了推理结构，但仍不清楚他们采用哪些特定的多步思想过程来解决复杂的任务。为了解决这一差距，我们提出了一个新颖的机械性解释性框架SICAF，旨在追踪和分析语言模型在多步推理任务中使用的推理策略。通过采用电路分析和自我影响功能，我们在整个推理过程中量化了每个令牌的不断发展的重要性，从而绘制了模型用于推理的途径。将SICAF应用于间接对象识别（IOI）预测任务上的GPT-2模型，我们演示了基础电路如何揭示与人类解释性相符的推理过程，从而提供了对模型内部逻辑的新见解。]]></description>
      <guid>https://arxiv.org/abs/2502.09022</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AOI敏感的数据转发，在无人机辅助物联网中具有分布式波束形成</title>
      <link>https://arxiv.org/abs/2502.09038</link>
      <description><![CDATA[ARXIV：2502.09038V1公告类型：新 
摘要：本文提出了一个基于分布式波束形成的无人机辅助转发系统，以增强物联网（IoT）中的信息时代（AOI）。具体而言，无人机在传感器节点（SNS）和远程基站（BS）之间收集和中继数据。但是，航班延迟会增加AOI并降低网络性能。为了减轻这种情况，我们采用分布式波束形成以扩展通信范围，降低飞行频率并确保连续数据继电器和有效的能量利用。然后，我们通过共同优化UAV轨迹和通信时间表来制定优化问题，以最大程度地减少AOI和无人机能耗。这个问题是非凸且具有高动力的问题，因此我们提出了深入的增强学习（DRL）算法来解决该问题，从而提高了稳定性和加速收敛速度。仿真结果表明，所提出的算法有效地解决了该问题，并优于其他基准算法。]]></description>
      <guid>https://arxiv.org/abs/2502.09038</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>游戏理论符合大型语言模型：系统调查</title>
      <link>https://arxiv.org/abs/2502.09053</link>
      <description><![CDATA[ARXIV：2502.09053V1公告类型：新 
摘要：游戏理论建立了一个基本框架，用于分析理性决策者之间的战略互动。大型语言模型（LLM）的快速发展引发了广泛的研究，探讨了这两个领域的交集。具体而言，正在应用游戏理论方法来评估和增强LLM功能，而LLM本身正在重塑经典游戏模型。本文对这些领域的交集进行了全面的调查，从三个角度探索了双向关系：（1）建立基于游戏的标准化基准测试，以评估LLM行为； （2）利用游戏理论方法来通过算法创新提高LLM性能； （3）通过游戏建模来表征LLM的社会影响。在这三个方面中，我们还强调了传统游戏模型的平衡分析如何受到LLMS的先进语言理解的影响，这反过来又扩展了游戏理论的研究。最后，我们确定了关键的挑战和未来的研究方向，并根据该领域的现状评估了它们的可行性。通过将理论上的严格与新兴的AI功能桥接，该调查旨在促进跨学科的合作并推动该不断发展的研究领域的进步。]]></description>
      <guid>https://arxiv.org/abs/2502.09053</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>节省成本的LLM级联</title>
      <link>https://arxiv.org/abs/2502.09054</link>
      <description><![CDATA[ARXIV：2502.09054V1公告类型：新 
摘要：LLM Cascades基于这样的想法：处理所有最大且最昂贵的LLM的查询效率低下。取而代之的是，Cascades部署了小的LLM来回答大多数查询，从而将大型且昂贵的LLM限制在最困难的查询中。这种方法可以大大降低成本而不会影响性能。但是，诸如金融或药品之类的风险敏感领域在避免模型错误时给予了额外的溢价。认识到即使是最昂贵的模型也可能犯错，这些域中的应用程序受益于允许LLM系统完全放弃在犯错误的机会时完全放弃查询的问题。但是，赋予级联的弃权能力对LLM Cascades提出了一个直接的设计问题：只能在最终模型或早期型号上放弃？由于小型和大型模型的误差模式是相关的，因此后一种策略可以通过让廉价的模型通过昂贵的型号预测弃权决策，从而进一步降低推理成本，从而消除了运行昂贵模型的需求。我们研究了LLM Cascades中“早期弃权”的好处，发现在六个基准中，它平均将总体测试损失降低了2.2％（GSM8K，MEDMCQA，MMLU，MMLU，Triviaqa，Triviaqa，Elthfulfulqa和Xsum）。这些收益是由于更有效的弃权使用而产生的，该利用的总体弃权率平均增加了4.1％，成本降低13.0％，错误率降低了5.0％。我们的发现表明，可以利用不同语言模型的误差模式之间的相关性来推动具有弃权的LLM系统的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2502.09054</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的逻辑推理：调查</title>
      <link>https://arxiv.org/abs/2502.09100</link>
      <description><![CDATA[ARXIV：2502.09100V1公告类型：新 
摘要：随着OpenAI O3和DeepSeek-R1等高级推理模型的出现，大型语言模型（LLMS）表现出了出色的推理能力。但是，他们执行严格的逻辑推理的能力仍然是一个悬而未决的问题。这项调查综合了LLM中逻辑推理的最新进步，这是AI研究的关键领域。它概述了LLM，其理论基础以及用于评估推理能力的基准的逻辑推理范围。我们分析了不同推理范式的现有能力 - 演绎，归纳性，绑架性和类比 - 并评估提高推理性能的策略，包括以数据为中心的调整，增强增强学习，解码策略以及神经敏感方法。审查以未来的方向结束，强调需要进一步探索以加强AI系统中的逻辑推理。]]></description>
      <guid>https://arxiv.org/abs/2502.09100</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>逻辑租赁诉讼：纽约的租赁法律合规性和LLM</title>
      <link>https://arxiv.org/abs/2502.09204</link>
      <description><![CDATA[ARXIV：2502.09204V1公告类型：新 
摘要：法律案件需要按照法律进行仔细的逻辑推理，而与非技术用户的互动必须使用自然语言。作为使用序言和自然语言处理的逻辑推理的应用程序，本文介绍了一种新颖的方法和系统，即逻辑，以自动化纽约州房东租户法律案件的分析。 Logiclease通过分析案例描述并引用所有相关法律来确定遵守相关法律要求。它利用LLM进行信息提取和序言进行法律推理。通过将信息提取与法律推理分开，Logiclease可以提高透明度并控制适用于每种情况的法律逻辑。我们通过一系列测试评估逻辑酶的准确性，效率和鲁棒性，达到100％的准确性和2.57秒的平均处理时间。 Logiclease通过提供明确的，分步的推理，引用特定的法律并通过避免幻觉的能力来区分自己的逻辑比最先进的法律分析系统具有优势，这是LLMS中的常见问题。]]></description>
      <guid>https://arxiv.org/abs/2502.09204</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实解释为计划</title>
      <link>https://arxiv.org/abs/2502.09205</link>
      <description><![CDATA[ARXIV：2502.09205V1公告类型：新 
摘要：最近，人们对AI的解释性有很大的兴趣，尤其是在黑箱机器学习模型中。  正如计划界正确观察到的那样，当手头的应用不是单一的决策或预测时，而是一系列取决于观察结果的动作时，需要更丰富的解释概念。 
  在本文中，我们旨在提供基于动作序列的``反事实解释&#39;&#39;的正式描述。然后，我们表明这自然会导致模型和解的帐户，这可能会采取用户纠正代理商的形式模型，或为代理的计划提出行动，我们将需要阐明什么是真实的与已知的措施，并且我们呼吁情况的模态片段来正式化这些直觉。部分真理，削弱了真理和虚假的信念，并表明我们的定义很容易推广到这些不同的环境。]]></description>
      <guid>https://arxiv.org/abs/2502.09205</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>