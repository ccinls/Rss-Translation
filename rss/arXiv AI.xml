<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 04 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>代理AI需要系统理论</title>
      <link>https://arxiv.org/abs/2503.00237</link>
      <description><![CDATA[ARXIV：2503.00237V1公告类型：新 
摘要：AI具有推理能力和某种程度的代理权的捐赠，被广泛视为通往更有能力和可推广系统的途径。我们的立场是，当前的代理AI的发展需要更全面的系统理论观点，以便充分了解其能力并减轻任何新兴风险。我们立场的主要动机是，AI开发目前过于专注于单个模型能力，通常忽略了更广泛的新兴行为，从而导致了真正的能力和相关代理AI的相关风险的重大低估。我们描述了一些基本机制，这些机制仅仅是由于它们与环境和其他药物的相互作用而从（相当简单）的代理中出现的。在各个领域的大量现有文献中，我们概述了增强药物认知，新兴的因果推理能力和元认知意识的机制。我们通过提出一些主要的开放挑战和指导来开发代理AI，最后。我们强调，系统级别的观点对于更好地理解和有目的塑造代理AI系统至关重要。]]></description>
      <guid>https://arxiv.org/abs/2503.00237</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类协作：性能与偏好之间的权衡</title>
      <link>https://arxiv.org/abs/2503.00248</link>
      <description><![CDATA[ARXIV：2503.00248V1公告类型：新 
摘要：尽管对协作AI的兴趣越来越浓厚，但设计无缝整合人类投入的系统仍然是一个主要挑战。在这项研究中，我们开发了一项任务，以系统地检查人类对协作代理的偏好。我们创建并评估了五个协作AI代理商，其策略在适应人类行为的方式和程度上有所不同。参与者与这些代理的子集进行了互动，评估了他们的感知性状，并选择了他们的首选药物。我们使用贝叶斯模型来了解代理的策略如何影响人类团队的绩效，AI的感知特征以及在成对代理比较中塑造人类优先的因素。我们的结果表明，对人类行为更体贴的代理人优于纯粹的性能最大化代理。此外，我们表明，这种以人为中心的设计可以提高AI合作者的喜好而不降低性能。我们发现证据表明不平等现象效应是人类选择的驱动力，这表明人们更喜欢协作代理，使他们有意义地为团队做出了贡献。综上所述，这些发现表明，与AI的合作如何从包括主观和客观指标在内的开发工作中受益。]]></description>
      <guid>https://arxiv.org/abs/2503.00248</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教师工作人员大型语言模型系统用于政策建议：2025年1月的洛杉矶野火的空气质量分析案例研究</title>
      <link>https://arxiv.org/abs/2503.00566</link>
      <description><![CDATA[ARXIV：2503.00566V1公告类型：新 
摘要：2025年1月的洛杉矶野火造成了超过2500亿美元的损失，持续了将近一个月的损失。在我们先前的工作（数字双胞胎建筑物）之后，我们修改和利用了多代理大型语言模型框架以及云映射集成，以研究洛杉矶野火期间的空气质量。大型语言模型的最新进展允许开箱即用的大规模数据分析。我们使用由讲师和工人代理人组成的多机构大语言系统。收到用户的说明后，讲师代理从云平台检索数据，并向工人制作指令提示。然后，工人分析数据并提供摘要。最终将摘要输入到讲师代理中，然后提供最终的数据分析。我们通过在洛杉矶野火期间根据空气质量评估我们的讲师工作人员LLM系统的健康建议来测试该系统对基于数据的政策建议的能力。]]></description>
      <guid>https://arxiv.org/abs/2503.00566</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用非轴心推理系统任意适用的关系响应建模：机器心理学方法</title>
      <link>https://arxiv.org/abs/2503.00611</link>
      <description><![CDATA[ARXIV：2503.00611V1公告类型：新 
摘要：任意适用的关系响应（AARR）是人类语言和推理的基石，指的是以灵活的，与上下文相关的方式联系符号的能力。在本文中，我们提出了一种新颖的理论方法，用于使用非轴心推理系统（NARS）在人工智能框架内建模AARR。 NARS是一种适合在不确定性下学习的自适应推理系统。通过将关系框架理论的原理（行为心理学的ARARR叙述）与NARS的推理机制相结合，我们从概念上证明了Aarr的关键特性如何（相互影响，组合构成和刺激功能的转换）可以从NARS的推理规则和记忆结构中脱颖而出。两个理论实验说明了这种方法：一种建模刺激等效性和功能传递，另一个建模涉及对立框架的复杂关系网络。在这两种情况下，该系统在逻辑上都证明了未经训练的关系和刺激意义的上下文敏感转换的推导，反映了已建立的人类认知现象。这些结果表明，可以通过适当设计的AI系统在概念上捕获Aarr（长期以来被认为是独特的人类），从而强调了将行为科学洞察力整合到人工通用智能（AGI）研究中的价值。]]></description>
      <guid>https://arxiv.org/abs/2503.00611</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新考虑基于电流解码器的车辆路由问题的求解器</title>
      <link>https://arxiv.org/abs/2503.00753</link>
      <description><![CDATA[ARXIV：2503.00753V1公告类型：新 
摘要：基于光解码器的求解器由于其效率和与增强学习算法的集成易用性，因此在解决车辆路由问题（VRP）方面已获得了知名度。但是，他们经常在对更大的问题实例或不同VRP变体中的概括中挣扎。本文重新审视了基于光解码器的方法，分析了它们对静态嵌入及其固有挑战的依赖的含义。具体而言，我们证明，在光解码器范式中，编码器隐含地负责捕获一组嵌入式内解决方案构建过程中所有潜在决策方案的信息，从而导致高度信息密度。此外，我们的经验分析表明，过于简单的解码器努力有效地利用了这些密集的信息，尤其是随着任务复杂性的增加，这将概括限制在分发外（OOD）设置时。在这些见解的基础上，我们表明，通过简单地添加身份映射和馈送式层，增强解码器的容量可以大大减轻概括问题。在实验上，我们的方法显着增强了在大规模实例和复杂的VRP变体上基于光解码器的方法的OOD概括，从而用重型解码器范式缩小了差距。我们的代码可在以下网址找到：https：//github.com/ziweileonhuang/reld-nco。]]></description>
      <guid>https://arxiv.org/abs/2503.00753</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM的法律推理基准，具有树木组织的结构，包括Factum Probandum，证据和经验</title>
      <link>https://arxiv.org/abs/2503.00841</link>
      <description><![CDATA[ARXIV：2503.00841V1公告类型：新 
摘要：尽管在法律申请中取得了进展，但对于公平裁决至关重要的法律推理仍未得到探索。我们提出了一个透明的法律推理架构，以富含等级的事实证据，证据和内在经验，从而实现公众审查并防止偏见。受此模式的启发，我们介绍了具有挑战性的任务，该任务采用了文本案例描述，并输出了层次结构，证明了最终决定的合理性。我们还为此任务创建了第一个众包数据集，从而实现了全面的评估。同时，我们提出了一个代理框架，该框架采用了全面的法律分析工具来解决挑战任务。该基准为``智能法院&#39;&#39;中的透明和负责的AI辅助法律推理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.00841</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NESYC：一个神经符号的连续学习者，用于开放域中的复杂体现任务</title>
      <link>https://arxiv.org/abs/2503.00870</link>
      <description><![CDATA[ARXIV：2503.00870V1公告类型：新 
摘要：我们探讨了神经符号的方法来概括可行的知识，从而使体现的代理能够在开放域环境中更有效地处理复杂的任务。体现代理人的一个主要挑战是对各种环境和情况的知识的概括，因为有限的经验通常将它们限制在他们的先验知识中。为了解决这个问题，我们介绍了一个新颖的框架NESYC，NESYC是一种神经符号的持续学习者，通过不断通过大型语言模型（LLMS）和符号工具从有限的经验中提出和验证知识，从而模仿了假设的脱离模型。具体而言，我们在NESYC中设计了一种对比性一般性改进方案，该方案迭代地使用LLMS生成假设，并通过符号工具进行对比验证。该方案加强了可接受行动的理由，同时最大程度地减少了不可接受的推论。此外，我们合并了基于内存的监视方案，该方案有效地检测动作错误并触发跨域的知识完善过程。对包括Alfworld，VirtualHome，Minecraft，RLBENCH和现实世界中的机器人方案 -  NESYC在求解一系列开放式启动环境中非常有效的复杂体现的任务非常有效的实验进行了实验。]]></description>
      <guid>https://arxiv.org/abs/2503.00870</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大语模型应用规则的概念掌握的证据</title>
      <link>https://arxiv.org/abs/2503.00992</link>
      <description><![CDATA[ARXIV：2503.00992V1公告类型：新 
摘要：在本文中，我们利用心理方法来研究LLMS在应用规则时的概念掌握。我们引入了一种新的程序，以使LLM产生的思想多样性与在人类样本中观察到的思想多样性相匹配。然后，我们进行了两个实验，以比较人类和LLM中的基于规则的决策。研究1发现，所有调查的LLMS都复制了人类模式，无论是在训练截止之前还是之后创建的场景是否提示。此外，我们发现了人类两组场景之间的意外差异。令人惊讶的是，即使这些差异在LLM响应中也复制了。研究2转向了人类规则应用的上下文特征：在强迫时间延迟下，人类样本比规则的文本更依赖于规则的文本，而不是其他考虑因素，例如规则的目的。.我们的结果表明，某些模型（Gemini Pro和Claude 3）以人类的方式做出了迅速响应的及时响应，以及时描述强制性延迟或其他时间压力，而其他模型则（GPT-4O和Llama 3.2 90B）doce wite a a coft time Pressive或dime time wite time wite wite time time time wite toce with。我们认为，收集的证据表明，LLM对统治的概念有掌握，对法律决策和哲学探究都有影响。]]></description>
      <guid>https://arxiv.org/abs/2503.00992</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用概率电路计数可满足性模量的确切求解器</title>
      <link>https://arxiv.org/abs/2503.01009</link>
      <description><![CDATA[ARXIV：2503.01009V1公告类型：新 
摘要：满意度模型计数（SMC）是一种最近提出的通用语言，旨在推理整合统计和象征人工智能的问题。 SMC公式是一个扩展的SAT公式，其中一些布尔变量的真实值由概率推断决定。现有的近似求解器优化了缺乏正式保证的替代目标。当前的精确求解器直接整合了SAT求解器和概率推理求解器，导致性能缓慢，因为这两个求解器的许多来回调用。我们提出了KOCO-SMC，这是一种集成的精确SMC求解器，可有效跟踪概率推理过程中的上限和上限。它通过仅使用部分变量分配来启用概率推断的早期估算来提高计算效率，而现有方法则需要完整的可变分配。在实验中，我们将KOCO-SMC与当前可用的大约和精确的SMC求解器进行了比较，并在大规模数据集和现实世界应用程序上进行了比较。我们的方法以高效率提供高质量的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.01009</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多项式强化学习具有长期绩效目标的服务劳动力优化</title>
      <link>https://arxiv.org/abs/2503.01069</link>
      <description><![CDATA[ARXIV：2503.01069V1公告类型：新 
摘要：劳动力优化在有效的组织运营中起着至关重要的作用，在有效的组织运营中，决策可能涵盖了几个不同的行政和时间范围。例如，将人员派遣到立即服务请求，同时以各种专业知识管理人才获取，这设定了一个高度动态的优化问题。现有的工作着重于特定的子问题，例如资源分配和设施位置，这些启发式方法以及最近的深入强化学习都可以解决。但是，这些可能不能准确地代表这些子问题并非完全独立的现实情况。我们的目的是通过创建模拟统一劳动力优化问题的模拟器来填补这一空白。具体而言，我们设计了一个模块化模拟器，以支持为综合劳动力优化问题的增强学习方法的开发。我们专注于三个相互依存的方面：人员调度，劳动力管理和人员定位。模拟器提供了可配置的参数化，以帮助探索具有不同级别的随机性和非平稳性的动态场景。为了促进基准测试和消融研究，我们还为上述方面包括了启发式和RL基准。]]></description>
      <guid>https://arxiv.org/abs/2503.01069</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>公平：促进制造工业互联网中的人工智能弹性</title>
      <link>https://arxiv.org/abs/2503.01086</link>
      <description><![CDATA[ARXIV：2503.01086V1公告类型：新 
摘要：在制造工业互联网（MII）中，人工智能（AI）系统越来越多地采用。调查和实现AI的弹性对于减轻AI系统在制造和工业物联网（IIOT）运营中的深远影响，导致关键决策非常重要。但是，定义AI系统的弹性并分析潜在的根本原因和相应的缓解策略存在很大的知识差距。在这项工作中，我们提出了一个新的框架，用于研究数据质量，AI管道和网络物理层的危险因素，随着时间的流逝，AI性能的弹性。提出的方法可以促进基于多模式多头自我潜在注意模型的有效诊断和缓解策略，以恢复AI绩效。该方法的优点是使用连接的气溶胶喷射打印（AJP）机器，雾节和云的MII测试床，并通过AI管道进行推理任务。]]></description>
      <guid>https://arxiv.org/abs/2503.01086</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于安全调度操作的混合元启发式车辆路由问题</title>
      <link>https://arxiv.org/abs/2503.01121</link>
      <description><![CDATA[ARXIV：2503.01121V1公告类型：新 
摘要：本文研究了安全调度（VRPSD）的车辆路由问题的优化。 VRPSD专注于安全性和巡逻应用程序，其中涉及具有挑战性的约束，包括精确的时机和严格的时间窗口。我们提出了三种基于不同元启发式学的算法，这些算法是自适应大型邻里搜索（ALNS），禁忌搜索（TS）和阈值接受（TA）。第一种算法将单相ALN与TA结合在一起，第二个算法使用具有TA的多相ALN，第三个集成了多相ALNS，TS和TA。实验是在包含251个客户请求的实例上进行的。结果表明，第三个算法，混合多相ALNS-TS-TS-TA算法可提供最佳性能。这种方法同时利用ALN的大区域搜索能力进行探索，并在多相ALN与TS和TA耦合时有效地逃脱了局部Optima。此外，在我们的实验中，混合多相ALNS-TS-TS-TA算法是唯一一种显示出所有尝试中计算时间增加的结果的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.01121</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有自动停止条件的约束多余的贝叶斯优化</title>
      <link>https://arxiv.org/abs/2503.01126</link>
      <description><![CDATA[ARXIV：2503.01126V1公告类型：新 
摘要：贝叶斯优化（BO）越来越多地用于关键应用中，以最低的成本找到最佳设计。尽管BO以样品效率而闻名，但仅依靠昂贵的高保真数据仍然会导致高昂的成本。在受约束的搜索空间中尤其如此，BO不仅必须优化，还必须确保可行性。 BO文献中的一个相关问题是缺乏系统的停止标准。为了解决这些挑战，我们开发了一个有限的成本感知的多保真BO（CMFBO）框架，该框架的目标是通过利用廉价的低保真源来最大程度地降低整体抽样成本，同时确保可行性。在我们的情况下，约束可能会在数据源中发生变化，甚至可能是黑框函数。我们还引入了系统的停止标准，该标准解决了与BO的融合评估相关的持久问题。我们的框架通过GP+ Python软件包在GitHub上公开可用，在这里，我们验证了它在多个基准问题上的功效。]]></description>
      <guid>https://arxiv.org/abs/2503.01126</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以帮助因果发现实验设计吗？</title>
      <link>https://arxiv.org/abs/2503.01139</link>
      <description><![CDATA[ARXIV：2503.01139V1公告类型：新 
摘要：设计适当的实验并选择最佳干预目标是科学或因果发现中的一个长期问题。仅凭观察数据来确定基本的因果结构本质上是很困难的。另一方面，介入的介入数据对于因果发现至关重要，但是通常昂贵且耗时的时间很费时，可以收集足够的干预数据来收集因果发现，以促进可涉及的方法，以促进介入的方法来确定介入或班期的介入目标。但是，由于有限的介入数据，基于数值的方法可能会产生次优的结果。 In this work, we investigate a different approach, whether we can leverage Large Language Models (LLMs) to assist with the intervention targeting in causal discovery by making use of the rich world knowledge about the experimental design in LLMs.Specifically, we present \oursfull (\ours) -- a robust framework that effectively incorporates LLMs to augment existing numerical approaches for the intervention targeting in causal discovery.在$ 4 $逼真的基准标准中，\ oures对现有方法表现出显着的改善和鲁棒性，甚至超过了人类，这证明了LLMS在协助实验设计科学发现方面的实用性。]]></description>
      <guid>https://arxiv.org/abs/2503.01139</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于强盗的及时设计策略选择改进及时优化器</title>
      <link>https://arxiv.org/abs/2503.01163</link>
      <description><![CDATA[ARXIV：2503.01163V1公告类型：新 
摘要：及时优化旨在寻找有效的提示，以增强大语模型（LLMS）的性能。尽管现有的及时优化方法已经发现了有效的提示，但它们通常与人类专家精心设计的复杂提示不同。迅速设计策略，代表改善及时性能的最佳实践，可能是改善及时优化的关键。最近，一种称为自动及时工程工具箱（APET）的方法已将各种及时的设计策略纳入及时的优化过程。在APET中，需要LLM隐式选择和应用适当的策略，因为及时设计策略可能会产生负面影响。由于LLM的优化功能有限，这种隐式选择可能是次优的。本文通过策略选择（OPTS）介绍了优化提示，该提示为及时设计实现了明确的选择机制。我们提出了三种机制，包括基于汤普森采样的方法，并将其集成到EVOPROMPT中，这是一种众所周知的迅速优化器。实验优化了两种LLMS，即Llama-3-8b-Instruct和GPT-4O Mini，使用大型基础台上进行了实验。我们的结果表明，及时设计策略的选择可以提高EVOPROMPT的性能，而基于汤普森的采样机制则取得了最佳的总体结果。我们的实验代码可在https://github.com/shiralab/opts上提供。]]></description>
      <guid>https://arxiv.org/abs/2503.01163</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用自动编码器的晶圆化学机械抛光系统的预后和健康管理</title>
      <link>https://arxiv.org/abs/2503.01176</link>
      <description><![CDATA[ARXIV：2503.01176V1公告类型：新 
摘要：2016年预后和健康管理数据挑战（PHM）跟踪了半导体晶圆抛光过程的健康状况。最终目标是通过监测组件健康状态来增强预测晶圆表面磨损的测量能力。这转化为大规模生产中节省成本。 PHM数据集包含许多基于传统物理方法未利用的时间序列测量值。另一方面，应用数据驱动的方法（例如深度学习到PHM数据集）是不平凡的。监督深度学习的主要问题是，PHM数据集无法使用类标签。其次，由无监督的深层学习者训练的特征空间并非针对预测能力或回归。在这项工作中，我们建议使用基于自动编码器的聚类，从而发现经过特征空间更适合进行回归。这是由于样品的分布更紧凑，分布到其最近的群集均值。我们通过将PHM数据集上提出方法的性能与几个基线（例如自动编码器以及最新方法）进行比较，证明了我们的主张。]]></description>
      <guid>https://arxiv.org/abs/2503.01176</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Optmetaopenfoam：基于CFD的敏感性分析和参数优化的大语言模型驱动的思想链</title>
      <link>https://arxiv.org/abs/2503.01273</link>
      <description><![CDATA[ARXIV：2503.01273V1公告类型：新 
摘要：将自然语言界面与计算流体动力学（CFD）合并为行业和研究提供了变革的机会。在这项研究中，我们介绍了Optmetaopenfoam-一个新颖的框架，该框架通过大型语言模型（LLM）驱动的思想链（COT）方法来桥接元openfoam，并通过外部分析和优化工具库。通过通过自然语言输入自动化复杂的CFD任务，该框架使非专家用户能够执行灵敏度分析和参数优化，并明显提高效率。测试数据集包含11个不同的CFD分析或优化任务，包括源自开放式式教程的基线仿真任务，该任务涵盖了流体动力学，燃烧和传热。结果证实，Optmetaopenfoam可以准确地解释用自然语言表达的用户要求，并与Metaopenfoam一起有效调用外部工具库以完成任务。此外，对非openfoam教程案例的验证（即氢燃烧室）表明，仅200个字符的自然语言输入可以触发一系列模拟，处理后，分析和优化任务，这些任务超过2,000行代码。这些发现强调了LLM驱动的COT方法论在将外部工具链接到高级分析和优化的情况下，将Optmetaopenfoam定位为简化CFD模拟的有效工具，并提高其工业和研究应用的便利性和效率。代码可在https://github.com/terry-cyx/metaopenfoam上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.01273</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从头开始学习猜想</title>
      <link>https://arxiv.org/abs/2503.01389</link>
      <description><![CDATA[ARXIV：2503.01389V1公告类型：新 
摘要：我们开发了一种自学方法，用于猜测来自OEI的16197问题的数据集上的归纳谓词。这些问题对于当今的SMT和ATP系统来说很难，因为它们需要诱导和算术推理的结合。
  Starting from scratch, our approach consists of a feedback loop that iterates between (i) training a neural translator to learn the correspondence between the problems solved so far and the induction predicates useful for them, (ii) using the trained neural system to generate many new induction predicates for the problems, (iii) fast runs of the z3 prover attempting to prove the problems using the generated predicates, (iv) using heuristics such as predicate size and解决方案速度在被证明的问题上选择了下一次培训的最佳谓词。
  该算法自行发现许多有趣的诱导谓词，最终解决了5565个问题，而CVC5，Vampire或Z3在60秒内解决了2265个问题。]]></description>
      <guid>https://arxiv.org/abs/2503.01389</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建间隔2型模糊会员资格功能：基于卡片的共同构建方法</title>
      <link>https://arxiv.org/abs/2503.01413</link>
      <description><![CDATA[arxiv：2503.01413v1公告类型：新 
摘要：自成立以来，模糊集已被广泛用于处理决策中的不确定性和不准确性。但是，常规的模糊集（通常称为1型模糊集（T1FSS））在捕获更高水平的不确定性方面存在局限性，尤其是当决策者（DMS）在会员学位上表达犹豫或歧义时。为了解决这个问题，通过将成员程度分配的不确定性纳入不确定性，从而提高了建模主观判断的灵活性，从而引入了间隔2型模糊集（IT2FSS）。尽管具有优势，但现有的IT2FS构造方法通常缺乏DMS的积极参与，这限制了决策模型的可解释性和有效性。这项研究提出了一种社会技术共同构建方法，用于通过促进DMS在偏好启发中的积极参与及其在多准则决策（MCDM）问题中的应用，来开发语言术语的IT2FS模型。我们的方法分为两个阶段。第一阶段涉及DM和决策分析师之间的交互过程，其中提出了修改版本的甲板卡（DOC）方法来以比例量表构建T1FS成员函数。然后，我们扩展了这种方法，以将歧义纳入主观判断中，并导致IT2FS模型，该模型可以更好地捕捉DM语言评估中的不确定性。第二阶段通过定义此类信息，聚合规则和可允许的有序原理的适当数学表示，将构建的IT2FS模型正式用于MCDM中的应用。所提出的框架不仅可以准确地代表DM的语言信息语义，从而提高了模糊决策的可靠性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.01413</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从假设到出版物：对AI驱动的研究支持系统的全面调查</title>
      <link>https://arxiv.org/abs/2503.01424</link>
      <description><![CDATA[ARXIV：2503.01424V1公告类型：新 
摘要：研究是推动人类文明发展的基本过程，但它需要研究人员的大量时间和精力。近年来，人工智能（AI）技术的快速发展激发了研究人员探索AI如何加速和增强研究。为了监视相关的进步，本文对该领域的进度进行了系统的审查。具体而言，我们将相关研究组织为三个主要类别：假设制定，假设验证和手稿出版。假设制定涉及知识综合和假设产生。假设验证包括对科学主张，定理证明和实验验证的验证。稿件出版物包括手稿写作和同行评审过程。此外，我们确定并讨论了这些领域中当前面临的挑战，以及潜在的未来研究方向。最后，我们还对各个领域的现有基准和工具进行了全面概述，这些基准和工具支持AI集成到研究过程中。我们希望本文成为初学者的介绍，并培养未来的研究。资源已在https://github.com/zkzhou126/ai-for-research上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2503.01424</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>