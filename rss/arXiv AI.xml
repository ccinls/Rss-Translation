<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 增强代理自动形式化和模拟博弈论场景</title>
      <link>https://arxiv.org/abs/2412.08805</link>
      <description><![CDATA[arXiv:2412.08805v1 公告类型：新
摘要：博弈论模拟是探索自然和人工代理之间相互作用的多功能工具。然而，对现实世界场景进行建模和开发模拟通常需要大量的人类专业知识和努力。为了简化这一过程，我们提出了一个框架，该框架能够使用由大型语言模型 (LLM) 增强的代理自动形式化博弈论场景。在这种方法中，LLM 增强的代理将自然语言场景描述转换为定义每个游戏规则的可执行逻辑程序，并验证这些程序的句法准确性。然后进行锦标赛模拟，在此期间，代理通过玩生成的游戏来测试其功能。当有基本事实支付矩阵时，还可以执行精确的语义验证。然后可以在进一步的模拟中使用经过验证的游戏来评估不同策略的有效性。我们针对五种著名的 2x2 同时移动游戏中的 55 种不同的自然语言描述对我们的方法进行了评估，结果表明，生成的游戏规则的句法正确率为 96%，语义正确率为 87%。此外，我们还评估了 LLM 增强型代理自动形式化游戏策略的能力。]]></description>
      <guid>https://arxiv.org/abs/2412.08805</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结构熵引导概率编码</title>
      <link>https://arxiv.org/abs/2412.08841</link>
      <description><![CDATA[arXiv:2412.08841v1 公告类型：新
摘要：概率嵌入比确定性嵌入有几个优势，因为它们将每个数据点映射到一个分布，从而更好地描述数据的不确定性和复杂性。许多工作侧重于在信息瓶颈 (IB) 原则下调整分布约束以增强表示学习。然而，这些提出的正则化项仅考虑每个潜在变量的约束，忽略了潜在变量之间的结构信息。在本文中，我们提出了一种新的结构熵引导概率编码模型，称为 SEPC。具体而言，我们通过提出结构熵正则化损失将潜在变量之间的关系纳入优化中。此外，由于传统的结构信息理论不太适合回归任务，我们提出了一种概率编码树，将回归任务转移到分类任务，同时消除了转换的影响。在 12 个自然语言理解任务（包括分类和回归任务）中的实验结果表明，SEPC 在有效性、泛化能力和对标签噪声的鲁棒性方面优于其他最先进的模型。代码和数据集可在 https://github.com/SELGroup/SEPC 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.08841</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经交互证明</title>
      <link>https://arxiv.org/abs/2412.08897</link>
      <description><![CDATA[arXiv:2412.08897v1 公告类型：新
摘要：我们考虑一个问题，即一个受信任但计算受限的代理（“验证者”）如何学习与一个或多个强大但不可信的代理（“证明者”）交互以解决给定的任务。更具体地说，我们研究使用神经网络表示代理的情况，并将该问题的解决方案称为神经交互证明。首先，我们引入了一个基于证明者-验证者游戏的统一框架，该框架概括了以前提出的交互协议。然后，我们描述了几种用于生成神经交互证明的新协议，并对新方法和现有方法进行了理论比较。最后，我们通过两个领域的实验来支持这一理论：一个说明关键思想的玩具图同构问题，以及一个使用大型语言模型的代码验证任务。通过这样做，我们旨在为未来神经交互证明及其在构建更安全的人工智能系统中的应用奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2412.08897</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文增强型序列图推理框架</title>
      <link>https://arxiv.org/abs/2412.09056</link>
      <description><![CDATA[arXiv:2412.09056v1 公告类型：新
摘要：本文研究了基于图结构数据的顺序推理，这是自动数学问题解决和神经图算法学习等各种热门领域的一项基本任务，吸引了大量研究兴趣。在这些任务中同时管理顺序和图结构信息是一项重大挑战。近年来，文献中出现了许多神经架构来解决这个问题。在这项工作中，我们概括了现有的架构并提出了一个上下文增强框架。关键的创新是，每一步的推理不仅依赖于前一步的结果，而且还利用了来自更多历史结果的信息聚合。这个想法源于我们的观察，在顺序图推理中，与传统的 seq-to-seq 任务相比，每一步的结果彼此之间具有更强的内在联系。我们表明该框架可以有效地与现有方法集成，增强其推理能力。在具有挑战性的 CLRS 推理基准上进行了实证评估，结果表明，所提出的框架显著提高了现有架构的性能，在基准测试中的大多数数据集上获得了最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2412.09056</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有模式的时间数值规划</title>
      <link>https://arxiv.org/abs/2412.09101</link>
      <description><![CDATA[arXiv:2412.09101v1 公告类型：新
摘要：我们考虑用 PDDL2.1 3 级表示的时间数值规划问题 $\Pi$，并展示如何生成 SMT 公式 $(i)$，其模型对应于 $\Pi$ 的有效计划，以及 $(ii)$，将最近提出的模式规划方法从数值扩展到时间情况。我们证明了该方法的正确性和完整性，并表明它在 10 个具有所需并发性的领域表现非常出色。]]></description>
      <guid>https://arxiv.org/abs/2412.09101</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于离线偏好的强化学习的数据集内轨迹回报正则化</title>
      <link>https://arxiv.org/abs/2412.09104</link>
      <description><![CDATA[arXiv:2412.09104v1 公告类型：新
摘要：离线基于偏好的强化学习 (PbRL) 通常分为两个阶段：首先，使用人类偏好来学习奖励模型并为无奖励的离线数据集注释奖励；其次，通过离线 RL 优化学习到的奖励来学习策略。然而，准确地从轨迹级偏好反馈建模分步奖励存在固有的挑战。引入的奖励偏差，特别是对预测奖励的高估，导致乐观的轨迹拼接，从而破坏离线 RL 阶段至关重要的悲观机制。为了应对这一挑战，我们提出了用于离线 PbRL 的数据集内轨迹回报正则化 (DTR)，它利用条件序列建模来减轻在奖励偏差下学习不准确轨迹拼接的风险。具体来说，DTR 采用决策转换器和 TD-Learning 来在保持行为策略的保真度和高数据集内轨迹回报与基于高奖励标签选择最佳动作之间取得平衡。此外，我们引入了一种集成正则化技术，可以有效地整合多个奖励模型，平衡奖励差异化和准确性之间的权衡。对各种基准的实证评估表明，DTR 优于其他最先进的基线]]></description>
      <guid>https://arxiv.org/abs/2412.09104</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有平等性的一阶和二阶依赖关系的目标驱动查询回答</title>
      <link>https://arxiv.org/abs/2412.09125</link>
      <description><![CDATA[arXiv:2412.09125v1 公告类型：新
摘要：对具有依赖关系的数据进行查询回答在大多数依赖关系应用中起着核心作用。通常通过使用追逐算法的适当变体来计算依赖关系和数据的通用模型来解决该问题，从而阐明依赖关系中隐含的所有知识。在此预处理步骤之后，可以通过评估计算出的通用模型来回答对依赖关系和数据的任意连接查询。但是，如果要回答的查询是固定的并且是预先知道的，则计算通用模型通常效率低下，因为在此过程中进行的许多推断可能与给定的查询无关。在这种情况下，避免得出不必要推断的目标驱动方法有望提高效率，因此在实践中更可取。
在本文中，我们介绍了我们认为是第一种使用等式推理对一阶和二阶依赖关系进行目标驱动查询回答的技术。我们的技术转换了输入依赖关系，这样将追逐应用于输出可以避免许多与查询无关的推断。转换分为几个步骤，包括以下三种新技术。首先，我们提出了 Marnette [60] 的奇异化技术的一种变体，该技术适用于二阶依赖关系，并纠正了 ten Cate 等人 [74] 相关公式的不完整性。其次，我们提出了一种相关性分析技术，可以从输入中消除那些可证明对查询答案没有贡献的依赖关系。第三，我们提出了魔法集算法 [19] 的一种变体，该算法可以使用平等推理处理二阶依赖关系。我们还展示了广泛的实证评估结果，结果表明，目标驱动的查询回答速度可以比计算完整的通用模型快几个数量级。]]></description>
      <guid>https://arxiv.org/abs/2412.09125</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LMAgent：用于多用户模拟的大型多模式代理社团</title>
      <link>https://arxiv.org/abs/2412.09237</link>
      <description><![CDATA[arXiv:2412.09237v1 公告类型：新
摘要：可信的多用户行为模拟对于理解复杂的社会系统至关重要。最近，基于大型语言模型 (LLM) 的人工智能代理取得了重大进展，使它们能够在各种任务中实现类似人类的智能。然而，真实的人类社会往往是动态和复杂的，涉及众多参与多模态交互的个体。在本文中，以电子商务场景为例，我们提出了 LMAgent，一个基于多模态 LLM 的超大规模多模态代理社会。在 LMAgent 中，除了与朋友自由聊天外，代理还可以自主浏览、购买和评论产品，甚至进行直播电子商务。为了模拟这个复杂的系统，我们引入了一种自洽提示机制来增强代理的多模态能力，从而显著提高了现有多代理系统的决策性能。此外，我们提出了一种结合小世界模型的快速记忆机制来提高系统效率，支持社会中超过 10,000 个代理模拟。对代理行为的实验表明，这些代理在行为指标上达到了与人类相当的表现。此外，与现有的基于 LLM 的多代理系统相比，表现出了更多不同且有价值的现象，例如羊群行为，这证明了 LMAgent 在可信的大规模社会行为模拟中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.09237</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过应用相关变量的领域知识来加速近似 MAP</title>
      <link>https://arxiv.org/abs/2412.09264</link>
      <description><![CDATA[arXiv:2412.09264v1 公告类型：新
摘要：贝叶斯网络中的 MAP 问题非常难以解决，即使是近似的也是如此。在之前的一篇论文中，我们介绍了最节俭解释启发式方法来解决 MAP，通过将中间变量集（既不是观察到的也不是 MAP 变量的一部分）划分为一组相关变量（被边缘化）和不相关变量（将从其域中分配一个采样值）。在本研究中，我们探讨了关于哪些变量与特定查询相关的知识（即领域知识）是否足以加快计算速度以击败精确 MAP 和近似 MAP，同时提供合理准确的结果。我们的结果尚无定论，但也表明这可能取决于 MAP 查询的细节，最突出的是 MAP 变量的数量。]]></description>
      <guid>https://arxiv.org/abs/2412.09264</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>警惕元认知懒惰：生成人工智能对学习动机、过程和表现的影响</title>
      <link>https://arxiv.org/abs/2412.09315</link>
      <description><![CDATA[arXiv:2412.09315v1 公告类型：新
摘要：随着技术和教育创新的不断发展，如今的学习者可以从教师、同学、教育技术以及最近的生成人工智能（如 ChatGPT）等代理处获得各种支持。混合智能的概念仍处于起步阶段，学习者如何从与人工智能、人类专家和智能学习系统等各种代理的共生关系中受益仍不得而知。新兴的混合智能概念还缺乏基于强有力的实证研究的对人机混合学习机制和后果的深刻见解和理解。为了解决这一差距，我们进行了一项随机实验研究，比较了不同代理（ChatGPT、人类专家、写作分析工具和无额外工具）支持的不同组学习者的动机、自我调节学习过程和写作任务的学习表现。共招募了 117 名大学生，并收集和分析了他们的多渠道学习、表现和动机数据。研究结果发现：接受不同学习支持的学习者在任务后内在动机方面没有差异；各组自我调节学习过程的频率和顺序存在显著差异；ChatGPT组在作文成绩提高方面表现优异，但知识获得和迁移方面差异不显著。研究​​发现，在没有动机差异的情况下，接受不同支持的学习者仍然表现出不同的自我调节学习过程，最终导致学习成绩的差异。尤其值得注意的是，ChatGPT等人工智能技术可能会促进学习者对技术的依赖，并潜在地引发元认知懒惰。]]></description>
      <guid>https://arxiv.org/abs/2412.09315</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI 预测 AGI：利用 AGI 预测和同行评审探索法学硕士的复杂推理能力</title>
      <link>https://arxiv.org/abs/2412.09385</link>
      <description><![CDATA[arXiv:2412.09385v1 公告类型：新 
摘要：我们委托 16 个最先进的大型语言模型 (LLM) 估计到 2030 年出现通用人工智能 (AGI) 的可能性。为了评估这些预测的质量，我们实施了自动化同行评审流程 (LLM-PR)。LLM 的估计值差异很大，从 3% (Reka-Core) 到 47.6% (GPT-4o)，中位数为 12.5%。这些估计与最近的一项专家调查非常吻合，该调查预测到 2027 年 AGI 的可能性为 10%，强调了 LLM 在预测复杂、推测性情景方面的相关性。LLM-PR 过程表现出很强的可靠性，这由较高的类内相关系数 (ICC = 0.79) 证明，反映了各个模型评分的显著一致性。在这些模型中，Pplx-70b-online 表现最佳，而 Gemini-1.5-pro-api 排名最低。与 LMSYS Chatbot Arena 等外部基准进行交叉比较后发现，LLM 排名在不同的评估方法中保持一致，这表明现有基准可能未涵盖与 AGI 预测相关的一些技能。我们进一步探索了基于外部基准的加权方案的使用，以优化 LLM 预测与人类专家预测的一致性。这项分析促成了新“AGI 基准”的开发，旨在突出 AGI 相关任务中的性能差异。我们的研究结果深入了解了 LLM 在推测性、跨学科预测任务中的能力，并强调了对创新评估框架的日益增长的需求，以评估复杂、不确定的现实场景中的 AI 性能。]]></description>
      <guid>https://arxiv.org/abs/2412.09385</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对理性的罕见信仰</title>
      <link>https://arxiv.org/abs/2412.09407</link>
      <description><![CDATA[arXiv:2412.09407v1 公告类型：新
摘要：理性的共同知识/信念是分析代理之间交互的传统标准假设。本文提出了一种基于图形的语言，用于捕捉代理可能对其他代理的理性具有的更复杂的高阶信念结构。两个主要贡献是一个解决方案概念，它捕捉基于给定信念结构的推理过程，以及一个将任何信念结构压缩为唯一最小形式的有效算法。]]></description>
      <guid>https://arxiv.org/abs/2412.09407</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模仿、探索和自我提升：慢思维推理系统的复现报告</title>
      <link>https://arxiv.org/abs/2412.09413</link>
      <description><![CDATA[arXiv:2412.09413v1 公告类型：新
摘要：最近，慢思考推理系统（例如 o1）在解决复杂推理任务方面表现出了卓越的能力。这些系统通常在响应查询之前进行扩展思考过程，从而使它们能够生成更彻底、更准确、更合理的解决方案。这些系统主要由行业开发和维护，其核心技术未公开披露。作为回应，研究界越来越多的研究旨在探索这些强大推理系统背后的技术基础。在这些先前努力的基础上，本文介绍了实现类似 o1 的推理系统的复现报告。我们引入了“模仿、探索和自我改进”框架作为训练推理模型的主要技术方法。在初始阶段，我们使用提炼的长格式思维数据来微调推理模型，使其能够调用慢思考模式。然后，通过生成多个 rollout 来鼓励模型探索具有挑战性的问题，这可以产生越来越多的高质量轨迹，从而得到正确的答案。此外，该模型通过迭代优化其训练数据集来进行自我改进。为了验证这种方法的有效性，我们在三个具有挑战性的基准上进行了广泛的实验。实验结果表明，与这些基准上的行业级推理系统相比，我们的方法实现了具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.09413</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可教育性的参数</title>
      <link>https://arxiv.org/abs/2412.09480</link>
      <description><![CDATA[arXiv:2412.09480v1 公告类型：新
摘要：可教育性模型是一种计算模型，最近被提出来描述认知能力，这种能力使得人类在地球上现有的生物物种中独一无二，能够创造先进的文明。可教育性被定义为获取和应用知识的能力。它既旨在描述人类的能力，也同样是机器可以有用地实现的理想描述。虽然目的是拥有一个数学上定义良好的计算模型，但在构建模型实例时需要做出许多决定。我们将这些决定称为{\it 参数}。在标准计算机中，两个参数是内存容量和时钟速率。对于任何一个，甚至对于它们的比率，都没有普遍最优的选择。同样，在标准机器学习系统中，两个参数是学习算法和用于训练的数据集。同样，对于任何一个，都没有普遍最优的选择。可教育系统比这两种系统都具有更多的参数。这篇短文讨论了可教育系统的一些主要参数及其存在的更广泛含义。]]></description>
      <guid>https://arxiv.org/abs/2412.09480</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中意识的数学框架</title>
      <link>https://arxiv.org/abs/1704.01148</link>
      <description><![CDATA[arXiv:1704.01148v6 公告类型：交叉 
摘要：本文提出了一种新颖的数学框架，用于弥合意识与其物理相关物之间的解释鸿沟（Levine，1983）。具体而言，我们提出，感质对应于神经网络拓扑数学表示中的奇点。至关重要的是，我们并不声称感质是奇点，也不声称奇点“解释”了为什么感质会有这样的感觉。相反，我们提出，奇点是原则性的、坐标不变的标记，在这些标记中，对系统动态进行纯定量描述的尝试达到了原则上的极限。通过将这些不可约性的形式标记整合到意识物理相关物的模型中，我们建立了一个框架，将感质视为本质上无法简化为复杂性、计算或信息的现象。这种方法借鉴了心灵哲学、数学、认知神经科学和人工智能 (AI) 的见解。它并没有解决意识的难题（Chalmers，1995），但它通过将感质的不可约性质整合到严格的物理主义框架中，推动了这一论述。虽然这些见解主要是理论上的，但它们也为未来的人工智能和人工意识 (AC) 研究开辟了道路，表明认识和利用不可约拓扑特征可能是超越渐进式、基于规模的改进并走向通用人工智能 (AGI) 和 AC 的重要途径。]]></description>
      <guid>https://arxiv.org/abs/1704.01148</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SiReRAG：索引相似和相关信息以进行多跳推理</title>
      <link>https://arxiv.org/abs/2412.06206</link>
      <description><![CDATA[arXiv:2412.06206v1 公告类型：交叉 
摘要：索引是实现检索增强生成 (RAG) 系统强大性能的重要一步。然而，现有方法基于语义相似性 (相似性) 或相关信息 (相关性) 来组织数据，但并未全面涵盖这两个角度。我们的分析表明，仅对一个角度进行建模会导致知识综合不足，从而导致在需要多跳推理的复杂任务上性能不佳。在本文中，我们提出了 SiReRAG，这是一种新颖的 RAG 索引方法，它明确考虑了相似和相关信息。在相似性方面，我们遵循现有工作并探索一些差异以基于递归摘要构建相似性树。在相关性方面，SiReRAG 从文本中提取命题和实体，通过共享实体对命题进行分组，并生成递归摘要以构建相关性树。我们将相似性和相关性树都索引并展平到统一的检索池中。我们的实验表明，SiReRAG 在三个多跳数据集（MuSiQue、2WikiMultiHopQA 和 HotpotQA）上的表现始终优于最先进的索引方法，F1 分数平均提高了 1.9%。作为一种相当有效的解决方案，SiReRAG 显著增强了现有的重新排序方法，平均 F1 分数提高了 7.8%。]]></description>
      <guid>https://arxiv.org/abs/2412.06206</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预防灾难风险的人工智能评估能做什么和不能做什么</title>
      <link>https://arxiv.org/abs/2412.08653</link>
      <description><![CDATA[arXiv:2412.08653v1 公告类型：交叉 
摘要：人工智能评估是人工智能治理工具包的重要组成部分，是当前预防灾难性风险的安全案例方法的基础。我们的论文研究了这些评估能告诉我们什么和不能告诉我们什么。如果评估人员付出足够的努力，评估可以确定人工智能能力的下限并评估某些滥用风险。
不幸的是，评估面临着当前范式无法克服的基本限制。这些包括无法确定能力的上限、无法可靠地预测未来模型能力或无法稳健地评估自主人工智能系统的风险。这意味着，虽然评估是有价值的工具，但我们不应该依赖它们作为确保人工智能系统安全的主要方式。我们最后提出了逐步改进前沿人工智能安全的建议，同时承认这些基本限制仍未解决。]]></description>
      <guid>https://arxiv.org/abs/2412.08653</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种受行为树启发的自主代理编程语言</title>
      <link>https://arxiv.org/abs/2412.08654</link>
      <description><![CDATA[arXiv:2412.08654v1 公告类型：交叉 
摘要：我们提出了一种针对自主代理的函数式编程语言设计，该语言基于行为树 (BT) 的思想和动机。BT 是设计机器人和人工智能中代理行为的流行模型。然而，随着它们的增长急剧增加，简单的 BT 模型已变得有限。人们越来越希望增加 BT 的功能，最终目标是让 BT 演变成一种独立的编程语言，以定义 BT 的模块化和反应性属性为中心。
在本文中，我们研究了如何扩展 BT 模型才能发展成这种语言。我们确定了一些必须解决的基本问题：实施“反应性”选择、“监控”安全关键条件以及在操作之间传递数据。我们提供各种小例子来证明这些问题很复杂，并且当前的 BT 方法不能以符合模块化的方式处理这些问题。相反，我们提供了一组简单的模块化编程原语来处理这些用例，并展示了如何将它们组合起来构建复杂的程序。我们为我们的受 BT 启发的语言提供了完整的规范，并在函数式编程语言 Haskell 中给出了实现。最后，我们通过将大型复杂的 BT 转换为简单、明确的程序来展示我们的语言。]]></description>
      <guid>https://arxiv.org/abs/2412.08654</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用集成学习区分诈骗和欺诈</title>
      <link>https://arxiv.org/abs/2412.08680</link>
      <description><![CDATA[arXiv:2412.08680v1 公告类型：交叉 
摘要：用户越来越多地向支持 LLM 的网络聊天机器人查询诈骗防御方面的帮助。消费者金融保护局的投诉数据库是评估 LLM 在用户诈骗查询方面的表现的丰富数据来源，但目前语料库并未区分诈骗和非诈骗。我们开发了一种 LLM 集成方法来区分诈骗和欺诈 CFPB 投诉，并描述了关于 LLM 在诈骗防御环境中的优势和劣势的初步发现。]]></description>
      <guid>https://arxiv.org/abs/2412.08680</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习具有部分测量的物理信息神经微分方程</title>
      <link>https://arxiv.org/abs/2412.08681</link>
      <description><![CDATA[arXiv:2412.08681v1 公告类型：交叉 
摘要：学习控制物理和时空过程的动力学是一个具有挑战性的问题，特别是在状态被部分测量的情况下。在这项工作中，我们解决了当系统状态的某些部分未被测量时，特别是当产生未测量状态的动力学未知时，学习控制这些系统的动力学的问题。受状态估计理论和物理信息神经微分方程的启发，我们提出了一个顺序优化框架，可以在其中学习控制未测量过程的动力学。我们利用数值模拟和从机电定位系统中提取的真实数据集来展示所提出方法的性能。我们展示了底层方程如何适应我们的形式主义，并展示了与基线相比所提出方法的改进性能。]]></description>
      <guid>https://arxiv.org/abs/2412.08681</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>