<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 10 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>意图：具有意图引导的对比聚类的轨迹预测框架</title>
      <link>https://arxiv.org/abs/2503.04952</link>
      <description><![CDATA[ARXIV：2503.04952V1公告类型：新 
摘要：公路代理的准确轨迹预测（例如，行人，车辆）是各种智能系统应用（例如自动驾驶和机器人导航）的重要先决条件。最近的研究强调了环境环境（例如地图）和轨迹的“多模式”的重要性，从而导致越来越复杂的模型结构。但是，实际部署需要轻巧的模型，这些模型可以快速迁移并适应新的环境。此外，公路代理的核心动机（称为其意图）值得进一步探索。在这项研究中，我们提倡理解和推理道路代理在轨迹预测任务中起关键作用，而主要的挑战是意图的概念是模糊和抽象的。为此，我们提出了意图，这是一个有效的意图引导的轨迹预测模型，仅依赖于道路代理轨迹中包含的信息。我们的模型在几个关键方面将自己与现有模型区分开：（i）我们通过对比度聚类明确地对道路代理的意图进行了模型，从而适应了人类在其轨迹中的模糊性和抽象。 （ii）提出的意图仅基于多层感知器（MLP），从而减少了训练和推理时间，从而使其非常有效，更适合于现实世界的部署。 （iii）通过利用估计的意图和用于转化轨迹观察的创新算法，我们获得了更强大的轨迹表示，从而导致了卓越的预测准确性。对行人和自动驾驶汽车的实际轨迹数据集进行了广泛的实验，证明了意图的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2503.04952</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>R1-Zero在2B非SFT模型上的视觉推理中的“ AHA力矩”</title>
      <link>https://arxiv.org/abs/2503.05132</link>
      <description><![CDATA[ARXIV：2503.05132V1公告类型：新 
摘要：最近DeepSeek R1证明了如何使用简单的基于规则的激励措施进行强化学习，可以在大型语言模型中自主发展复杂的推理，其特征在于“ AHA时刻”，在该模型中，该模型在训练过程中表现出自我反思和增加的响应长度。但是，将这一成功扩展到多模式推理的尝试通常未能重现这些关键特征。在本报告中，我们介绍了仅在非SFT 2B模型上进行多模式推理的这些新兴特征的首次成功复制。从QWEN2-VL-2B开始，直接在SAT数据集上应用强化学习，我们的模型在CVBENCH上的准确性为59.47％，超过基本模型大约30％，并超过SFT设置约2％。此外，我们分享了失败的尝试和见解，以尝试使用指令模型使用RL实现类似R1的推理。旨在阐明所涉及的挑战。我们的主要观察结果包括：（1）在指导模型上应用RL通常会导致微不足道的推理轨迹，并且（2）幼稚的奖励无效地引发推理能力。该项目代码可在https://github.com/turningpoint-ai/visualthinker-r1-zero上获得]]></description>
      <guid>https://arxiv.org/abs/2503.05132</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FEDMABENCH：通过分散的异构用户数据基准基准移动代理</title>
      <link>https://arxiv.org/abs/2503.05143</link>
      <description><![CDATA[ARXIV：2503.05143V1公告类型：新 
摘要：移动代理最近吸引了大量研究参与。移动代理培训的传统方法取决于集中式数据收集，从而导致高成本和有限的可扩展性。利用联邦学习的分布式培训通过利用现实世界用户数据，提供可扩展性和降低成本来提供替代方案。但是，关键的挑战，包括缺乏标准化的基准，阻碍了该领域的进步。
  为了应对挑战，我们介绍了FedMabench，这是对移动代理的联合培训和评估的第一个基准，该基准是专门为异构场景设计的。 FedMabench具有6个数据集，具有30多个子集，8种联合算法，10多个基本模型以及超过5个类别的800多个应用程序，提供了一个全面的框架，用于评估各种环境中的移动试剂。通过广泛的实验，我们发现了一些关键见解：联邦算法始终超过本地培训；特定应用的分布在异质性中起着至关重要的作用。而且，即使是不同类别的应用程序也可以在培训期间显示出相关性。 https：//github.com/wwh0411/fedmabench可以公开获取fedmabench，并附有数据集，网址为：https：//huggingface.co/datasets/wwh0411/fedmabench。]]></description>
      <guid>https://arxiv.org/abs/2503.05143</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>路径池：无火车结构增强，可高效的知识图检索生成</title>
      <link>https://arxiv.org/abs/2503.05203</link>
      <description><![CDATA[ARXIV：2503.05203V1公告类型：新 
摘要：尽管大型语言模型在许多任务中取得了巨大的成功，但它们仍然遭受现实应用应用中的幻觉和知识不足的困扰。许多基于图形的知识检索生成（kg-rag）方法通过利用kgs中的结构和语义信息作为外部知识基础来提高LLM的质量和信誉。但是，这些方法难以有效地纳入结构信息，即产生高计算成本或不足的可用知识。受图表表示学习中的平滑操作的启发，我们提出了Path Poy boming，这是一种简单，无火车的策略，通过新颖的以路径为中心的池操作引入结构信息。它以插件的方式无缝地集成到现有的kg-rag方法中，从而实现了更丰富的结构信息利用率。广泛的实验表明，将路径集合纳入最新的kg rag方法会始终提高各种环境的性能，同时引入可忽略不计的额外成本。代码即将在https://github.com/hrwang00/path-pooling上发布。]]></description>
      <guid>https://arxiv.org/abs/2503.05203</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>写作板：生成写作的全面基准</title>
      <link>https://arxiv.org/abs/2503.05244</link>
      <description><![CDATA[ARXIV：2503.05244V1公告类型：新 
摘要：大语言模型（LLM）的最新进展具有显着增强的文本生成能力，但是评估其在生成写作中的表现仍然是一个挑战。现有的基准主要集中于通用文本生成或写作任务的限制，未能捕获各个领域的高质量书面内容的不同要求。为了弥合这一差距，我们介绍了写作Bench，这是一个综合基准，旨在评估6个核心写作领域和100个子域中的LLM，其中包括创意，有说服力，内容丰富和技术写作。我们进一步提出了一个依赖查询的评估框架，该框架使LLMS能够动态生成特定于实例的评估标准。该框架与微调的评论家模型相辅相成，以了解标准的评分，从而使样式，格式和长度评估。该框架的数据策展能力进一步证明了该框架的有效性，该功能使7B参数模型能够接近最先进的性能（SOTA）性能。我们开源基准，以及评估工具和模块化框架组件，以促进LLM的书面发展。]]></description>
      <guid>https://arxiv.org/abs/2503.05244</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向生成AI系统的评估科学</title>
      <link>https://arxiv.org/abs/2503.05336</link>
      <description><![CDATA[ARXIV：2503.05336V1公告类型：新 
摘要：在现实部署环境中，预期和了解生成AI系统的性能和安全性越来越重要。但是，当前的评估生态系统不足：常用的静态基准面临有效性挑战，并且逐个案例审核很少进行。在这篇文章中，我们倡导为生成AI系统的评估科学成熟。尽管生成AI对系统安全工程和测量科学造成了独特的挑战，但该领域可以从其他领域的安全评估实践（包括运输，航空航天和制药工程）中获得有价值的见解。特别是，我们介绍了三个关键课程：评估指标必须适用于现实世界的绩效，指标必须进行迭代完善，并且必须建立评估机构和规范。采用这些见解，我们概述了一种具体的路径，以一种更严格的方法来评估生成AI系统。]]></description>
      <guid>https://arxiv.org/abs/2503.05336</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VLMS Play Starcraft II：基准和多模式决策方法</title>
      <link>https://arxiv.org/abs/2503.05383</link>
      <description><![CDATA[ARXIV：2503.05383V1公告类型：新 
摘要：我们介绍了VLM意见，这是一种多模式的星际争霸II环境，将人造代理人的感知与人类游戏玩法相吻合。诸如SMAC之类的传统框架依靠抽象状态表示，这些表示与人类感知显着不同，从而限制了代理行为的生态有效性。我们的环境通过结合RGB的视觉输入和自然语言观察来解决这种限制，这些观察在游戏过程中更加紧密地模拟了人类认知过程。 VLM  - 注意框架由三个集成组件组成：（1）通过专门的自我发言机制来增强视觉模型，以进行战略单位靶向和战场评估，（2）检索授权的生成系统，利用领域特定的星际争霸型星际争霸II知识II知识，以实现战术决策，以及（3）基于动态的任务分配，该系统是一种动态的远程行为。我们在21种自定义方案中进行的实验评估表明，由基础模型（特别是QWEN-VL和GPT-4O）提供动力的基于VLM的代理可以执行复杂的战术动作，而无需显式培训，可以实现与需要实质训练迭代的传统MARL方法相当的性能。这项工作为开发与人类一致的Starcraft II代理商的基础建立了基础，并推进了多模式游戏AI的更广泛的研究议程。我们的实施可从https://github.com/camel-ai/vlm-play-starcraft2获得。]]></description>
      <guid>https://arxiv.org/abs/2503.05383</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大语言模型的本体生成</title>
      <link>https://arxiv.org/abs/2503.05388</link>
      <description><![CDATA[ARXIV：2503.05388V1公告类型：新 
摘要：即使对于经验丰富的本体论工程师，本体论工程过程也很复杂，耗时且容易出错。在这项工作中，我们研究了大语模型（LLMS）的潜力直接根据使用用户故事和能力问题描述的本体论要求提供有效的猫头鹰本体学草稿。我们的主要贡献是对自动化本体发展的两种新提示技术的介绍和评估：无记忆的CQBYCQ和Ontogenia。我们还强调了三个结构标准在本体评估中的重要性，以及专家定性评估，强调了对多维评估的需求，以捕获生成的本体论的质量和可用性。我们的实验在十个本体的基准数据集上进行，具有100个不同的CQ和29个不同的用户故事，使用两种提示技术比较了三个LLM的性能。结果表明，在LLM支持的本体论工程中，对当前的最新技术有所改善。更具体地说，具有原子症的OpenAi O1-preiview模型可产生足够质量的本体，以满足本体论工程师的要求，在建模能力方面的表现明显优于新手本体论工程师。但是，我们仍然注意到一些常见的错误和结果质量的可变性，这在使用LLMS进行本体论创作支持时要考虑到这一点很重要。我们讨论了这些局限性，并提出了未来研究的指示。]]></description>
      <guid>https://arxiv.org/abs/2503.05388</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>R1搜索者：通过增强学习激励LLMS中的搜索能力</title>
      <link>https://arxiv.org/abs/2503.05592</link>
      <description><![CDATA[ARXIV：2503.05592V1公告类型：新 
摘要：现有的大型推理模型（LRMS）表明了增强学习的潜力（RL），以增强大语言模型〜（LLMS）的复杂推理能力。尽管他们在数学和编码等具有挑战性的任务上取得了显着的绩效，但他们通常依靠自己的内部知识来解决问题，这可能是不足的时间敏感或知识密集型问题，从而导致不准确和幻觉。为了解决这个问题，我们建议\ textbf {r1-searcher}，这是一种新颖的基于两阶段结果的RL方法，旨在增强LLM的搜索功能。此方法允许LLMS自主调用外部搜索系统在推理过程中访问其他知识。我们的框架仅依赖于RL，而无需流程奖励或蒸馏以进行冷启动。 ％有效地推广到室外数据集并支持基础和指导模型。我们的实验表明，即使与封闭源GPT-4O-Mini相比，我们的方法也明显优于先前的强抹布方法。]]></description>
      <guid>https://arxiv.org/abs/2503.05592</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>静态与代理游戏大师AI，用于促进独奏角色扮演体验</title>
      <link>https://arxiv.org/abs/2502.19519</link>
      <description><![CDATA[ARXIV：2502.19519V2公告类型：交叉 
摘要：本文介绍了单人角色扮演游戏的游戏大师AI。 AI旨在提供基于文本的叙述和经验，通常与Dungeons＆Dragons（例如Dungeons＆Dragons）相关。我们报告了设计过程和一系列实验，以改善功能和经验设计，从而产生了两个功能版本。虽然我们系统的V1使用简化的及时工程，但V2利用多代理体系结构和React框架来包括推理和操作。比较评估表明，V2作为代理系统保持发挥作用，同时显着改善了模块化和游戏体验，包括沉浸和好奇心。我们的发现有助于AI驱动的互动小说的演变，突出了增强独奏角色扮演体验的新途径。]]></description>
      <guid>https://arxiv.org/abs/2502.19519</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>功能 - 连接赌博</title>
      <link>https://arxiv.org/abs/2503.01855</link>
      <description><![CDATA[ARXIV：2503.01855V1公告类型：交叉 
摘要：理想的赌博框架提供了一种基础方法来不精确概率理论，但在很大程度上依赖于线性实用性假设。本文介绍了{\ em函数连接赌博}，这是一种适用于非线性实用程序的概括，同时保留基本的理性属性。我们建立了用于函数互晶的核心公理，并证明了通过连续线性函数来表征可接受的赌博的表示定理。然后，将该框架应用于分析跨期选择中的各种形式的折现，包括双曲线，准纤维，依赖于状态的折扣。我们演示了如何将这些替代指数折扣的替代方案集成到功能相互框架中。这种统一的处理为理论基础提供了建模可取性范式内复杂的时间偏好模式，从而在真实不确定性下弥合了规范理论和观察到的行为之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2503.01855</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型使用UNSPSC分类法优化项目分类</title>
      <link>https://arxiv.org/abs/2503.04728</link>
      <description><![CDATA[ARXIV：2503.04728V1公告类型：交叉 
摘要：有效的项目分类对于企业至关重要，可以使非结构化数据集转换为简化库存管理的有组织类别。尽管重要性很重要，但项目分类仍然高度主观，并且在行业和企业中缺乏统一的标准。联合国标准产品和服务代码（UNDPC）提供了一个标准化的系统来编目库存，但是采用UNSPSC分类通常需要大量的手动努力。本文研究了大型语言模型（LLMS）的部署，以根据项目描述将库存数据分类为UNSPSC代码。我们评估了LLM在分类各种数据集，探索其语言处理能力及其潜力作为标准化库存分类工具的潜力方面的准确性和效率。我们的发现表明，LLM可以大大减少项目分类中涉及的体力劳动，同时保持高精度，为努力增强其库存管理实践的企业提供可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.04728</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>认知逻辑程序：非地面和计算复杂性</title>
      <link>https://arxiv.org/abs/2503.04731</link>
      <description><![CDATA[ARXIV：2503.04731V1公告类型：交叉 
摘要：答案集编程（ASP）是一个突出的问题建模和解决框架，其解决方案称为答案集。认知逻辑程序（ELP）扩展了ASP，以推理所有或某些答案集。 ELP的解决方案可以看作是多个答案集（称为世界观）的后果。虽然对命题计划的复杂性进行了充分的研究，但非地面案例仍然开放。本文确定了非地面ELP的复杂性。我们为著名的程序片段提供了全面的图片，事实证明，该类别的Nexptime是完整的，可以访问Oracles to \ sigma^p_2。在定量环境中，我们为计算#exp以外的复杂性建立复杂性结果。为了减轻高复杂性，我们在界定的谓词ARITY的情况下建立了结果，达到了多项式层次结构的第四级。最后，我们为参数width提供了伦理紧密的运行时结果，该宽度在定量推理中具有应用，在该定量推理中我们推理了认知文字的（边际）概率。]]></description>
      <guid>https://arxiv.org/abs/2503.04731</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI和操纵的伦理：面向设计的研究议程</title>
      <link>https://arxiv.org/abs/2503.04733</link>
      <description><![CDATA[ARXIV：2503.04733V1公告类型：交叉 
摘要：生成AI可以大规模自动化，有效的操作。尽管关于生成AI的一般道德讨论日益增长，但对特定的操纵风险仍未得到充分研究。本文概述了包括操纵的概念，经验和设计维度，理解和遏制操纵风险的关键的基本询问。通过强调这些问题，本文强调了对操纵的适当概念化的必要性，以确保负责生成的AI技术的负责发展。]]></description>
      <guid>https://arxiv.org/abs/2503.04733</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以为可持续食品做什么？</title>
      <link>https://arxiv.org/abs/2503.04734</link>
      <description><![CDATA[ARXIV：2503.04734V1公告类型：交叉 
摘要：粮食系统负责人类引起的温室气体排放的三分之一。我们调查了哪些大型语言模型（LLM）可以促进减少粮食生产的环境影响。我们根据可持续食品文献和与领域专家的合作定义了设计和预测任务的类型，并评估了我们类型学四个任务的六个LLM。例如，对于可持续的蛋白质设计任务，食品科学专家估计，与LLM的合作可以平均将花费的时间降低45％，而与另一位专家人类食品科学家合作的22％。但是，对于可持续的菜单设计任务，LLMS在指示考虑人类满意度和气候影响时会产生次优的解决方案。我们提出了一个将LLM与组合优化集成以提高推理能力的一般框架。我们的方法将食物选择的排放量减少了79％，同时保持了参与者对自己选择的满意。我们的结果表明，在优化技术的支持下，LLMS的潜力加速了可持续的食品开发和采用。]]></description>
      <guid>https://arxiv.org/abs/2503.04734</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标准化智能：将生成AI调整以进行监管和运营合规性</title>
      <link>https://arxiv.org/abs/2503.04736</link>
      <description><![CDATA[ARXIV：2503.04736V1公告类型：交叉 
摘要：建立了有助于系统和流程的互操作性，质量和准确性的技术标准或简单的标准指南和规则。近年来，我们目睹了新兴的范式转变，在该范式上，采用生成AI（Genai）模型大大提高，在包括工程，法律，医疗保健和教育等标准驱动的行业中传播了实施利益。在本文中，我们评估了跨领域和扇区不同标准的关键水平，并通过对最新的Genai模型的当前合规能力进行评分来补充它们。为了支持讨论，我们概述了将Genai集成为标准合规任务的可能的挑战和机遇，同时还为与制定和使用标准有关的实体提供了可行的建议。总体而言，我们认为，通过计算方法使Genai与标准标准保持一致可以帮助加强监管和运营合规性。我们预计，这一研究领域将在不久的将来的更大，更强大的基于Genai的系统的管理，监督和可信赖性中发挥核心作用。]]></description>
      <guid>https://arxiv.org/abs/2503.04736</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用绩效因素分析的粗心检测：一种与学习意外不同关系的新操作</title>
      <link>https://arxiv.org/abs/2503.04737</link>
      <description><![CDATA[ARXIV：2503.04737V1公告类型：交叉 
摘要：数字学习平台中粗心大意的检测取决于上下文滑移模型，该模型利用有条件的概率和贝叶斯知识追踪（BKT）来识别粗心的错误，尽管有知识，但学生尽管有知识。但是，由于使用条件概率，该模型无法有效地评估具有多种技能的问题的粗心度。此限制范围缩小了可以应用模型的范围。因此，我们提出了一个新颖的模型，即《超越知识》特征粗心（BKFC）模型。该模型使用绩效因素分析（PFA）和行为特征从日志数据中蒸馏出来，检测到粗心的错误，从而在检测到粗心时控制知识。我们应用了BKFC来检测中学生的数据中的粗心大意，从而在十进制数字和操作上玩学习游戏。我们进行了分析，将使用上下文滑移与BKFC模型检测到的粗心错误进行了分析。出乎意料的是，这两种方法确定的粗心错误并不一致。我们发现，学生的测试后表现（与过去的结果相对应）与使用上下文滑动模型检测到的粗心大学相关，同时与使用BKFC模型检测到的粗心大意相关。这些结果突出了粗心的复杂性，并强调了操作粗心和粗心错误的更广泛挑战。]]></description>
      <guid>https://arxiv.org/abs/2503.04737</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI生成的作品中的版权：专利法最新发展的教训</title>
      <link>https://arxiv.org/abs/2503.04738</link>
      <description><![CDATA[ARXIV：2503.04738V1公告类型：交叉 
摘要：在Thaler诉专利，设计和商标审计长（DABUS）中，Smith J.认为，AI所有者可以根据其对AI系统的所有权和控制AI生成的发明而对AI的所有者拥有专利所有权。这种AI拥有者的方法揭示了一种新的选择，可以分配AI生成的产出。尽管该判断主要是关于专利法中AI生成的发明的发明和所有权，但它对版权法具有重要意义。在分析了将现有司法方法应用于AI生成的作品的版权所有权的弱点之后，本文研究了AI-WONDER方法是否是确定AI基因生成作品的版权所有权的更好选择。本文认为，尽管合同可以用来在用户想要商业利用产出的情况下围绕AI拥有者方法进行工作，但该方法仍然比迄今为止建议的其他方法提供了更多的确定性和更少的相关方交易成本。]]></description>
      <guid>https://arxiv.org/abs/2503.04738</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负责任的人工智能系统：通过值得信赖的AI，可审核，问责制和治理的社会信任的路线图</title>
      <link>https://arxiv.org/abs/2503.04739</link>
      <description><![CDATA[ARXIV：2503.04739V1公告类型：交叉 
摘要：人工智能（AI）已经成熟为一项技术，需要开发公平，包容，可信赖，可信赖，安全，安全，透明且负责的责任框架。通过建立此类框架，我们可以在缓解风险的同时，尤其是在高风险的情况下，利用AI的全部潜力。这就要求设计基于值得信赖的人工智能技术和道德原则的负责人AI系统，以确保在整个设计，开发和部署中确保可审核性和问责制，并遵守特定领域的规定和标准。
  本文从整体角度探讨了负责任的AI系统的概念，该角度涵盖了四个关键方面：1）监管环境； 2）值得信赖的AI技术以及标准化和评估； 3）可审核性和问责制； 4）AI治理。本文的目的是两倍。首先，我们以分析和概述的形式分析和理解这四个维度及其互连。其次，本文的最终目标是在负责人的AI系统设计中提出路线图，以确保他们能够获得社会的信任。为了实现这种可信度，本文还从全球治理的角度促进了关于AI的道德，法律，社会，经济和文化方面的跨学科讨论。最后但并非最不重要的一点是，我们还反思了当前状态和在不久的将来需要开发的那些方面，正如十个教训所学。]]></description>
      <guid>https://arxiv.org/abs/2503.04739</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Prism：集成合成和调解的透视推理，作为AI对齐的多镜头框架</title>
      <link>https://arxiv.org/abs/2503.04740</link>
      <description><![CDATA[ARXIV：2503.04740V1公告类型：交叉 
摘要：在这项工作中，我们提出了综合综合和调解（PRISM）的观点推理，这是一个多个观点的框架，用于解决AI一致性中的持续挑战，例如人类价值观和规范游戏矛盾。基于认知科学和道德心理学，Prism将道德关注组织分为七个“基础世界观”，每个人都假设捕捉人类道德认知的独特层面，从以生存为重点的反射到高级综合的观点。然后，它采用帕累托风格的优化方案来调和竞争优先级，而无需将它们降低到单个度量标准。在可靠的上下文验证可靠使用的假设下，该框架遵循一个结构化的工作流，引发了特定于观点的响应，将它们综合为平衡的结果，并以透明和迭代的方式介导了剩余的冲突。通过参考认知科学，道德心理学和神经科学的道德认知方法的分层方法，Prism阐明了不同的道德驱动力如何相互作用和系统地记录并调节道德权衡。我们通过工作原型产生的实际产出来说明其功效，将棱镜应用于诸如公共卫生政策，工作场所自动化和教育等领域的经典一致性问题。通过将AI的审议锚定在这些人类有利位置中，Prism的目的是绑定可能会流入非人类或以机器为中心的领域的解释性飞跃。我们简要概述了未来的方向，包括现实世界的部署和正式验证，同时保持着核心关注多观点的综合和冲突调解。]]></description>
      <guid>https://arxiv.org/abs/2503.04740</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>