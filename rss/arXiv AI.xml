<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 02 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>超越人工智能对齐的偏好</title>
      <link>https://arxiv.org/abs/2408.16984</link>
      <description><![CDATA[arXiv:2408.16984v1 公告类型：新
摘要：人工智能对齐的主流实践假设 (1) 偏好是人类价值观的充分代表，(2) 人类理性可以从最大化偏好满足的角度来理解，(3) 人工智能系统应该与一个或多个人类的偏好保持一致，以确保它们的行为安全并符合我们的价值观。无论是隐含遵循还是明确认可，这些承诺都构成了我们所说的人工智能对齐的偏好方法。在本文中，我们描述并挑战了偏好方法，描述了可供进一步研究的概念和技术替代方案。我们首先调查了理性选择理论作为描述模型的局限性，解释了偏好如何无法捕捉人类价值观的厚语义内容，以及效用表示如何忽略了这些价值观可能存在的不可比性。然后，我们批判了预期效用理论 (EUT) 对人类和人工智能的规范性，借鉴了表明理性主体不必遵守 EUT 的论点，同时强调了 EUT 对哪些偏好在规范上是可接受的保持沉默。最后，我们认为这些限制促使我们重新构建人工智能协调的目标：人工智能系统不应与人类用户、开发者或人类的偏好保持一致，而应与适合其社会角色（例如通用助手的角色）的规范标准保持一致。此外，这些标准应由所有相关利益相关者协商并达成一致。在这种替代的协调概念上，多种人工智能系统将能够服务于不同的目的，与促进互利和限制伤害的规范标准保持一致，尽管我们的价值观多元且不同。]]></description>
      <guid>https://arxiv.org/abs/2408.16984</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有侧面沟通的战略武器优于低遗憾 MAB 算法</title>
      <link>https://arxiv.org/abs/2408.17101</link>
      <description><![CDATA[arXiv:2408.17101v1 公告类型：新
摘要：在战略多臂老虎机设置中，当手臂拥有关于玩家行为的完美信息时，它们可以建立一个平衡点：1. 它们保留几乎所有的价值，2. 它们让玩家产生相当大的（线性）遗憾。这项研究表明，即使完整信息不是公开提供给所有手臂的，而是在它们之间共享的，也有可能实现类似的平衡。主要挑战在于设计一种激励手臂进行真实交流的通信协议。]]></description>
      <guid>https://arxiv.org/abs/2408.17101</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别和聚类 PvP 游戏中团队组成的对抗关系以实现有效的平衡分析</title>
      <link>https://arxiv.org/abs/2408.17180</link>
      <description><![CDATA[arXiv:2408.17180v1 公告类型：新
摘要：如何在游戏设置中量化平衡？这个问题对于游戏设计师来说至关重要，尤其是在玩家对战 (PvP) 游戏中，分析预定义团队组合之间的强度关系（例如多人在线战斗竞技场 (MOBA) 游戏中的英雄组合或纸牌游戏中的卡组）对于增强游戏玩法和实现平衡至关重要。我们已经开发了两种超越简单胜率的高级措施来量化零和竞争场景中的平衡。这些措施来自胜利值估计，它采用通过 Bradley-Terry 模型的强度评级近似值和通过矢量量化的反关系近似值，显着降低了与传统胜利值估计相关的计算复杂性。在这些模型的整个学习过程中，我们确定了有用的组合类别并确定了它们的反关系，与人类玩家的体验保持一致，而不需要特定的游戏知识。我们的方法依赖于一种简单的技术，即在极小的状态空间中使用确定性矢量量化过程来提高离散表示中的码本利用率。我们的框架已在流行的在线游戏中得到验证，包括《帝国时代 II》、《炉石传说》、《荒野乱斗》和《英雄联盟》。在这些游戏中观察到的强度关系的准确性与传统的成对获胜值预测相当，同时也为分析提供了更易于管理的复杂性。最终，我们的研究结果有助于更深入地了解 PvP 游戏动态，并提出了一种可显着改善游戏平衡评估和设计的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.17180</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用最大一致性签名进行推理</title>
      <link>https://arxiv.org/abs/2408.17190</link>
      <description><![CDATA[arXiv:2408.17190v1 公告类型：新
摘要：我们分析了 Lang 和 Marquis 基于遗忘的一般推理方法的一个具体实例。更准确地说，我们讨论了一种使用最大一致子签名进行不一致信息推理的方法，其中最大一致子签名是命题的最大集合，以至于忘记剩余的命题可以恢复一致性。我们深入分析了最大一致子签名和相应的最小不一致子签名，并表明命中集对偶也适用于它们。我们进一步分析了基于最大一致子签名的推理关系，这些推理关系与非单调推理和计算复杂性的合理性假设有关。我们还考虑了我们的方法与不一致性测量和副一致性推理的关系。]]></description>
      <guid>https://arxiv.org/abs/2408.17190</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向符号化XAI——通过特征间人类可理解的逻辑关系进行解释</title>
      <link>https://arxiv.org/abs/2408.17198</link>
      <description><![CDATA[arXiv:2408.17198v1 公告类型：新
摘要：可解释人工智能 (XAI) 在促进 AI 系统的透明度和信任方面发挥着至关重要的作用，其中传统的 XAI 方法通常提供一个抽象级别的解释，通常以突出显示单个或多个输入特征的热图形式出现。然而，我们想知道模型的抽象推理或问题解决策略是否也可能相关，因为它们与人类解决问题的方式更接近。我们提出了一个称为符号 XAI 的框架，该框架将相关性归因于表达输入特征之间逻辑关系的符号查询，从而捕获模型预测背后的抽象推理。该方法建立在模型预测的简单但通用的多阶分解之上。可以使用基于高阶传播的相关性方法（例如 GNN-LRP）或 XAI 中常用的基于扰动的解释方法来指定此分解。我们的框架的有效性在自然语言处理 (NLP)、视觉和量子化学 (QC) 领域得到了证明，这些领域中抽象的符号领域知识非常丰富，并且用户对此非常感兴趣。符号 XAI 框架提供了对模型决策过程的理解，既可由用户灵活定制，又可通过逻辑公式供人类阅读。]]></description>
      <guid>https://arxiv.org/abs/2408.17198</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多式联运城市交通网络中弹性即服务 (RaaS) 的方法框架</title>
      <link>https://arxiv.org/abs/2408.17233</link>
      <description><![CDATA[arXiv:2408.17233v1 公告类型：新
摘要：公共交通系统的通勤流量正在增加。这种增长凸显了弹性策略的必要性，以管理意外的服务中断，确保快速有效的响应，最大限度地减少对利益相关者的不利影响，并增强系统维持基本功能和快速恢复的能力。本研究旨在探索通过弹性即服务 (RaaS) 策略管理公共交通中断，开发优化模型以有效分配资源并最大限度地降低运营商和乘客的成本。提出的模型包括多种交通选择，例如公交车、出租车和自动货车，并根据可用性、容量、速度和与中断车站的距离等因素评估它们作为铁路中断服务的桥接替代方案。这确保部署最合适的车辆以保持服务连续性。该模型应用于法兰西岛地区、巴黎和郊区的案例研究，并辅以微观模拟，与现有的解决方案（如公交车桥接和备用车队）进行了比较。结果凸显了该模型在降低成本、提高利益相关者满意度、优化中断期间的运输管理方面的表现。]]></description>
      <guid>https://arxiv.org/abs/2408.17233</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>灵活有效地将大型语言模型与领域专家相结合</title>
      <link>https://arxiv.org/abs/2408.17280</link>
      <description><![CDATA[arXiv:2408.17280v1 公告类型：新
摘要：我们提出了一个工具包，用于从经过训练的模型创建低成本的混合领域专家 (MOE)。该工具包可用于从模型或适配器创建混合。我们进行了广泛的测试，并提供了使用该工具包定义生成的 MOE 架构的指导。公共存储库可用。]]></description>
      <guid>https://arxiv.org/abs/2408.17280</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型连接领域知识和流程发现</title>
      <link>https://arxiv.org/abs/2408.17316</link>
      <description><![CDATA[arXiv:2408.17316v1 公告类型：新
摘要：发现良好的流程模型对于不同的流程分析任务（例如一致性检查和流程改进）至关重要。自动化流程发现方法通常会忽略有价值的领域知识。这些知识（包括来自领域专家的见解和详细的流程文档）在流程发现过程中仍未得到充分利用。本文利用大型语言模型 (LLM) 将这些知识直接集成到流程发现中。我们使用从 LLM 派生的规则来指导模型构建，确保与领域知识和实际流程执行保持一致。通过集成 LLM，我们在用自然语言表达的流程知识和稳健流程模型的发现之间架起了一座桥梁，大大推进了流程发现方法。为了展示我们框架的可用性，我们与 UWV 员工保险机构进行了案例研究，展示了其实际优势和有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.17316</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>交通专业知识与残差强化学习相结合：基于知识模型的 CAV 轨迹控制残差强化学习</title>
      <link>https://arxiv.org/abs/2408.17380</link>
      <description><![CDATA[arXiv:2408.17380v1 公告类型：新
摘要：基于模型的强化学习 (RL) 通过使用虚拟环境模型，有望比无模型 RL 表现出更高的样本效率。然而，由于复杂系统和环境中的不确定性，很难获得足够准确的环境动态表示。不准确的环境模型可能会降低基于模型的 RL 的样本效率和性能。此外，虽然基于模型的 RL 可以提高样本效率，但它通常仍需要大量的训练时间才能从头开始学习，这可能会限制其相对于无模型方法的优势。为了应对这些挑战，本文引入了一种知识驱动的基于模型的残差强化学习框架，旨在通过将既定的专家知识注入学习过程并避免从零开始的问题来提高学习效率。我们的方法将交通专家知识集成到虚拟环境模型中，采用智能驾驶员模型 (IDM) 进行基本动态，采用神经网络进行残差动态，从而确保对复杂场景的适应性。我们提出了一种将传统控制方法与残差强化学习相结合的新策略，无需从头开始学习，即可实现高效学习和策略优化。所提出的方法应用于 CAV 轨迹控制任务，以消除混合交通流中的走走停停波。实验结果表明，我们提出的方法使 CAV 代理在轨迹控制方面在样本效率、交通流平稳性和交通流动性方面的表现优于基线代理。源代码和补充材料可在 https://github.com/zihaosheng/traffic-expertise-RL/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.17380</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索解释内容和格式对用户理解和信任的影响</title>
      <link>https://arxiv.org/abs/2408.17401</link>
      <description><![CDATA[arXiv:2408.17401v1 公告类型：新
摘要：近年来，已经引入了各种方法来解释“黑盒”AI模型的输出。然而，人们并不清楚用户是否真的理解和信任这些解释。在本文中，我们重点研究了用于评估癌症风险的回归工具的解释，并研究了解释的内容和格式对以用户为中心的理解和信任指标的影响。关于内容，我们尝试了两种解释方法：流行的 SHAP，基于博弈论概念，因此对于日常用户来说可能比较复杂；以及基于特征遮挡的遮挡-1，可能更容易理解。关于格式，我们将 SHAP 解释呈现为图表 (SC)，这是常规做法，将遮挡-1 解释呈现为图表 (OC) 和文本 (OT)，它们的简单性质也使其更具吸引力。实验相当于用户研究，询问具有两种不同专业水平的参与者（普通人群和接受过一些医学培训的人），询问他们对回归工具输出解释的主观和客观理解以及信任程度。在两项研究中，我们发现，在基于内容进行比较时，主观理解和信任方面，人们明显更喜欢 occlusion-1 解释，而不是 SHAP 解释。然而，在控制格式的情况下直接比较解释只会在大多数情况下发现 OT 解释优于 SC 解释的证据，这表明 occlusion-1 解释优于 SHAP 解释可能是由人们更喜欢文本而不是图表作为解释所驱动的。最后，我们没有发现客观理解方面解释类型之间存在差异的证据。因此，总的来说，解释的内容和格式的选择需要仔细注意，因为在某些情况下，格式而不是内容可能在改善用户体验方面发挥关键作用。]]></description>
      <guid>https://arxiv.org/abs/2408.17401</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种有效的通道修剪信息理论框架</title>
      <link>https://arxiv.org/abs/2408.16772</link>
      <description><![CDATA[arXiv:2408.16772v1 公告类型：交叉 
摘要：通道修剪是一种很有前途的加速和压缩卷积神经网络的方法。然而，目前的修剪算法仍然存在未解决的问题，即如何正确分配逐层修剪率并以令人信服的标准丢弃最不重要的通道。在本文中，我们通过信息论和神经网络的可解释性提出了一种新的通道修剪方法。具体而言，我们将信息熵视为卷积层的预期信息量。此外，如果我们将矩阵假设为线性方程组，则矩阵的秩越高，表示其解越多，这表明不确定性越大。从信息论的角度来看，秩也可以描述信息量。在神经网络中，将秩和熵视为卷积层的两个信息指标，我们提出一个融合函数来达到它们的折衷，其中融合结果被定义为“信息浓度”。在预定义逐层剪枝率时，我们以信息集中度为参考，而非采用启发式和工程调优，从而提供更易于解释的解决方案。此外，我们利用 Shapley 值（神经网络可解释性的有力工具）来评估通道贡献，并丢弃最不重要的通道以进行模型压缩，同时保持其性能。大量实验证明了我们方法的有效性和良好的性能。例如，我们的方法在 CIFAR-10 上为 ResNet-56 减少 45.5% 的 FLOP 并删除 40.3% 的参数时，准确率提高了 0.21%。此外，我们的方法在 ImageNet 上为 ResNet-50 减少 41.6% 的 FLOP 并删除 35.0% 的参数，获得了 0.43%/0.11% 的 Top-1/Top-5 准确率损失。]]></description>
      <guid>https://arxiv.org/abs/2408.16772</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强化学习训练机器人的在线行为修改，以实现富有表现力的用户控制</title>
      <link>https://arxiv.org/abs/2408.16776</link>
      <description><![CDATA[arXiv:2408.16776v1 公告类型：交叉
摘要：强化学习 (RL) 是机器人学习任务的有效方法。然而，在典型的 RL 中，最终用户在部署机器人后几乎无法控制机器人如何执行任务。为了解决这个问题，我们引入了在线行为修改的概念，在这个范例中，用户可以实时控制机器人的行为特征，因为它使用 RL 训练的策略自主完成任务。为了展示这种以用户为中心的人机交互公式的价值，我们提出了一种基于行为多样性的算法，即可调节的 RL 动力学控制 (ACORD)，并展示了它在模拟和用户研究中对在线行为修改的适用性。在研究中 (n=23)，用户在机器人自主描绘形状时调整绘画风格。我们将 ACORD 与 RL 和共享自主 (SA) 进行比较，并表明 ACORD 提供了用户偏好的控制和表达级别，与 SA 相当，但具有自主执行的潜力和 RL 的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2408.16776</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 逻辑理论的归纳学习：复杂性分级分析</title>
      <link>https://arxiv.org/abs/2408.16779</link>
      <description><![CDATA[arXiv:2408.16779v1 公告类型：交叉 
摘要：这项工作提出了一种新颖的系统方法来分析大型语言模型 (LLM) 在逻辑理论归纳方面的能力和局限性，这些模型具有来自形式推理引擎的反馈。分析是针对规则依赖结构的复杂性分级的，可以量化 LLM 性能的特定推理挑战。将 LLM 与形式化方法相结合是自然语言处理领域的一个有前途的前沿，是提高模型推理控制和可解释性的重要途径。特别是，对复杂的事实和规则集进行归纳学习，对当前的自回归模型提出了独特的挑战，因为它们缺乏明确的符号基础。虽然它们可以通过形式系统来补充，但 LLM 在归纳学习方面提供的属性尚未得到很好的理解和量化。实证结果表明，最大的 LLM 可以取得与 SOTA 归纳逻辑编程 (ILP) 系统基线相媲美的结果，但对于 LLM 来说，跟踪长谓词关系链比理论复杂性更困难。]]></description>
      <guid>https://arxiv.org/abs/2408.16779</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$EvoAl^{2048}$</title>
      <link>https://arxiv.org/abs/2408.16780</link>
      <description><![CDATA[arXiv:2408.16780v1 公告类型：交叉 
摘要：随着人工智能解决方案进入安全关键产品，人工智能产品生成的解决方案的可解释性和可解释性变得越来越重要。从长远来看，这样的解释是获得用户接受基于人工智能的系统决策的关键。我们报告了应用基于模型驱动的优化来搜索解决游戏 2048 的可解释和可解释策略。本文使用开源软件 EvoAl 描述了 GECCO&#39;24 可解释控制竞赛的解决方案。我们的目标是开发一种创建易于适应新想法的可解释政策的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.16780</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于降雨预测后处理的不确定性感知分割</title>
      <link>https://arxiv.org/abs/2408.16792</link>
      <description><![CDATA[arXiv:2408.16792v1 公告类型：交叉 
摘要：准确的降水预报对于洪水管理、农业规划、水资源分配和天气预警等应用至关重要。尽管数值天气预报 (NWP) 模型取得了进展，但它们仍然表现出显著的偏差和不确定性，尤其是在高空间和时间分辨率下。为了解决这些限制，我们探索了不确定性感知的深度学习模型，用于对每日累积定量降水预报进行后处理，以获得预测不确定性，从而更好地权衡准确性和可靠性。我们的研究比较了不同的最先进模型，并提出了一种著名的 SDE-Net 的变体，称为 SDE U-Net，专门针对像我们这样的分割问题。我们评估了它在典型和强烈降水事件中的表现。
我们的结果表明，所有深度学习模型都明显优于平均基线 NWP 解决方案，我们对 SDE U-Net 的实现在准确性和可靠性之间表现出最佳的权衡。将这些考虑不确定性的模型整合到操作预报系统中，可以改善决策并提高对天气相关事件的准备。]]></description>
      <guid>https://arxiv.org/abs/2408.16792</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>船舶设计中的生成式人工智能</title>
      <link>https://arxiv.org/abs/2408.16798</link>
      <description><![CDATA[arXiv:2408.16798v1 公告类型：交叉 
摘要：船舶设计过程错综复杂，受船体形状的影响很大，船体形状约占总成本的 70%。传统方法依赖于基于船舶设计原理和工程分析的人为迭代过程。相比之下，生成式人工智能提出了一种新方法，利用植根于机器学习和人工智能的计算算法来优化船体设计。本报告概述了为此目的系统地创建生成式人工智能，涉及数据集收集、模型架构选择、训练和验证等步骤。该报告利用由 30,000 个船体形状组成的“SHIP-D”数据集，采用高斯混合模型 (GMM) 作为生成模型架构。GMM 提供了一个统计框架来分析数据分布，这对于有效生成创新船舶设计至关重要。总体而言，这种方法有望通过探索更广阔的设计空间并有效整合多学科优化目标来彻底改变船舶设计。]]></description>
      <guid>https://arxiv.org/abs/2408.16798</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HLogformer：用于表示日志数据的分层转换器</title>
      <link>https://arxiv.org/abs/2408.16803</link>
      <description><![CDATA[arXiv:2408.16803v1 公告类型：交叉 
摘要：Transformer 因其在处理各种数据结构方面的多功能性而广受好评，但它们在日志数据中的应用仍未得到充分探索。日志数据的特点是其分层的、类似字典的结构，在使用传统的 Transformer 模型处理时会带来独特的挑战。传统方法通常依赖于手工制作的模板来解析日志，这个过程劳动密集型且缺乏通用性。此外，标准 Transformer 对日志序列的线性处理忽略了日志条目内丰富的嵌套关系，导致表示不理想和内存使用过多。
为了解决这些问题，我们引入了 HLogformer，这是一种专为日志数据设计的新型分层 Transformer 框架。HLogformer 利用日志条目的层次结构显着降低内存成本并增强表示学习。与将日志数据视为平面序列的传统模型不同，我们的框架以尊重其固有层次结构组织的方式处理日志条目。这种方法可确保对细粒度细节和更广泛的上下文关系进行全面编码。
我们的贡献有三点：首先，HLogformer 是第一个设计动态分层转换器的框架，专门用于类似字典的日志数据。其次，它大大降低了处理大量日志序列所需的内存成本。第三，全面的实验表明，HLogformer 可以更有效地编码分层上下文信息，这证明它对于合成异常检测和产品推荐等下游任务非常有效。]]></description>
      <guid>https://arxiv.org/abs/2408.16803</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>物理信息神经网络及其扩展</title>
      <link>https://arxiv.org/abs/2408.16806</link>
      <description><![CDATA[arXiv:2408.16806v1 公告类型：交叉 
摘要：在本文中，我们回顾了已成为科学机器学习主要支柱的新方法物理信息神经网络 (PINN)，我们介绍了最近的实际扩展，并提供了数据驱动的控制微分方程发现的具体示例。]]></description>
      <guid>https://arxiv.org/abs/2408.16806</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GSTAM：利用结构注意力匹配实现高效图形蒸馏</title>
      <link>https://arxiv.org/abs/2408.16871</link>
      <description><![CDATA[arXiv:2408.16871v1 公告类型：交叉 
摘要：图蒸馏已成为将大型图数据集缩减为更小、更易于管理和信息丰富的数据集的解决方案。现有方法主要针对节点分类，涉及计算密集型过程，并且无法捕获完整图数据集的真实分布。为了解决这些问题，我们引入了具有结构注意力匹配的图蒸馏 (GSTAM)，这是一种用于压缩图分类数据集的新方法。GSTAM 利用 GNN 的注意力图将原始数据集中的结构信息提炼到合成图中。结构注意力匹配机制利用 GNN 优先分类的输入图区域，有效地将这些信息提炼到合成图中并提高整体蒸馏性能。综合实验证明了 GSTAM 优于现有方法，在极端浓缩率下实现了 0.45% 至 6.5% 的更好性能，凸显了其在推进图形分类任务的蒸馏方面的潜在用途（代码可在 https://github.com/arashrasti96/GSTAM 获得）。]]></description>
      <guid>https://arxiv.org/abs/2408.16871</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习中的梯度分析推理隐私风险</title>
      <link>https://arxiv.org/abs/2408.16913</link>
      <description><![CDATA[arXiv:2408.16913v1 公告类型：交叉 
摘要：在分布式学习设置中，模型使用从潜在敏感用户数据计算出的共享梯度进行迭代更新。虽然以前的工作已经研究了共享梯度的各种隐私风险，但我们的论文旨在提供一种系统的方法来分析梯度中泄露的私人信息。我们提出了一个统一的基于游戏的框架，涵盖了广泛的攻击，包括属性、属性、分布和用户披露。我们通过对不同数据模态的五个数据集进行大量实验，研究了对手的不同不确定性如何影响他们的推理能力。我们的结果表明，在分布式学习中，仅依靠数据聚合来实现对推理攻击的隐私是无效的。我们进一步评估了五种类型的防御，即梯度修剪、有符号梯度下降、对抗性扰动、变分信息瓶颈和差异隐私，包括静态和自适应对手设置。我们提供了一个信息论观点来分析这些防御梯度推理的有效性。最后，我们介绍了一种审计属性推理隐私的方法，通过制作对抗性金丝雀记录来改进对最坏情况隐私的经验估计。]]></description>
      <guid>https://arxiv.org/abs/2408.16913</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>