<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 17 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>知识图谱上的神经符号推理：从查询角度进行的综述</title>
      <link>https://arxiv.org/abs/2412.10390</link>
      <description><![CDATA[arXiv:2412.10390v1 公告类型：新
摘要：知识图谱推理在数据挖掘、人工智能、网络和社会科学等各个领域都至关重要。这些知识图谱充当人类知识的综合存储库，有助于推断新信息。传统的符号推理尽管有其优势，但仍难以应对这些图中不完整和嘈杂的数据所带来的挑战。相比之下，神经符号人工智能的兴起标志着一项重大进步，将深度学习的稳健性与符号推理的精确性相结合。这种整合旨在开发不仅具有高度可解释性和可解释性而且用途广泛的人工智能系统，有效地弥合符号和神经方法之间的差距。此外，大型语言模型 (LLM) 的出现开辟了知识图谱推理的新领域，使以前所未有的方式提取和综合知识成为可能。本调查对知识图谱推理进行了全面回顾，重点关注各种查询类型和神经符号推理的分类。此外，它还探讨了知识图谱推理与大型语言模型的创新集成，突出了突破性进步的潜力。这份全面的概述旨在通过详细了解知识图谱推理的当前状况和未来方向，为数据挖掘、人工智能、网络和社会科学等多个领域的研究人员和从业者提供支持。]]></description>
      <guid>https://arxiv.org/abs/2412.10390</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TANGO：无需训练的具身化 AI 代理，用于执行开放世界任务</title>
      <link>https://arxiv.org/abs/2412.10402</link>
      <description><![CDATA[arXiv:2412.10402v1 公告类型：新
摘要：大型语言模型 (LLM) 已展示出将各种模块组合在一起以创建可对图像执行复杂推理任务的程序的出色能力。在本文中，我们提出了 TANGO，这是一种通过已在图像中观察到的 LLM 扩展程序组合的方法，旨在将这些功能集成到能够观察和行动的具身代理中。具体来说，通过采用简单的 PointGoal 导航模型结合基于记忆的探索策略作为引导代理穿越世界的基础原语，我们展示了单个模型如何在没有额外训练的情况下解决各种任务。我们要求 LLM 组合提供的原语来解决特定任务，仅使用提示中的几个上下文示例。我们在三个关键的具身人工智能任务上评估了我们的方法：开放集对象目标导航、多模态终身导航和开放具身问答，在具有挑战性的零样本场景中无需任何特定的微调即可实现最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2412.10402</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GROOT-2：弱监督多模态指令跟随代理</title>
      <link>https://arxiv.org/abs/2412.10410</link>
      <description><![CDATA[arXiv:2412.10410v1 公告类型：新
摘要：开发能够遵循多模态指令的代理仍然是机器人技术和人工智能领域的一项基本挑战。尽管对未标记数据集（无语言指令）进行大规模预训练使代理能够学习各种行为，但这些代理在遵循指令方面往往遇到困难。虽然使用指令标签扩充数据集可以缓解此问题，但大规模获取如此高质量的注释是不切实际的。为了解决这个问题，我们将问题定义为半监督学习任务，并引入 GROOT-2，这是一种多模态可指导代理，使用一种将弱监督与潜在变量模型相结合的新方法进行训练。我们的方法由两个关键部分组成：受限的自我模仿，它利用大量未标记的演示使策略能够学习不同的行为，以及人类意图对齐，它使用一组较小的标记演示来确保潜在空间反映人类意图。 GROOT-2 的有效性在四种不同的环境中得到验证，从视频游戏到机器人操作，证明了其强大的多模式指令遵循能力。]]></description>
      <guid>https://arxiv.org/abs/2412.10410</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>游戏动作中的隐写术</title>
      <link>https://arxiv.org/abs/2412.10442</link>
      <description><![CDATA[arXiv:2412.10442v1 公告类型：新
摘要：潜意识交流问题已在各种形式的隐写术中得到解决，主要依赖于视觉、听觉和语言媒体。然而，该领域面临着一个根本性的悖论：随着隐藏艺术的进步，启示科学也在进步，从而导致持续的进化相互作用。这项研究旨在扩展被认为是可行的隐写媒介的边界。我们探索了一种隐写范式，其中隐藏的信息通过多个代理与环境交互的事件进行传达。每个代理都充当编码器，学习一种策略来掩盖隐藏信息的存在，而这些隐藏信息似乎针对的是无辜的目标。同时，观察者充当解码器，学习将行为模式与各自的代理联系起来，尽管它们具有动态性质，从而揭示隐藏的信息。代理之间的交互受多代理强化学习框架的支配，并由观察者的反馈塑造。这个框架概括了一个博弈论困境，其中代理面临着选择合作以创建可区分的行为模式还是背叛以追求个体最优但可能重叠的偶发性行动之间的决定。作为概念证明，我们通过迷宫游戏举例说明了动作隐写术，迷宫游戏是一项导航任务，其中潜意识交流隐藏在驶向目的地的动作中。该隐写系统已通过实验评估得到系统验证，评估了其失真和容量以及在面对模拟被动和主动对手时的保密性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.10442</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在因果学习中是否存在偏见？</title>
      <link>https://arxiv.org/abs/2412.10509</link>
      <description><![CDATA[arXiv:2412.10509v1 公告类型：新
摘要：因果学习是一种认知过程，即根据可用信息发展做出因果推理的能力，通常由规范原则指导。这个过程容易出现错误和偏见，例如因果错觉，即人们认为两个变量之间存在因果关系，尽管缺乏支持证据。这种认知偏见被认为是许多社会问题的根源，包括社会偏见、刻板印象形成、错误信息和迷信思想。在这项研究中，我们调查大型语言模型 (LLM) 是否会产生因果错觉，无论是在现实世界中还是在受控的实验室环境中进行因果学习和推理。为此，我们建立了一个超过 2K 个样本的数据集，其中包括纯相关情况、零偶然性情况以及时间信息通过将潜在影响置于原因之前来排除因果关系可能性的情况。然后，我们提示模型做出陈述或回答因果问题，以评估它们在这些结构化环境中错误推断因果关系的倾向。我们的研究结果表明，法学硕士中存在强烈的因果错觉偏见。具体来说，在涉及虚假相关性的开放式生成任务中，模型表现出的偏见水平与对人类受试者的类似研究中观察到的偏见水平相当，甚至更低。然而，当面对零偶然性情景或否定因果关系的时间线索时，需要以 0-100 的量表做出反应，模型表现出明显更高的偏见。这些发现表明，模型并没有统一、一致或可靠地内化准确因果学习所必需的规范原则。]]></description>
      <guid>https://arxiv.org/abs/2412.10509</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从黑盒二元分类器中提取 PAC 决策树：基于 BERT 的语言模型上的性别偏见研究案例</title>
      <link>https://arxiv.org/abs/2412.10513</link>
      <description><![CDATA[arXiv:2412.10513v1 公告类型：新
摘要：决策树是一种流行的机器学习方法，以其固有的可解释性而闻名。在可解释的人工智能中，决策树可以用作复杂黑盒人工智能模型的替代模型，也可以用作此类模型的部分近似值。这种方法的一个关键挑战是确定提取的决策树对原始模型的准确度，以及在多大程度上可以将其作为其行为的近似值。在这项工作中，我们研究了使用可能近似正确 (PAC) 框架为从人工智能模型中提取的决策树提供保真度的理论保证。基于 PAC 框架的理论结果，我们调整了决策树算法以确保在某些条件下的 PAC 保证。我们专注于二元分类并进行实验，从基于 BERT 的语言模型中提取具有 PAC 保证的决策树。我们的结果表明这些模型存在职业性别偏见。]]></description>
      <guid>https://arxiv.org/abs/2412.10513</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://arxiv.org/abs/2412.10673</link>
      <description><![CDATA[arXiv:2412.10673v1 公告类型：新
摘要：数学奥林匹克是一项享有盛誉的竞赛，提出和解决问题的能力备受推崇。构建提出和解决奥林匹克问题的人工智能对自动定理发现和证明提出了一个尚未解决的挑战，尤其是在几何学中，因为它结合了数值和空间元素。我们介绍了 TongGeometry，这是一个支持基于树搜索的引导式问题提出和解决的欧几里得几何系统。这个高效的几何系统建立了迄今为止最广泛的几何定理库：在与现有技术相同的计算预算内，TongGeometry 发现了 67 亿条需要辅助构造的几何定理，其中 41 亿条表现出几何对称性。其中，10 个定理被提交给地区数学奥林匹克竞赛，TongGeometry 的 3 个提案在实际竞赛中入选，获得了国家队资格考试或中国和美国顶级民间奥林匹克竞赛的参赛资格。在经过微调的大型语言模型的指导下，TongGeometry 解决了 IMO-AG-30 的所有国际数学奥林匹克几何问题，首次超越金牌获得者。它还在更广泛的奥林匹克级问题上超越了现有的最先进水平。该系统的全部功能可以在消费级机器上使用，使模型更容易获得并促进其使用的广泛民主化。打个比方，与仅仅像学生一样解决问题的现有系统不同，TongGeometry 就像一个几何教练，发现、提出和证明定理。]]></description>
      <guid>https://arxiv.org/abs/2412.10673</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AuctionNet：大型游戏决策的新基准</title>
      <link>https://arxiv.org/abs/2412.10798</link>
      <description><![CDATA[arXiv:2412.10798v1 公告类型：新 
摘要：大型游戏中的决策是人工智能 (AI) 中的一个重要研究领域，对现实世界具有重大影响。然而，对现实大型游戏环境的有限访问阻碍了该领域的研究进展。在本文中，我们提出了 \textbf{AuctionNet}，这是源自现实世界在线广告平台的大型广告拍卖出价决策的基准。AuctionNet 由三部分组成：广告拍卖环境、基于环境的预生成数据集以及几种基线出价决策算法的性能评估。更具体地说，该环境通过多个模块的交互有效地复制了现实世界广告拍卖的完整性和复杂性：广告机会生成模块采用深度生成模型来弥合模拟数据和现实世界数据之间的差距，同时降低敏感数据泄露的风险；竞价模块实现了使用不同决策算法训练的各种自动竞价代理；拍卖模块以经典的广义第二价格 (GSP) 拍卖为基础，但也允许根据需要定制拍卖机制。为了方便研究并提供对游戏环境的洞察，我们还根据环境预先生成了一个相当大的数据集。该数据集包含 48 个不同代理相互竞争的轨迹，总计超过 5 亿条记录，占用 80GB 的存储空间。作为 AuctionNet 的一部分，还介绍了线性规划、强化学习和出价决策生成模型等基线算法的性能评估。我们注意到 AuctionNet 不仅适用于广告拍卖中的出价决策算法研究，也适用于大型游戏中的一般决策领域。]]></description>
      <guid>https://arxiv.org/abs/2412.10798</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在医生的推理任务中表现出超人的表现</title>
      <link>https://arxiv.org/abs/2412.10849</link>
      <description><![CDATA[arXiv:2412.10849v1 公告类型：新
摘要：大型语言模型 (LLM) 在医疗任务上的表现传统上是使用多项选择题基准来评估的。然而，这样的基准受到高度限制，充斥着 LLM 的反复令人印象深刻的表现，并且与实际临床场景中的表现关系不明确。临床推理是医生运用批判性思维收集和综合临床数据以诊断和管理医疗问题的过程，仍然是模型性能的一个有吸引力的基准。先前的 LLM 在常规和复杂的诊断场景中表现出超越临床医生的潜力。我们试图评估 OpenAI 的 o1-preview 模型，该模型旨在通过生成响应之前的思维链过程来增加运行时间。我们通过五个实验来描述 o1-preview 的性能，包括鉴别诊断生成、诊断推理显示、分类鉴别诊断、概率推理和管理推理，由经过验证的心理测量的医生专家进行裁决。我们的主要结果是将 o1-preview 的输出与具有历史人类控制和先前 LLM 基准的相同先前实验进行比较。在鉴别诊断生成和诊断和管理推理的质量方面观察到了显著的改善。在概率推理或分类鉴别诊断方面没有观察到任何改善。这项研究强调了 o1-preview 在需要复杂批判性思维的任务（例如诊断和管理）上表现出色，而其在概率推理任务上的表现与过去的模型相似。需要新的稳健基准和与人类医生相比的 LLM 能力的可扩展评估，以及在真实临床环境中评估 AI 的试验。]]></description>
      <guid>https://arxiv.org/abs/2412.10849</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>递归聚合作为答案集编程中的内涵函数：语义和强等价性</title>
      <link>https://arxiv.org/abs/2412.10975</link>
      <description><![CDATA[arXiv:2412.10975v1 公告类型：新
摘要：本文表明，由求解器 clingo 和 dlv 实现的带有聚合的程序的语义可以表征为 Here-and-There 逻辑中具有内涵函数的扩展一阶公式。此外，这种表征可用于研究任一语义下带有聚合的程序的强等价性。我们还提出了一种转换，将检查强等价性的任务简化为经典一阶逻辑中的推理，这为自动化此过程奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2412.10975</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedG-KRP：医学图谱知识表示探索</title>
      <link>https://arxiv.org/abs/2412.10982</link>
      <description><![CDATA[arXiv:2412.10982v1 公告类型：新
摘要：大型语言模型 (LLM) 最近成为强大的工具，并在许多医学领域得到应用。LLM 能够从多种来源整合大量信息以生成响应（类似于人类专家的过程），这使得许多人看到了将 LLM 部署用于临床的潜力。然而，医学是一个准确推理至关重要的领域。许多研究人员质疑经常用于测试 LLM 的多项选择题回答 (MCQA) 基准的有效性。研究人员和临床医生都必须对 LLM 的能力充满信心，才能将它们部署到医疗环境中。为了满足这种理解需求，我们引入了一种基于知识图 (KG) 的方法来评估 LLM 的生物医学推理能力。本质上，我们绘制了 LLM 如何链接医学概念，以便更好地理解它们的推理方式。我们测试了 GPT-4、Llama3-70b 和 PalmyraMed-70b（一种专门的医学模型）。我们邀请了一组医学生来审查总共 60 个 LLM 生成的图表，并将这些图表与大型生物医学知识图谱 BIOS 进行比较。我们观察到 GPT-4 在人工审查中表现最佳，但在基本事实比较中表现最差；医学模型 PalmyraMed 则相反。我们的工作提供了一种可视化 LLM 医学推理路径的方法，以便可以安全有效地在临床环境中实施它们。]]></description>
      <guid>https://arxiv.org/abs/2412.10982</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型概率推理中的双重特征</title>
      <link>https://arxiv.org/abs/2412.11009</link>
      <description><![CDATA[arXiv:2412.11009v1 公告类型：新
摘要：我们进行了三项实验来研究大型语言模型 (LLM) 如何评估后验概率。我们的研究结果揭示了在最先进的模型中后验判断中两种模式的共存：一种遵循贝叶斯规则的规范模式，以及一种依赖于相似性的基于代表性的模式——与人类的系统 1 和系统 2 思维相似。此外，我们观察到 LLM 很难从记忆中回忆起基准率信息，而制定及时的工程策略来减轻基于代表性的判断可能具有挑战性。我们进一步推测，双重判断模式可能是强化学习中采用对比损失函数的结果，这些损失函数来自人类反馈。我们的研究结果强调了减少 LLM 中认知偏差的潜在方向以及在关键领域谨慎部署 LLM 的必要性。]]></description>
      <guid>https://arxiv.org/abs/2412.11009</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法律：托管和基金服务合同的法律代理工作流程</title>
      <link>https://arxiv.org/abs/2412.11063</link>
      <description><![CDATA[arXiv:2412.11063v1 公告类型：新
摘要：托管和基金服务领域的法律合同管理着关键方面，例如关键提供商责任、费用表和赔偿权利。然而，由于冗长的非结构化文本流、有限的 LLM 上下文窗口和复杂的法律术语，现成的大型语言模型 (LLM) 很难吸收这些合同。为了应对这些挑战，我们引入了 LAW（托管和基金服务合同的法律代理工作流程）。LAW 采用模块化设计，通过协调一套特定于领域的工具和文本代理来响应用户查询。我们的实验表明，通过集成多个专门的代理和工具，LAW 的表现明显优于基线。LAW 在计算合同终止日期等复杂任务方面尤其出色，超过基线 92.9%。此外，LAW 通过利用可重复使用的、特定领域的工具，为传统的精细法律 LLM 提供了一种经济高效的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.11063</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>既见森林又见树木：使用大型多模态模型解决基于可视图形和树的数据结构问题</title>
      <link>https://arxiv.org/abs/2412.11088</link>
      <description><![CDATA[arXiv:2412.11088v1 公告类型：新
摘要：生成式人工智能系统的最新进展引起了教育工作者对学术诚信的担忧。除了擅长解决编程问题和基于文本的多项选择题之外，最近的研究还发现，大型多模态模型 (LMM) 可以仅基于图像解决帕森斯问题。然而，这类问题本质上仍然是基于文本的，依赖于模型将代码块的图像转换为其对应文本的能力。在本文中，我们进一步研究了 LMM 仅基于图像解决图形和树数据结构问题的能力。为了实现这一点，我们通过计算构建和评估一个新的基准数据集，该数据集包含 9,072 个不同的图形和树数据结构任务样本，以评估 GPT-4o、GPT-4v、Gemini 1.5 Pro、Gemini 1.5 Flash、Gemini 1.0 Pro Vision 和 Claude 3 模型系列的性能。 GPT-4o 和 Gemini 1.5 Flash 分别在树和图上表现最佳。GPT-4o 在树样本上的准确率达到 87.6%，而 Gemini 1.5 Flash 在图样本上的准确率达到 56.2%。我们的研究结果强调了结构和视觉变化对模型性能的影响。这项研究不仅引入了 LMM 基准以促进复制和进一步探索，而且还强调了 LMM 在解决复杂计算问题方面的潜力，对教学和评估实践具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2412.11088</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型打造活跃商人非玩家角色</title>
      <link>https://arxiv.org/abs/2412.11189</link>
      <description><![CDATA[arXiv:2412.11189v1 公告类型：新
摘要：我们强调了导致当前商人非玩家角色 (NPC) 被动的两个重要问题：定价和沟通。虽然沉浸式互动一直是焦点，但商人 NPC 和玩家之间就商品价格进行的谈判尚未得到足够的重视。首先，我们将被动定价定义为商家修改预定义商品价格的有限能力。其次，被动沟通意味着商家只能以脚本方式与玩家互动。为了解决这些问题并创建一个活跃的商家 NPC，我们提出了一个基于大型语言模型 (LLM) 的商家框架，称为 MART，它由评估模块和谈判模块组成。我们进行了两个实验，通过比较不同的训练方法和 LLM 大小来指导游戏开发者选择合适的实现。我们的研究结果表明，微调方法（例如监督微调 (SFT) 和知识蒸馏 (KD)）在使用较小的 LLM 实现主动商家 NPC 时是有效的。此外，我们发现 LLM 的响应中出现了三起不正常的情况。我们希望我们的发现能够指导开发人员使用 LLM 开发活跃的商家 NPC。]]></description>
      <guid>https://arxiv.org/abs/2412.11189</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代号作为大型语言模型的基准</title>
      <link>https://arxiv.org/abs/2412.11373</link>
      <description><![CDATA[arXiv:2412.11373v1 公告类型：新
摘要：在本文中，我们建议使用流行的基于单词的棋盘游戏 Codenames 作为评估大型语言模型 (LLM) 推理能力的合适基准。Codenames 对实现成功的 AI 性能提出了一个非常有趣的挑战，需要对语言、心智理论和认知推理能力有深入的理解。之前为 Codenames 开发代理的尝试很大程度上依赖于词嵌入技术，这些技术的词汇范围有限，并且与不同方法搭配使用时表现不佳。LLM 已经展示了增强的基于语言任务的推理和理解能力，但在横向思维挑战中仍然会受到影响。我们在各种棋盘设置中评估了几种最先进的 LLM 的能力，包括 GPT-4o、Gemini 1.5、Claude 3.5 Sonnet 和 Llama 3.1。我们的结果表明，虽然某些 LLM 总体上表现优于其他 LLM，但不同的模型在游戏过程中表现出不同的突发行为，并且在特定角色中表现出色。我们还评估了不同组合的 LLM 在合作游戏时的表现，表明 LLM 代理比以前的技术更适用于更广泛的队友。]]></description>
      <guid>https://arxiv.org/abs/2412.11373</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RL-LLM-DT：一种基于 RL 评估和 LLM 增强的自动决策树生成方法</title>
      <link>https://arxiv.org/abs/2412.11417</link>
      <description><![CDATA[arXiv:2412.11417v1 公告类型：新
摘要：传统上，双人零和游戏的人工智能开发依赖于两种主要技术：决策树和强化学习 (RL)。一种常见的方法是使用固定的决策树作为一个玩家的策略，同时训练 RL 代理作为对手来识别决策树中的漏洞，从而迭代地提高其战略实力。然而，这个过程通常需要大量的人工干预来在识别决策树的弱点后对其进行改进，导致效率低下并阻碍策略增强过程的完全自动化。幸运的是，大型语言模型 (LLM) 的出现为自动化该过程提供了变革性的机会。我们提出了 RL-LLM-DT，一种基于 RL 评估和 LLM 增强的自动决策树生成方法。给定初始决策树，该方法涉及两个重要的迭代步骤。响应策略搜索：RL 用于发现针对决策树的反策略。策略改进：LLM 分析故障场景并生成改进的决策树代码。在我们的方法中，RL 专注于发现决策树的缺陷，而 LLM 则被要求生成改进的决策树。当 RL 找不到树的任何缺陷或 LLM 无法改进树时，迭代改进过程终止。为了评估这种集成方法的有效性，我们在冰壶比赛中进行了实验。经过迭代改进后，我们基于决策树的冰壶 AI 在 Jidi 平台上的 34 个冰壶 AI 中排名第一，这表明 LLM 可以显著增强决策树的鲁棒性和适应性，代表了游戏 AI 领域的重大进步。我们的代码可以在 https://github.com/Linjunjie99/RL-LLM-DT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.11417</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经典路径规划问题质量多样性算法的理论分析</title>
      <link>https://arxiv.org/abs/2412.11446</link>
      <description><![CDATA[arXiv:2412.11446v1 公告类型：新
摘要：质量多样性 (QD) 算法已被证明可以为机器人、游戏和组合优化中的挑战性问题提供一系列高质量的解决方案。到目前为止，解释它们在实践中的良好行为的理论基础远远落后于它们的实际成功。我们为这些算法的理论理解做出了贡献，并研究了 QD 算法在寻求多个解决方案的经典规划问题中的行为。我们研究了所有对最短路径 (APSP) 问题，该问题基于给定输入图的所有节点对给出了行为空间的自然公式，可供 Map-Elites QD 算法使用。我们的结果表明，Map-Elites QD 算法能够高效地并行计算每对节点的最短路径。此外，我们研究了交叉的父选择技术，与标准 QD 方法相比，该技术表现出显着的速度提升。]]></description>
      <guid>https://arxiv.org/abs/2412.11446</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对具身代理的对比提示集成高效策略自适应</title>
      <link>https://arxiv.org/abs/2412.11484</link>
      <description><![CDATA[arXiv:2412.11484v1 公告类型：新
摘要：对于与环境交互的具身强化学习 (RL) 代理，希望能够快速适应看不见的视觉观察，但实现零样本适应能力在 RL 环境中被视为一个具有挑战性的问题。为了解决这个问题，我们提出了一个新颖的对比提示集成 (ConPE) 框架，该框架利用预训练的视觉语言模型和一组视觉提示，从而能够根据具身代理遇到的各种环境和物理变化进行有效的策略学习和适应。具体来说，我们设计了一种基于引导注意力的集成方法，在视觉语言模型上使用多个视觉提示来构建稳健的状态表示。每个提示都是根据单个领域因素进行对比学习的，这些因素会显著影响代理的自我中心感知和观察。对于给定的任务，基于注意力的集成和策略是联合学习的，因此得到的状态表示不仅可以推广到各个领域，而且还针对学习任务进行了优化。通过实验，我们表明 ConPE 在几个具体代理任务中表现优于其他最先进的算法，包括 AI2THOR 中的导航、自我中心元世界中的操纵和 CARLA 中的自动驾驶，同时还提高了策略学习和适应的样本效率。]]></description>
      <guid>https://arxiv.org/abs/2412.11484</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从 LLM 到现成代理的具身 CoT 提炼</title>
      <link>https://arxiv.org/abs/2412.11499</link>
      <description><![CDATA[arXiv:2412.11499v1 公告类型：新
摘要：我们解决了在决策系统在容量有限的现成设备上及时运行的环境中利用大型语言模型 (LLM) 执行复杂具身任务的挑战。我们提出了 DeDer，这是一个将具身推理能力从 LLM 分解和提炼为高效的基于小型语言模型 (sLM) 的策略的框架。在 DeDer 中，基于 LLM 的策略的决策过程被重组为具有推理策略和规划策略的层次结构。推理策略是从通过 LLM 的具身情境学习和自我验证生成的数据中提炼出来的，因此它可以产生有效的原理。在原理的指导下，规划策略可以有效地提供优化的计划。反过来，DeDer 允许采用部署在现成设备上的两种策略的 sLM。此外，为了提高针对具体化任务的中间原理的质量，我们设计了具体化知识图谱，并且为了通过单一推理及时生成多个原理，我们还使用了对比提示注意模型。我们在 ALFRED 基准上进行的实验表明，DeDer 超越了领先的语言规划和提炼方法，表明通过 DeDer 得出的基于 sLM 的具体化策略的适用性和效率。]]></description>
      <guid>https://arxiv.org/abs/2412.11499</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>