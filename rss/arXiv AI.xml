<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LABIIUM：人工智能增强型零配置测量自动化系统</title>
      <link>https://arxiv.org/abs/2412.16172</link>
      <description><![CDATA[arXiv:2412.16172v1 公告类型：新
摘要：实验室环境的复杂性需要简化仪器交互并增强测量自动化的解决方案。传统工具通常需要配置、软件和编程技能，从而阻碍了生产力。以前的方法，包括专用软件套件和自定义脚本，通常无法提供符合编程实践的用户友好型解决方案。我们介绍了 LABIIUM，这是一种 AI 增强型零配置测量自动化系统，旨在简化实验工作流程并提高用户生产力。LABIIUM 集成了一个由大型语言模型 (LLM) 驱动的 AI 助手来生成代码。LABIIUM 的实验室自动化测量桥 (LAMB) 使用 VSCode 和 Python 等标准工具实现无缝仪器连接，从而消除了设置开销。为了展示其功能，我们进行了实验，涉及测量带有电流源负载的简单双晶体管反相放大器的参数传递曲线。使用不同的提示场景对 AI 助手进行了评估，并与多个模型进行了比较，包括 Claude Sonnet 3.5、Gemini Pro 1.5 和 GPT-4o。使用实施梯度加权自适应随机采样 (GWASS) 方法的专家解决方案作为基线。将 AI 助手生成的解决方案与专家解决方案和具有 10,000 个点的均匀线性扫描基线进行了比较。图表结果显示，LLM 能够成功完成最基本的均匀扫描，但 LLM 无法开发自适应扫描算法来与 GWASS 竞争。评估强调了 LABIIUM 提高实验室生产力和支持研究和行业数字化转型的能力，并强调了未来需要开展的工作，以提高 LLM 在电子测量科学任务中的表现。]]></description>
      <guid>https://arxiv.org/abs/2412.16172</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从法学硕士 (LLM) 中挖掘数学猜想：一种修剪方法</title>
      <link>https://arxiv.org/abs/2412.16177</link>
      <description><![CDATA[arXiv:2412.16177v1 公告类型：新
摘要：我们提出了一种使用大型语言模型 (LLM) 生成数学猜想的新方法。我们重点关注溶解器（一种群论中相对较新的构造），展示了如何利用 ChatGPT、Gemini 和 Claude 等 LLM 来生成猜想。通过允许 LLM 生成反例，可以对这些猜想进行修剪。我们的结果表明，LLM 能够产生原创的猜想，这些猜想虽然不是开创性的，但可以通过反例合理或可证伪，尽管它们在代码执行方面表现出局限性。]]></description>
      <guid>https://arxiv.org/abs/2412.16177</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可能需要更复杂的环境来发现不断发展的机器人终身学习的好处</title>
      <link>https://arxiv.org/abs/2412.16184</link>
      <description><![CDATA[arXiv:2412.16184v1 公告类型：新
摘要：众所周知，生命内学习（定义为额外的控制器优化循环）有利于机器人形态的进化，以适应运动。在这项工作中，我们通过在两种不同的环境中进行比较来进一步研究这一点：一个容易的平坦环境和一个更具挑战性的山丘环境。我们表明，在丘陵环境中学习比在平坦环境中更有益，并且可能需要在更具挑战性的环境中评估机器人才能看到学习的好处。]]></description>
      <guid>https://arxiv.org/abs/2412.16184</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TAACKIT：使用持续知识集成工具进行跟踪注释和分析</title>
      <link>https://arxiv.org/abs/2412.16228</link>
      <description><![CDATA[arXiv:2412.16228v1 公告类型：新
摘要：机器学习 (ML) 是一种强大的工具，可用于高效分析数据、检测模式和预测文本、音频和图像等各个领域的趋势。注释工具的可用性对于 ML 应用程序的进步至关重要，它可以生成可靠的注释数据。在地理空间轨迹领域，缺乏此类工具来注释和验证数据会阻碍快速且易于访问的 ML 应用程序开发。本文介绍了使用持续知识集成工具 (TAACKIT) 的轨迹注释和分析，以实现注释地理空间轨迹数据和验证 ML 模型的至关重要的功能。我们演示了空中交通领域的 ML 应用程序用例，以说明其数据注释和模型评估能力，并量化注释工作量的减少。]]></description>
      <guid>https://arxiv.org/abs/2412.16228</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将认知的通用模型扩展到情感的建议</title>
      <link>https://arxiv.org/abs/2412.16231</link>
      <description><![CDATA[arXiv:2412.16231v1 公告类型：新
摘要：在任何完整的类人思维模型中，认知和情感都必须结合在一起。本文提出了对认知通用模型（一种关于这种思维需要什么的不断发展的共识）的扩展，包括情感和元认知评估的一对相关模块，以及这两个新模块与通用模型现有模块和链接之间的普遍联系。]]></description>
      <guid>https://arxiv.org/abs/2412.16231</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>陪审团评估定理</title>
      <link>https://arxiv.org/abs/2412.16238</link>
      <description><![CDATA[arXiv:2412.16238v1 公告类型：新
摘要：多数投票 (MV) 是典型的“群体智慧”算法。考虑 MV 何时最适合群体决策的定理可以追溯到孔多塞 1785 年的陪审团决策定理。孔多塞使用的错误独立性假设在这里被用来证明一个纯粹代数评估 (AE) 的陪审团评估定理。三个或更多二元陪审员足以获得他们参加的联合测试中唯一可能的正确性统计数据。AE 被证明优于 MV，因为它允许人们根据陪审员的同意或不同意来选择少数人的投票。此外，AE 对错误独立性假设的失败感到震惊。对来自美国社区调查的人口统计数据集进行标记实验，以在几乎与错误无关的集合上比较 MV 和 AE。一般来说，使用代数评估可以获得更好的分类器评估和组标签决策。]]></description>
      <guid>https://arxiv.org/abs/2412.16238</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代理商还不够</title>
      <link>https://arxiv.org/abs/2412.16241</link>
      <description><![CDATA[arXiv:2412.16241v1 公告类型：新
摘要：随着人工智能 (AI) 日益融入我们生活的各个方面，代理正在经历复兴。这些代表人类行事的自主程序既不是新事物，也不是主流人工智能运动所独有的。通过探索代理的过去化身，我们可以了解以前做过什么、什么有效，更重要的是，什么没有成功以及原因。这种理解让我们能够检查当前对代理的关注有何不同。虽然生成式人工智能很有吸引力，但仅靠这项技术不足以让新一代代理更成功。为了使当前的代理浪潮有效且可持续，我们设想了一个生态系统，它不仅包括代理，还包括代表用户偏好和行为的 Sims，以及直接与用户交互并在代理的帮助下协调用户任务执行的助手。]]></description>
      <guid>https://arxiv.org/abs/2412.16241</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经多样性是集体人工智能学习的关键</title>
      <link>https://arxiv.org/abs/2412.16244</link>
      <description><![CDATA[arXiv:2412.16244v1 公告类型：新
摘要：世界上许多最紧迫的问题，例如气候变化和全球和平，都需要复杂的集体解决问题的技能。最近的研究表明，个人行为的多样性是发展这种技能和提高集体表现的关键。然而，集体人工智能学习中的行为多样性研究不足，当今的机器学习范式通常倾向于同质代理策略而不是异质代理策略，这主要是由于计算方面的考虑。在这项工作中，我们采用新颖的多样性测量和控制范式来研究行为异质性对集体人工智能学习几个方面的影响。通过团队合作和其他合作任务中的实验，我们展示了无偏见的行为角色的出现，这些角色可以改善团队成果；神经多样性如何与形态多样性协同作用；多样化的代理如何在稀疏的奖励环境中更有效地找到合作解决方案；以及行为异质的团队如何学习和保留潜在技能以克服反复的干扰。总体而言，我们的结果表明，通过控制多样性，我们可以获得比同质训练范式更重要的好处，这表明多样性是集体人工智能学习的一个基本组成部分，这一见解迄今为止被忽视了。]]></description>
      <guid>https://arxiv.org/abs/2412.16244</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化低速自动驾驶：强化学习方法实现路线稳定性和最高速度</title>
      <link>https://arxiv.org/abs/2412.16248</link>
      <description><![CDATA[arXiv:2412.16248v1 公告类型：新
摘要：近年来，自动驾驶引起了广泛关注，尤其是在优化不同条件下的车辆性能方面。本文解决了在遵循预定义路线的同时保持低速自动驾驶的最大速度稳定性的挑战。利用强化学习 (RL)，我们提出了一种新颖的方法来优化驾驶策略，使车辆即使在低速情况下也能实现接近最大速度而不会影响安全性或路线准确性。]]></description>
      <guid>https://arxiv.org/abs/2412.16248</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Autoware.Flex：人机指导的动态可重构自动驾驶系统</title>
      <link>https://arxiv.org/abs/2412.16265</link>
      <description><![CDATA[arXiv:2412.16265v1 公告类型：新
摘要：现有的自动驾驶系统 (ADS) 可以独立做出驾驶决策，但它们面临两个重大限制。首先，在复杂场景中，ADS 可能会误解环境并做出不适当的驾驶决策。其次，这些系统无法将人类驾驶偏好纳入其决策过程。本文提出了 Autoware.Flex，这是一种新颖的 ADS 系统，它将人类输入纳入驾驶过程，允许用户指导 ADS 做出更合适的决策并确保他们的偏好得到满足。实现这一目标需要解决两个关键挑战：(1) 将以自然语言表达的人类指令转换为 ADS 可以理解的格式，以及 (2) 确保这些指令在 ADS 的决策框架内安全一致地执行。对于第一个挑战，我们采用大型语言模型 (LLM) 并辅以 ADS 专业知识库来增强特定领域的翻译。对于第二个挑战，我们设计了一种验证机制，以确保人类指令能够带来安全一致的驾驶行为。在模拟器和现实世界的自动驾驶汽车上进行的实验表明，Autoware.Flex 可以有效地解释人类指令并安全地执行它们。]]></description>
      <guid>https://arxiv.org/abs/2412.16265</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MetaScientist：用于自动化机械超材料设计的人机协同框架</title>
      <link>https://arxiv.org/abs/2412.16270</link>
      <description><![CDATA[arXiv:2412.16270v1 公告类型：新 
摘要：新型机械超材料的发现是一个知识密集且资源要求高的过程，其特性主要由其工程结构而不是化学成分决定。为了加速新型超材料的设计，我们提出了 MetaScientist，这是一个人机协同系统，它将先进的人工智能功能与专家监督相结合，主要包括两个阶段：（1）假设生成，系统执行复杂的推理以生成新颖且科学合理的假设，并以领域特定的基础模型和从现有文献中检索到的归纳偏差为支持；（2）3D 结构合成，使用基于文本假设的新型 3D 扩散模型合成 3D 结构，并使用基于 LLM 的细化模型对其进行细化，以获得更好的结构特性。在每个阶段，领域专家都会迭代验证系统输出，并提供反馈和补充材料，以确保输出与科学原理和人类偏好保持一致。通过人类科学家的广泛评估，MetaScientist 能够提供新颖、有效的机械超材料设计，这些设计有可能在超材料领域产生巨大影响。]]></description>
      <guid>https://arxiv.org/abs/2412.16270</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SMILE 映射基于指令的图像编辑思维</title>
      <link>https://arxiv.org/abs/2412.16277</link>
      <description><![CDATA[arXiv:2412.16277v1 公告类型：新
摘要：尽管基于指令的图像编辑模型在生成高质量图像方面取得了最新进展，但它们仍被称为黑匣子，是透明度和用户信任的重大障碍。为了解决这个问题，我们引入了 SMILE（具有局部解释的统计模型无关可解释性），这是一种新颖的模型无关的局部可解释性，它提供了可视化热图来阐明文本元素对图像生成模型的影响。我们将我们的方法应用于各种基于指令的图像编辑模型，如 Pix2Pix、Image2Image-turbo 和 Diffusers-Inpaint，并展示了我们的模型如何提高可解释性和可靠性。此外，我们使用稳定性、准确性、保真度和一致性指标来评估我们的方法。这些发现表明，模型无关的可解释性在医疗保健和自动驾驶等关键应用中具有可靠性和可信度的惊人潜力，同时也鼓励进一步研究可解释性在增强可靠图像编辑模型方面的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.16277</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根据患者报告的结果对 LLM 和 SLM 进行基准测试</title>
      <link>https://arxiv.org/abs/2412.16291</link>
      <description><![CDATA[arXiv:2412.16291v1 公告类型：新
摘要：LLM 已经改变了许多任务的执行，包括医疗领域的任务。其中，将患者报告的结果 (PRO) 总结为简洁的自然语言报告对临床医生特别有意义，因为它使他们能够专注于关键的患者问题并花更多时间进行有意义的讨论。虽然现有的 LLM 工作（如 GPT-4）已经显示出令人印象深刻的结果，但利用 SLM 可能会带来真正的突破，因为它们具有可在本地部署的优势，可确保患者数据隐私并遵守医疗保健法规。本研究将几种 SLM 与 LLM 进行了基准测试，以总结放射治疗背景下的患者报告问答表。我们使用各种指标来评估它们的精确度和可靠性。研究结果强调了 SLM 在高风险医疗任务中的前景和局限性，促进了更高效和隐私保护的 AI 驱动的医疗保健解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.16291</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现具有神经自我-他人重叠的安全诚实的 AI 代理</title>
      <link>https://arxiv.org/abs/2412.16325</link>
      <description><![CDATA[arXiv:2412.16325v1 公告类型：新
摘要：随着人工智能系统越来越多地做出关键决策，欺骗性人工智能对信任和安全构成了重大挑战。我们提出了自我-他人重叠 (SOO) 微调，这是人工智能安全领域的一种有前途的方法，可以大大提高我们构建诚实人工智能的能力。受认知神经科学对同理心的研究启发，SOO 旨在协调人工智能模型如何代表自己和他人。我们对具有 7B、27B 和 78B 参数的 LLM 进行的实验证明了 SOO 的有效性：Mistral-7B-Instruct-v0.2 的欺骗性响应从 73.6% 下降到 17.2%，且一般任务绩效没有下降，而 Gemma-2-27b-it 和 CalmeRys-78B-Orpo-v0.1 的欺骗性响应分别从 100% 降低到 9.3% 和 2.7%，对能力的影响很小。在强化学习场景中，经过 SOO 训练的代理表现出显著减少的欺骗行为。SOO 专注于对比自我和其他参照观察，为跨 AI 架构的泛化提供了强大的潜力。虽然当前的应用侧重于语言模型和简单的 RL 环境，但 SOO 可以为更广泛领域的更值得信赖的 AI 铺平道路。伦理影响和长期影响值得进一步研究，但 SOO 代表了 AI 安全研究向前迈出的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2412.16325</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社会科学对于社会责任基础模型的实施必不可少</title>
      <link>https://arxiv.org/abs/2412.16355</link>
      <description><![CDATA[arXiv:2412.16355v1 公告类型：新
摘要：随着基础模型的兴起，人们越来越担心它们的潜在社会影响。社会科学长期以来一直在研究变革性技术对现有权力体系的社会影响，以及这些体系如何被新技术破坏或强化。在这篇立场文件中，我们以先前研究早期技术的社会影响为基础，提出了一个概念框架，将基础模型研究为社会技术系统，结合社会科学专业知识，以更好地理解这些模型如何影响权力体系，预测在各种应用中部署这些模型的影响，并研究旨在减轻社会危害的技术干预措施的有效性。我们提倡在基础模型研究和开发的所有阶段建立人工智能和社会科学之间的跨学科和协作研究范式，以促进对社会负责的研究实践和用例，并概述了促进此类研究的几种策略。]]></description>
      <guid>https://arxiv.org/abs/2412.16355</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于碰撞的多边缘最优传输动力学</title>
      <link>https://arxiv.org/abs/2412.16385</link>
      <description><![CDATA[arXiv:2412.16385v1 公告类型：新
摘要：受玻尔兹曼动力学的启发，我们提出了一种基于碰撞的动力学，采用蒙特卡罗解决方案算法，通过随机成对交换样本索引来近似解决多边际最优传输问题。所提出方法的计算复杂度和内存使用量与样本数量成线性关系，使其在高维设置中具有很高的吸引力。在几个例子中，我们展示了所提出方法与最先进方法相比的效率。]]></description>
      <guid>https://arxiv.org/abs/2412.16385</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数字内容创作中生成式人工智能模型的伦理与技术问题</title>
      <link>https://arxiv.org/abs/2412.16389</link>
      <description><![CDATA[arXiv:2412.16389v1 公告类型：新
摘要：GPT-4o 和 DALL-E 3 等生成式 AI 模型正在重塑数字内容创作，为行业提供工具，以非凡的创造力和效率生成多样化和复杂的文本和图像。本文研究了这些模型在创意工作流程中的能力和挑战。虽然它们在生成具有创造力、多样性和技术精度的内容方面表现出色，但也引发了重大的道德问题。我们的研究解决了两个关键的研究问题：(a) 这些模型在创造力、多样性、准确性和计算效率方面的表现如何，以及 (b) 它们带来的道德风险，特别是在偏见、真实性和潜在滥用方面。通过一系列结构化的实验，我们分析了它们的技术性能并评估了其输出的道德影响，结果表明，尽管生成模型增强了创造性过程，但它们往往反映了训练数据的偏见，并带有需要仔细监督的道德漏洞。这项研究提出了道德准则，以支持负责任的人工智能融入行业实践，促进创新与道德诚信之间的平衡。]]></description>
      <guid>https://arxiv.org/abs/2412.16389</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于持续分层强化学习和规划的自主选项发明</title>
      <link>https://arxiv.org/abs/2412.16395</link>
      <description><![CDATA[arXiv:2412.16395v1 公告类型：新
摘要：抽象是扩大强化学习 (RL) 的关键。然而，自主学习抽象状态和动作表示以实现迁移和泛化仍然是一个具有挑战性的未解决的问题。本文提出了一种在连续 RL 设置中发明、表示和利用表示时间扩展行为的选项的新方法。我们的方法解决了一系列随机问题，这些问题的特点是视野长、奖励稀疏、转换和奖励函数未知。
我们的方法不断学习和维护可解释的状态抽象，并使用它来发明具有抽象符号表示的高级选项。这些选项满足三个关键要求：(1) 可组合性，以便通过前瞻规划有效解决任务，(2) 可跨问题实例重用，以最大限度地减少重新学习的需要，以及 (3) 相互独立，以减少选项之间的干扰。我们的主要贡献是不断学习具有符号表示的可迁移、可泛化选项的方法，以及将搜索技术与 RL 相结合以有效地规划这些学习到的选项来解决新问题的方法。实证结果表明，最终方法可以有效地学习抽象知识并在问题实例之间迁移抽象知识，与最先进的方法相比，其样本效率更高。]]></description>
      <guid>https://arxiv.org/abs/2412.16395</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识作为遍历性的破缺</title>
      <link>https://arxiv.org/abs/2412.16411</link>
      <description><![CDATA[arXiv:2412.16411v1 公告类型：新
摘要：我们构建了一个热力学势，可以指导在一组二元自由度上定义的生成模型的训练。我们认为，在描述减少后，为了使生成模型在计算上可管理，势会产生多个最小值。这反映在生成模型本身的自由能中出现了多个最小值。采用 N 个二元自由度的训练样本的种类通常远低于全相空间的大小 2^N。我们认为，未表示的配置应该被认为是由一个高温相组成，该高温相与组成训练集的配置之间有一个很大的能隙。因此，训练相当于以不同束缚态库的形式对自由能表面进行采样，每个束缚态都会破坏遍历性。遍历性的破坏会阻止逃逸到组成高温相的近连续状态中；因此，这对于正常的功能是必要的。然而，它可能会产生副作用，限制对训练集中代表性不足的模式的访问。同时，库内的遍历性破坏使学习和检索都变得复杂。作为补救措施，可以同时使用多个生成模型——每个自由能最小值最多一个模型。]]></description>
      <guid>https://arxiv.org/abs/2412.16411</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度强化学习的航空航天安全关键应用系统</title>
      <link>https://arxiv.org/abs/2412.16489</link>
      <description><![CDATA[arXiv:2412.16489v1 公告类型：新
摘要：航空航天领域人工智能 (AI) 应用的最新进展已显示出显着增长，特别是在控制系统方面。随着高性能计算 (HPC) 平台的不断发展，它们有望取代当前的飞行控制或发动机控制计算机，从而提高计算能力。这种转变将允许实时 AI 应用程序（例如图像处理和缺陷检测）无缝集成到监控系统中，提供实时感知和增强的故障检测和适应。此外，AI 在航空航天领域的潜力还延伸到控制系统，其应用范围从完全自主到通过辅助功能增强人类控制。AI，特别是深度强化学习 (DRL)，可以显着改进控制系统，无论是用于自主操作还是作为增强工具。]]></description>
      <guid>https://arxiv.org/abs/2412.16489</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>