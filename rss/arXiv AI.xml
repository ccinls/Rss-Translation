<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>InfraLib：为大规模基础设施管理提供强化学习和决策支持</title>
      <link>https://arxiv.org/abs/2409.03167</link>
      <description><![CDATA[arXiv:2409.03167v1 公告类型：新
摘要：基础设施系统的有效管理对于经济稳定、可持续性和公共安全至关重要。然而，由于系统规模庞大、组件随机恶化、部分可观测性和资源限制，基础设施管理具有挑战性。虽然强化学习 (RL) 等数据驱动方法为优化管理策略提供了有希望的途径，但由于缺乏合适的模拟环境，它们在基础设施中的应用受到限制。我们介绍了 InfraLib，这是一个用于建模和分析基础设施管理问题的综合框架。InfraLib 采用分层随机方法来真实地模拟基础设施系统及其恶化。它支持实际功能，例如建模组件不可用性、周期性预算和灾难性故障。为了促进研究，InfraLib 提供了用于专家数据收集、模拟驱动分析和可视化的工具。我们通过对现实世界道路网络的案例研究和具有 100,000 个组件的综合基准来展示 InfraLib 的功能。]]></description>
      <guid>https://arxiv.org/abs/2409.03167</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>寻找树木：通过搜索实现黑箱系统的决策树策略合成</title>
      <link>https://arxiv.org/abs/2409.03260</link>
      <description><![CDATA[arXiv:2409.03260v1 公告类型：新
摘要：决策树由于其可解释性，作为（动态）系统的控制策略很有吸引力。不幸的是，构建或综合这样的策略是一项艰巨的任务。以前的方法通过模仿神经网络策略、近似通过形式综合获得的表格策略、采用强化学习或将问题建模为混合整数线性程序来实现这一点。然而，这些工作可能需要访问难以获得的准确策略或环境的形式模型（在形式综合的范围内），并且可能无法保证最终树策略的质量或大小。相比之下，我们提出了一种在给定黑盒环境和规范以及树谓词离散化的情况下综合最佳决策树策略的方法，其中最优性是根据实现目标的步骤数定义的。我们的方法是一种专门的搜索算法，它系统地探索给定离散化下的（指数级大的）决策树空间。关键组件是一种新颖的修剪机制，可显著减少搜索空间。我们的方法代表了一种概念上新颖的方法，即使在具有黑盒规范的黑盒环境中，也可以合成具有最优性保证的小型决策树策略。]]></description>
      <guid>https://arxiv.org/abs/2409.03260</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>战略思维链：通过策略引出引导法学硕士中的准确推理</title>
      <link>https://arxiv.org/abs/2409.03271</link>
      <description><![CDATA[arXiv:2409.03271v1 公告类型：新
摘要：思路链 (CoT) 范式已成为增强大型语言模型 (LLM) 推理能力的关键方法。然而，尽管 CoT 方法被广泛采用并取得了成功，但由于无法始终如一地确保生成的推理路径的质量，因此经常表现出不稳定性，从而导致推理性能不佳。为了应对这一挑战，我们提出了 \textbf{战略思路链} (SCoT)，这是一种新颖的方法，旨在通过在生成中间推理步骤之前整合战略知识来改进 LLM 性能。SCoT 在单个提示中采用两阶段方法：首先引出有效的问题解决策略，然后用它来指导生成高质量的 CoT 路径和最终答案。我们在八个具有挑战性的推理数据集上进行的实验显示出显著的改进，包括使用 Llama3-8b 模型在 GSM8K 数据集上分别增加了 21.05% 和在 Tracking\_Objects 数据集上增加了 24.13%。此外，我们扩展了 SCoT 框架以开发一种具有自动匹配演示的少样本方法，从而获得了更强大的结果。这些发现强调了 SCoT 的有效性，凸显了其在复杂推理任务中大幅提高 LLM 性能的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.03271</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChartMoE：用于高级图表理解的专家连接器的混合体</title>
      <link>https://arxiv.org/abs/2409.03277</link>
      <description><![CDATA[arXiv:2409.03277v1 公告类型：新
摘要：自动图表理解对于内容理解和文档解析至关重要。多模态大型语言模型 (MLLM) 通过特定领域的对齐和微调展示了卓越的图表理解能力。然而，对齐训练在图表领域的应用仍未得到充分探索。为了解决这个问题，我们提出了 ChartMoE，它采用混合专家 (MoE) 架构来取代传统的线性投影仪来弥合模态差距。具体来说，我们通过不同的对齐任务训练多个线性连接器，这些连接器被用作不同专家的基础初始化参数。此外，我们引入了 ChartMoE-Align，这是一个包含超过 900K 图表表 JSON 代码四倍的数据集，用于执行三个对齐任务（图表表/JSON/代码）。结合 vanilla 连接器，我们以四种不同的方式初始化不同的专家，并采用高质量的知识学习来进一步完善 MoE 连接器和 LLM 参数。大量实验证明了 MoE 连接器和我们的初始化策略的有效性，例如，ChartMoE 在 ChartQA 基准上将之前最先进的准确率从 80.48% 提高到了 84.64%。]]></description>
      <guid>https://arxiv.org/abs/2409.03277</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>iText2KG：使用大型语言模型构建增量知识图谱</title>
      <link>https://arxiv.org/abs/2409.03284</link>
      <description><![CDATA[arXiv:2409.03284v1 公告类型：新
摘要：大多数可用数据都是非结构化的，因此很难获取有价值的信息。自动构建知识图谱 (KG) 对于结构化数据并使其可访问至关重要，可让用户有效地搜索信息。KG 还有助于洞察、推理和推理。传统的 NLP 方法（例如命名实体识别和关系提取）是信息检索的关键，但面临局限性，包括使用预定义的实体类型和需要监督学习。当前的研究利用大型语言模型的功能，例如零次或少量学习。然而，未解决和语义重复的实体和关系仍然带来挑战，导致图不一致并需要大量的后处理。此外，大多数方法都依赖于主题。在本文中，我们提出了 iText2KG，这是一种无需后处理的增量、主题独立的 KG 构建方法。这种即插即用的零样本方法适用于广泛的知识图谱构建场景，包含四个模块：文档提取器、增量实体提取器、增量关系提取器以及图谱集成器和可视化。我们的方法在三个场景中表现出比基线方法更好的性能：将科学论文转换为图谱、将网站转换为图谱以及将简历转换为图谱。]]></description>
      <guid>https://arxiv.org/abs/2409.03284</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>游戏开始：面向语言模型作为强化学习实验者</title>
      <link>https://arxiv.org/abs/2409.03402</link>
      <description><![CDATA[arXiv:2409.03402v1 公告类型：新
摘要：我们提出了一种代理架构，可以自动化部分常见强化学习实验工作流程，从而实现具体代理对控制域的自动掌握。为此，它利用 VLM 来执行人类实验者通常需要的一些功能，包括监控和分析实验进度、根据代理过去的成功和失败提出新任务、将任务分解为一系列子任务（技能）以及检索要执行的技能 - 使我们的系统能够构建自动化学习课程。我们相信这是在强化学习的整个实验周期中利用 VLM 的系统的首批提案之一。我们提供了该系统的第一个原型，并研究了当前模型和技术在所需自动化水平方面的可行性。为此，我们使用标准 Gemini 模型（无需额外微调）为语言调节的 Actor-Critic 算法提供技能课程，以引导数据收集，帮助学习新技能。以这种方式收集的数据被证明可用于学习和迭代改进机器人领域的控制策略。对系统构建不断增长的技能库和判断这些技能训练进度的能力的额外检查也显示出有希望的结果，这表明所提出的架构为具身代理完全自动掌握任务和领域提供了潜在的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.03402</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TRACE-cs：课程安排问题中对比解释的可信推理</title>
      <link>https://arxiv.org/abs/2409.03671</link>
      <description><![CDATA[arXiv:2409.03671v1 公告类型：新
摘要：我们提出了 TRACE-cs，这是一种新颖的混合系统，它将符号推理与大型语言模型 (LLM) 相结合，以解决调度问题中的对比查询。TRACE-cs 利用 SAT 求解技术对调度约束进行编码并为用户查询生成解释，同时利用 LLM 将用户查询处理为逻辑子句，并将符号求解器生成的解释细化为自然语言句子。通过集成这些组件，我们的方法展示了将符号方法与 LLM 相结合以创建具有正确性保证的可解释 AI 代理的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.03671</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CortexCompile：利用 Cortical 启发式架构实现增强型多智能体 NLP 代码合成</title>
      <link>https://arxiv.org/abs/2409.02938</link>
      <description><![CDATA[arXiv:2409.02938v1 公告类型：交叉 
摘要：当前的自动代码生成方法通常依赖于缺乏实时适应性和可扩展性的单片模型。这种限制在需要动态调整和效率的复杂编程任务中尤为明显。将神经科学原理融入自然语言处理 (NLP) 有可能彻底改变自动代码生成。本文介绍了 CortexCompile，这是一种新型模块化系统，其灵感来自人脑皮层区域的专门功能。通过模拟前额叶皮层、顶叶皮层、颞叶和运动皮层的不同作用，与 GPT-4o 等传统单片模型相比，CortexCompile 在可扩展性、效率和适应性方面取得了显着进步。该系统的架构具有任务编排代理，可管理动态任务委派和并行处理，从而有助于在日益复杂的编程任务中生成高度准确和优化的代码。实验评估表明，CortexCompile 在开发时间、准确性和用户满意度方面始终优于 GPT-4o，尤其是在涉及实时战略游戏和第一人称射击游戏的任务中。这些发现强调了神经科学启发的架构在解决当前 NLP 模型的局限性方面的可行性，为更高效、更像人类的 AI 系统铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.02938</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型的多模式适配器</title>
      <link>https://arxiv.org/abs/2409.02958</link>
      <description><![CDATA[arXiv:2409.02958v1 公告类型：交叉 
摘要：大型预训练视觉语言模型（例如 CLIP）已在广泛的图像分类任务中展示了最先进的性能，而无需重新训练。小样本 CLIP 与在下游任务上训练的现有专门架构具有竞争力。最近的研究表明，使用轻量级自适应方法可以进一步提高 CLIP 的性能。然而，以前的方法分别适应 CLIP 模型的不同模态，忽略了视觉和文本表示之间的相互作用和关系。在这项工作中，我们提出了多模态适配器，一种用于 CLIP 的多模态自适应的方法。具体来说，我们添加了一个可训练的多头注意力层，该层结合了文本和图像特征以产生两者的加性自适应。与现有的自适应方法相比，多模态适配器基于其在看不见的类别上的表现，表现出更好的通用性。我们进行了额外的消融和调查，以验证和解释所提出的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.02958</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自动调整激励来管理多个代理</title>
      <link>https://arxiv.org/abs/2409.02960</link>
      <description><![CDATA[arXiv:2409.02960v1 公告类型：交叉 
摘要：在未来几年，人工智能代理将用于做出更复杂的决策，包括涉及许多不同人群的情况。一个巨大的挑战是，人工智能代理倾向于为自己的利益行事，而不像人类那样经常考虑从长远来看什么对每个人都最好。在本文中，我们探索了一种让自利的代理朝着有利于整个社会的目标努力的方法。我们提出了一种方法，通过为某些动作分配激励来添加管理代理来调解代理交互。我们用供应链管理问题测试了我们的方法，并表明该框架 (1) 将原始奖励提高了 22.2%，(2) 将代理的奖励提高了 23.8%，(3) 将经理的奖励提高了 20.1%。]]></description>
      <guid>https://arxiv.org/abs/2409.02960</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 中的幻觉检测：快速且内存高效的微调模型</title>
      <link>https://arxiv.org/abs/2409.02976</link>
      <description><![CDATA[arXiv:2409.02976v1 公告类型：交叉 
摘要：在高风险环境中实施人工智能时，不确定性估计是必不可少的组成部分，例如自动驾驶汽车、医药或保险。大型语言模型 (LLM) 近年来越来越受欢迎，但它们容易产生幻觉，这可能会在高风险环境中造成严重伤害。尽管 LLM 取得了成功，但它们的训练和运行成本很高：它们需要大量的计算和内存，从而阻止了在实践中使用集成方法。在这项工作中，我们提出了一种新方法，可以快速且内存友好地训练 LLM 集成。我们表明，由此产生的集成可以检测幻觉，并且在实践中是一种可行的方法，因为只需要一个 GPU 进行训练和推理。]]></description>
      <guid>https://arxiv.org/abs/2409.02976</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的软件工程代理：一项调查</title>
      <link>https://arxiv.org/abs/2409.02977</link>
      <description><![CDATA[arXiv:2409.02977v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展形成了 AI 代理的新范式，即基于 LLM 的代理。与独立的 LLM 相比，基于 LLM 的代理通过增强 LLM 感知和利用外部资源和工具的能力，大大扩展了 LLM 的多功能性和专业性。迄今为止，基于 LLM 的代理已在软件工程 (SE) 中得到应用并显示出显著的有效性。多个代理与人机交互之间的协同作用为解决复杂的现实世界 SE 问题带来了进一步的希望。在这项工作中，我们对基于 LLM 的 SE 代理进行了全面而系统的调查。我们收集了 106 篇论文，并从两个角度对它们进行分类，即 SE 和代理视角。此外，我们讨论了这一关键领域的开放挑战和未来方向。本调查的存储库位于https://github.com/FudanSELab/Agent4SE-Paper-List。]]></description>
      <guid>https://arxiv.org/abs/2409.02977</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你的生成模型可以检测分布外的协变量偏移吗？</title>
      <link>https://arxiv.org/abs/2409.03043</link>
      <description><![CDATA[arXiv:2409.03043v1 公告类型：交叉 
摘要：检测分布外（OOD）传感数据和协变量分布偏移旨在识别与捕获的、正态的和分布内（ID）集具有不同高级图像统计数据的新测试示例。现有的OOD检测文献主要关注语义偏移，对协变量偏移几乎没有共识。生成模型以无监督的方式捕获ID数据，使它们能够有效地识别与该学习分布有显着偏差的样本，而不管下游任务如何。在这项工作中，我们通过涉及各种模型的广泛分析阐明了生成模型检测和量化领域特定协变量偏移的能力。为此，我们推测仅通过对高频信号相关和独立细节进行建模就足以检测大多数发生的传感故障（全局信号统计中的异常和偏差）。我们提出了一种用于 OOD 检测的新方法 CovariateFlow，该方法专门针对使用条件正则化流 (cNF) 对异方差高频图像分量进行协变量化。我们在 CIFAR10 vs. CIFAR10-C 和 ImageNet200 vs. ImageNet200-C 上的结果证明了该方法的有效性，因为它可以准确检测 OOD 协变量偏移。这项工作有助于提高成像系统的保真度，并在存在协变量偏移的情况下帮助机器学习模型进行 OOD 检测。]]></description>
      <guid>https://arxiv.org/abs/2409.03043</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更好地验证解释并应用于不正确性和分布外检测</title>
      <link>https://arxiv.org/abs/2409.03060</link>
      <description><![CDATA[arXiv:2409.03060v1 公告类型：交叉 
摘要：基于 VeriX（Verified eXplainability，arXiv：2212.01051），一种为机器学习模型输出生成最佳验证解释的系统，我们提出了 VeriX+，它显著改善了验证解释的大小和生成时间。我们引入了一种基于边界传播的灵敏度技术来改善大小，并引入了一种基于二分搜索的置信度排名遍历来改善时间——这两种技术是正交的，可以独立使用或一起使用。我们还展示了如何将 QuickXplain（Junker 2004）算法适应我们的设置，以在大小和时间之间进行权衡。在标准基准上的实验评估表明，这两个指标都有显著的改进，例如，GTSRB 数据集上的大小减少了 38%，MNIST 上的时间减少了 90%。我们还探索了经过验证的解释的应用，并表明解释大小是检测不正确和分布不均检测的有用代理。]]></description>
      <guid>https://arxiv.org/abs/2409.03060</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MobileUNETR：用于高效医学图像分割的轻量级端到端混合视觉转换器</title>
      <link>https://arxiv.org/abs/2409.03062</link>
      <description><![CDATA[arXiv:2409.03062v1 公告类型：交叉 
摘要：皮肤癌分割对医学图像分析提出了重大挑战。许多现有的解决方案，主要是基于 CNN 的，都面临着缺乏全局上下文理解的问题。或者，一些方法采用大规模 Transformer 模型来弥合全局上下文差距，但代价是模型大小和计算复杂度。最后，许多基于 Transformer 的方法主要依赖于基于 CNN 的解码器，而忽略了基于 Transformer 的解码模型的好处。认识到这些局限性，我们通过引入 MobileUNETR 来满足对高效轻量级解决方案的需求，其旨在克服与 CNN 和 Transformer 相关的性能限制，同时最小化模型大小，为高效图像分割迈出有希望的一步。MobileUNETR 有 3 个主要特点。1) MobileUNETR 由一个轻量级混合 CNN-Transformer 编码器组成，以帮助以有效的方式平衡局部和全局上下文特征提取； 2) 一种新型混合解码器，在解码阶段同时利用不同分辨率的低级和全局特征来生成准确的掩码；3) MobileUNETR 超越了大型复杂架构，以 300 万个参数和 1.3 GFLOP 的计算复杂度实现了卓越的性能，分别将参数和 FLOPS 减少了 10 倍和 23 倍。我们在四个公开可用的皮肤病变分割数据集上进行了广泛的实验来验证我们提出的方法的有效性，包括 ISIC 2016、ISIC 2017、ISIC 2018 和 PH2 数据集。代码将在以下网址公开：https://github.com/OSUPCVLab/MobileUNETR.git]]></description>
      <guid>https://arxiv.org/abs/2409.03062</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>后门防御、可学习性和混淆</title>
      <link>https://arxiv.org/abs/2409.03077</link>
      <description><![CDATA[arXiv:2409.03077v1 公告类型：交叉 
摘要：我们通过攻击者和防御者之间的游戏引入了针对后门的可防御性的正式概念。在这个游戏中，攻击者修改了一个函数，使其在称为“触发器”的特定输入上表现不同，而在几乎所有其他地方表现相同。然后，​​防御者尝试在评估时检测触发器。如果防御者以足够高的概率成功，则该函数类被称为可防御的。使防御成为可能的攻击者的关键约束是攻击者的策略必须适用于随机选择的触发器。
我们的定义很简单，没有明确提到学习，但我们证明它与可学习性密切相关。在计算无界设置中，我们使用 Hanneke 等人 (2022) 的投票算法来表明可防御性本质上是由函数类的 VC 维度决定的，与 PAC 可学习性非常相似。在计算受限的设置中，我们使用类似的论证来表明有效的 PAC 可学习性意味着有效的可防御性，但反之则不然。另一方面，我们使用不可区分性混淆来表明多项式大小电路类不是可有效防御的。最后，我们以多项式大小决策树为例，防御比学习更容易。因此，我们将有效可防御性确定为有效可学习性和混淆之间的一个值得注意的中间概念。]]></description>
      <guid>https://arxiv.org/abs/2409.03077</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决早期痴呆症检测中的差距：通过机器学习增强诊断模型的途径</title>
      <link>https://arxiv.org/abs/2409.03147</link>
      <description><![CDATA[arXiv:2409.03147v1 公告类型：交叉 
摘要：全球老龄化趋势加剧，导致包括阿尔茨海默病在内的痴呆症病例增加，这凸显了对早期和准确诊断方法的迫切需求。传统的诊断技术，如认知测试、神经影像学和生物标志物分析，在敏感性、可及性和成本方面面临重大限制，尤其是在早期阶段。本研究探索了机器学习 (ML) 作为一种变革性方法的潜力，通过利用 ML 模型分析和整合复杂的多模态数据集，包括认知评估、神经影像学和遗传信息，来增强早期痴呆症的检测。对现有文献进行了全面审查，以评估各种 ML 模型，包括监督学习、深度学习和集成学习和变压器模型等先进技术，评估它们的准确性、可解释性和临床整合潜力。研究结果表明，虽然 ML 模型在提高诊断精度和实现早期干预方面显示出巨大的潜力，但其普遍性、可解释性和道德部署方面仍然存在挑战。本研究最后概述了未来的方向，旨在提高 ML 模型在痴呆症检测中的临床实用性，强调跨学科合作和符合道德的框架，以改善阿尔茨海默病和其他形式痴呆症的早期检测和干预策略。]]></description>
      <guid>https://arxiv.org/abs/2409.03147</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图论之争：大型语言模型的灵活可靠的推理框架</title>
      <link>https://arxiv.org/abs/2409.03155</link>
      <description><![CDATA[arXiv:2409.03155v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 可能会因缺乏相关知识而在实际应用中出现幻觉。相比之下，知识图谱包含广泛的多关系结构，可存储大量符号事实。因此，人们广泛探索了 LLM 与知识图谱的集成，其中知识图谱问答 (KGQA) 是集成的关键试金石。此任务要求 LLM 通过从知识图谱中检索相关三元组来回答自然语言问题。然而，现有的方法面临两个重大挑战：\textit{过长的推理路径分散了答案生成的注意力}，以及 \textit{假阳性关系阻碍了路径细化}。在本文中，我们提出了一个迭代交互式 KGQA 框架，该框架利用 LLM 的交互式学习功能来执行图谱推理和辩论 (DoG)。具体而言，DoG 采用子图聚焦机制，允许 LLM 在每个推理步骤后进行答案尝试，从而减轻冗长的推理路径的影响。另一方面，DoG 利用多角色辩论团队逐步简化复杂问题，减少假阳性关系的影响。这种辩论机制确保了推理过程的可靠性。在五个公共数据集上的实验结果证明了我们架构的有效性和优越性。值得注意的是，在 WebQuestions 和 GrailQA 上的准确率分别比最先进的方法 ToG 高出 23.7% 和 9.1%。此外，在上述数据集上与各种 LLM 的集成实验凸显了 DoG 的灵活性。代码可在 \url{https://github.com/reml-group/DoG} 获得。]]></description>
      <guid>https://arxiv.org/abs/2409.03155</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过对话持续学习技能和任务</title>
      <link>https://arxiv.org/abs/2409.03166</link>
      <description><![CDATA[arXiv:2409.03166v1 公告类型：交叉 
摘要：持续和交互式机器人学习是一个具有挑战性的问题，因为机器人与人类用户共存，人类用户希望机器人能够学习新技能，以样本效率永久地解决新任务。在这项工作中，我们提出了一个框架，让机器人通过与人类用户的自然语言对话交互来查询和学习视觉运动机器人技能和任务相关信息。以前的方法要么侧重于提高跟随代理的指令性能，要么被动学习新技能或概念。相反，我们使用对话结合语言技能基础嵌入来查询或确认用户请求的技能和/或任务。为了实现这一目标，我们为我们的代理开发并集成了三个不同的组件。首先，我们提出了一种具有低秩自适应的新型视觉运动控制策略 ACT（ACT-LoRA），它使现有的 SoTA ACT 模型能够执行少量持续学习。其次，我们开发了一个对齐模型，将技能实施中的演示投射到共享嵌入中，这样我们就知道何时向用户提问和/或演示。最后，我们集成了现有的 LLM 来与人类用户交互，以进行扎实的交互式持续技能学习来解决任务。我们的 ACT-LoRA 模型在仅使用五次演示训练新技能时，可以 100% 准确率学习新的微调技能，同时在 RLBench 数据集中对预训练技能的准确率仍保持 74.75%，而其他模型则明显不足。我们还对 8 名受试者进行了一项以人为本的研究，以展示我们组合框架的持续学习能力。我们在制作三明治的任务中取得了 75% 的成功率，真实的机器人从参与者数据中学习，这表明机器人可以使用我们的方法从与非专家用户的对话中学习新技能或任务知识。]]></description>
      <guid>https://arxiv.org/abs/2409.03166</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绕过 DARCY 防御：难以区分的通用对抗触发器</title>
      <link>https://arxiv.org/abs/2409.03183</link>
      <description><![CDATA[arXiv:2409.03183v1 公告类型：交叉 
摘要：用于自然语言处理 (NLP) 的神经网络 (NN) 分类模型容易受到通用对抗触发器 (UAT) 攻击，该攻击会触发模型对任何输入产生特定预测。DARCY 借用了“蜜罐”概念来诱饵多个陷门，有效地检测由 UAT 生成的对抗性示例。不幸的是，我们发现了一种新的 UAT 生成方法，称为 IndisUAT，它生成触发器（即标记）并使用它们来制作对抗性示例，其特征分布与 DARCY 检测层中随机选择类别中的良性示例的特征分布没有区别。产生的对抗性示例在受 DARCY 保护的模型中导致预测结果的最大损失。同时，产生的触发器在文本生成、文本推理和阅读理解的黑盒模型中是有效的。最后，在 NLP 任务的 NN 模型下的评估结果表明，IndisUAT 方法可以有效绕过 DARCY 并穿透其他防御。例如，IndisUAT 可以使 DARCY 检测的真正阳性率至少降低 40.8% 和 90.6%，并使 RNN 和 CNN 模型中的准确率至少降低 33.3% 和 51.6%。IndisUAT 使 BERT 对抗防御模型的准确率降低至少 34.0%，并使 GPT-2 语言模型即使在非种族背景下也会产生种族主义输出。]]></description>
      <guid>https://arxiv.org/abs/2409.03183</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>