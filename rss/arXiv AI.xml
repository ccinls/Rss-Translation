<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>弥合文本、语音和视频之间的数据来源差距</title>
      <link>https://arxiv.org/abs/2412.17847</link>
      <description><![CDATA[arXiv:2412.17847v1 公告类型：新
摘要：人工智能的进步很大程度上取决于训练数据的规模和质量。尽管如此，在检查文本以外的成熟数据集的属性方面，仍存在实证分析的不足。在这项工作中，我们对各种模式（流行的文本、语音和视频数据集）进行了最大规模和首创的纵向审计，从其详细的来源趋势和使用限制到其地理和语言表示。我们的手动分析涵盖了 1990 年至 2024 年之间的近 4000 个公共数据集，涵盖 608 种语言、798 个来源、659 个组织和 67 个国家/地区。我们发现，自 2019 年以来，多模态机器学习应用程序已大量转向网络爬取、合成和社交媒体平台（如 YouTube）来获取训练集，超过了所有其他来源。其次，追踪数据集派生链我们发现，虽然不到 33% 的数据集是受限制许可的，但广泛使用的文本、语音和视频数据集中超过 80% 的源内容带有非商业限制。最后，与公共 AI 训练数据集中代表的语言和地理位置数量不断增加相反，我们的审计表明，自 2013 年以来，相对地理和多语言代表性的衡量标准未能显着提高其覆盖范围。我们认为，审计的广度使我们能够在生态系统层面实证检验数据来源、限制和西方中心主义的趋势，并且了解这些问题对于负责任的 AI 的进步至关重要。为了持续提高数据集透明度和负责任地使用，我们发布了整个多模式审计，允许从业者跨文本、语音和视频追踪数据来源。]]></description>
      <guid>https://arxiv.org/abs/2412.17847</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开放科学在人工智能领域的不合理有效性：一项复制研究</title>
      <link>https://arxiv.org/abs/2412.17859</link>
      <description><![CDATA[arXiv:2412.17859v1 公告类型：新
摘要：科学界已经报道了可重复性危机，但它对人工智能研究的影响程度尚不完全清楚。因此，我们进行了一项系统的复制研究，包​​括 30 项高度引用的人工智能研究，这些研究依赖于原始材料（如果有）。最后，八篇文章被拒绝，因为它们需要访问数据或硬件，而作为项目的一部分，这些数据或硬件几乎不可能获得。六篇文章成功复制，五篇文章部分复制。总共有 50% 的文章在一定程度上被复制。代码和数据的可用性与可重复性密切相关，因为 86% 共享代码和数据的文章被完全或部分复制，而 33% 仅共享数据的文章也是如此。数据文档的质量与成功复制相关。记录不全或指定错误的数据可能会导致复制失败。令人惊讶的是，代码文档的质量与成功复制无关。只要代码是共享的，代码是否记录不全、部分缺失或没有版本控制对于成功复制并不重要。这项研究强调了开放科学的有效性以及正确记录数据工作的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.17859</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>闭环交通生成的因果组合扩散模型</title>
      <link>https://arxiv.org/abs/2412.17920</link>
      <description><![CDATA[arXiv:2412.17920v1 公告类型：新
摘要：模拟对于自动驾驶的安全评估至关重要，特别是在捕捉复杂的交互行为时。然而，在长尾情况下生成真实且可控的交通场景仍然是一项重大挑战。现有的生成模型存在用户定义的可控性和现实约束之间的目标冲突，这在安全关键环境中被放大。在这项工作中，我们引入了因果组合扩散模型 (CCDiff)，这是一个结构引导的扩散框架，用于解决这些挑战。我们首先将可控和现实的闭环模拟的学习公式化为一个约束优化问题。然后，CCDiff 通过自动识别并将因果结构直接注入扩散过程，在坚持现实性的同时最大化可控性，提供结构化指导以增强现实性和可控性。通过对基准数据集和闭环模拟器的严格评估，CCDiff 在生成真实且用户偏好的轨迹方面比最先进的方法有显著的进步。我们的结果显示了 CCDiff 在提取和利用因果结构方面的有效性，并根据碰撞率、越野率、FDE 和舒适度等关键指标显示出更好的闭环性能。]]></description>
      <guid>https://arxiv.org/abs/2412.17920</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Contrato360 2.0：使用大型语言模型和代理的文档和数据库驱动的问答系统</title>
      <link>https://arxiv.org/abs/2412.17942</link>
      <description><![CDATA[arXiv:2412.17942v1 公告类型：新
摘要：我们提出了一个问答 (Q\&amp;A) 应用程序，旨在通过利用合同文件 (PDF) 中的组合信息和从合同管理系统 (数据库) 中检索的数据来支持合同管理流程。这些数据由大型语言模型 (LLM) 处理，以提供准确且相关的答案。通过使用检索增强生成 (RAG)、文本到 SQL 技术和动态协调工作流的代理，这些响应的准确性得到进一步提高。这些技术消除了重新训练语言模型的需要。此外，我们采用了 Prompt Engineering 来微调响应的重点。我们的研究结果表明，这种多代理协调和技术组合显着提高了答案的相关性和准确性，为未来的信息系统提供了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.17942</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭露监控资本主义：追踪网络数据收集的隐秘世界</title>
      <link>https://arxiv.org/abs/2412.17944</link>
      <description><![CDATA[arXiv:2412.17944v1 公告类型：新
摘要：本研究调查了监控资本主义的机制，重点关注网络导航和搜索过程中的个人数据传输。分析网络流量可以揭示各种实体如何跟踪和收集数字足迹。该研究揭示了用户和网络服务之间交换的特定数据类型，强调了这些过程中涉及的复杂算法。我们提供了数据收集实践的具体证据，并提出了增强数据保护和透明度的策略。我们的研究结果强调了需要强大的数据保护框架和合乎道德的数据使用来解决数字时代的隐私问题。]]></description>
      <guid>https://arxiv.org/abs/2412.17944</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适当的NNUE数据集的研究</title>
      <link>https://arxiv.org/abs/2412.17948</link>
      <description><![CDATA[arXiv:2412.17948v1 公告类型：新
摘要：NNUE（高效可更新神经网络）彻底改变了国际象棋引擎的开发，几乎所有顶级引擎都采用 NNUE 模型来保持竞争性能。NNUE 训练的一个关键挑战是创建高质量的数据集，特别是在国际象棋等复杂领域，战术和战略评估至关重要。然而，构建有效数据集的方法仍然不太为人所知，记录不足。在本文中，我们提出了一种算法，用于生成和过滤由稳定且不受战术波动影响的“安静”位置组成的数据集。我们的方法为数据集创建提供了一种清晰的方法，可以在各种评估函数中复制和推广。测试表明引擎性能显着提高，证实了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.17948</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型实现多源问答系统的动态多代理编排和检索</title>
      <link>https://arxiv.org/abs/2412.17964</link>
      <description><![CDATA[arXiv:2412.17964v1 公告类型：新
摘要：我们提出了一种方法，该方法结合了大型语言模型 (LLM) 检索中的几种先进技术，以支持开发强大的多源问答系统。该方法旨在通过协调的多代理编排和动态检索方法集成来自不同数据源（包括非结构化文档 (PDF) 和结构化数据库）的信息。我们的方法利用专门的代理（例如 SQL 代理、检索增强生成 (RAG) 代理和路由器代理），根据每个查询的性质动态选择最合适的检索策略。为了进一步提高准确性和上下文相关性，我们采用了动态提示工程，它可以实时适应特定于查询的上下文。该方法的有效性在合同管理领域得到了证明，其中复杂的查询通常需要非结构化和结构化数据之间的无缝交互。我们的结果表明，这种方法提高了响应的准确性和相关性，为开发可跨不同领域和数据源运行的问答系统提供了一个多功能且可扩展的框架。]]></description>
      <guid>https://arxiv.org/abs/2412.17964</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从神经元激活的角度理解人工神经网络的行为</title>
      <link>https://arxiv.org/abs/2412.18073</link>
      <description><![CDATA[arXiv:2412.18073v1 公告类型：新
摘要：本文通过神经元激活动力学的视角探索深度神经网络 (DNN) 的复杂行为。我们提出了一个概率框架，可以将模型的神经元激活模式分析为一个随机过程，揭示神经缩放规律的理论见解，例如过度参数化和损失随数据集大小的幂律衰减。通过推导关键的数学关系，我们提出激活神经元的数量以 $N(1-(\frac{bN}{D+bN})^b)$ 的形式增加，神经元激活应遵循幂律分布。基于这两个数学结果，我们展示了 DNN 如何在过度参数化的情况下保持泛化能力，并阐明了当数据集大小在对数轴上绘制时在损失曲线中观察到的相变现象（即数据量级线性增加）。此外，通过结合上述两种现象和神经元激活的幂律分布，我们得出了神经网络损失函数随数据规模增加而呈幂律衰减的结果。此外，我们的分析弥合了经验观察与理论基础之间的差距，提供了关于参数效率和模型压缩性的可通过实验测试的预测。这些发现为理解神经网络扩展奠定了基础，并为优化 DNN 性能提供了新的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.18073</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对大型语言模型的多任务分子生成的属性增强指令调整</title>
      <link>https://arxiv.org/abs/2412.18084</link>
      <description><![CDATA[arXiv:2412.18084v1 公告类型：新
摘要：大型语言模型（LLM）广泛应用于各种自然语言处理任务，如问答和机器翻译。然而，由于缺乏标记数据和人工注释生化特性的困难，分子生成任务的性能仍然有限，尤其是涉及多属性约束的任务。在这项工作中，我们提出了一个两步框架 PEIT（属性增强指令调整）来改进分子相关任务的 LLM。在第一步中，我们使用文本描述、SMILES 和生化特性作为多模态输入来预训练一个名为 PEIT-GEN 的模型，通过对齐多模态表示来合成指令数据。第二步，我们使用合成数据对现有的开源 LLM 进行微调，生成的 PEIT-LLM 可以处理分子字幕、基于文本的分子生成、分子属性预测以及我们新提出的多约束分子生成任务。实验结果表明，我们预先训练的 PEIT-GEN 在分子字幕方面的表现优于 MolT5 和 BioT5，表明模态在文本描述、结构和生化特性之间具有良好的一致性。此外，PEIT-LLM 在多任务分子生成方面表现出了良好的改进，证明了 PEIT 框架对各种分子任务的可扩展性。我们在 https://github.com/chenlong164/PEIT 中发布了代码、构建的指令数据和模型检查点。]]></description>
      <guid>https://arxiv.org/abs/2412.18084</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoSculpt：使用强化学习和图形学习的基于模式的模型自动修剪框架</title>
      <link>https://arxiv.org/abs/2412.18091</link>
      <description><![CDATA[arXiv:2412.18091v1 公告类型：新
摘要：随着深度神经网络 (DNN) 越来越多地部署在边缘设备上，优化模型以适应受限的计算资源至关重要。现有的自动修剪方法面临着挑战，因为 DNN 模型的多样性、各种运算符（例如过滤器）以及难以平衡修剪粒度和模型精度。为了解决这些限制，我们引入了 AutoSculpt，这是一个基于模式的自动修剪框架，旨在通过利用图形学习和深度强化学习 (DRL) 来提高效率和准确性。AutoSculpt 会自动识别和修剪 DNN 架构中现有推理引擎可以识别的常规模式，从而实现运行时加速。 AutoSculpt 中的三个关键步骤包括：(1) 将 DNN 构建为图形以编码其拓扑和参数依赖关系，(2) 嵌入计算效率高的修剪模式，以及 (3) 利用 DRL 迭代优化自动修剪策略，直到达到压缩和准确性之间的最佳平衡。实验结果证明了 AutoSculpt 在各种架构（包括 ResNet、MobileNet、VGG 和 Vision Transformer）中的有效性，修剪率高达 90%，FLOP 减少率提高近 18%，优于所有基准。代码可在 https://anonymous.4open.science/r/AutoSculpt-DDA0 上找到]]></description>
      <guid>https://arxiv.org/abs/2412.18091</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>围手术期人工智能聊天机器人 (PEACH) 的真实部署与评估——一种用于围手术期医学的大型语言模型聊天机器人</title>
      <link>https://arxiv.org/abs/2412.18096</link>
      <description><![CDATA[arXiv:2412.18096v1 公告类型：新
摘要：大型语言模型 (LLM) 正在成为医疗保健领域的强大工具，特别是对于复杂的特定领域任务。本研究描述了围手术期 AI 聊天机器人 (PEACH) 的开发和评估，这是一个基于 LLM 的安全系统，与当地围手术期指南相结合，以支持术前临床决策。PEACH 在 Pair Chat（由新加坡政府开发）内的安全 Claude 3.5 Sonet LLM 框架中嵌入了 35 个机构围手术期协议，并在静默部署中使用真实数据进行了测试。评估了准确性、安全性和可用性。根据潜在危害对偏差和幻觉进行分类，并使用技术接受模型 (TAM) 评估用户反馈。在初始静默部署后进行了更新以修改一项协议。
在 240 次现实世界临床迭代中，PEACH 实现了第一代 97.5% (78/80) 的准确率，在三次迭代中实现了 96.7% (232/240) 的总体准确率。更新后的 PEACH 显示出 97.9% (235/240) 的准确率，与 95% 准确率的零假设有统计学上的显著差异 (p = 0.018，95% CI：0.952-0.991)。观察到的幻觉和偏差最小 (分别为 1/240 和 2/240)。临床医生报告称，PEACH 在 95% 的病例中加快了决策速度，PEACH 内的评分者信度范围为 kappa 0.772-0.893，主治医生之间的 kappa 范围为 0.610-0.784。
PEACH 是一种准确、适应性强的工具，可提高围手术期决策的一致性和效率。未来的研究应该探索其跨专业的可扩展性及其对临床结果的影响。]]></description>
      <guid>https://arxiv.org/abs/2412.18096</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过高效元内核上的混合预填充/解码/验证调度，利用 SOTA 优化解决生产 LLM 服务系统中的动态性问题</title>
      <link>https://arxiv.org/abs/2412.18106</link>
      <description><![CDATA[arXiv:2412.18106v1 公告类型：新
摘要：满足生产级大型语言模型 (LLM) 服务系统对低延迟和成本效率日益增长的需求需要集成先进的优化技术。然而，LLM 的动态和不可预测的输入输出长度，加上这些优化，加剧了工作负载变化的问题，使得难以在 AI 加速器上保持高效率，尤其是具有基于图块的编程模型的 DSA。为了应对这一挑战，我们推出了 XY-Serve，这是一种多功能、Ascend 原生、端到端生产 LLM 服务系统。核心思想是一种抽象机制，通过将计算分解为统一的、硬件友好的、细粒度的元原语来平滑工作负载的变化。为了引起注意，我们提出了一个元内核，它使用架构感知的图块大小来计算 matmul-softmax-matmul 的基本模式。对于 GEMM，我们引入了一种虚拟填充方​​案，该方案可适应动态形状变化，同时使用具有各种固定图块大小的高效 GEMM 基元。XY-Serve 与 vLLM 和谐相处。实验结果表明，与 Ascend NPU 上当前公开可用的基线相比，端到端吞吐量提高了 89%。此外，与现有库相比，我们的方法优于现有的 GEMM（平均快 14.6%）和注意力（平均快 21.5%）内核。虽然这项工作是 Ascend 原生的，但我们相信该方法也可以很容易地应用于 SIMT 架构。]]></description>
      <guid>https://arxiv.org/abs/2412.18106</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SlimGPT：大型语言模型的分层结构化修剪</title>
      <link>https://arxiv.org/abs/2412.18110</link>
      <description><![CDATA[arXiv:2412.18110v1 公告类型：新
摘要：大型语言模型（LLM）因其在各个领域的卓越能力而备受关注，其巨大的参数规模对实际部署提出了挑战。结构化剪枝是一种平衡模型性能和效率的有效方法，但在计算资源受限的情况下恢复性能是剪枝LLM的主要挑战。因此，我们基于Optimal Brain Surgeon框架提出了一种低成本、快速的LLM结构化剪枝方法SlimGPT。我们提出了快速、接近最优的分批贪婪剪枝，通过分组Cholesky分解提高了头部剪枝误差估计的准确性，并通过动态组大小提高了FFN的剪枝效率，从而在一小时内实现近似局部最优的剪枝结果。此外，我们从误差累积的角度探讨了分层剪枝的局限性，并提出了增量剪枝率，这是一种非均匀剪枝策略，可以减少性能下降。在 LLaMA 基准上的实验结果表明，SlimGPT 优于其他方法并取得了最佳效果。]]></description>
      <guid>https://arxiv.org/abs/2412.18110</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AIGT：基于提示的人工智能生成表</title>
      <link>https://arxiv.org/abs/2412.18111</link>
      <description><![CDATA[arXiv:2412.18111v1 公告类型：新
摘要：表格数据占企业数据资产的 80% 以上，在各个领域都至关重要。随着人们对隐私保护和数据共享限制的担忧日益增加，生成高质量的合成表格数据已变得至关重要。最近的进展表明，大型语言模型 (LLM) 可以通过利用语义信息并克服独热编码带来的高维数据挑战来有效地生成逼真的表格数据。然而，当前的方法并没有充分利用表格中丰富的信息。为了解决这个问题，我们引入了基于提示增强的人工智能生成表 (AIGT)，这是一种利用元数据信息（例如表描述和模式）作为提示来生成超高质量合成数据的新方法。为了克服 LLM 的 token 限制约束，我们提出了长 token 分区算法，使 AIGT 能够对任何规模的表进行建模。 AIGT在支付宝风控体系中的20个公开数据集中的14个和2个真实行业数据集上取得了最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2412.18111</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoDroid-V2：通过代码生成增强基于 SLM 的 GUI 代理</title>
      <link>https://arxiv.org/abs/2412.18116</link>
      <description><![CDATA[arXiv:2412.18116v1 公告类型：新 
摘要：大型语言模型 (LLM) 为移动 UI 代理带来了令人兴奋的新进展，这是一个长期存在的研究领域，旨在通过移动 UI 交互完成任意自然语言任务。然而，现有的 UI 代理通常需要强大的大型模型的高推理能力，而这些模型很难在最终用户的设备上本地部署，这引起了对用户隐私和集中服务成本的巨大担忧。减少所需模型大小的一种方法是使用高质量的训练数据定制较小的领域特定模型，例如各种类型的应用程序和任务的大规模人工演示，而这样的数据集极难获得。受最近小型语言模型 (SLM) 卓越编码能力的启发，我们建议将 UI 任务自动化问题转换为代码生成问题，该问题可以通过设备上的 SLM 有效解决，并通过设备上的代码解释器高效执行。与可以使用公共数据集进行大量预训练的常规编码任务不同，由于目标应用程序的多样性、复杂性和多变性，生成 UI 自动化代码具有挑战性。因此，我们采用以文档为中心的方法，自动为每个应用程序构建细粒度的 API 文档，并根据此文档生成不同的任务示例。通过使用合成文档和任务示例指导代理，它学会生成精确而高效的脚本来完成看不见的任务。基于与最先进的移动 UI 代理的详细比较，我们的方法有效地改善了移动任务自动化，成功率显著提高，延迟/令牌消耗更低。代码将开源。]]></description>
      <guid>https://arxiv.org/abs/2412.18116</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过消除计算冗余实现子图图神经网络的精确加速</title>
      <link>https://arxiv.org/abs/2412.18125</link>
      <description><![CDATA[arXiv:2412.18125v1 公告类型：新
摘要：图神经网络 (GNN) 已成为图任务的流行框架。许多最近的研究提出了在每个图的众多子图上使用图卷积方法，这一概念称为子图图神经网络 (子图 GNN)，以增强 GNN 区分非同构图的能力。为了最大限度地提高表现力，子图 GNN 通常要求每个子图的大小与原始图相等。尽管子图 GNN 性能令人印象深刻，但由于子图数量庞大且规模庞大，导致训练数据激增，导致存储和计算效率低下，因此子图 GNN 面临挑战。针对这一问题，本文提出了 Ego-Nets-Fit-All (ENFA) 模型，该模型将较小的自我网络统一作为子图，从而提供更大的存储和计算效率，同时保证即使将整个图作为子图，也能与原始子图 GNN 的输出相同。关键在于识别并消除子图之间的冗余计算。例如，节点 $v_i$ 可能出现在多个子图中，但远离所有子图的中心（子图之间的不对称部分）。因此，它在每个子图中的前几轮消息传递可以在原始图中计算一次，而不是在每个子图中计算多次。这种策略使我们的 ENFA 能够以精确的方式加速子图 GNN，而不像以前的采样方法那样经常损失性能。在各种数据集上进行的大量实验表明，与传统的子图 GNN 相比，ENFA 可以将存储空间减少 29.0% 至 84.5%，并将训练效率提高高达 1.66 倍。]]></description>
      <guid>https://arxiv.org/abs/2412.18125</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们已经进入人工智能文本生成世界了吗？量化和监控社交媒体上的人工智能文本生成</title>
      <link>https://arxiv.org/abs/2412.18148</link>
      <description><![CDATA[arXiv:2412.18148v1 公告类型：新
摘要：社交媒体平台上人工智能生成文本 (AIGT) 的出现越来越多。然而，AIGT 的滥用可能会对公众舆论产生深远影响，例如传播错误信息和操纵叙述。尽管 AIGT 非常重要，但仍然缺乏对社交媒体上 AIGT 流行程度进行系统性评估的研究。为了解决这一差距，本文旨在量化、监控和分析在线社交媒体平台上的 AIGT。我们首先从 3 个主要社交媒体平台（Medium、Quora 和 Reddit）收集一个包含约 240 万条帖子的数据集 (SM-D) 。然后，我们构建了一个多样化的数据集 (AIGTBench) 来训练和评估 AIGT 检测器。AIGTBench 结合了流行的开源数据集和我们由 12 个 LLM 从社交媒体文本生成的 AIGT 数据集，作为评估主流检测器的基准。通过这种设置，我们确定了性能最佳的检测器 (OSM-Det)。然后，我们将 OSM-Det 应用于 SM-D 以跟踪 AIGT 随时间的变化，并观察 2022 年 1 月至 2024 年 10 月期间社交媒体平台上 AI 归因率 (AAR) 的不同趋势。具体来说，Medium 和 Quora 的 AAR 显着增加，分别从 1.77% 上升到 37.03% 和 2.06% 上升到 38.95%。相比之下，Reddit 的增长速度较慢，同期 AAR 从 1.31% 增加到 2.45%。我们进一步的分析表明，AIGT 在多个维度上与人类书写的文本不同，包括语言模式、主题分布、参与度水平和作者的关注者分布。我们设想我们对社交媒体中 AIGT 的分析和发现可以为该领域的未来研究提供启示。]]></description>
      <guid>https://arxiv.org/abs/2412.18148</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VISION：用于科学用户设施中自然人机交互的模块化 AI 助手</title>
      <link>https://arxiv.org/abs/2412.18161</link>
      <description><![CDATA[arXiv:2412.18161v1 公告类型：新
摘要：科学用户设施（例如同步加速器光束线）配备了各种各样的硬件和软件工具，这些工具需要人机交互的代码库。这通常需要开发人员参与建立用户/研究人员与复杂仪器之间的联系。生成式人工智能的出现为弥合这一知识差距提供了机会，实现了无缝沟通和高效的实验工作流程。在这里，我们通过组装多个支持人工智能的认知块来展示虚拟科学伴侣 (VISION) 的模块化架构，每个认知块都为专门的任务提供大型语言模型 (LLM) 的支架。借助 VISION，我们在光束线工作站上以低延迟执行了基于 LLM 的操作，并在 X 射线散射光束线上演示了第一个语音控制实验。模块化和可扩展的架构可以轻松适应新仪器和功能。基于自然语言的科学实验的发展是即将到来的未来的基石，届时科学外皮层——科学家认知的综合延伸——可能会从根本上改变科学实践和发现。]]></description>
      <guid>https://arxiv.org/abs/2412.18161</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注释法国文学中对神话实体的引用</title>
      <link>https://arxiv.org/abs/2412.18270</link>
      <description><![CDATA[arXiv:2412.18270v1 公告类型：新
摘要：在本文中，我们探讨了大型语言模型 (LLM) 对现代和当代法国文学中罗马和希腊神话实体引用的注释相关性。我们提出了一种注释方案，并证明最近的 LLM 可以直接应用于有效地遵循该方案，尽管偶尔也会犯重大的分析错误。此外，我们表明 LLM（更具体地说是 ChatGPT）能够为文学作者对神话引用的使用提供解释性见解。然而，我们还发现 LLM 很难准确识别小说中的相关段落（当用作信息检索引擎时），经常产生幻觉并生成虚构的例子——这个问题引起了重大的道德担忧。尽管如此，如果使用得当，LLM 仍然是执行高精度注释的宝贵工具，尤其是对于那些仅通过手动方法难以大规模全面注释的任务。]]></description>
      <guid>https://arxiv.org/abs/2412.18270</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用直接优势策略优化提高大型语言模型的多步推理能力</title>
      <link>https://arxiv.org/abs/2412.18279</link>
      <description><![CDATA[arXiv:2412.18279v1 公告类型：新 
摘要：强化学习（RL）在增强大型语言模型（LLM）推理能力方面的作用越来越重要。尽管RL在许多场景中取得了成功，但在提高LLM的推理能力方面仍然存在许多挑战。一个挑战是稀疏奖励，这使RL的优化变得困难并且需要大量的数据样本。另一个挑战源于RL固有的不稳定性，特别是在使用Actor-Critic（AC）方法来推导最优策略时，这往往会导致不稳定的训练过程。为了解决这些问题，我们引入了直接优势策略优化（DAPO），一种新颖的步骤级离线RL算法。与仅依赖结果奖励来优化策略的标准对齐（例如DPO）不同，DAPO使用评论家函数来预测每一步的推理准确率，从而生成密集信号来细化生成策略。此外，DAPO 中的 Actor 和 Critic 组件是独立训练的，避免了 PPO 等标准 AC 算法中观察到的共同训练不稳定性。我们在数学和代码查询数据集上训练 DAPO，然后在多个基准上评估其性能。我们的结果表明，DAPO 可以有效增强 SFT 模型和 RL 模型的数学和代码能力，证明了 DAPO 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.18279</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>