<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 24 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过临床经验学习，提高大语言模型代理的互动诊断能力</title>
      <link>https://arxiv.org/abs/2503.16463</link>
      <description><![CDATA[ARXIV：2503.16463V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展显示出有希望的医学诊断结果，其中一些研究表明，与人类医生相比，在特定情况下的表现出色。但是，LLM的诊断功能通常被高估了，因为它们的性能在需要主动信息收集的交互式诊断设置中显着恶化。这项研究调查了性能降解现象背后的潜在机制，并提出了解决方案。我们确定LLMS的主要缺陷在于初始诊断阶段，尤其是在信息收集效率和初始诊断形成中，而不是随后的鉴别诊断阶段。为了解决这一限制，我们开发了一种插件方法增强（PPME）LLM代理商，利用了来自中国和美国医疗机构的350万种电子病历。我们的方法整合了专业模型，以通过监督和加强学习技术训练当前疾病史的初始疾病诊断和调查。实验结果表明，与基准相比，PPME LLM提高了30％以上。 PPME LLM在交互式诊断方案中的最终诊断准确性接近了与使用完整临床数据实现的水平相当的水平。这些发现表明，尽管需要进一步的验证研究，但仍有发展自主诊断系统的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.16463</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过临床咨询流动以动态诊断来授权医疗多代理</title>
      <link>https://arxiv.org/abs/2503.16547</link>
      <description><![CDATA[ARXIV：2503.16547V1公告类型：新 
摘要：传统的基于AI的医疗保健系统通常依赖单模式数据，从而限制了由于不完整的信息而限制了诊断准确性。但是，基础模型的最新进展显示出有希望增强诊断结合多模式信息的潜力。尽管这些模型在静态任务中表现出色，但由于信息收集的持久性不足，他们无法管理动态诊断，无法管理多转交互，并且经常做出过早的诊断决策。要解决此问题，我们提出了一个由咨询流和加强学习启发的多代理框架（RL），以模拟整个咨询过程，以整个临床诊断，以进行多个临床诊断。我们的方法结合了从诊所咨询流和医学教科书结构的层次结构集，以有效地指导决策过程。该策略改善了代理相互作用，使它们能够根据动态状态进行适应和优化操作。我们评估了公共动态诊断基准的框架。与现有基于基础模型的方法相比，提出的框架明显改善了基线方法和实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.16547</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过视觉模型在增强学习中进行自动语义解释性</title>
      <link>https://arxiv.org/abs/2503.16724</link>
      <description><![CDATA[ARXIV：2503.16724V1公告类型：新 
摘要：增强学习中的语义解释性（RL）可以通过使代理商的决策可理解和可验证，从而实现透明度，问责制和更安全的部署。然而，实现这一目标需要一个由人类理解的概念组成的特征空间，传统上依赖人类规范，并且不推广到看不见的环境。在这项工作中，我们通过授权自动化（SILVA）引入了语义上可解释的强化学习，这是一个自动化框架，利用预先训练的视觉模型（VLM）进行语义特征提取和基于可解释的树的模型进行策略优化。席尔瓦（Silva）首先查询VLM，以确定看不见的环境的相关语义特征，然后从环境中提取这些功能。最后，它通过RL训练可解释的控制树，以透明且可解释的方式将提取的特征映射到动作。为了解决直接使用VLM提取功能的计算效率低下，我们开发了一个功能提取管道，该功能提取管道生成用于训练轻量级卷积网络的数据集，该网络随后在RL期间使用。通过利用VLMS自动化基于树的RL，Silva消除了可解释模型先前要求的人类注释的依赖，同时还克服了仅VLM的能力，即可单独实现有效的机器人策略，从而实现了无需人类循环的语义上可解释的强化学习。]]></description>
      <guid>https://arxiv.org/abs/2503.16724</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在多模式大型语言模型时代迈向代理推荐系统</title>
      <link>https://arxiv.org/abs/2503.16734</link>
      <description><![CDATA[ARXIV：2503.16734V1公告类型：新 
摘要：大型语言模型（LLM）的最新突破导致了代理AI系统的出现，这些系统超出了独立模型的功能。通过授权LLMS感知外部环境，整合多模式信息并与各种工具进行交互，这些代理系统在复杂的任务中表现出更大的自主权和适应性。这种演变为推荐系统（RS）带来了新的机会：基于LLM的代理RS（LLM-ARS）可以提供更多的交互式，上下文感知和主动的建议，从而有可能重塑用户体验并扩大RS的应用程序范围。尽管有希望的早期结果，但仍有基本挑战，包括如何有效地纳入外部知识，具有可控性的平衡自主权以及评估动态的多峰设置中的性能。在此观点论文中，我们首先介绍了LLM-ARS的系统分析：（1）澄清核心概念和体系结构； （2）强调代理能力（例如计划，内存和多模式推理）如何提高建议质量； （3）在安全，效率和终生个性化等领域概述了关键的研究问题。我们还讨论了开放问题和未来的方向，认为LLM-ARS将推动下一波RS创新。最终，我们预见到范式转向智能，自主和协作的推荐经验，这些体验与用户不断发展的需求和复杂的决策过程更加一致。]]></description>
      <guid>https://arxiv.org/abs/2503.16734</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Superarc：基于递归理论和算法概率的第一原理的一般和超级智能的测试</title>
      <link>https://arxiv.org/abs/2503.16743</link>
      <description><![CDATA[ARXIV：2503.16743V1公告类型：新 
摘要：我们引入了以算法概率为基础的开放式测试，该测试可以避免在其人工通用智能（AGI）和超级智能（ASI）主张的情况下对边境模型的定量评估中的基准污染。与其他测试不同，该测试不依赖于统计压缩方法（例如GZIP或LZW），它们与香农熵更紧密相关，而不是与Kolmogorov的复杂性。该测试挑战了与基本本质智能的特征有关的方面，例如在反问题的背景下（从观察结果产生新知识）中的综合和模型创建。我们认为，基于模型抽象和最佳贝叶斯推论的指标可以为测试智能提供一个强大的框架，包括自然智能（人类和动物），狭窄的AI，AGI和ASI。我们的结果没有表明LLM收敛到定义的智能水平，尤其是AGI或ASI的明确证据。我们发现，LLM模型版本往往脆弱且增量，因为新版本的性能可能比较旧版本差，并且进步很大程度上是由训练数据的规模驱动的。将结果与一种混合神经肌符号方法进行了比较，从理论上讲，从理论上保证了基于算法概率和kolmogorov复杂性原理的最佳推理的模型收敛。该方法在短二进制序列上的概念验证中的表现优于LLM。我们的发现证实了对LLM的基本局限性的怀疑，将其视为对对人类语言的掌握感知的优化系统。发现来自同一开发人员的不同LLM版本之间的进展是不一致且有限的，尤其是在没有固体符号对应物的情况下。]]></description>
      <guid>https://arxiv.org/abs/2503.16743</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过思考的推理有助于移动GUI代理吗？一项实证研究</title>
      <link>https://arxiv.org/abs/2503.16788</link>
      <description><![CDATA[ARXIV：2503.16788V1公告类型：新 
摘要：推理能力显着提高了视觉模型（VLM）的性能（VLM），例如数学问题解决，编码和视觉提问。但是，它们对现实世界应用的影响尚不清楚。本文介绍了有关启用推理VLM在移动GUI代理的有效性的首次实证研究，该域需要解释复杂的屏幕布局，了解用​​户指令并执行多转交互。我们评估了两对商业模型-Gemini 2.0 Flash和Claude 3.7十四行诗 - 跨两个静态基准（ScreenSpot和AndroidControl）以及一个交互式环境（AndroidWorld）跨越了它们的基础和推理增强版本。我们出人意料地发现，Claude 3.7十四行诗推理模型在Androidworld上实现了最先进的表现。但是，推理VLM通常比静态基准的非调理模型具有边际改进，甚至在某些代理设置中甚至会降低性能。值得注意的是，推理和非争议VLM在不同的任务集上失败了，这表明推理确实有影响，但其优势和缺点相互平衡。我们将这些矛盾之处归因于基准和VLM的局限性。根据调查结果，我们提供了有关基准，VLMS及其在动态引用推理VLM中的适应性方面进一步增强移动GUI代理的见解。实验数据可在https://github.com/llamatouch/vlm-reasoning-traces上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2503.16788</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号学习的可学习性分析</title>
      <link>https://arxiv.org/abs/2503.16797</link>
      <description><![CDATA[ARXIV：2503.16797V1公告类型：新 
摘要：本文分析了混合系统中神经符号（NESY）任务的可学习性。我们表明，NESY任务的可学习性可以由其派生的约束满意度问题（DCSP）来表征。具体而言，如果相应的DCSP具有独特的解决方案，则可以学习任务。否则，它是无法完成的。对于可学习的任务，我们通过利用假设空间的聚类属性来建立错误界限。此外，我们分析了一般NESY任务的渐近误差，表明预期误差与解决方案之间的分歧相同。我们的结果提供了确定可学习性并为新算法设计的见解的原则方法。]]></description>
      <guid>https://arxiv.org/abs/2503.16797</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内部评估是不够的：通用AI的强大第三方缺陷披露</title>
      <link>https://arxiv.org/abs/2503.16861</link>
      <description><![CDATA[ARXIV：2503.16861V1公告类型：新 
摘要：通用AI（GPAI）系统的广泛部署引入了重大的新风险。然而，在GPAI系统中报告缺陷的基础架构，实践和规范仍然严重发达，远远落后于诸如软件安全的更既定的领域。根据软件安全，机器学习，法律，社会科学和政策领域的专家之间的合作，我们确定了GPAI系统中缺陷的评估和报告中的关键差距。我们要求采取三项干预措施以提高系统安全性。首先，我们建议对研究人员使用标准化的AI缺陷报告和参与规则，以减轻GPAI系统中提交，复制和分类缺陷的过程。其次，我们建议GPAI系统提供商采用广泛的缺陷披露计划，从漏洞赏金中借用，并提供法律安全的港口来保护研究人员。第三，我们主张开发改进的基础设施，以协调许多可能受到影响的利益相关者的缺陷报告分布。这些干预措施越来越紧迫，这是由于越狱和其他可能在不同提供商GPAI系统中转移的缺陷的率所证明的。通过促进AI生态系统中的强大报告和协调，这些建议可以显着提高GPAI系统的安全性，安全性和问责制。]]></description>
      <guid>https://arxiv.org/abs/2503.16861</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>地图：一个基于七大人格和苏格拉底式多模式科学问题解决的多代理框架</title>
      <link>https://arxiv.org/abs/2503.16905</link>
      <description><![CDATA[ARXIV：2503.16905V1公告类型：新 
摘要：多模式科学问题（MSP）涉及需要整合多种模式（例如文本和图表）的复杂问题，在人工智能中提出了重大挑战。尽管在解决传统科学问题方面取得了进展，但MSP仍然面临两个主要问题：多模式的综合推理在科学问题解决方面的挑战以及缺乏反思性和重新思考的能力。为了解决这些问题，我们根据七大人格和苏格拉底指导（MAP）介绍了一个多代理框架。该框架采用了七个不同的代理，可利用反馈机制和苏格拉底式方法来指导MSP的分辨率。为了解决第一个问题，我们提出了一种进步的四个代理解决策略，每个代理都专注于解决问题过程的特定阶段。对于第二期，我们介绍了一位受苏格拉底询问的启发的评论家，这促使批判性思维并刺激自主学习。我们在Emma，Olympiad和Mathvista数据集上进行了广泛的实验，实现了令人鼓舞的结果，在所有任务中，当前的SOTA模型都超过了15.84％。同时，附加的分析实验还验证了模型的进步以及泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2503.16905</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于软件定义网络的深入强化学习，一种具有交换节点选择策略的新段路由方法</title>
      <link>https://arxiv.org/abs/2503.16914</link>
      <description><![CDATA[ARXIV：2503.16914V1公告类型：新 
摘要：现有的段路由（SR）方法需要首先确定路由，然后使用路径分割方法选择交换节点以形成段路由路径（SRP）。当路由发生变化时，他们需要对路径进行重新分割。此外，他们不考虑流动桌发行时间，这无法最大化发行速度的速度。为了解决这些问题，本文建立了一个优化模型，该模型可以同时构成路由策略和路径分割策略，以选择适当的交换节点以减少流桌发行时间。它还设计了一种基于深钢筋学习（DRL-SR）的智能段路由算法，以解决所提出的模型。首先，交通矩阵被设计为深钢筋学习代理的状态空间。该矩阵包括多个QoS性能指标，流台发行时间开销和SR标签堆栈深度。其次，设计了动作选择策略和相应的奖励功能，在其中代理选择下一个节点考虑路由；此外，考虑到控制器将流表向交换节点发出流程表的时间成本系数，设计了新添加的节点是否作为交换节点和相应的奖励功能选择了新添加的节点。最后，一系列实验及其结果表明，与现有方法相比，设计的分段路线优化模型和智能解决方案算法（DRL-SR）可以减少完成分段路线建立任务所需的时间开销，同时优化诸如吞吐量，延迟，延迟和数据包损失等性能指标。]]></description>
      <guid>https://arxiv.org/abs/2503.16914</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过典型实例识别来解释口腔病变诊断的机器学习</title>
      <link>https://arxiv.org/abs/2503.16938</link>
      <description><![CDATA[ARXIV：2503.16938V1公告类型：新 
摘要：医疗保健中的决策过程可能是高度复杂且具有挑战性的。机器学习工具为协助这些过程提供了巨大的潜力。但是，许多当前的方法依赖于不容易被专家解释的复杂模型。这强调了开发可解释的模型的需求，这些模型可以在临床决策中提供有意义的支持。在接近此类任务时，人类通常将手头的情况与记忆中印记的一些关键示例和代表性案例进行比较。使用一种选择这样的示例性案例并以其预测为基础的方法，可能有助于获得针对此类问题的高性能解释解决方案。为此，我们在口服病变检测问题上评估了一种可解释的原型选择模型Pivottree，该模型专门试图检测来自口腔图像的肿瘤，疏远和创伤性溃疡性病变的存在。我们证明了在绩效方面使用这种方法的功效，并提供了定性和定量的比较，而专家选择的示例性案例和地面真相原型。]]></description>
      <guid>https://arxiv.org/abs/2503.16938</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经引导方程发现</title>
      <link>https://arxiv.org/abs/2503.16953</link>
      <description><![CDATA[ARXIV：2503.16953V1公告类型：新 
摘要：深度学习方法对方程发现变得越来越有吸引力。我们通过概述了最近的论文概述以及使用我们的模块化方程发现系统mgmt（$ \ textbf {m} $ ulti-task $ \ textbf {g textbf {g} $ rammar-rammar-rammar-fextbf {m-carlo {m-carlo {m} $，我们展示了使用神经引导方程发现的优势和缺点。 $ \ textbf {t} $ ree搜索方程发现）。该系统使用神经引导的蒙特卡洛树搜索（MCTS），并通过由无上下文的语法定义的搜索空间支持受监督和强化学习。我们总结了方程发现系统的七个理想属性，强调了将表格数据集嵌入此类学习方法的重要性。使用MGMT的模块化结构，我们比较了七个架构（其中包括RNN，CNNS和Transformers）将表格数据集嵌入在对比度学习的辅助任务上，以在方程发现任务上进行对比度学习。对于几乎所有模块组合，监督的学习都优于强化学习。此外，我们的实验表明将语法规则用作动作空间而不是令牌的优势。 MCT的两种改编（寻求风险的MCT和AMEX-MCT）可以通过这种搜索来改善方程发现。]]></description>
      <guid>https://arxiv.org/abs/2503.16953</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>游戏的实时扩散策略：通过Q增强的增强一致性政策</title>
      <link>https://arxiv.org/abs/2503.16978</link>
      <description><![CDATA[ARXIV：2503.16978V1公告类型：新 
摘要：扩散模型在捕获游戏代理的复杂和多模式动作分布方面表现出了令人印象深刻的性能，但是它们的缓慢推理速度可阻止在实时游戏环境中实用的部署。尽管一致性模型为一步一代提供了一种有希望的方法，但在应用于政策学习时，它们通常会遭受训练不稳定和绩效降解的困扰。在本文中，我们介绍了CPQE（Q-Emembles的一致性策略），该策略将一致性模型与Q emembles结合在一起，以应对这些挑战。CPQE通过Q-增强功能利用不确定性估计，以提供更可靠的价值函数近似值，从而提供了与经典的Double Q NetWork方法相比，可以提供更好的训练稳定性和提高的训练稳定性。我们在多种游戏场景中进行的广泛实验表明，CPQE的推理速度最高为60 Hz，这比最先进的扩散策略仅在20 Hz下运行，同时保持了与多步分散扩散方法相当的性能。 CPQE始终优于最先进的一致性模型方法，在整个学习过程中都表明了更高的奖励和增强的训练稳定性。这些结果表明，CPQE为在游戏和其他实时应用程序中部署基于扩散的策略提供了一种实用的解决方案，在该应用程序和其他实时应用程序中，多模式行为建模和快速推断都是至关重要的要求。]]></description>
      <guid>https://arxiv.org/abs/2503.16978</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯网络指南的结构和参数学习软件包-2025 Edition</title>
      <link>https://arxiv.org/abs/2503.17025</link>
      <description><![CDATA[ARXIV：2503.17025V1公告类型：新 
摘要：需要代表人工智能来代表世界的运作方式。贝叶斯网络（BNS）已被证明是该任务的有效且通用的工具。 BN需要在变量之间构建依赖关系的结构，并学习控制这些关系的参数。这些任务（称为结构学习和参数学习）由研究界积极研究，并提出了几种算法，没有单一的方法确立自己的标准。已经开发了广泛的软件，工具和包装，用于BNS分析，并提供给学术研究人员和行业从业人员。由于没有一定大小的解决方案，因此将第一个实用步骤并向这一领域定向，这对外部者和初学者来说是一项挑战。在本文中，我们回顾了迄今为止，为BNS结构和参数学习的最相关的工具和软件，并向初学者的受众提供了我们的主观建议。此外，我们还提供了一个易于庆祝的概述表，总结了所有软件包及其主要功能。通过提高读者对哪种可用软件可能最适合其需求的了解，我们可以提高对现场的可访问性，并使初学者更容易迈出第一步。]]></description>
      <guid>https://arxiv.org/abs/2503.17025</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打破无法区分的物体的对称性</title>
      <link>https://arxiv.org/abs/2503.17251</link>
      <description><![CDATA[ARXIV：2503.17251V1公告类型：新 
摘要：当对约束编程中的问题以及其他相关范式中建模问题时，通常会发生难以区分的对象。当可以将对象视为从一组未标记的对象中绘制的对象时，就会发生它们，而在它们上允许的唯一操作是平等测试。例如，社会高尔夫球手问题中的高尔夫球手是无法区分的。如果我们确实标记了高尔夫球手，那么在一个解决方案中，高尔夫球手的任何重新标记都会提供另一种有效的解决方案。因此，我们可以将$ n $的对称组视为在一组$ n $难以区分的对象上。在本文中，我们展示了如何打破无法区分的对象产生的对称性。我们展示了如何在不可区分的类型中正确定义难以区分的对象的对称性，例如在无法区分的对象索引的矩阵中。然后，我们展示如何正确打破所得的对称性。从本质上讲，高级建模语言，无法区分的对象被封装在“未命名类型”中。我们提供了本质上未命名类型的完全对称破坏的实施。]]></description>
      <guid>https://arxiv.org/abs/2503.17251</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>捕获具有奖励功能的个人偏好</title>
      <link>https://arxiv.org/abs/2503.17338</link>
      <description><![CDATA[ARXIV：2503.17338V1公告类型：新 
摘要：从人类反馈中学习的强化学习通常使用不区分人的奖励模型来模拟偏好。我们认为，这不太可能在具有很高分歧潜力的上下文中成为一个不错的设计选择，例如在大型语言模型的培训中。我们提出了一种将奖励模型专门针对一个人或人群的方法。我们的方法基于这样的观察，即可以将单个偏好作为一组通用奖励功能的线性组合捕获。我们展示了如何学习此类功能，并随后使用它们来快速将奖励模型调整为特定个人，即使他们的偏好未反映在培训数据中。我们介绍了大型语言模型的实验，将提出的体系结构与非自适应奖励模型以及适应性对应物进行了比较，包括进行中文个性化的模型。根据培训数据中有多少分歧，我们的模型要么大大优于基准，要么与更简单的体系结构和更稳定的培训相匹配。]]></description>
      <guid>https://arxiv.org/abs/2503.17338</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HCAST：由人为校准的自主软件任务</title>
      <link>https://arxiv.org/abs/2503.17354</link>
      <description><![CDATA[ARXIV：2503.17354V1公告类型：新 
摘要：要了解和预测高度自主的AI系统的社会影响，我们需要基于接地的基准，即直接将AI性能与我们关心的现实世界效应联系起来的指标。我们提出HCAST（由人为校准的自治软件任务），这是189机器学习工程，网络安全，软件工程和一般推理任务的基准。我们从熟练的这些领域的人中收集563个人类基准（总计1500小时），在与AI代理相同的条件下工作，这使我们估计Hcast任务使人类在一分钟至8个小时之间。衡量人类的时间任务提供了一个直观的指标，以评估AI功能，并帮助回答“可以信任代理商来完成需要人类X小时的任务吗？”的问题。我们评估了建立在Frontier基础模型上的AI代理的成功率，我们发现目前的代理在70-80％的时间上成功完成了不到一小时的人，而在人体中，少于人类超过4个小时的任务的时间不到20％。]]></description>
      <guid>https://arxiv.org/abs/2503.17354</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OnDev-LCT：启用式轻量级卷积变压器朝联盟学习</title>
      <link>https://arxiv.org/abs/2401.11652</link>
      <description><![CDATA[ARXIV：2401.11652V1公告类型：交叉 
摘要：联合学习（FL）已成为一种有希望的方法，可以在保留隐私的同时跨多个边缘设备进行机器学习模型。 FL取决于参与模型的效率及其应对分布式学习的独特挑战的能力。尽管视觉变压器（VIT）的几种变体作为现代卷积神经网络（CNN）的替代方案表现出了巨大的潜力，但用于集中式培训，但前所未有的规模和较高的计算需求阻碍了他们在资源受限的边缘设备上的部署，从而挑战了他们在FL中广泛应用的挑战。由于FL中的客户端设备通常具有有限的计算资源和通信带宽，因此用于此类设备的模型必须在模型大小，计算效率和适应FL中遇到的多样和非IID数据分布的能力之间取得平衡。为了应对这些挑战，我们提出了OnDev-LCT：轻巧的卷积变压器，用于具有有限的培训数据和资源的设备视觉任务。我们的模型通过利用剩余线性瓶颈块中利用有效的深度可分离卷积来提取局部特征，而多头自我注意力（MHSA）机制在LCT Encoder中隐含促进捕获图像的全局图像来促进，我们的模型通过LCT令牌结合了图像特异性的电感偏置。基准图像数据集上的广泛实验表明，我们的模型的表现优于现有的轻质视觉模型，同时具有较少的参数和较低的计算需求，使其适合具有数据异质性和通信瓶颈的FL场景。]]></description>
      <guid>https://arxiv.org/abs/2401.11652</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>剪辑ping：用邻居的邻居指导促进轻巧的视觉语言模型</title>
      <link>https://arxiv.org/abs/2412.03871</link>
      <description><![CDATA[ARXIV：2412.03871V2公告类型：交叉 
摘要：除了对比性语言图像预训练（剪辑）的成功之外，最近的趋势标志着朝着探索轻巧视觉模型在资源受限的场景中的适用性的转变。这些模型仅依靠单个图像文本对比学习目标，通常会产生次优性能，从而聚焦对更有效的训练机制的需求可以保证稳健的跨模式特征对齐。在这项工作中，我们提出了剪辑剪辑：对比性的语言图像预训练与邻居固有的邻居指导，这是一种新颖而简单而有效的训练范式，旨在提高具有最小的计算范围的轻量级视觉模型的性能，并具有最小的计算范围内开销和较低的数据需求。从任意训练的编码器中提取的剪辑 - 束引导程序单峰特征，以获取亲近邻居样品的固有指导，即最近的邻居（NN）和Cross近邻居（XNN）。我们发现，这些邻居的额外对比度有很大程度上提高了跨模式的对准，从而使轻量级模型能够学习更多具有丰富语义多样性的通用特征。广泛的实验表明，剪辑夹在零拍和跨模式检索任务中显着超过其同龄人。具体而言，与原始剪辑相比，在使用300万（图像，文本）对的VIT-XS Image编码器时，与原始剪辑相比，FlickR30K检索的零摄像机分类为10.7％（I2T）和5.7％（t2i）的5.5％增长。此外，剪贴画在几个下游任务中在线性评估协议下展示了强大的可传递性。]]></description>
      <guid>https://arxiv.org/abs/2412.03871</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Openai的AI模型和系统的外部红色团队的方法</title>
      <link>https://arxiv.org/abs/2503.16431</link>
      <description><![CDATA[ARXIV：2503.16431V1公告类型：交叉 
摘要：红色小组已成为评估AI模型和系统可能风险的关键实践。它有助于发现新颖的风险，在现有缓解中的压力测试可能差距，丰富现有的定量安全指标，促进创建新的安全测量结果，并增强公众信任以及AI风险评估的合法性。这份白皮书描述了Openai在外部红色小组中的工作，并从这项工作中得出了一些更一般的结论。我们描述了基于外部红色团队的设计注意事项，其中包括：选择红色团队的组成，确定访问水平，并提供进行红色团队所需的指导。此外，我们展示了红色团队的结果，例如对风险评估和自动化评估的投入。我们还描述了外部红色小组的局限性，以及如何适应更广泛的AI模型和系统评估。通过这些贡献，我们希望AI开发人员和部署者，评估创建者和政策制定者将能够更好地设计红色团队活动，并更深入地了解外部红色团队如何适应模型部署和评估流程。这些方法正在发展，随着围绕红色小组成熟的生态系统的成熟和模型本身作为红色团队的工具，不同方法的价值继续转移。]]></description>
      <guid>https://arxiv.org/abs/2503.16431</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>