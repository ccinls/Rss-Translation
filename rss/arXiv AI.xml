<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 21 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>社会智能的评估和建模：人类和人工智能能力的比较研究</title>
      <link>https://arxiv.org/abs/2405.11841</link>
      <description><![CDATA[arXiv:2405.11841v1 公告类型：新
摘要：面对当前关于大型语言模型 (LLM) 是否达到接近人类智能水平的争论（Mitchell &amp; Krakauer，2023；Bubeck 等，2023；Kosinski，2023；Shiffrin &amp; Mitchell，2023；Ullman，2023），本研究引入了评估社交智力的基准，社交智力是人类认知最独特的方面之一。我们开发了一个全面的社会动态理论框架，并引入了两个评估任务：逆推理 (IR) 和逆逆规划 (IIP)。我们的方法还包括一个基于递归贝叶斯推理的计算模型，该模型擅长阐明各种人类行为模式。大量的实验和详细的分析表明，人类在整体性能、零样本学习、一次性泛化和对多模态的适应性方面都超越了最新的 GPT 模型。值得注意的是，GPT 模型仅在最基本的顺序（顺序 = 0）上表现出社交智能，与人类社交智能（顺序 &gt;= 2）形成鲜明对比。进一步的研究表明，LLM 倾向于依靠模式识别来寻找捷径，这让人怀疑它们是否拥有真正的人类水平的社交智能。我们的代码、数据集、附录和人类数据发布在 https://github.com/bigai-ai/Evaluate-n-Model-Social-Intelligence。]]></description>
      <guid>https://arxiv.org/abs/2405.11841</guid>
      <pubDate>Tue, 21 May 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>可配置的镜像下降：迈向决策的统一</title>
      <link>https://arxiv.org/abs/2405.11746</link>
      <description><![CDATA[arXiv:2405.11746v1 公告类型：新
摘要：决策问题普遍存在，分为单智能体（例如 Atari）、合作多智能体（例如 Hanabi）、竞争性多智能体（例如德州扑克）以及混合合作和竞争（例如足球）在现实世界。提出了各种方法来解决具体的决策问题。尽管在特定类别中取得了成功，但这些方法通常是独立发展的，不能推广到其他类别。因此，决策的一个基本问题是：\emph{我们能否开发\textbf{单一算法}来解决\textbf{ALL}类别的决策问题？}解决这个问题有几个主要挑战： ）不同的决策类别涉及不同数量的智能体和不同的智能体之间的关系，ii）不同的类别有不同的解决方案概念和评估措施，以及iii）缺乏覆盖所有类别的综合基准。这项工作通过三个主要贡献提出了解决该问题的初步尝试。 i）我们提出广义镜像下降（GMD），这是 MD 变体的概括，它考虑了多种历史政策并适用于更广泛的 Bregman 散度。 ii）我们提出了可配置的镜像下降（CMD），其中引入元控制器来根据评估措施动态调整 GMD 中的超参数。 iii) 我们构建了 \textsc{GameBench}，其中包含 15 个跨不同决策类别的学术友好型游戏。大量实验表明，与基线相比，CMD 实现了经验上的竞争或更好的结果，同时提供了探索决策的不同维度的能力。]]></description>
      <guid>https://arxiv.org/abs/2405.11746</guid>
      <pubDate>Tue, 21 May 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>从 SHAP 分数到特征重要性分数</title>
      <link>https://arxiv.org/abs/2405.11766</link>
      <description><![CDATA[arXiv:2405.11766v1 公告类型：新
摘要：可解释人工智能（XAI）的中心目标是在给出一些预测的情况下为机器学习（ML）模型的特征分配相对重要性。最近普遍使用的 SHAP 和 LIME 等工具说明了通过特征归因进行可解释性任务的重要性。不幸的是，使用 SHAP 和 LIME 的博弈论基础对特征归因进行精确计算可能会产生明显不令人满意的结果，这相当于报告了误导性的相对特征重要性。最近的工作针对严格的特征归因，通过研究特征的公理聚合，该聚合基于特征选择的解释的基于逻辑的定义。本文表明，特征归因和先验投票权之间存在本质关系，并且最近提出的公理聚合代表了过去研究的权力指数范围的一些实例。此外，目前还不清楚如何将一些最广泛使用的功效指数用作特征重要性评分（​​FIS），即在 XAI 中使用功效指数，以及这些指数中哪些最适合 XAI 的目的特征归因，即未产生可被视为不满意的结果。本文提出了 FIS 应表现出的新颖的理想特性。此外，本文还提出了具有所提出特性的新型 FIS。最后，本文根据所提出的属性对最著名的功率指数进行了严格分析。]]></description>
      <guid>https://arxiv.org/abs/2405.11766</guid>
      <pubDate>Tue, 21 May 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的 POI 分类的语义轨迹数据挖掘</title>
      <link>https://arxiv.org/abs/2405.11715</link>
      <description><![CDATA[arXiv:2405.11715v1 公告类型：新
摘要：人类出行轨迹挖掘对于交通系统、增强路线优化、交通管理和人类出行模式研究至关重要。以前没有集成语义信息的基于规则的方法在效率和准确性方面都表现出局限性。语义信息，例如从兴趣点 (POI) 数据推断的活动类型，可以显着提高轨迹挖掘的质量。然而，整合这些见解具有挑战性，因为许多 POI 的特征信息不完整，而当前基于学习的 POI 算法需要数据集的完整性来进行分类。在本文中，我们介绍了一种用于人类旅行轨迹挖掘的新颖管道。我们的方法首先利用大型语言模型 (LLM) 强大的推理和理解能力来用活动类型注释 POI，然后使用基于贝叶斯的算法来推断轨迹中每个停留点的活动。在我们使用 OpenStreetMap (OSM) POI 数据集的评估中，我们的方法在 POI 分类中实现了 93.4% 的准确率和 96.1% F-1 分数，在活动推断中实现了 91.7% 的准确率和 92.3% F-1 分数。]]></description>
      <guid>https://arxiv.org/abs/2405.11715</guid>
      <pubDate>Tue, 21 May 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>Hummer：走向有限的竞争偏好数据集</title>
      <link>https://arxiv.org/abs/2405.11647</link>
      <description><![CDATA[arXiv:2405.11647v1 公告类型：新
摘要：偏好数据集对于将人类偏好纳入预训练的语言模型至关重要，在人类反馈强化学习的成功中发挥着关键作用。然而，这些数据集经常表现出相互冲突的对齐目标，导致更容易受到越狱攻击，并且在调整下游任务以优先考虑特定对齐目标而不会对其他目标产生负面影响方面面临挑战。在这项工作中，我们引入了一种新颖的统计指标，即对齐维度冲突，来量化偏好数据集中的冲突程度。然后，我们提出 \texttt{Hummer} 及其细粒度变体 \texttt{Hummer-F}，作为具有减少冲突对齐目标的创新的成对偏好数据集。 Hummer 是基于 UltraFeedback 构建的，并通过 GPT-4 的 AI 反馈进行了增强，被标记为旨在减少对齐目标之间竞争的首选数据集。此外，我们开发了奖励模型 HummerRM 和 HummerRM-F，它们采用混合采样方法来有效平衡不同的对齐目标。这种采样方法将 HummerRM 定位为针对特定领域进一步微调和减少攻击漏洞的理想模型。]]></description>
      <guid>https://arxiv.org/abs/2405.11647</guid>
      <pubDate>Tue, 21 May 2024 06:27:06 GMT</pubDate>
    </item>
    <item>
      <title>提高 LLM 问答准确率：本体来救援！</title>
      <link>https://arxiv.org/abs/2405.11706</link>
      <description><![CDATA[arXiv:2405.11706v1 公告类型：新
摘要：越来越多的证据表明，具有大型语言模型 (LLM) 的问答 (QA) 系统采用企业 SQL 数据库的知识图/语义表示（即文本到 SPARQL），与系统相比能够实现更高的准确性直接在 SQL 数据库上回答问题（即文本到 SQL）。我们之前的基准研究表明，通过使用知识图谱，准确率从 16% 提高到 54%。问题仍然是：如何进一步提高准确率并降低错误率？基于我们之前研究的观察结果，即不准确的 LLM 生成的 SPARQL 查询遵循错误的路径，我们提出了一种方法，包括 1) 基于本体的查询检查 (OBQC)：通过利用知识图的本体进行检查来检测错误如果LLM生成的SPARQL查询与本体的语义匹配，并且2)LLM修复：使用LLM的错误解释来修复SPARQL查询。使用与数据基准的聊天，我们的主要发现是我们的方法将整体准确率提高到 72%，其中包括额外 8% 的“我不知道”未知结果。因此，总体错误率为20%。这些结果进一步证明，投资知识图谱（即本体论）可以为 LLM 支持的问答系统提供更高的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.11706</guid>
      <pubDate>Tue, 21 May 2024 06:27:06 GMT</pubDate>
    </item>
    <item>
      <title>查询、交互和集成：零样本多模态医学推理的主动代理协作框架</title>
      <link>https://arxiv.org/abs/2405.11640</link>
      <description><![CDATA[arXiv:2405.11640v1 公告类型：新 
摘要：大型语言模型 (LLM) 在医疗保健领域的应用引起了广泛的研究兴趣。然而，它们在医疗保健领域的表现仍未得到充分研究并且可能受到限制，因为 i) 它们缺乏丰富的领域特定知识和医学推理技能；ii) 大多数最先进的 LLM 都是单模态、纯文本模型，不能直接处理多模态输入。为此，我们提出了一个多模态医学协作推理框架 \textbf{MultiMedRes}，它结合了一个学习者代理，可以从特定领域的专家模型中主动获取重要信息，以解决医学多模态推理问题。我们的方法包括三个步骤：i) \textbf{Inquire}：学习者代理首先将给定的复杂医学推理问题分解为多个领域特定子问题； ii) \textbf{交互}：然后，代理通过重复“提问-回答”过程与领域特定专家模型进行交互，以逐步获得不同的领域特定知识；iii) \textbf{整合}：代理最终整合所有获取的领域特定知识，以准确解决医学推理问题。我们在 X 射线图像的差异视觉问答任务上验证了我们方法的有效性。实验表明，我们的零样本预测达到了最先进的性能，甚至优于全监督方法。此外，我们的方法可以纳入各种 LLM 和多模态 LLM，以显著提高其性能。]]></description>
      <guid>https://arxiv.org/abs/2405.11640</guid>
      <pubDate>Tue, 21 May 2024 06:27:05 GMT</pubDate>
    </item>
    <item>
      <title>通过社会福利优化评估群体公平性</title>
      <link>https://arxiv.org/abs/2405.11421</link>
      <description><![CDATA[arXiv:2405.11421v1 公告类型：新
摘要：统计奇偶性指标作为实现公平的一种手段在人工智能界得到了广泛的研究和认可，但它们至少存在两个弱点。他们无视决策的实际福利后果，因此可能无法实现弱势群体所期望的公平。此外，它们往往彼此不相容，并且没有令人信服的理由选择其中之一而不是另一个。本文探讨了基于优化社会福利函数（SWF）的更广泛的社会正义概念是否有助于评估各种平等定义。我们关注的是众所周知的阿尔法公平性 SWF，70 年来一直通过公理和讨价还价的论据来捍卫它。我们分析了最佳解决方案，并表明它可以在某些条件下证明人口均等或均等赔率的合理性，但通常需要偏离这些类型的均等。此外，我们发现预测利率平价的用处有限。这些结果表明，优化理论可以阐明如何在人工智能中实现群体公平这一激烈讨论的问题。]]></description>
      <guid>https://arxiv.org/abs/2405.11421</guid>
      <pubDate>Tue, 21 May 2024 06:27:04 GMT</pubDate>
    </item>
    <item>
      <title>CPS-LLM：基于大型语言模型的人在环工厂网络物理系统安全使用计划生成器</title>
      <link>https://arxiv.org/abs/2405.11458</link>
      <description><![CDATA[arXiv:2405.11458v1 公告类型：新
摘要：我们探索在人机循环人机网络物理系统（CPS）中使用大语言模型（LLM），将高级提示转化为个性化的行动计划，并随后将该计划转换为由现实世界的 CPS 控制器自动执行的顺序决策的基础推理，以实现控制目标。我们表明，将法学硕士置于情境中相对简单，因此它可以生成特定领域的计划。然而，这些计划对于物理系统来说可能无法执行，或者该计划对于人类用户来说可能不安全。为了解决这个问题，我们提出了 CPS-LLM，这是一种使用指令调整框架重新训练的 LLM，它确保生成的计划不仅符合 CPS 的物理系统动态，而且对人类用户来说也是安全的。 CPS-LLM由两个创新组件组成：a）基于液体时间常数神经网络的物理动力学系数估计器，可以推导出具有一些未测量的状态变量的动力学模型的系数； b) 然后使用模型系数来训练法学硕士，其中包含动力系统痕迹和相应模型系数的提示。我们证明，当 CPS-LLM 与 BARD 等情境化聊天机器人集成时，它可以生成可行且安全的计划来管理外部事件，例如 1 型糖尿病受试者使用的自动胰岛素输送系统的膳食。]]></description>
      <guid>https://arxiv.org/abs/2405.11458</guid>
      <pubDate>Tue, 21 May 2024 06:27:04 GMT</pubDate>
    </item>
    <item>
      <title>使用大数据和法学硕士本体的森林火灾管理决策支持系统</title>
      <link>https://arxiv.org/abs/2405.11346</link>
      <description><![CDATA[arXiv:2405.11346v1 公告类型：新
摘要：森林对于生态平衡至关重要，但森林火灾是森林损失的主要原因，带来了巨大的风险。评估野火风险并预测资源需求的火灾天气指数至关重要。随着传感器网络在医疗保健和环境监测等领域的兴起，语义传感器网络越来越多地用于收集风速、温度和湿度等气候数据。然而，处理这些数据流以确定火灾天气指数面临着挑战，这凸显了有效森林火灾检测的重要性日益增加。本文讨论了使用 Apache Spark 进行早期森林火灾检测，利用气象和地理数据增强火灾风险预测。基于我们之前开发的用于管理 Monesterial 自然公园森林火灾的语义传感器网络 (SSN) 本体和语义 Web 规则语言 (SWRL)，我们扩展了 SWRL，以使用大型语言模型 (LLM) 改进决策支持系统 (DSS)和 Spark 框架。我们利用 Spark 流实现了针对各种火灾场景的实时警报，并使用本体指标、基于查询的评估、LLM 分数精度、F1 分数和召回措施验证了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.11346</guid>
      <pubDate>Tue, 21 May 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>使用布尔矩阵逻辑编程模拟 Petri 网</title>
      <link>https://arxiv.org/abs/2405.11412</link>
      <description><![CDATA[arXiv:2405.11412v1 公告类型：新
摘要：最近对关系知识库的关注引发了对理解实体之间关系如何变化的需求。Petri 网可以表示知识结构并动态模拟实体之间的交互，因此它们非常适合实现这一目标。然而，由于高级符号操作的限制，逻辑程序很难处理广泛的 Petri 网。为了应对这一挑战，我们引入了一种称为布尔矩阵逻辑编程 (BMLP) 的新方法，利用布尔矩阵作为 Prolog 评估逻辑程序的替代计算机制。在这个框架内，我们提出了两种新的 BMLP 算法来模拟一类称为基本网的 Petri 网。这是通过将基本网转换为逻辑上等价的数据记录程序来实现的。我们通过经验证明，BMLP 算法可以比表格 B-Prolog、SWI-Prolog、XSB-Prolog 和 Clingo 快 40 倍地评估这些程序。我们的工作使得使用 Prolog 对基本网络进行有效模拟成为可能，扩大了使用逻辑编程技术对复杂系统进行分析、学习和验证的范围。]]></description>
      <guid>https://arxiv.org/abs/2405.11412</guid>
      <pubDate>Tue, 21 May 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>Uni-MoE：通过专家组合扩展统一多模式法学硕士</title>
      <link>https://arxiv.org/abs/2405.11273</link>
      <description><![CDATA[arXiv:2405.11273v1 公告类型：新
摘要：多模态大型语言模型（MLLM）的最新进展强调了可扩展模型和数据对提高性能的重要性，但这通常会产生大量的计算成本。尽管专家混合 (MoE) 架构已被用来有效扩展大型语言和图像文本模型，但这些工作通常涉及较少的专家和有限的模式。为了解决这个问题，我们的工作提出了利用 MoE 架构开发统一 MLLM 的开创性尝试，称为 Uni-MoE，可以处理多种模式。具体来说，它具有特定于模态的编码器和连接器，用于统一的多模态表示。我们还在法学硕士内实现了稀疏 MoE 架构，以通过模态级数据并行性和专家级模型并行性实现高效训练和推理。为了增强多专家协作和泛化，我们提出了一种渐进式培训策略：1）使用具有不同跨模态数据的各种连接器进行跨模态对齐，2）使用跨模态指令数据训练特定模态专家以激活专家的能力偏好，以及 3) 在混合多模式指令数据上利用低秩适应 (LoRA) 调整 Uni-MoE 框架。我们在一组全面的多模态数据集上评估了指令调整的 Uni-MoE。广泛的实验结果证明了 Uni-MoE 的主要优势是显着减少处理混合多模式数据集的性能偏差，同时改进了多专家协作和泛化。我们的研究结果强调了 MoE 框架在推进 MLLM 方面的巨大潜力，代码可在 https://github.com/HITsz-TMG/UMOE-Scaling-Uni​​fied-Multimodal-LLMs 上获取。]]></description>
      <guid>https://arxiv.org/abs/2405.11273</guid>
      <pubDate>Tue, 21 May 2024 06:27:02 GMT</pubDate>
    </item>
    <item>
      <title>反事实逻辑与因果推理认识论</title>
      <link>https://arxiv.org/abs/2405.11284</link>
      <description><![CDATA[arXiv:2405.11284v1 公告类型：新
摘要：2021年诺贝尔经济学奖表彰了一种因果推理理论，值得哲学家更多关注。为此，我开发了一种辩证法，将刘易斯-斯塔纳克的辩论延伸到称为条件排除中间（CEM）的逻辑原则上。我首先为 CEM 扮演好警察，并为此给出了一个新的论证：基于诺贝尔奖获得者理论的奎因​​-普特南不可或缺的论证。但后来我改变立场，扮演坏警察：我用一种新的因果推理理论破坏了这一论点，该理论保留了原始理论的成功，但省却了 CEM。]]></description>
      <guid>https://arxiv.org/abs/2405.11284</guid>
      <pubDate>Tue, 21 May 2024 06:27:02 GMT</pubDate>
    </item>
    <item>
      <title>通过答案集编程进行组合优化的大邻域优先搜索</title>
      <link>https://arxiv.org/abs/2405.11305</link>
      <description><![CDATA[arXiv:2405.11305v1 公告类型：新
摘要：我们提出大邻域优先搜索（LNPS）来解决答案集编程（ASP）中的组合优化问题。 LNPS 是一种元启发式算法，从初始解决方案开始，然后通过交替破坏和优先搜索当前解决方案来迭代尝试找到更好的解决方案。由于邻域的可变性，LNPS 允许灵活搜索，而不必强烈依赖于破坏算子。我们提出了一种基于 ASP 的 LNPS 实现。由此产生的 heulingo 求解器表明，LNPS 可以显着增强 ASP 的优化求解性能。此外，我们通过将 LNPS 方法与（自适应）大型邻域搜索进行实证对比来确定 LNPS 方法的竞争力。]]></description>
      <guid>https://arxiv.org/abs/2405.11305</guid>
      <pubDate>Tue, 21 May 2024 06:27:02 GMT</pubDate>
    </item>
    <item>
      <title>迈向知识注入的自动化疾病诊断助手</title>
      <link>https://arxiv.org/abs/2405.11181</link>
      <description><![CDATA[arXiv:2405.11181v1 公告类型：新
摘要：随着互联网通信和远程医疗的进步，人们越来越多地转向网络进行各种医疗保健活动。随着疾病和症状数量的不断增加，诊断患者变得具有挑战性。在这项工作中，我们构建了一个诊断助手来协助医生，它根据医患互动来识别疾病。在诊断过程中，医生结合症状学知识和诊断经验，准确、高效地识别疾病。受此启发，我们通过医患互动来研究医学知识在疾病诊断中的作用。我们提出了一种双通道、知识注入、话语感知的疾病诊断模型（KI-DDI），其中第一个通道使用基于变压器的编码器对医患沟通进行编码，而另一个通道使用基于变压器的编码器创建症状疾病的嵌入图注意力网络（GAT）。在下一阶段，对话和知识图嵌入被融合在一起，并输入到深度神经网络中以进行疾病识别。此外，我们首先开发了一个具有同理心的对话医学语料库，其中包含患者和医生之间的对话，并注释有意图和症状信息。所提出的模型展示了对现有最先进模型的显着改进，确立了（a）医生为额外症状提取（除了患者自我报告之外）所做的努力和（b）注入医学知识的关键作用有效识别疾病。很多时候，患者也会展示自己的身体状况，这是诊断的重要证据。因此，整合视觉感官信息将是增强诊断助理能力的有效途径。]]></description>
      <guid>https://arxiv.org/abs/2405.11181</guid>
      <pubDate>Tue, 21 May 2024 06:27:01 GMT</pubDate>
    </item>
    <item>
      <title>论证性因果发现</title>
      <link>https://arxiv.org/abs/2405.11250</link>
      <description><![CDATA[arXiv:2405.11250v1 公告类型：新
摘要：因果发现相当于发掘数据特征之间的因果关系。它是因果推理的重要伴侣，对于建立科学知识而不诉诸昂贵或不可能的随机对照试验是必不可少的。在本文中，我们探讨了使用符号表示进行推理如何支持因果发现。具体来说，我们部署基于假设的论证 (ABA)，一种完善而强大的知识表示形式，结合因果关系理论，来学习反映数据中因果依赖关系的图表。我们证明我们的方法表现出理想的特性，特别是在自然条件下，它可以检索真实因果图。我们还在因果发现标准基准的四个数据集上对答案集编程 (ASP) 中的方法实施了实验，表明我们的方法与既定基线相比效果良好。]]></description>
      <guid>https://arxiv.org/abs/2405.11250</guid>
      <pubDate>Tue, 21 May 2024 06:27:01 GMT</pubDate>
    </item>
    <item>
      <title>潜在状态估计帮助 UI 代理进行推理</title>
      <link>https://arxiv.org/abs/2405.11120</link>
      <description><![CDATA[arXiv:2405.11120v1 公告类型：新
摘要：在现实环境中运行的代理的一个常见问题是，环境对其行为的响应可能是不确定的，并且是通过噪声观察到的。这使得环境状态和完成任务的进度成为潜在的。尽管最近法学硕士在各种基准上的推理能力令人印象深刻，但法学硕士是否可以建立潜在状态的估计并利用它们进行推理尚未得到明确研究。我们在自治 UI 代理的现实世界中研究了这个问题。我们发现，以零样本方式适当提示法学硕士可以被正式理解为在文本空间中形成潜在状态的点估计。然后，在自主 UI 代理的背景下，我们表明以这种方式使用的 LLM 在推断潜在状态的各个方面（例如执行的（与命令的）动作和任务进展）方面的准确度超过 76\%$。使用公共和内部基准以及三种推理方法（零样本、CoT-SC 和 ReAct），我们表明，明确估计和推理潜在状态的 LLM 支持的代理能够成功完成比其他代理多 1.6 倍的任务那不。]]></description>
      <guid>https://arxiv.org/abs/2405.11120</guid>
      <pubDate>Tue, 21 May 2024 06:27:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenRLHF：易于使用、可扩展且高性能的 RLHF 框架</title>
      <link>https://arxiv.org/abs/2405.11143</link>
      <description><![CDATA[arXiv:2405.11143v1 公告类型：新
摘要：随着大型语言模型（LLM）按比例规律不断增长，人类反馈强化学习（RLHF）因其出色的性能而受到广泛关注。然而，与预训练或微调单个模型不同，通过人类反馈（RLHF）扩展强化学习来训练大型语言模型给四个模型之间的协调带来了挑战。我们推出 OpenRLHF，这是一个能够实现高效 RLHF 扩展的开源框架。与在同一 GPU 上共置四个模型的现有 RLHF 框架不同，OpenRLHF 使用 Ray、vLLM 和 DeepSpeed 重新设计了超过 70B 参数的模型调度，利用改进的资源利用率和多样化的训练方法。 OpenRLHF 与 Hugging Face 无缝集成，提供具有优化算法和启动脚本的开箱即用解决方案，确保用户友好性。 OpenRLHF 实现了 RLHF、DPO、拒绝采样和其他对齐技术。 OpenRLHF 的代码支持最先进的 LLM 开发，可从 https://github.com/OpenLLMAI/OpenRLHF 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.11143</guid>
      <pubDate>Tue, 21 May 2024 06:27:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是道德伪君子吗？基于道德基础的研究</title>
      <link>https://arxiv.org/abs/2405.11100</link>
      <description><![CDATA[arXiv:2405.11100v1 公告类型：新
摘要：大型语言模型（LLM）已成为人工智能争论的中心舞台。然而，在如何评估法学硕士是否符合重要的人类价值观方面仍然存在差距。在本文中，我们调查了最先进的 LLM、GPT-4 和 Claude 2.1（Gemini Pro 和 LLAMA 2 没有生成有效结果）是否是道德伪君子。我们采用两种基于道德基础理论的研究工具：（i）道德基础问卷（MFQ），它调查哪些价值观在抽象道德判断中被认为与道德相关； (ii) 道德基础小插图 (MFV)，它评估与每个道德基础相关的具体场景中的道德认知。我们将这些不同的道德评价抽象之间的价值观冲突描述为虚伪。我们发现，与人类相比，这两个模型在每个工具内都表现出了合理的一致性，但当我们将 MFQ 中存在的抽象价值观与 MFV 的具体道德违规评估进行比较时，它们表现出矛盾和虚伪的行为。]]></description>
      <guid>https://arxiv.org/abs/2405.11100</guid>
      <pubDate>Tue, 21 May 2024 06:26:59 GMT</pubDate>
    </item>
    <item>
      <title>Jill Watson：由 ChatGPT 提供支持的虚拟助教</title>
      <link>https://arxiv.org/abs/2405.11070</link>
      <description><![CDATA[arXiv:2405.11070v1 公告类型：新
摘要：对话式人工智能代理通常需要大量未公开发布的训练数据集，仅限于社交聊天或处理特定领域，并且可能不容易扩展以适应人工智能技术的最新进展。本文介绍了 Jill Watson，一个利用 ChatGPT 功能的会话式虚拟教学助理 (VTA)。基于 ChatGPT 的 Jill Watson 无需事先培训，并采用模块化设计，允许使用受小冰启发的基于技能的架构集成新的 API。 Jill Watson 也非常适合智能教科书，因为它可以使用多个大型文档进行处理和对话。我们专门利用公开可用的资源来实现可重复性和可扩展性。比较分析表明，我们的系统优于传统的基于知识的 Jill Watson 以及 OpenAI Assistants 服务。我们采取了许多安全措施来减少幻觉和中毒的发生。本文还包括来自课堂环境的真实示例，展示了吉尔·沃森的不同特征及其有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.11070</guid>
      <pubDate>Tue, 21 May 2024 06:26:58 GMT</pubDate>
    </item>
    </channel>
</rss>