<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在快车道中的公平竞争：将体育精神整合到自主赛车系统中</title>
      <link>https://arxiv.org/abs/2503.03774</link>
      <description><![CDATA[ARXIV：2503.03774V1公告类型：新 
摘要：自主赛车作为高速决策和运动控制的平台引起了极大的关注。尽管现有的方法主要集中于轨迹计划和超越策略，但体育精神在确保公平竞争中的作用仍然在很大程度上没有探索。在人类赛车中，诸如单动规则和足够空间规则之类的规则可以防止危险且非竞技场的行为。但是，自主赛车系统通常缺乏执行这些原则的机制，可能导致不安全的动作。本文介绍了一个双层游戏理论框架，将体育精神（SPS）整合到竞赛中。在高水平上，我们使用Stackelberg游戏对赛车意图进行建模，其中使用蒙特卡洛树搜索（MCT）来得出最佳策略。在低水平上，车辆相互作用被公一般的NASH平衡问题（GNEP）配制，以确保所有试剂在优化其轨迹的同时遵循体育精神限制。仿真结果证明了拟议方法在执行体育精神规则的同时保持竞争性绩效的有效性。我们分析了攻击者和捍卫者坚持或无视体育精神规则的不同情况，并展示了这些约束的知识如何影响战略决策。这项工作强调了在自动赛车中平衡竞争和公平性的重要性，并为发展道德和安全的AI驱动赛车系统奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2503.03774</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在模拟搜索中预测沟通中的团队绩效</title>
      <link>https://arxiv.org/abs/2503.03791</link>
      <description><![CDATA[ARXIV：2503.03791V1公告类型：新 
摘要：了解单个特征如何影响团队绩效是有价值的，但是这些特征并不总是可以直接观察到的。先前的研究推断了行为数据的信任之类的特征。我们分析对话数据以识别团队特征及其与团队成果的相关性。使用基于Minecraft的搜索和响应实验的转录本，我们将主题建模和聚类应用于发现关键的相互作用模式。我们的发现表明，可以通过这些推论来解释团队成果的变化，并从各个特征和团队动态中得出了不同级别的预测能力。]]></description>
      <guid>https://arxiv.org/abs/2503.03791</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学会通过自愿承诺进行谈判</title>
      <link>https://arxiv.org/abs/2503.03866</link>
      <description><![CDATA[ARXIV：2503.03866V1公告类型：新 
摘要：自主代理的部分一致性和冲突导致许多现实应用程序中的混合情景。但是，即使合作产生更好的结果，代理商也可能无法在实践中进行合作。这种失败的一个知名原因来自不可限制的承诺。为了促进代理商之间的承诺更好的合作，我们定义了马尔可夫承诺游戏（MCGS），这是承诺游戏的一种变体，代理商可以自愿承诺他们提出的未来计划。基于MCG，我们通过政策梯度提出了可学习的承诺协议。我们进一步提出了与激励兼容的学习，以通过更好的社会福利加速融合到平衡。在挑战混合动力任务的实验结果表明，与其对应物相比，我们方法的经验收敛速度更快和更高的回报。我们的代码可在https://github.com/shuhui-zhu/dcl上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.03866</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SED2AM：使用深厚的增强学习解决多行程时间依赖的车辆路由问题</title>
      <link>https://arxiv.org/abs/2503.04085</link>
      <description><![CDATA[ARXIV：2503.04085V1公告类型：新 
摘要：具有变压器风格的策略网络的基于深度强化学习（DRL）的框架已经证明了它们在各种车辆路由问题（VRP）变体中的功效。但是，将这些方法应用于具有最大工作时间约束的多行程时间依赖的车辆路由问题（MTTDVRP） - 城市物流的关键要素 - 仍然在很大程度上没有探索。本文介绍了一种基于DRL的方法，称为同时编码器和双解码器注意模型（SED2AM），该模型是针对MTTDVRP量身定制的，具有最大的工作时间约束。提出的方法向策略网络的编码模块引入了时间局部归纳偏置，从而有效地说明了旅行距离或时间的时间依赖性。 SED2AM的解码模块包括一个车辆选择解码器，该解码器可从车队中选择车辆，从而有效地将旅行与用于功能性多行程路由的车辆相关联。此外，该解码模块配备了用于构造车辆旅行的旅行施工解码器。该策略模型配备了两类的状态表示，车队状态和路由状态，在最大工作时间约束的情况下提供了有效路线构建所需的信息。使用来自两个加拿大两个主要城市的现实世界数据集的实验结果不仅表明SED2AM的表现优于当前基于DRL的最新基于DRL和基于元数据的基线，而且还证明了其解决大规模问题的普遍性。]]></description>
      <guid>https://arxiv.org/abs/2503.04085</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>发音教学中的人工智能：外语教师的使用和信念</title>
      <link>https://arxiv.org/abs/2503.04128</link>
      <description><![CDATA[ARXIV：2503.04128V1公告类型：新 
摘要：外语教室中的发音教学通常是一个被忽视的重点领域。随着人工智能（AI）的广泛采用及其潜在的好处，研究了AI如何用于发音教学和理解教师对该工具的信念，对于改善学习成果至关重要。这项研究旨在研究AI对发音教学的使用如何在教师之间的不同人口统计学和专业因素上有所不同，以及这些因素（包括AI使用）如何影响教师对AI的信念。这项研究涉及117英语作为外语（EFL）在塞浦路斯工作的服务教师，他们完成了一项在线调查，旨在评估他们对AI的有效性，其缺点，以及他们愿意将AI整合到教学实践中的信念。结果表明，与他们对使用的担忧相比，教师更有可能就AI的感知有效性及其采用的意愿达成共识。此外，从事高等教育和成人教育的教师，以及接受过更广泛培训的人，在教学中更频繁地使用AI。利用AI的老师经常表达了与其有效性更强大的一致性，而接受更多培训的人则不太可能对其整合表示担忧。鉴于许多老师目前接受的培训有限，这些发现表明需要量身定制的培训课程，以满足教育工作者的特定需求和关注点，最终促进了在发音教学中采用AI。]]></description>
      <guid>https://arxiv.org/abs/2503.04128</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>肾脏畅通无阻：私人大型语言模型的无代码部署具有医学文档增强知识数据库的肾脏疾病</title>
      <link>https://arxiv.org/abs/2503.04153</link>
      <description><![CDATA[ARXIV：2503.04153V1公告类型：新 
摘要：保护肾脏疾病的医疗决策支持需要局部部署大型语言模型（LLMS），同时保持临床推理能力。当前解决方案面临三个挑战：1）基于云的LLMS构成数据安全风险； 2）本地模型部署要求技术专长； 3）一般LLM缺乏整合医学知识的机制。检索授权系统还在医疗文档处理和临床可用性方面挣扎。我们开发了一个台式系统，这是一个集成了三个技术组件的桌面系统：1）通过本地推理引擎的无代码部署（SOTA）开源LLM（例如DeepSeek-R1，Qwen2.5）； 2）结合上下文感知的块和智能过滤的医学文档处理管道； 3）自适应检索和增强管道（ADDREP）采用代理协作来提高医疗文件的召回率。图形界面旨在使临床医生能够管理医疗文件并进行AI驱动咨询，而无需技术专业知识。对1,455个具有挑战性的肾脏学考试问题的实验验证证明了Addrep的有效性：具有智能知识整合的准确性29.1％（比基线+8.1％），同时通过4.9％的拒绝率来抑制幻觉。与主流产品（Nothinglm，Chatbox，GPT4All）的比较案例研究表明，肾脏在实际临床查询中的出色表现。肾脏open代表了第一个无代码医疗LLM系统，可实现安全文档增强的医疗Q＆amp; a台式机。它的设计为隐私敏感的临床AI应用建立了一个新的框架。该系统大大降低了技术障碍，同时提高了证据可追溯性，使更多的医务人员或患者可以方便地使用SOTA开源LLMS。]]></description>
      <guid>https://arxiv.org/abs/2503.04153</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计时器：纵向临床记录的时间指导建模和评估</title>
      <link>https://arxiv.org/abs/2503.04176</link>
      <description><![CDATA[ARXIV：2503.04176V1公告类型：新 
摘要：大型语言模型（LLM）已成为有前途的工具，可帮助您完成医疗任务，但处理电子健康记录（EHRS）由于其纵向性质而提出了独特的挑战。尽管LLMS执行医疗任务的能力继续改善，但他们在多次患者访问和时间范围内推理时间依赖性的能力仍未得到探索。我们介绍了计时器（纵向临床记录的时间指导建模和评估），该框架将教学响应对接地到患者记录的不同部分，作为指导评估和纵向临床记录的调整中的关键维度。我们开发了计时器基础，这是第一个评估纵向EHR的时间推理功能的时间表的基准，以及计时器教学，这是LLMS的指导方法学方法，可以随着时间的推移学习推理。我们证明，随着计时器的生成基准，对计时器的绩效进行了微调，在计时器基础上提高了7.3％的绩效，这表明及时指导调节可以改善EHR推理的模型性能。]]></description>
      <guid>https://arxiv.org/abs/2503.04176</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VirtualXai：一个以用户为中心的框架，用于利用GPT生成角色的评估</title>
      <link>https://arxiv.org/abs/2503.04261</link>
      <description><![CDATA[ARXIV：2503.04261V1公告类型：新 
摘要：在当今数据驱动的时代，计算系统生成了大量的数据，这些数据驱动了行业的数字转换，其中人工智能（AI）起着关键作用。当前，对可解释AI（XAI）的需求增加了，以提高AI模型的解释性，透明度和可信度。但是，评估XAI方法仍然具有挑战性：现有的评估框架通常集中于定量属性，例如保真度，一致性和稳定性，而无需考虑诸如满意度和解释性之类的定性特征。此外，从业者在选择适当的数据集，AI模型和XAI方法时面临缺乏指导，这是人类协作中的主要障碍。为了解决这些差距，我们提出了一个框架，该框架通过基于大型语言模型（LLM）背景故事的“选集”的虚拟角色将定量基准与定性用户评估集成在一起。我们的框架还结合了一个基于内容的推荐系统，该系统利用数据集特定的特性将新输入数据与基准数据集的存储库匹配。这产生了估计的XAI分数，并为给定情况提供了最佳AI模型和XAI方法的量身定制建议。]]></description>
      <guid>https://arxiv.org/abs/2503.04261</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在网络安全应用中应用RL和MAL的指南</title>
      <link>https://arxiv.org/abs/2503.04262</link>
      <description><![CDATA[ARXIV：2503.04262V1公告类型：新 
摘要：强化学习（RL）和多代理增强学习（MARL）已成为解决自动化网络防御（ACD）挑战的有前途的方法。这些技术在高维环境中提供了自适应的决策能力。该报告为网络安全专业人员和研究人员提供了一套结构化的准则，以评估RL和MARL对特定用例的适用性，这些因素考虑了诸如解释性，勘探需求以及多机构协调的复杂性等因素。它还讨论了关键算法方法，实施挑战和现实世界中的约束，例如数据稀缺和对抗性干扰。该报告进一步概述了开放研究问题，包括政策最佳性，代理合作水平以及将MARL系统集成到运营网络安全框架中。通过弥合理论进步和实际部署，这些准则旨在提高AI驱动的网络防御策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.04262</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MathMistake检查器：逐步的数学问题错误的全面演示通过及时引导LLM</title>
      <link>https://arxiv.org/abs/2503.04291</link>
      <description><![CDATA[ARXIV：2503.04291V1公告类型：新 
摘要：我们提出了一个新颖的系统，即MathMistake检查器，旨在通过两个阶段的过程在数学问题中逐步自动化发现，并在数学问题中找到漫长的答案。该系统旨在从教学的角度简化评分，提高效率并增强学习经验。它集成了先进的技术，包括计算机视觉和最新大型语言模型（LLM）的经过思考链。我们的系统支持开放式分级无参考答案，并通过提供目标反馈来促进个性化学习。我们证明了它在各种数学问题（例如计算和单词问题）中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.04291</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将AI基准数据映射到通过专家启发的定量风险估计</title>
      <link>https://arxiv.org/abs/2503.04299</link>
      <description><![CDATA[ARXIV：2503.04299V1公告类型：新 
摘要：文献和多个专家指出了大型语言模型（LLM）的许多潜在风险，但是对实际危害的直接测量仍然很少。迄今为止，AI风险评估的重点是衡量模型的功能，但模型的功能仅是风险的指标，而不是衡量风险的指标。更好地建模和量化AI风险方案可以帮助桥接这种断开连接，并将LLM的功能与有形现实世界的危害联系起来。本文通过证明如何使用现有的AI基准来促进风险估计的创建，从而为该领域做出了早期贡献。我们描述了一项试点研究的结果，其中专家使用AI基准Cybench的信息来产生概率估计。我们表明，对于此目的，该方法似乎很有希望，同时指出可以进一步加强其在定量AI风险评估中的应用。]]></description>
      <guid>https://arxiv.org/abs/2503.04299</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ADECTENTSAFE：通过层次数据管理保护基于大型语言模型的大型多代理系统</title>
      <link>https://arxiv.org/abs/2503.04392</link>
      <description><![CDATA[ARXIV：2503.04392V1公告类型：新 
摘要：基于大型语言模型的多机构系统正在彻底改变自主沟通和协作，但它们仍然容易受到安全威胁，例如未经授权的访问和数据泄露。为了解决这个问题，我们介绍了Admentafe，这是一个新颖的框架，可通过层次信息管理和内存保护来增强MAS安全性。 AgesentsAfe按安全级别对信息进行了分类，从而限制了对授权代理的敏感数据访问。 AgestentsAfe结合了两个组成部分：威胁性，通过验证信息权威并防止假冒来确保沟通，以及hierarcache，这是一种自适应内存管理系统，可以防御未经授权的访问和恶意中毒，代表了代理人记忆的第一个系统防御。各种LLM的实验表明，在对抗条件下，代理可以显着提高系统的弹性，使国防成功率超过80％。此外，AdgententAfe展示了可扩展性，随着代理数量和信息复杂性的增长，保持稳健的性能。结果强调了代理在确保MAS及其实现现实应用的潜力方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.04392</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更宽还是更深？使用自适应分支树搜索缩放LLM推理时间计算</title>
      <link>https://arxiv.org/abs/2503.04412</link>
      <description><![CDATA[ARXIV：2503.04412V1公告类型：新 
摘要：最近的进步表明，增加推理时间计算可以显着提高大语模型（LLMS）的推理能力。尽管重复的采样（即生成多个候选输出）是一种高效的策略，但它不会利用外部反馈信号进行改进，这些反馈信号通常在编码等任务中可用。在这项工作中，我们提出了$ \ textit {自适应分支蒙特卡洛树搜索（AB-MCTS）} $，这是一个新颖的推理时间框架，可以通过原则上的多转探索和利用来概括重复采样。在搜索树中的每个节点上，AB-MCTs通过根据外部反馈信号来重新审视现有的响应来动态地决定是否扩大新的候选响应或“更深”来“更宽”。我们使用Frontier模型评估了有关复杂编码和工程任务的方法。经验结果表明，AB-MCT始终胜过重复采样和标准MCT，强调将LLMS的响应多样性与多转化溶液的细化相结合以进行有效的推理时间缩放的重要性。]]></description>
      <guid>https://arxiv.org/abs/2503.04412</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从想法到CAD：语言模型驱动的多代理系统，用于协作设计</title>
      <link>https://arxiv.org/abs/2503.04417</link>
      <description><![CDATA[ARXIV：2503.04417V1公告类型：新 
摘要：使用计算机辅助设计（CAD）创建数字模型是一个需要深入专业知识的过程。在工业产品开发中，此过程通常涉及整个工程师团队，涵盖需求工程，CAD本身和质量保证。我们提出了一种方法，该方法通过基于视觉语言模型（VLM）的多代理系统来反映团队结构，并访问参数CAD工具和工具文档。结合需求工程，CAD工程和基于视觉的质量保证的代理，模型是由草图和/或文本描述自动生成的。可以在与用户的迭代验证循环中合作地完善所得模型。对于行业专家和为3D打印模型创建模型的业余爱好者，我们的方法有可能提高设计过程的有效性。我们在各种设计任务的示例中演示了体系结构的潜力，并提供了几种展示体系结构各个组件的好处的消融。]]></description>
      <guid>https://arxiv.org/abs/2503.04417</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>激活空间干预措施可以在大语模型之间转移</title>
      <link>https://arxiv.org/abs/2503.04429</link>
      <description><![CDATA[ARXIV：2503.04429V1公告类型：新 
摘要：对AI模型中表示普遍性的研究揭示了跨领域，模式和体系结构的趋同的增长。但是，代表性普遍性的实际应用在很大程度上尚未探索。我们通过证明可以通过学习的共享激活空间在模型之间转移安全干预措施来弥合这一差距。我们在两项已建立的AI安全任务上证明了这种方法：后门去除和拒绝有害提示，显示了以可预测的方式改变转向向量的转向向量。此外，我们提出了一个新任务，即\ textit {损坏的功能}，其中模型被微调以嵌入与后门相关的知识。这测试了他们将有用技能与后门分开的能力，反映了现实世界中的挑战。遍历遍历，QWEN和GEMMA模型家族的广泛实验表明，我们的方法使使用较小的模型可以有效地对齐较大的模型。此外，我们证明了基础模型和微调模型之间的自动编码器映射可以用作可靠的``轻型安全开关&#39;&#39;，从而可以在模型行为之间进行动态切换。]]></description>
      <guid>https://arxiv.org/abs/2503.04429</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Toolfuzz-自动化代理工具测试</title>
      <link>https://arxiv.org/abs/2503.04479</link>
      <description><![CDATA[ARXIV：2503.04479V1公告类型：新 
摘要：大语言模型（LLM）代理利用现实世界中LLM的高级推理功能。要与环境接口，这些代理通常依靠工具，例如Web搜索或数据库API。由于代理向LLM提供了沿用户查询的工具文档，因此本文档的完整性和正确性至关重要。但是，工具文档通常是过度，不足或未指定的，阻碍了代理商的准确性。标准软件测试方法难以确定这些错误以自然语言表达。因此，尽管其重要性，但目前尚无自动化方法来测试代理的工具文档。为了解决此问题，我们提出了Toolfuzz，这是工具文档自动测试的第一种方法。 ToolFuzz旨在发现两种类型的错误：（1）导致工具运行时错误的用户查询以及（2）导致代理响应不正确的用户查询。 ToolFuzz可以生成大量而多样的自然输入集，有效地查找工具描述以低误报速率的错误。此外，我们提出了两种直接的及时工程方法。我们评估了32种常见的Langchain工具和35种新创建的自定义工具和2种新型基准测试的所有三种工具测试方法，以进一步加强评估。我们发现，许多公开可用的工具都被规定了。具体而言，我们表明工具模具与及时工程方法相比，识别20倍的错误输入，这使其成为构建可靠AI代理的关键组件。]]></description>
      <guid>https://arxiv.org/abs/2503.04479</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>点播DNN推断的动态定价在边缘-AI市场</title>
      <link>https://arxiv.org/abs/2503.04521</link>
      <description><![CDATA[ARXIV：2503.04521V1公告类型：新 
摘要：边缘计算和AI的融合产生了Edge-AI，从而使网络边缘的实时AI应用程序和服务部署。 Edge-AI中的基本研究问题之一是边缘推理加速度，该加速度旨在通过利用从最终设备到Edge Edge服务器的分区推理任务的细粒度卸载来实现低延迟的高准确性DNN推理服务。但是，现有研究尚未采用实用的边缘市场观点，该观点将系统地探索AI用户的个性化推理需求（例如推理准确性，延迟和任务复杂性），为提供边缘推理服务的AI服务提供商提供的收入激励措施，以及在与市场相关的环境中提供多方利益的人。为了弥合这一差距，我们提出了一种基于拍卖的边缘推理定价机制（AERIA），以最大化收入，以解决DNN模型分区，边缘推理定价和资源分配的多维优化问题。我们研究了按需DNN推理加速度的多EXIT设备 - 设备边缘的协同推理方案，并分析AI服务提供商，AI用户和边缘基础架构提供商之间的拍卖动态。由于通过随机共识估算和成本分配技术设计的战略机制设计，Edge-ai市场具有多种理想的特性，包括收入最大化，激励兼容性和嫉妒性的竞争力，这对于维持我们拍卖成果的有效性，真实性和公平性至关重要。基于四个代表性DNN推理工作量的广泛的仿真实验表明，我们的航空机制在收入最大化方面显着优于几种最先进的方法，这表明Aeria在边缘-AI市场中对按需DNN推断的功效。]]></description>
      <guid>https://arxiv.org/abs/2503.04521</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>太阳能：用于推理的大规模架构的可扩展优化</title>
      <link>https://arxiv.org/abs/2503.04530</link>
      <description><![CDATA[ARXIV：2503.04530V1公告类型：新 
摘要：大型语言模型（LLM）在推理方面表现出色，但仍受其经营链（COT）方法的限制，这些方法在需要更细微的拓扑推理的复杂任务中挣扎。我们引入了用于推理的大规模体系结构的太阳能，可扩展的优化，该框架动态优化了各种推理拓扑以提高准确性和效率。
  我们的拓扑注释生成（TAG）系统可自动化拓扑数据集创建和细分，从而改善培训和评估。此外，我们提出了拓扑规模，这是一个奖励驱动的框架，它使培训和推理缩放量化，为LLMS配备自适应，任务意识到的推理。
  太阳能在数学和GSM8K上取得了可观的收益：拓扑调整 +5％精度， +9％，并获得拓扑奖励，而混合缩放率则获得 +10.02％。对于复杂问题，它还将响应长度降低了5％以上，从而降低了推理潜伏期。
  为了促进奖励系统，我们培训了一个多任务拓扑奖励模型（M-TRM），该模型自主选择了最佳的推理拓扑并在单次传球中选择答案，从而消除了对多个单任务TRM（S-TRM）进行培训和推断的需求，从而降低了培训成本和推理延迟。此外，在性能方面，M-TRM超过了所有S-TRM，将准确性提高 +10％，等级相关性提高 +9％。
  据我们所知，太阳能在引入自动注释过程和动态推理拓扑竞争机制的同时，为可扩展的高精度LLM推理设定了新的基准。]]></description>
      <guid>https://arxiv.org/abs/2503.04530</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语模型中的基准推理鲁棒性</title>
      <link>https://arxiv.org/abs/2503.04550</link>
      <description><![CDATA[ARXIV：2503.04550V1公告类型：新 
摘要：尽管大型语言模型（LLM）最近在诸如DeepSeek之类的推理中取得了成功，但我们首次确定了推理鲁棒性和概括的关键困境：对新颖或不完整数据的显着绩效降低，这表明依赖于记忆模式而不是系统性的推理。我们的仔细检查揭示了这个问题的基础四个关键的独特局限性：（1）位置偏见 - 模型在多电量输入中偏爱早期的疑问，但在后者中回答了错误的疑问（例如，GPT-4O的准确性从75.8％下降到72.8％）； （2）指令敏感性 - 在QWEN2.5系列中，绩效下降了5.0％，在DeepSeek-V3中下降了5.0％，并在辅助指导下下降了5.0％； （3）数值脆弱性 - 值替代急剧降低了准确性（例如，GPT-4O从97.5％下降到82.5％，GPT-O1-Mini从97.5％下降到92.5％）； （4）内存依赖性 - 丢失关键数据时，模型诉诸猜测。这些发现进一步凸显了对启发式召回对严格逻辑推断的依赖，这表明了推理鲁棒性的挑战。为了全面研究这些鲁棒性挑战，本文介绍了一种新颖的基准，称为数学 - 摩托车，该基准利用了丢失的信息触发的幻觉来揭示推理差距。这是通过一种基于指导的方法来实现的，该方法生成多种数据集，这些数据集与培训分布非常相似，促进了整体鲁棒性评估并推进了更健壮的推理框架的发展。字段中的不良字符摘要。]]></description>
      <guid>https://arxiv.org/abs/2503.04550</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ValuePilot：一个两阶段的框架，用于增值驱动决策</title>
      <link>https://arxiv.org/abs/2503.04569</link>
      <description><![CDATA[ARXIV：2503.04569V1公告类型：新 
摘要：尽管人工智能（AI）的最新进展，但仍提出了挑战，以确保培训数据集中未考虑的任务中的个性化决策。为了解决这个问题，我们提出了Purebalot，这是一个两相值驱动的决策框架，其中包括数据集生成工具包DGT和对生成数据培训的决策模块DMM。 DGT能够通过自动过滤技术和人类策划来基于价值维度和紧密反映现实世界任务的情况生成场景，以确保数据集的有效性。在生成的数据集中，DMM学会了识别场景的固有值，计算动作可行性并导航多个价值维度之间的权衡，以做出个性化的决策。广泛的实验表明，鉴于人类的价值偏好，我们的DMM与人类的决策最紧密地保持一致，表现优于Claude-3.5-Sonnet，Gemini-2-Flash，Llama-3.1-405B和GPT-4O。这项研究是对价值驱动决策的初步探索。我们希望它将激发人们对社区内的价值驱动决策和个性化决策的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2503.04569</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>