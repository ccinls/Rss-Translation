<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>StateAct：使用大型语言模型进行行动和规划的状态跟踪和推理</title>
      <link>https://arxiv.org/abs/2410.02810</link>
      <description><![CDATA[arXiv:2410.02810v1 公告类型：新
摘要：在交互式环境中使用大型语言模型 (LLM) 规划和采取行动解决“真实”任务已成为 AI 方法的新前沿。虽然最近的进展使 LLM 能够与在线工具交互、解决机器人任务等等，但长距离推理任务仍然是 LLM 的问题。解决此问题的现有方法非常耗费资源，需要额外的数据或人为制定的规则，相反，我们提出了一种基于少量上下文学习的简单方法，以通过状态跟踪增强“思路链”，以便使用 LLM 进行规划和行动。我们表明，我们的方法在 Alfworld 上为上下文学习方法建立了新的最先进水平（比以前最好的少量上下文学习方法高出 \textbf{+14\%}），并且性能与使用额外训练数据和额外工具（如代码执行）的方法相当。我们还证明了，我们增强的“状态链”允许代理解决更长远的问题，并在解决任务所需的步骤数量方面更加高效。我们展示了我们的方法适用于各种 LLM，包括基于 API 的和开源的。最后，我们还进行了消融研究，并表明“思想链”有助于提高状态跟踪的准确性，而 json 结构会损害整体性能。我们在 \url{https://github.com/ai-nikolai/StateAct} 上开源代码和注释。]]></description>
      <guid>https://arxiv.org/abs/2410.02810</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SAC-KG：利用大型语言模型作为领域知识图谱的熟练自动构造器</title>
      <link>https://arxiv.org/abs/2410.02811</link>
      <description><![CDATA[arXiv:2410.02811v1 公告类型：新 
摘要：知识图谱 (KG) 在跨专业领域的知识密集型任务中发挥着关键作用，其中获取精确可靠的知识至关重要。然而，现有的 KG 构建方法严重依赖人工干预来获得合格的 KG，这严重阻碍了其在现实世界场景中的实际适用性。为了应对这一挑战，我们提出了一个通用的 KG 构建框架，名为 SAC-KG，以利用大型语言模型 (LLM) 作为领域知识图谱的熟练自动构造器。SAC-KG 有效地让 LLM 作为领域专家来生成专业且精确的多层级 KG。具体而言，SAC-KG 由三个组件组成：生成器、验证器和修剪器。对于给定的实体，生成器从原始领域语料库中生成其关系和尾部，以构建专门的单层 KG。验证器和剪枝器协同工作，纠正生成错误，并判断新生成的尾部是否需要对下一级知识图谱进行进一步迭代，从而保证准确率。实验表明，SAC-KG 自动构建了百万以上节点规模的领域知识图谱，准确率达到 89.32%，与现有的知识图谱构建任务的最优方法相比，准确率提升了 20% 以上。]]></description>
      <guid>https://arxiv.org/abs/2410.02811</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于乘积t范数的双极模糊关系方程系统</title>
      <link>https://arxiv.org/abs/2410.02816</link>
      <description><![CDATA[arXiv:2410.02816v1 公告类型：新
摘要：双极模糊关系方程是模糊关系方程的泛化，它考虑了未知变量及其逻辑连接否定。变量的出现及其否定同时出现可以为某些框架提供非常有用的信息，在这些框架中，人类推理起着关键作用。因此，双极模糊关系方程系统的解析是一个非常有趣的研究课题。
本文重点研究基于最大乘积 t 范数组合的双极模糊关系方程系统。具体来说，将研究这些双极方程系统的解集的可解性和代数结构，包括此类系统由独立项等于零的方程组成的情况。因此，本文补充了作者对双极最大乘积模糊关系方程可解性的贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.02816</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT 在不确定性下的判断</title>
      <link>https://arxiv.org/abs/2410.02820</link>
      <description><![CDATA[arXiv:2410.02820v1 公告类型：新
摘要：我们研究人类认知中固有的偏见（例如损失厌恶、框架效应和合取谬误）是否体现在 GPT-4o 在概率场景中的判断和决策方式中。通过对九种认知偏见进行 1350 次实验并分析统计与启发式推理的响应，我们展示了 GPT-4o 在响应具有相似潜在概率符号的提示时采用的矛盾方法。我们的研究结果还揭示了人工智能的表现好坏参半，即使它对同一提示进行相同的迭代，也表现出类似人类的启发式错误和统计上合理的决策。]]></description>
      <guid>https://arxiv.org/abs/2410.02820</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DANA：领域感知神经符号代理，确保一致性和准确性</title>
      <link>https://arxiv.org/abs/2410.02823</link>
      <description><![CDATA[arXiv:2410.02823v1 公告类型：新
摘要：大型语言模型 (LLM) 已展现出卓越的能力，但其固有的概率性质往往会导致复杂问题解决任务中的不一致和不准确。本文介绍了 DANA（领域感知神经符号代理），这是一种通过将领域特定知识与神经符号方法相结合来解决这些问题的架构。我们首先通过神经符号视角分析当前的 AI 架构，包括 AutoGPT、LangChain ReAct 和 OpenAI 的 ChatGPT，重点介绍它们对概率推理的依赖如何导致不一致的输出。作为回应，DANA 以自然语言和符号形式捕获和应用领域专业知识，从而实现更确定和更可靠的问题解决行为。我们使用开源 OpenSSA 框架中的分层任务计划 (HTP) 实现了 DANA 的变体。此实现在 FinanceBench 财务分析基准上实现了超过 90% 的准确率，在一致性和准确性方面均远超当前基于 LLM 的系统。DANA 在半导体等实体行业中的应用表明，其用于整合知识的灵活架构可有效缓解 LLM 的概率限制，并有潜力解决需要可靠性和精确度的复杂现实问题。]]></description>
      <guid>https://arxiv.org/abs/2410.02823</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 可能不是人类级别的玩家，但他们可以成为测试员：使用 LLM 代理测量游戏难度</title>
      <link>https://arxiv.org/abs/2410.02829</link>
      <description><![CDATA[arXiv:2410.02829v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已证明其作为各种任务中的自主代理的潜力。一个新兴的应用是使用 LLM 玩游戏。在这项工作中，我们探讨了游戏行业的一个实际问题：LLM 可以用来衡量游戏难度吗？我们提出了一个使用 LLM 代理的通用游戏测试框架，并在两款广泛玩的策略游戏：Wordle 和 Slay the Spire 上对其进行了测试。我们的结果揭示了一个有趣的发现：虽然 LLM 的表现可能不如普通人类玩家，但在简单、通用的提示技术的指导下，它们的表现与人类玩家指出的难度具有统计显著的强相关性。这表明 LLM 可以作为在开发过程中衡量游戏难度的有效代理。根据我们的实验，我们还概述了将 LLM 纳入游戏测试过程的一般原则和指导方针。]]></description>
      <guid>https://arxiv.org/abs/2410.02829</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>技能问题：CS:GO 技能评级系统分析</title>
      <link>https://arxiv.org/abs/2410.02831</link>
      <description><![CDATA[arXiv:2410.02831v1 公告类型：新
摘要：网络游戏的迅速崛起催生了对精确技能评级系统的需求，以便跟踪改进和公平匹配。尽管部署了许多具有各种理论基础的技能评级系统，但在分析这些算法的实际性能方面所做的工作较少。在本文中，我们通过替代模型的视角对 Elo、Glicko2 和 TrueSkill 进行了实证分析，其中技能评级通过可配置的获取函数影响未来的匹配。我们同时关注整体性能和数据效率，并根据大量《反恐精英：全球攻势》比赛数据集进行敏感性分析。]]></description>
      <guid>https://arxiv.org/abs/2410.02831</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLaMA-Berry：针对 O1 类奥林匹克级数学推理的成对优化</title>
      <link>https://arxiv.org/abs/2410.02884</link>
      <description><![CDATA[arXiv:2410.02884v1 公告类型：新
摘要：本文提出了一种先进的数学问题解决框架 LLaMA-Berry，用于增强大型语言模型 (LLM) 的数学推理能力。该框架将蒙特卡洛树搜索 (MCTS) 与迭代自优化相结合以优化推理路径，并利用成对奖励模型全局评估不同路径。通过利用 LLM 的自我批评和重写功能，应用于 MCTS (SR-MCTS) 的自优化通过促进更有效地探索解决方案空间来克服传统逐步和贪婪搜索算法的低效和局限性。然后使用受人类反馈强化学习 (RLHF) 启发的成对偏好奖励模型 (PPRM) 对解决方案之间的成对偏好进行建模，利用增强型 Borda 计数 (EBC) 方法将这些偏好综合成全局排名分数以找到更好的答案。该方法解决了数学推理任务中评分变异性和非独立分布的挑战。该框架已在通用和高级基准测试中进行了测试，与 ToT 和 rStar 等现有方法相比，在搜索效率和解决问题能力方面表现出色，特别是在复杂的奥林匹克级基准测试中，包括 GPQA、AIME24 和 AMC23。]]></description>
      <guid>https://arxiv.org/abs/2410.02884</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>演绎和归纳推理在大型语言模型中的作用</title>
      <link>https://arxiv.org/abs/2410.02892</link>
      <description><![CDATA[arXiv:2410.02892v1 公告类型：新
摘要：大型语言模型 (LLM) 在人工智能方面取得了实质性进展，特别是在推理任务方面。然而，它们对静态提示结构的依赖，加上有限的动态推理能力，往往限制了它们对复杂且不断变化的问题空间的适应性。在本文中，我们提出了演绎和归纳 (DID) 方法，通过在提示构建过程中动态整合演绎和归纳推理来增强 LLM 推理。从认知科学中汲取灵感，DID 方法反映了人类的自适应推理机制，提供了一个灵活的框架，允许模型根据任务环境和性能调整其推理路径。我们在 AIW 和 MR-GSM8K 等已建立的数据集以及我们的自定义数据集 Holiday Puzzle 上通过实证验证了 DID 的有效性，该数据集提出了有关不同假期日期计算挑战的任务。通过利用 DID 的混合提示策略，我们展示了解决方案准确性和推理质量的显著提升，而且没有带来大量计算开销。我们的研究结果表明，DID 为 LLM 中的推理提供了更强大且认知一致的框架，有助于开发由认知科学模型指导的高级 LLM 驱动的问题解决策略。]]></description>
      <guid>https://arxiv.org/abs/2410.02892</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应噪声分配微调具有差异隐私的语言模型</title>
      <link>https://arxiv.org/abs/2410.02912</link>
      <description><![CDATA[arXiv:2410.02912v1 公告类型：新
摘要：语言模型能够记忆详细的模式和信息，从而产生双刃剑效应：它们利用存储的知识在下游任务上实现了令人印象深刻的建模性能，但也引发了严重的隐私问题。传统的基于差分隐私的训练方法通过在所有参数中采用均匀的噪声分布来提供强大的保护。然而，这忽略了隐私保护中各个参数的不同敏感性和贡献，并且经常导致模型不理想。为了解决这些限制，我们提出了 ANADP，这是一种根据模型参数的重要性自适应地分配加性噪声的新算法。我们证明 ANADP 缩小了一系列数据集上常规微调和传统 DP 微调之间的性能差距，同时保持了所需的隐私约束。]]></description>
      <guid>https://arxiv.org/abs/2410.02912</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度逻辑问题的 RAG 系统内在评估</title>
      <link>https://arxiv.org/abs/2410.02932</link>
      <description><![CDATA[arXiv:2410.02932v1 公告类型：新 
摘要：我们引入了整体性能指数 (OPI)，这是一种用于评估涉及深度逻辑查询的应用的检索增强生成 (RAG) 机制的内在指标。OPI 计算为两个关键指标的调和平均值：逻辑关系正确率和 BERT 嵌入相似度得分在地面实况和生成答案之间的平均值。我们应用 OPI 来评估流行的 RAG 工具 LangChain 的性能，使用从 GPT-4o 微调的逻辑关系分类器在 Hugging Face 的 RAG-Dataset-12000 上。我们的研究结果显示 BERT 嵌入相似度得分与外部评估得分之间存在很强的相关性。在常用的检索器中，使用基于 BERT 嵌入的余弦相似度检索器优于其他检索器，而基于欧几里得距离的检索器性能最弱。此外，我们证明，通过算法或合并检索到的句子来组合多个检索器，与单独使用任何单个检索器相比，可以获得更优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.02932</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AiBAT：人工智能/建造、组装和测试说明</title>
      <link>https://arxiv.org/abs/2410.02955</link>
      <description><![CDATA[arXiv:2410.02955v1 公告类型：新
摘要：构建、组装和测试说明 (IBAT) 是指在硬件上进行任何操作时使用的过程，包括测试、组装和维护。目前，IBAT 文档的生成非常耗时，因为用户必须手动引用并将信息从工程图和零件清单传输到 IBAT 说明中。然而，随着机器学习和计算机视觉的进步，可以让人工智能 (AI) 模型执行 IBAT 模板的部分填充，从而腾出工程师的时间来完成更高技能的任务。AiBAT 是一种用于协助用户编写 IBAT 的新型系统。它的工作原理是首先分析装配图文档，提取信息并对其进行解析，然后用提取的信息填充 IBAT 模板。这种辅助创作有可能节省时间和降低成本。本文概述了 AiBAT 系统，包括有希望的初步结果和对未来工作的讨论。]]></description>
      <guid>https://arxiv.org/abs/2410.02955</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引导式搜索流：通过最佳路径引导学习使用语言模型进行更好的搜索</title>
      <link>https://arxiv.org/abs/2410.02992</link>
      <description><![CDATA[arXiv:2410.02992v1 公告类型：新
摘要：虽然语言模型在一系列任务中表现出令人印象深刻的能力，但它们在需要复杂规划和推理的任务中仍然举步维艰。最近的研究提出在搜索过程而不是最优解上训练语言模型，从而获得更好的泛化性能，即使搜索过程嘈杂甚至次优。然而，这些研究忽视了最优解的价值，最优解可以作为指导更有效搜索的分步标志。在这项工作中，我们探索如何利用最优解来增强语言模型的搜索和规划能力。为此，我们提出了引导流搜索 (GSoS)，它以渐进的方式将最优解无缝地整合到自我生成过程中，产生高质量的搜索轨迹。然后通过监督微调将这些轨迹提炼到预训练模型中。我们的方法显着增强了语言模型在 Countdown 上的搜索和规划能力，这是一个简单但具有挑战性的数学推理任务。值得注意的是，将我们的方法与 RL 微调相结合可以取得进一步的改进，而之前的监督微调方法并没有从 RL 中获益。此外，我们的方法比以子目标奖励的形式利用最优解决方案更有效。]]></description>
      <guid>https://arxiv.org/abs/2410.02992</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图像优先还是文本优先？优化大型语言模型提示和推理任务中的模态排序</title>
      <link>https://arxiv.org/abs/2410.03062</link>
      <description><![CDATA[arXiv:2410.03062v1 公告类型：新
摘要：本文研究了多模态提示中的图像和文本排序如何影响大型语言模型 (LLM) 的推理性能。我们使用三种商业 LLM 进行了实证评估。我们的结果表明，呈现模态的顺序会显著影响性能，特别是在不同复杂程度的任务中。对于涉及单个图像的简单任务，模态排序对准确性有明显影响。然而，在涉及多幅图像和复杂推理步骤的更复杂任务中，排序的影响减弱，这可能是由于任务的认知要求增加。我们的研究结果还强调了问题/提示结构的重要性。在嵌套和多步骤推理任务中，模态排序在塑造模型性能方面发挥了关键作用。虽然 LLM 在推理的初始阶段表现出色，但它们很难重新整合早期的信息，这凸显了 Transformer 架构中多跳推理的挑战。这表明，将模态顺序与推理步骤的逻辑流程相一致比单纯的模态顺序更为重要。这些见解为改进多模态提示设计提供了宝贵的启示，在教育、医学成像和跨模态学习等领域具有更广泛的应用。]]></description>
      <guid>https://arxiv.org/abs/2410.03062</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ProcBench：多步推理和遵循程序的基准</title>
      <link>https://arxiv.org/abs/2410.03117</link>
      <description><![CDATA[arXiv:2410.03117v1 公告类型：新
摘要：推理是广泛智力活动的核心，虽然大型语言模型 (LLM) 的能力不断进步，但它们在推理任务中的表现仍然有限。推理背后的过程和机制尚未完全了解，但关键要素包括路径探索、相关知识的选择和多步推理。通过综合这些组件来解决问题。在本文中，我们提出了一个专注于推理能力特定方面的基准：多步推理的直接评估。为此，我们设计了一个特殊的推理任务，其中通过大量消除路径探索和隐性知识利用来专门关注多步推理。我们的数据集包括显式指令和相应问题对，其中解决问题所需的程序在指令中完全详细说明。此设置允许模型仅通过遵循提供的指令来解决问题。通过构建需要不同步骤数才能解决的问题并评估每一步的响应，我们可以全面评估最先进的 LLM 遵循指令的能力。为了确保评估的稳健性，我们包括多个不同的任务。此外，通过比较任务之间的准确性、利用步骤感知指标并应用单独定义的复杂性度量，我们进行了实验，深入了解了 LLM 在推理任务中的能力和局限性。我们的发现对 LLM 的发展具有重要意义，并突出了未来研究在提高其推理能力方面的领域。我们的数据集可在 \url{https://huggingface.co/datasets/ifujisawa/procbench} 获得，代码可在 \url{https://github.com/ifujisawa/proc-bench} 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.03117</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AIME：通过多个 LLM 评估器优化 AI 系统</title>
      <link>https://arxiv.org/abs/2410.03131</link>
      <description><![CDATA[arXiv:2410.03131v1 公告类型：新
摘要：基于文本的 AI 系统优化通常涉及反馈循环方案，其中单个 LLM 以自然语言生成当前输出的评估以改进下一次迭代的输出。然而，在这项工作中，我们通过经验证明，对于具有多个评估标准的实际复杂任务（代码生成），仅使用一个 LLM 评估器往往会让生成的代码中的错误无法被发现，从而导致评估不正确并最终导致测试用例性能不佳。受此失败案例的启发，我们假设存在一种最佳评估策略，该策略在响应和基本事实之间采样评估。然后我们从理论上证明多个评估器的线性组合可以近似该最佳策略。根据这一见解，我们提出了通过多个 LLM 评估器 (AIME) 进行 AI 系统优化。AIME 是一种评估协议，它利用多个 LLM，每个 LLM 都独立地根据不同的标准生成评估，然后通过连接将它们组合在一起。我们提供了一项广泛的实证研究表明，AIME 在代码生成任务中的表现优于基线方法，与 LeetCodeHard 和 HumanEval 数据集上的单个 LLM 评估协议相比，错误检测率高出高达 $62\%$，成功率高出高达 $16\%$。我们还表明，选择评估者的数量和使用哪些标准并非易事，因为它可能会影响协议成功率高达 $12\%$。]]></description>
      <guid>https://arxiv.org/abs/2410.03131</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应掩蔽增强视觉基础</title>
      <link>https://arxiv.org/abs/2410.03161</link>
      <description><![CDATA[arXiv:2410.03161v1 公告类型：新
摘要：近年来，视觉基础中的零样本和少样本学习引起了广泛关注，这主要归功于在 LAION-5B 和 DataComp-1B 等扩展数据集上进行大规模视觉语言预训练的成功。然而，这些数据集的不断扩展带来了重大挑战，特别是在数据可用性和计算开销方面，从而阻碍了低样本学习能力的提升。在本文中，我们提出了 IMAGE，即使用高斯辐射模型的解释性掩蔽，旨在增强低样本学习场景中的词汇基础，而无需增加数据集大小。从认知科学和掩蔽自动编码器 (MAE) 的最新成功中汲取灵感，我们的方法利用视觉主干生成的特征图显着区域的自适应掩蔽。这使得模型能够通过重建被遮挡的信息来学习鲁棒的广义表示，从而促进对局部和全局特征的有效关注。我们在基准数据集（包括 COCO 和 ODinW）上评估了我们的方法的有效性，证明了其在零样本和少样本任务中的卓越性能。实验结果一致表明，IMAGE 的表现优于基线模型，在少样本场景中实现了增强的泛化和更高的性能。这些发现凸显了通过注意力机制和高斯建模进行自适应特征操作的潜力，它可以作为依赖不断扩展数据集大小来推进零样本和少样本学习的方法的有前途的替代方案。我们的代码在 https://github.com/git-lenny/IMAGE 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2410.03161</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型通过不相交公理丰富本体</title>
      <link>https://arxiv.org/abs/2410.03235</link>
      <description><![CDATA[arXiv:2410.03235v1 公告类型：新
摘要：尽管本体在知识图谱中可用于复杂的推理和一致性检查，但本体通常缺乏类之间的明确不相交声明。在本研究中，我们探索了大型语言模型 (LLM) 通过识别和断言类不相交公理来丰富本体的潜力。我们的方法旨在利用 LLM 中嵌入的隐性知识，使用提示工程来获取这些知识以对本体不相交进行分类。我们在 DBpedia 本体上验证了我们的方法，重点是开源 LLM。我们的研究结果表明，在有效的提示策略的指导下，LLM 可以可靠地识别不相交的类关系，从而简化本体完成过程而无需大量的手动输入。为了全面丰富不相交性，我们提出了一个过程，该过程考虑了不相交和子类语句之间的逻辑关系，以保持可满足性并减少对 LLM 的调用次数。这项工作为 LLM 在自动本体增强方面的未来应用奠定了基础，并提供了通过战略提示设计优化 LLM 性能的见解。我们的代码在 GitHub 上公开提供，网址为 https://github.com/n28div/llm-disjointness。]]></description>
      <guid>https://arxiv.org/abs/2410.03235</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向业务流程管理任务的大型语言模型基准</title>
      <link>https://arxiv.org/abs/2410.03255</link>
      <description><![CDATA[arXiv:2410.03255v1 公告类型：新
摘要：越来越多的组织正在为各种任务部署大型语言模型 (LLM)。尽管 LLM 具有普遍的实用性，但它容易出错，从不准确到幻觉。为了客观地评估现有 LLM 的能力，需要进行性能基准测试。然而，这些基准测试通常不会转化为更具体的实际任务。本文解决了在业务流程管理 (BPM) 领域对 LLM 性能进行基准测试的差距。目前，没有特定于 BPM 的基准测试，因此不确定不同的 LLM 是否适合 BPM 任务。本文系统地比较了四个 BPM 任务的 LLM 性能，重点关注小型开源模型。分析旨在确定特定于任务的性能变化，比较开源模型与商业模型的有效性，并评估模型大小对 BPM 任务性能的影响。本文深入了解了 LLM 在 BPM 中的实际应用，指导组织根据其特定需求选择合适的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.03255</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论自然语言处理中的不确定性</title>
      <link>https://arxiv.org/abs/2410.03446</link>
      <description><![CDATA[arXiv:2410.03446v1 公告类型：新
摘要：深度学习在过去十年中带来了越来越强大的系统，这些系统部署在各种各样的应用程序中。在自然语言处理中，该领域已经通过许多突破发生了变化，包括大型语言模型，这些模型越来越多地用于面向用户的应用程序。为了获得这项技术的好处并减少潜在的危害，量化模型预测的可靠性和笼罩其发展的不确定性非常重要。
本论文研究了如何从语言、统计和神经角度表征自然语言处理中的不确定性，以及如何通过实验流程的设计来减少和量化不确定性。我们通过理论和实证研究归纳模型偏差在文本分类任务中的影响，进一步探索建模中的不确定性量化。相应的实验包括三种不同语言（丹麦语、英语和芬兰语）和任务的数据以及大量不同的不确定性量化方法。此外，我们提出了一种基于非可交换共形预测的自然语言生成校准采样方法，该方法可以提供更紧密的标记集，更好地覆盖实际延续。最后，我们开发了一种使用辅助预测器量化大型黑盒语言模型中置信度的方法，其中置信度仅根据目标模型的输入和生成的输出文本进行预测。]]></description>
      <guid>https://arxiv.org/abs/2410.03446</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>