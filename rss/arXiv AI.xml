<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 28 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>O1 复制之旅：战略进展报告——第 1 部分</title>
      <link>https://arxiv.org/abs/2410.18982</link>
      <description><![CDATA[arXiv:2410.18982v1 公告类型：新
摘要：本文介绍了一种开创性的人工智能研究方法，体现在我们的 O1 复制之旅中。为了响应 OpenAI 开创性的 O1 模型的发布，我们开始了一项透明的实时探索，以复制其功能，同时重新构想进行和交流人工智能研究的过程。我们的方法解决了现代人工智能研究中的关键挑战，包括长期团队项目的孤立性、延迟的信息共享以及对不同贡献的缺乏认可。通过提供我们复制工作的全面、实时记录，包括成功和失败，我们旨在促进开放科学，加速集体进步，并为人工智能驱动的科学发现奠定基础。我们的研究进展报告与传统研究论文有很大不同，在整个研究过程中提供持续更新、全过程透明度和积极的社区参与。从技术上讲，我们提出了旅程学习范式，鼓励模型不仅学习捷径，还学习完整的探索过程，包括反复试验、反思和回溯。仅使用 327 个训练样本，并且没有任何额外的技巧，旅程学习在 MATH 数据集上的表现就比传统监督学习高出 8% 以上，展示了其极其强大的潜力。我们认为这是我们成功解码的 O1 技术中最关键的组成部分。我们在 https://github.com/GAIR-NLP/O1-Journey 上分享了宝贵的资源，包括技术假设和见解、认知探索地图、定制开发的工具等。]]></description>
      <guid>https://arxiv.org/abs/2410.18982</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Infogent：基于代理的 Web 信息聚合框架</title>
      <link>https://arxiv.org/abs/2410.19054</link>
      <description><![CDATA[arXiv:2410.19054v1 公告类型：新
摘要：尽管在任务完成基准上 Web 代理似乎表现良好，但大多数现有方法都是基于一个前提来评估代理的：Web 导航任务由线性操作序列组成，最终状态标志着任务完成。相比之下，我们的工作侧重于信息聚合的 Web 导航，其中代理必须探索不同的网站来收集复杂查询的信息。我们从两个不同的角度考虑 Web 信息聚合：(i) 直接 API 驱动的访问依赖于 Web 的纯文本视图，利用外部工具（如 Google Search API）来导航 Web，利用抓取工具来提取网站内容。(ii) 交互式可视化访问使用网页截图，需要与浏览器交互才能导航和访问信息。受这些不同的信息访问设置的启发，我们引入了 Infogent，这是一个用于 Web 信息聚合的新型模块化框架，涉及三个不同的组件：导航器、提取器和聚合器。在不同信息访问设置上进行的实验表明，在 FRAMES 上的直接 API 驱动访问下，Infogent 比现有的 SOTA 多代理搜索框架提高了 7%，在 AssistantBench 上的交互式可视化访问下，比现有的信息搜索网络代理提高了 4.3%。]]></description>
      <guid>https://arxiv.org/abs/2410.19054</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReasonAgain：使用可提取的符号程序来评估数学推理</title>
      <link>https://arxiv.org/abs/2410.19056</link>
      <description><![CDATA[arXiv:2410.19056v1 公告类型：新
摘要：现有的数学数据集通过使用最终答案或从静态示例得出的中间推理步骤来评估大型语言模型 (LLM) 的推理能力。然而，前一种方法未能揭示模型对捷径和错误推理的使用，而后一种方法在容纳替代解决方案方面带来了挑战。在这项工作中，我们寻求使用符号程序作为自动评估的手段，如果模型能够在程序的各种输入中始终如一地产生正确的最终答案。我们首先使用 GPT4-o 提取流行数学数据集 (GSM8K 和 MATH) 的程序。对于那些使用原始输入输出对验证的可执行程序，发现它们封装了解决原始文本问题所需的正确推理。然后，我们提示 GPT4-o 使用基于提取的程序的替代输入输出对生成新问题。我们应用生成的数据集来评估 LLM 集合。在我们的实验中，与原始静态示例相比，使用我们提出的评估方法，我们观察到准确度明显下降，这表明最先进的 LLM 中的数学推理存在脆弱性。]]></description>
      <guid>https://arxiv.org/abs/2410.19056</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RSA-Control：基于语用学的轻量级可控文本生成框架</title>
      <link>https://arxiv.org/abs/2410.19109</link>
      <description><![CDATA[arXiv:2410.19109v1 公告类型：新
摘要：尽管自然语言生成取得了重大进展，但控制语言模型以生成具有所需属性的文本仍然是一项艰巨的挑战。在这项工作中，我们引入了 RSA-Control，这是一个基于语用学的无需训练的可控文本生成框架。RSA-Control 通过在虚拟说话者和听众之间进行递归推理来指导生成过程，从而提高了听众在干扰因素中正确解释目标属性的可能性。此外，我们引入了一个可自行调整的合理性参数，该参数允许根据上下文自动调整控制强度。我们对两种任务类型和两种语言模型进行的实验表明，RSA-Control 在保持语言流畅性和内容一致性的同时实现了强大的属性控制。我们的代码可在 https://github.com/Ewanwong/RSA-Control 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.19109</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PDL：一种声明式提示编程语言</title>
      <link>https://arxiv.org/abs/2410.19135</link>
      <description><![CDATA[arXiv:2410.19135v1 公告类型：新
摘要：大型语言模型 (LLM) 风靡全球，使许多以前难以实现的 AI 用途成为可能。LLM 通过高度表达的文本提示进行控制并返回文本答案。不幸的是，这种非结构化文本作为输入和输出使基于 LLM 的应用程序变得脆弱。这促使了提示框架的兴起，提示框架在 LLM 和外部世界之间进行调解。然而，现有的提示框架要么学习曲线高，要么剥夺了开发人员对确切提示的控制权。为了克服这一困境，本文介绍了提示声明语言 (PDL)。PDL 是一种简单的声明性面向数据语言，基于 YAML，将提示放在最前沿。PDL 可与许多 LLM 平台和 LLM 配合使用。它支持编写调用 LLM 和工具的交互式应用程序，并可以轻松实现聊天机器人、RAG 或代理等常见用例。我们希望 PDL 能够使快速编程变得更简单、更稳定、更有趣。]]></description>
      <guid>https://arxiv.org/abs/2410.19135</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自我监督可以使基于相似性的链接预测焕发活力吗？</title>
      <link>https://arxiv.org/abs/2410.19183</link>
      <description><![CDATA[arXiv:2410.19183v1 公告类型：新
摘要：尽管基于端到端学习的链接预测 (LP) 方法的最新进展已显示出卓越的能力，但传统的基于相似性的 LP 方法在没有已知链接标签的无监督场景中仍然具有重要意义。然而，在基于相似性的 LP 中，选择用于相似性计算的节点特征可能具有挑战性。信息量较少的节点特征可能导致 LP 性能不佳。为了应对这些挑战，我们将自监督图学习技术集成到基于相似性的 LP 中，并提出了一种新方法：自监督基于相似性的 LP (3SLP)。3SLP 适用于基于相似性的 LP 的无监督条件，无需已知链接标签的帮助。具体而言，3SLP 引入了一种双视图对比节点表示学习 (DCNRL)，具有精心设计的数据增强和节点表示学习。 DCNRL 致力于开发更具信息量的节点表示，以替代基于相似度的 LP 主干中的节点属性作为输入。在基准数据集上进行的大量实验表明 3SLP 具有显著的改进，其性能比传统基于相似度的 LP 基线高出多达 21.2%（AUC）。]]></description>
      <guid>https://arxiv.org/abs/2410.19183</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tailored-LLaMA：使用特定任务提示优化修剪后的 LLaMA 模型中的小样本学习</title>
      <link>https://arxiv.org/abs/2410.19185</link>
      <description><![CDATA[arXiv:2410.19185v1 公告类型：新
摘要：大型语言模型在语言理解和生成方面表现出令人印象深刻的能力。尽管如此，从头开始训练这些模型，即使是最不复杂的十亿参数变体也需要大量的计算资源，这使得它对许多组织来说在经济上是不切实际的。由于大型语言模型充当通用任务求解器，本文研究了它们针对特定任务的微调。我们使用特定于任务的数据集和提示来微调两个具有 50 亿和 40 亿个参数的修剪后的 LLaMA 模型。该过程利用预先训练的权重并使用 LoRA 方法关注权重子集。微调 LLaMA 模型的一个挑战是制定针对特定任务的精确提示。为了解决这个问题，我们提出了一种在两个主要约束下微调 LLaMA 模型的新方法：任务特异性和提示有效性。我们的方法 Tailored LLaMA 最初采用结构修剪将模型大小从 7B 减少到 5B 和 4B 参数。随后，它应用针对任务精心设计的提示，并利用 LoRA 方法加速微调过程。此外，对修剪了 50% 的模型进行微调不到一小时，通过 50 次小样本学习，在 20% 压缩率下将分类任务的平均准确率恢复到 95.68%，在 50% 压缩率下将分类任务的平均准确率恢复到 86.54%。我们对这两个修剪变体的 Tailored LLaMA 的验证表明，即使压缩到 50%，模型在小样本分类和生成任务中仍能保持基线模型准确率的 65% 以上。这些发现凸显了我们的定制方法在显著减小模型大小的同时保持高性能的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.19185</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAP：多人类价值观对齐调色板</title>
      <link>https://arxiv.org/abs/2410.19198</link>
      <description><![CDATA[arXiv:2410.19198v1 公告类型：新
摘要：确保生成式 AI 系统与人类价值观保持一致至关重要，但具有挑战性，尤其是在考虑多种人类价值观及其潜在权衡时。由于人类价值观可以个性化并随时间动态变化，因此理想的价值观一致水平因不同种族、行业部门和用户群体而异。在现有框架内，很难同时定义人类价值观并相应地在不同方向上调整 AI 系统，例如无害、乐于助人和积极性。为了解决这个问题，我们开发了一种新颖的第一原理方法，称为多人类价值观对齐调色板 (MAP)，它以结构化和可靠的方式在多种人类价值观之间导航对齐。MAP 将对齐问题表述为具有用户定义约束的优化任务，这些约束定义了人类价值目标。它可以通过原始对偶方法有效地解决，该方法确定用户定义的对齐目标是否可以实现以及如何实现它。我们对 MAP 进行了详细的理论分析，量化了价值观之间的权衡、对约束的敏感性、多值对齐和顺序对齐之间的基本联系，并证明线性加权奖励足以实现多值对齐。大量实验证明了 MAP 能够以原则性的方式对齐多个值，同时在各种任务中提供强大的实证性能。]]></description>
      <guid>https://arxiv.org/abs/2410.19198</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与物联网应用相结合</title>
      <link>https://arxiv.org/abs/2410.19223</link>
      <description><![CDATA[arXiv:2410.19223v1 公告类型：新
摘要：本文通过三个关键主题的案例研究，识别并分析了大型语言模型 (LLM) 可以使物联网 (IoT) 网络更加智能和响应更快的应用：DDoS 攻击检测、物联网系统的宏编程和传感器数据处理。我们的结果表明，在小样本学习下，GPT 模型的检测准确率达到 87.6%，而经过微调的 GPT 将检测准确率提高到 94.9%。给定一个宏编程框架，GPT 模型能够使用框架中的高级函数编写脚本来处理可能发生的事件。此外，GPT 模型通过提供快速和高质量的响应（包括预期结果和总结的见解）显示出处理大量传感器数据的有效性。总体而言，该模型展示了其为自然语言界面提供支持的潜力。我们希望研究人员能够发现这些案例研究能够启发他们进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2410.19223</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>设计具有个性的 LLM 智能体：一种心理测量方法</title>
      <link>https://arxiv.org/abs/2410.19238</link>
      <description><![CDATA[arXiv:2410.19238v1 公告类型：新
摘要：本研究介绍了一种新方法，使用大五人格框架为基于大型语言模型的代理（代理）分配可量化、可控制和心理测量验证的个性。它试图克服人类受试者研究的限制，提出代理作为社会科学研究的可访问工具。通过一系列四项研究，本研究证明了为代理分配心理测量有效的个性特征的可行性，使它们能够复制复杂的类似人类的行为。第一项研究在 LLM 的语义空间内建立了对人格结构和人格测试的理解。随后的两项研究——使用经验和模拟数据——说明了创建代理的过程，并通过显示人类和代理对人格测试的答案之间的高度对应性来验证结果。最后的研究通过使用代理来复制已知的人类性格特征和决策行为在涉及风险承担和道德困境的场景中的相关性，进一步证实了这种对应关系，从而验证了心理测量方法设计代理的有效性及其在社会和行为研究中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2410.19238</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分散式自治组织、数字孪生和大型语言模型自主构建信息物理系统</title>
      <link>https://arxiv.org/abs/2410.19262</link>
      <description><![CDATA[arXiv:2410.19262v1 公告类型：新
摘要：当前的自主建筑研究主要集中在能源效率和自动化方面。虽然传统的人工智能已经推动了自主建筑研究，但它通常依赖于预定义的规则，难以适应复杂、不断发展的建筑运营。此外，设施管理的集中式组织结构阻碍了决策的透明度，限制了真正的建筑自主性。可以克服这些挑战的去中心化治理和自适应建筑基础设施的研究仍然相对未被探索。本文通过引入一种新颖的去中心化自主建筑网络物理系统框架来解决这些限制，该框架集成了去中心化自治组织、大型语言模型和数字孪生，以创建一个智能、自我管理、可操作和财务自主的建筑基础设施。本研究开发了一个全栈去中心化应用程序，以促进建筑基础设施的去中心化治理。开发了一个基于 LLM 的人工智能助手，为区块链和建筑运营管理相关任务提供直观的人机交互，并实现自主建筑运营。测试了六个真实场景，以评估自主建筑系统的可行性，包括建筑收入和支出管理、人工智能辅助设施控制和建筑系统的自主调整。结果表明，原型成功执行了这些操作，证实了该框架适用于开发具有分散治理和自主运营的建筑基础设施。]]></description>
      <guid>https://arxiv.org/abs/2410.19262</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>类脑推理的规范理论</title>
      <link>https://arxiv.org/abs/2410.19315</link>
      <description><![CDATA[arXiv:2410.19315v1 公告类型：新
摘要：证据下限 (ELBO) 是训练深度生成模型（例如变分自动编码器 (VAE)）的广泛使用的目标。在神经科学文献中，相同的目标被称为变分自由能，暗示了大脑功能和机器学习的潜在统一框架。尽管 ELBO 最大化在解释生成模型（包括扩散模型）方面很有用，但它通常被认为过于宽泛，无法为神经科学或机器学习中的特定架构提供规范性指导。在这项工作中，我们表明，在泊松假设下对一般序列数据最大化 ELBO 会导致脉冲神经网络通过其膜电位动力学执行贝叶斯后验推理。由此产生的模型，即迭代泊松 VAE (iP-VAE)，与基于高斯假设的以前受大脑启发的预测编码模型相比，与生物神经元有更紧密的联系。与摊销和迭代 VAE 相比，iP-VAE 可以学习更稀疏的表示，并且对分布外样本表现出更好的泛化能力。这些发现表明，优化 ELBO 并结合泊松假设，为开发 NeuroAI 中的规范理论奠定了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2410.19315</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LArctan-SKAN：使用可学习三角函数的简单高效的单参数 Kolmogorov-Arnold 网络</title>
      <link>https://arxiv.org/abs/2410.19360</link>
      <description><![CDATA[arXiv:2410.19360v1 公告类型：新
摘要：本文提出了一种设计单参数 Kolmogorov-Arnold 网络 (SKAN) 的新方法，该方法利用由三角函数构造的单参数函数 (SFunc)。开发了三种新的 SKAN 变体：LSin-SKAN、LCos-SKAN 和 LArctan-SKAN。在 MNIST 数据集上的实验验证表明，LArctan-SKAN 在准确性和计算效率方面都表现出色。具体而言，LArctan-SKAN 显著提高了现有模型的测试集准确性，优于所有纯 KAN 变体，包括 FourierKAN、LSS-SKAN 和 Spl-KAN。它在准确性方面也超过了基于混合 MLP 的模型，例如 MLP+rKAN 和 MLP+fKAN。此外，LArctan-SKAN 表现出了显著的计算效率，与 MLP+rKAN 和 MLP+fKAN 相比，训练速度分别提升了 535.01% 和 49.55%。这些结果证实了利用三角函数构造的 SKAN 的有效性和潜力。实验代码可从 https://github.com/chikkkit/LArctan-SKAN 获取。]]></description>
      <guid>https://arxiv.org/abs/2410.19360</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建值得信赖的人工智能：经验风险最小化的开发者指南</title>
      <link>https://arxiv.org/abs/2410.19361</link>
      <description><![CDATA[arXiv:2410.19361v1 公告类型：新
摘要：人工智能系统越来越多地影响个人和社会领域的关键决策。虽然经验风险最小化 (ERM) 推动了人工智能的大部分成功，但它通常优先考虑准确性而不是可信度，这往往会导致偏见、不透明性和其他不利影响。本文讨论了如何将可信人工智能的关键要求转化为 ERM 组件的设计选择。我们希望为构建符合新兴人工智能可信度标准的人工智能系统提供可行的指导。]]></description>
      <guid>https://arxiv.org/abs/2410.19361</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从示例中学习神经策略验证匹配机制</title>
      <link>https://arxiv.org/abs/2410.19384</link>
      <description><![CDATA[arXiv:2410.19384v1 公告类型：新
摘要：设计有效的双边匹配机制是机制设计中的一个主要问题，而匹配的优劣并不总是可以公式化的。
现有的工作通过搜索具有某些属性的参数化机制系列来解决此问题，方法是学习拟合包含偏好配置文件和匹配结果示例的人工数据集。
然而，这种方法没有考虑策略证明机制，隐式假设代理数量为常数，并且没有考虑代理的公共上下文信息。
在本文中，我们通过扩展串行独裁（SD）提出了一种新的参数化策略证明匹配机制系列。
我们开发了一种新型的基于注意力的神经网络，称为 NeuralSD，它可以从包含公共上下文信息的人工数据集中学习策略证明机制。
NeuralSD 由使 SD 可微的张量运算构建，并通过从上下文信息中估计 SD 的顺序来学习参数化机制。
我们进行了实验，从具有不同数量代理的匹配示例中学习策略验证匹配。
我们证明了我们的方法在回归性能和其他指标方面表现出了上下文感知学习优于基线。]]></description>
      <guid>https://arxiv.org/abs/2410.19384</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>先暴露后防御：通过暴露模型统一和增强后门防御</title>
      <link>https://arxiv.org/abs/2410.19427</link>
      <description><![CDATA[arXiv:2410.19427v1 公告类型：新
摘要：后门攻击通过使用预先设计的后门触发器毒害一小部分训练数据，秘密地将触发器植入深度神经网络 (DNN)。这种脆弱性在大型模型时代更加严重，因为对网络爬取数据集进行大量（预）训练很容易受到攻击。在本文中，我们介绍了一种名为 Expose Before You Defend (EBYD) 的新型两步防御框架。EBYD 将现有的后门防御方法统一为一个性能增强的综合防御系统。具体而言，EBYD 首先通过称为后门暴露的模型预处理步骤暴露后门模型中的后门功能，然后将检测和删除方法应用于暴露的模型以识别和消除后门特征。在后门暴露的第一步中，我们提出了一种称为 Clean Unlearning (CUL) 的新技术，它主动从后门模型中取消学习干净的特征以揭示隐藏的后门特征。我们还探索了用于后门暴露的各种模型编辑/修改技术，包括微调、模型稀疏化和权重扰动。使用 EBYD，我们在 2 个视觉数据集（CIFAR-10 和 ImageNet 子集）和 4 个语言数据集（SST-2、IMDB、Twitter 和 AG&#39;s News）上对 10 次图像攻击和 6 ​​次文本攻击进行了广泛的实验。结果证明了后门暴露对于后门防御的重要性，表明暴露的模型可以显著有益于一系列下游防御任务，包括后门标签检测、后门触发恢复、后门模型检测和后门移除。我们希望我们的工作能够激发更多使用暴露模型开发高级防御框架的研究。我们的代码可在以下网址获得：https://github.com/bboylyg/Expose-Before-You-Defend。]]></description>
      <guid>https://arxiv.org/abs/2410.19427</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有离线价值函数记忆和顺序探索的离线到在线多智能体强化学习</title>
      <link>https://arxiv.org/abs/2410.19450</link>
      <description><![CDATA[arXiv:2410.19450v1 公告类型：新
摘要：离线到在线强化学习已成为一种强大的范例，利用离线数据进行初始化和在线微调来提高样本效率和性能。然而，大多数现有研究都集中在单智能体设置上，对多智能体扩展的探索有限，即离线到在线多智能体强化学习 (O2O MARL)。在 O2O MARL 中，随着智能体数量的增加，两个关键挑战变得更加突出：(i) 在从离线到在线阶段的过渡期间，由于分布变化而导致忘记预先训练的 Q 值的风险，以及 (ii) 在大型联合状态动作空间中进行有效探索的难度。为了应对这些挑战，我们提出了一种新颖的 O2O MARL 框架，称为具有顺序探索的离线值函数记忆 (OVMSE)。首先，我们引入了离线值函数记忆 (OVM) 机制来计算目标 Q 值，保留离线训练期间获得的知识，确保过渡更平滑，并实现高效的微调。其次，我们提出了一种针对 O2O MARL 量身定制的分散式顺序探索 (SE) 策略，该策略有效利用预先训练的离线策略进行探索，从而显著减少要探索的联合状态-动作空间。在星际争霸多智能体挑战 (SMAC) 上进行的大量实验表明，OVMSE 明显优于现有基线，实现了卓越的样本效率和整体性能。]]></description>
      <guid>https://arxiv.org/abs/2410.19450</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EDGE：通过丰富的多粒度合成数据增强对 GUI 的理解</title>
      <link>https://arxiv.org/abs/2410.19461</link>
      <description><![CDATA[arXiv:2410.19461v1 公告类型：新
摘要：在各种应用程序的图形用户界面 (GUI) 上运行的自主代理具有巨大的实用价值。与依赖结构化文本和定制后端的基于大型语言模型 (LLM) 的方法不同，使用大型视觉语言模型 (LVLM) 的方法更直观、适应性更强，因为它们可以直观地感知屏幕并直接与屏幕交互，这使得它们在没有文本元数据和定制后端的一般场景中不可或缺。鉴于现有工作中缺乏与 GUI 相关的任务的高质量训练数据，本文旨在通过数据驱动的方法增强 LVLM 对 GUI 的理解和交互能力。我们提出了 EDGE，这是一个通用数据合成框架，可自动从 Web 上的网页生成大规模、多粒度的训练数据。在各种 GUI 和代理基准上的评估结果表明，使用通过 EDGE 生成的数据集训练的模型表现出卓越的网页理解能力，然后可以轻松转移到以前从未见过的桌面和移动环境中。我们的方法大大减少了对手动注释的依赖，使研究人员能够利用网络上的大量公共资源来推进他们的工作。我们的源代码、数据集和模型可在 https://anonymous.4open.science/r/EDGE-1CDB 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.19461</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>邦加德梦游仙境：视觉谜题仍让人工智能疯狂？</title>
      <link>https://arxiv.org/abs/2410.19546</link>
      <description><![CDATA[arXiv:2410.19546v1 公告类型：新
摘要：最近，新开发的视觉语言模型 (VLM) 应运而生，例如 OpenAI 的 GPT-4o，似乎展示了跨文本和图像模态的高级推理能力。然而，这些语言引导感知和抽象推理方面的进步的深度仍未得到充分探索，而且尚不清楚这些模型是否真的能实现其雄心勃勃的承诺。为了评估进展并发现不足，我们进入了 Bongard 问题的仙境，这是一组经典的视觉推理难题，需要类似人类的模式识别和抽象推理能力。虽然 VLM 偶尔能够成功识别判别概念并解决一些问题，但它们经常会失败，无法理解和推理视觉概念。令人惊讶的是，即使是对人类来说似乎微不足道的基本概念，例如简单的螺旋，也带来了重大挑战。此外，即使被要求明确关注和分析这些概念，它们仍然表现不佳，这不仅表明它们缺乏对这些基本视觉概念的理解，而且无法推广到未见过的概念。这些观察结果强调了 VLM 目前的局限性，强调了类人视觉推理和机器认知之间仍然存在巨大差距，并强调了该领域持续创新的必要性。]]></description>
      <guid>https://arxiv.org/abs/2410.19546</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Oracle 查询与黑盒代理共享控制</title>
      <link>https://arxiv.org/abs/2410.19612</link>
      <description><![CDATA[arXiv:2410.19612v1 公告类型：新
摘要：共享控制问题涉及机器人学习与人类合作。在学习共享控制策略时，代理之间的简短通信通常可以显著减少运行时间并提高系统的准确性。我们扩展了共享控制问题，使其能够直接查询合作代理。我们考虑两种对查询的潜在响应，即预言机：一种可以为学习者提供他们应该采取的最佳行动，即使该行动可能是短视错误的，另一种知识仅限于其系统的一部分。鉴于这一额外的信息渠道，这项工作进一步提出了三种选择何时查询的启发式方法：基于强化学习、基于效用和基于熵。这些启发式方法旨在降低系统的整体学习成本。在两种环境中的实证结果表明，查询以学习更好的控制策略的好处以及所提出的启发式方法之间的权衡。]]></description>
      <guid>https://arxiv.org/abs/2410.19612</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>