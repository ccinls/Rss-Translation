<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 11 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于效用的深度多目标强化学习基础设施维护优化</title>
      <link>https://arxiv.org/abs/2406.06184</link>
      <description><![CDATA[arXiv:2406.06184v1 公告类型：新
摘要：在本文中，我们介绍了多目标深度集中式多智能体演员评论家 (MO- DCMAC)，这是一种用于基础设施维护优化的多目标强化学习 (MORL) 方法，而这一领域传统上由单目标强化学习 (RL) 方法主导。以前的单目标 RL 方法通过奖励塑造将多个目标（例如崩溃概率和成本）组合成一个单一的奖励信号。相比之下，即使效用函数是非线性的，MO-DCMAC 也可以直接优化针对多个目标的策略。我们使用两个效用函数评估了 MO-DCMAC，它们使用崩溃概率和成本作为输入。第一个效用函数是阈值效用，其中 MO-DCMAC 应该最小化成本，以使崩溃概率永远不会超过阈值。第二个基于资产经理用于评估维护计划的故障模式、影响和关键性分析 (FMECA) 方法。我们在多种维护环境中评估了 MO-DCMAC 和两种效用函数，其中包括基于阿姆斯特丹历史码头墙案例研究的环境。我们将 MO-DCMAC 的性能与目前用于制定维护计划的基于启发式方法的多种基于规则的策略进行了比较。我们的结果表明，MO-DCMAC 在各种环境和效用函数中的表现都优于传统的基于规则的策略。]]></description>
      <guid>https://arxiv.org/abs/2406.06184</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:12 GMT</pubDate>
    </item>
    <item>
      <title>不确定情境下法学硕士决策行为评价框架</title>
      <link>https://arxiv.org/abs/2406.05972</link>
      <description><![CDATA[arXiv:2406.05972v1 公告类型：新 
摘要：在做出不确定的决策时，个人往往会偏离理性行为，这可以通过三个维度来评估：风险偏好、概率加权和损失规避。鉴于大型语言模型 (LLM) 在决策过程中的广泛使用，评估其行为是否符合人类规范和道德期望或表现出潜在偏见至关重要。一些实证研究已经调查了 LLM 的理性和社会行为表现，但其内部决策倾向和能力仍未得到充分了解。本文提出了一个基于行为经济学的框架来评估 LLM 的决策行为。通过多项选择题实验，我们估计了三个商业 LLM 在无上下文环境中的风险偏好、概率加权和损失规避程度：ChatGPT-4.0-Turbo、Claude-3-Opus 和 Gemini-1.0-pro。我们的结果表明，LLM 通常表现出与人类相似的模式，例如风险规避和损失规避，并且倾向于过分重视小概率。然而，这些行为在不同的 LLM 中表现的程度存在显著差异。我们还探索了它们在嵌入社会人口特征时的行为，发现了显著的差异。例如，当用性少数群体或身体残疾的属性建模时，Claude-3-Opus 表现出更高的风险规避，从而导致更保守的选择。这些发现强调了在决策场景中部署 LLM 时需要仔细考虑道德影响和潜在偏见。因此，本研究提倡制定标准和指南，以确保 LLM 在道德界限内运作，同时提高其在复杂决策环境中的效用。]]></description>
      <guid>https://arxiv.org/abs/2406.05972</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:11 GMT</pubDate>
    </item>
    <item>
      <title>论在人机协作中考虑人类对人工智能行为的信念的效用</title>
      <link>https://arxiv.org/abs/2406.06051</link>
      <description><![CDATA[arXiv:2406.06051v1 公告类型：新
摘要：为了实现有效的人机协作，仅仅优化人工智能性能而忽略人类是不够的。最近的研究表明，设计人工智能代理来考虑人类行为可以提高人机协作的性能。然而，大多数现有方法的局限性在于它们假设人类行为是静态的，与人工智能行为无关。实际上，人类可能会根据对人工智能行为的观察来调整他们的行动计划。在本文中，我们通过让协作人工智能代理考虑其人类伙伴的信念（即人类伙伴认为人工智能代理正在做什么）并设计其行动计划以促进与人类伙伴的更轻松协作来解决这一限制。具体来说，我们开发了一个人类信念模型，该模型解释了人类如何推理其人工智能伙伴的行为。基于这个信念模型，我们开发了一个人工智能代理，它在制定与人类合作的策略时同时考虑人类行为和人类信念。通过大量现实世界的人类受试者实验，我们证明了我们的信念模型能够更准确地预测人类对人工智能行为的信念。此外，我们还表明，考虑到人类信念的人工智能代理设计可以提高人机协作的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.06051</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:11 GMT</pubDate>
    </item>
    <item>
      <title>EXPIL：游戏学习的解释性谓词发明</title>
      <link>https://arxiv.org/abs/2406.06107</link>
      <description><![CDATA[arXiv:2406.06107v1 公告类型：新
摘要：强化学习 (RL) 已被证明是训练在各种游戏中表现出色的代理的强大工具。然而，神经网络模型的黑箱性质往往阻碍我们理解代理行为背后的原因。最近的研究试图通过使用预训练神经代理的指导来编码基于逻辑的策略来解决这个问题，从而做出可解释的决策。这种方法的一个缺点是需要大量以谓词形式预定义的背景知识，限制了它的适用性和可扩展性。在这项工作中，我们提出了一种新方法，即游戏学习的解释性谓词发明 (EXPIL)，它从预训练的神经代理中识别和提取谓词，随后用于基于逻辑的代理，从而减少对预定义背景知识的依赖。我们对各种游戏的实验评估证明了 EXPIL 在实现逻辑代理的可解释行为方面的有效性，同时需要较少的背景知识。]]></description>
      <guid>https://arxiv.org/abs/2406.06107</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:11 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的代理工作流和 LLM 描述组件的调查</title>
      <link>https://arxiv.org/abs/2406.05804</link>
      <description><![CDATA[arXiv:2406.05804v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展催化了复杂的代理工作流程的发展，为传统的单路径、思路链 (CoT) 提示技术提供了改进。本调查总结了常见的工作流程，特别关注 LLM 配置文件组件 (LMPC) 和对非 LLM 组件的忽略。进行此类探索的原因是为了促进更清楚地了解 LLM 角色并了解 LMPC 的可重用性。]]></description>
      <guid>https://arxiv.org/abs/2406.05804</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:10 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与表征编辑对齐：控制视角</title>
      <link>https://arxiv.org/abs/2406.05954</link>
      <description><![CDATA[arXiv:2406.05954v1 公告类型：新
摘要：将大型语言模型 (LLM) 与人类目标对齐对于实际应用至关重要。然而，微调 LLM 以进行对齐通常会受到不稳定训练的影响，并且需要大量的计算资源。测试时对齐技术（例如提示和引导解码）不会修改底层模型，其性能仍然取决于原始模型的功能。为了应对这些挑战，我们提出通过表示编辑来对齐 LLM。我们方法的核心是将预训练的自回归 LLM 视为离散时间随机动力系统。为了实现特定目标的对齐，我们将外部控制信号引入该语言动力系统的状态空间。我们根据贝尔曼方程直接在隐藏状态上训练值函数，从而实现基于梯度的优化以获得测试时的最佳控制信号。我们的实验表明，与微调方法相比，我们的方法优于现有的测试时对齐技术，同时所需的资源明显更少。]]></description>
      <guid>https://arxiv.org/abs/2406.05954</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:10 GMT</pubDate>
    </item>
    <item>
      <title>VillagerAgent：基于图形的多代理框架，用于协调 Minecraft 中的复杂任务依赖关系</title>
      <link>https://arxiv.org/abs/2406.05720</link>
      <description><![CDATA[arXiv:2406.05720v1 公告类型：新
摘要：在本文中，我们旨在评估多智能体系统对复杂依赖关系的依赖，包括空间、因果和时间约束。首先，我们在 Minecraft 环境中构建了一个名为 VillagerBench 的新基准。VillagerBench 包含各种任务，旨在测试多智能体协作的各个方面，从工作量分配到动态适应和同步任务执行。其次，我们引入了有向无环图多智能体框架 VillagerAgent 来解决复杂的智能体间依赖关系并提高协作效率。该解决方案包含一个任务分解器，用于创建有向无环图 (DAG) 以进行结构化任务管理，一个用于任务分配的代理控制器，以及一个用于跟踪环境和代理数据的状态管理器。我们对 VillagerBench 的实证评估表明，VillagerAgent 优于现有的 AgentVerse 模型，减少了幻觉并提高了任务分解效率。研究结果凸显了 VillagerAgent 在推进多智能体协作方面的潜力，为动态环境提供了可扩展且可推广的解决方案。源代码已在 GitHub 上开源（https://github.com/cnsdqd-dyb/VillagerAgent）。]]></description>
      <guid>https://arxiv.org/abs/2406.05720</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>具有可解释性和不变性的动态不确定因果关系图在临床诊断中的方法和实际应用</title>
      <link>https://arxiv.org/abs/2406.05746</link>
      <description><![CDATA[arXiv:2406.05746v1 公告类型：新
摘要：人工智能辅助临床诊断是医疗保健领域的一大需求。现有的深度学习模型缺乏可解释性，主要侧重于图像分析。最近开发的动态不确定因果关系图 (DUCG) 方法是因果关系驱动的、可解释的，并且在不同的应用场景中保持不变，不存在数据收集、标记、拟合、隐私、偏见、泛化、高成本和高能耗的问题。通过临床专家和 DUCG 技术人员的密切合作，构建了 46 个涵盖 54 个主诉的 DUCG 模型。无需分类即可诊断 1,000 多种疾病。在实际应用之前，46 个 DUCG 模型经过第三方医院的回顾性验证。经验证的诊断精度不低于 95%，其中每种疾病（包括罕见疾病）的诊断精度不低于 80%。经过验证，46 个 DUCG 模型在中国的实际应用中。已进行超过一百万次真实诊断，仅发现 17 次误诊。由于 DUCG 的透明度，导致误诊的错误被发现并纠正。经常应用 DUCG 的临床医生的诊断能力得到了显著提高。在介绍先前提出的 DUCG 方法之后，本文介绍了潜在医疗检查的推荐算法，并提炼了 DUCG 的关键思想。]]></description>
      <guid>https://arxiv.org/abs/2406.05746</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>EmbSpatial-Bench：使用大型视觉语言模型对具身任务的空间理解进行基准测试</title>
      <link>https://arxiv.org/abs/2406.05756</link>
      <description><![CDATA[arXiv:2406.05756v1 公告类型：新
摘要：大型视觉语言模型（LVLM）的近期快速发展表明了它们在具身任务中的潜力。然而，具身环境中的空间理解这一关键技能尚未得到彻底评估，导致当前 LVLM 与合格的具身智能之间的差距未知。因此，我们构建了 EmbSpatial-Bench，这是一个用于评估 LVLM 具身空间理解的基准。该基准是从具身场景中自动得出的，从自我中心的角度涵盖了 6 种空间关系。实验揭示了当前 LVLM（甚至 GPT-4V）的能力不足。我们进一步提出了 EmbSpatial-SFT，这是一个旨在提高 LVLM 具身空间理解的指令调整数据集。]]></description>
      <guid>https://arxiv.org/abs/2406.05756</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯网络中不确定参数的全局灵敏度分析</title>
      <link>https://arxiv.org/abs/2406.05764</link>
      <description><![CDATA[arXiv:2406.05764v1 公告类型：新
摘要：传统上，贝叶斯网络的敏感性分析研究以一次一个（OAT）的方式单独修改其条件概率表条目的影响。然而，这种方法无法全面说明每个输入的相关性，因为两个或多个参数的同时扰动通常会导致 OAT 分析无法捕获的高阶效应。我们建议改为进行基于全局方差的敏感性分析，其中 $n$ 个参数被视为不确定，并联合评估它们的重要性。我们的方法通过将不确定性编码为网络的 $n$ 个附加变量来工作。为了防止在添加这些维度时出现维数灾难，我们使用低秩张量分解将新势分解为更小的因子。最后，我们将 Sobol 方法应用于生成的网络以获得 $n$ 个全局敏感性指数。使用专家引出和学习的贝叶斯网络的基准阵列，我们证明 Sobol 指数与 OAT 指数存在显著差异，从而揭示不确定参数及其相互作用的真实影响。]]></description>
      <guid>https://arxiv.org/abs/2406.05764</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的强化学习，用于车辆元宇宙中动态无人机辅助车辆双胞胎迁移</title>
      <link>https://arxiv.org/abs/2406.05422</link>
      <description><![CDATA[arXiv:2406.05422v1 公告类型：新 
摘要：空地一体化网络可以减轻地面交通网络的通信压力，并在路边单元（RSU）覆盖稀疏的偏远地区和用户对车辆服务需求高的市中心地区提供支持 6G 的车载元宇宙服务卸载。车辆孪生（VT）是物理车辆的数字孪生，可实现更具沉浸感和真实感的车辆服务，这些服务可以在 RSU 上卸载和更新，以管理和向乘客和驾驶员提供车载元宇宙服务。车辆的高移动性和 RSU 信号覆盖范围有限，当车辆离开 RSU 信号覆盖范围时，需要进行 VT 迁移以确保服务连续性。然而，不均匀的 VT 任务迁移可能会使某些 RSU 过载，这可能会导致服务延迟增加，从而影响用户的沉浸式体验。本文提出了一种空地一体化网络中无人机 (UAV) 辅助的动态 VT 迁移框架，其中无人机充当空中边缘服务器，在 VT 任务卸载期间协助地面 RSU。在该框架中，我们提出了一种基于扩散的强化学习 (RL) 算法，该算法可以在无人机辅助的车载网络中有效地做出沉浸式 VT 迁移决策。为了平衡 RSU 的工作负载并提高 VT 迁移质量，我们设计了一种基于无人机启发式搜索策略的新型动态路径规划算法。仿真结果表明，基于扩散的无人机辅助 RL 算法比其他基线方案表现更好。]]></description>
      <guid>https://arxiv.org/abs/2406.05422</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>一种可扩展且接近最优的长轨迹一致性检查方法</title>
      <link>https://arxiv.org/abs/2406.05439</link>
      <description><![CDATA[arXiv:2406.05439v1 公告类型：新
摘要：在我们这个数据丰富的世界中，来自传感器和预测模型的长轨迹和大型事件日志变得越来越普遍。在这种情况下，由于寻找最佳对齐的复杂性呈指数级增长，一致性检查（流程挖掘中的一项关键任务）在计算上可能变得不可行。
本文介绍了一种新颖的滑动窗口方法来解决这些可扩展性挑战，同时保留了基于对齐方法的可解释性。通过将轨迹分解为可管理的子轨迹并迭代地将每个子轨迹与流程模型对齐，我们的方法显着减少了搜索空间。
该方法使用捕获轨迹和流程模型的结构属性的全局信息来做出明智的对齐决策，即使它们对于局部子轨迹是最佳的，也会丢弃没有希望的对齐。这提高了结果的整体准确性。
实验评估表明，所提出的方法在大多数情况下始终能够找到最佳对齐，并突出了其可扩展性。理论复杂性分析进一步支持了这一点，结果表明，与其他常见的一致性检查方法相比，搜索空间的增长有所减少。
这项工作为大规模流程挖掘应用的高效一致性检查做出了宝贵贡献。]]></description>
      <guid>https://arxiv.org/abs/2406.05439</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士 (LLM) 制定因果业务流程推理基准</title>
      <link>https://arxiv.org/abs/2406.05506</link>
      <description><![CDATA[arXiv:2406.05506v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于提高组织效率和自动化任务。虽然最初并非为复杂的认知过程而设计，但最近的努力已进一步扩展到将 LLM 应用于推理、规划和决策等活动。在业务流程中，这种能力对于利用 LLM 经过训练的大量语料库来深入了解此类流程非常有价值。在这项工作中，我们为开发一个基准埋下了伏笔，该基准旨在评估 LLM 推理业务运营的因果和流程视角的能力。我们将这种观点称为因果增强业务流程 (BP^C)。基准的核心包括一组与 BP^C 相关的情况、一组关于这些情况的问题以及一组用于系统地解决这些问题的基本事实答案的演绎规则。此外，借助 LLM 的强大功能，种子随后会被实例化为更大规模的特定领域情况和问题集。BP^C 推理对于流程干预和流程改进至关重要。我们的基准可以用于两种可能的方式之一：测试任何目标 LLM 的性能，并训练 LLM 以提高其推理 BP^C 的能力。]]></description>
      <guid>https://arxiv.org/abs/2406.05506</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>在线 DPO：基于快慢追逐的在线直接偏好优化</title>
      <link>https://arxiv.org/abs/2406.05534</link>
      <description><![CDATA[arXiv:2406.05534v1 公告类型：新 
摘要：直接偏好优化 (DPO) 通过直接在人类偏好数据集上进行训练来改善大型语言模型 (LLM) 与人类价值观的一致性，从而无需奖励模型。然而，由于跨领域人类偏好的存在，直接持续训练可能导致灾难性的遗忘，限制 DPO 的性能和效率。受物种进化的种内竞争的启发，我们提出了一种用于偏好对齐的在线快慢追逐 DPO (OFS-DPO)，通过模型之间的快速和慢速追逐来模拟竞争，以促进快速适应。具体来说，我们首先推导出在线学习的遗憾上限，用最小-最大优化模式验证我们的动机。在此基础上，我们引入了两个使用低秩自适应 (LoRA) 的相同模块，它们具有不同的优化速度来模拟种内竞争，并提出了一个新的正则化项来指导它们的学习。为了进一步缓解跨域场景中的灾难性遗忘，我们扩展了 OFS-DPO 并使用 LoRA 模块组合策略，从而产生了跨域在线快慢追逐 DPO (COFS-DPO)。该方法利用来自不同任务域的快速模块参数的线性组合，充分利用历史信息来实现持续的价值对齐。实验结果表明，OFS-DPO 在域内对齐方面优于 DPO，而 COFS-DPO 在跨域持续学习场景中表现出色。]]></description>
      <guid>https://arxiv.org/abs/2406.05534</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>推理之流：发散思维法学硕士政策的有效训练</title>
      <link>https://arxiv.org/abs/2406.05673</link>
      <description><![CDATA[arXiv:2406.05673v1 公告类型：新
摘要：发散思维是产生多样化解决方案的认知过程，是人类创造力和解决问题的标志。对于机器来说，在复杂的推理问题中采样多样化的解决方案轨迹对于稳健的结果、数据增强和增强模型泛化至关重要。大型语言模型 (LLM) 通常难以生成高质量、多样化的推理。虽然监督微调有助于提高质量，但它需要大量的监督数据来捕捉解决方案的全部多样性。或者，像 PPO 这样的强化学习方法旨在找到有限的最高奖励解决方案，同时忽略解决方案的多样性，类似于聚合思维。为了解决这些限制，我们提出了推理流 (FoR)——一种有效的 LLM 训练方法，能够用最少的数据实现多样化的推理。FoR 将多步骤 LLM 推理表述为从初始状态到终止状态的马尔可夫流。该公式允许采用原则性的 GFlowNet 方法来训练 LLM 作为策略，该策略能够以与非标准化奖励成比例的概率对多个推理路径进行采样。实证结果表明，在有限的训练数据（例如 15 个示例）的情况下，FoR 可以发现多种高质量的解决方案，这些解决方案在三个任务中远远超越了当前最先进的方法，包括具身推理 (BlocksWorld)、数学谜题解决 (Game24) 和逻辑推理 (PrOntoQA)。代码可在 https://github.com/Yu-Fangxu/FoR 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.05673</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:08 GMT</pubDate>
    </item>
    <item>
      <title>M3GIA：受认知启发的多语言和多模式通用智能能力基准</title>
      <link>https://arxiv.org/abs/2406.05343</link>
      <description><![CDATA[arXiv:2406.05343v1 公告类型：新
摘要：由于最近的多模态大型语言模型 (MLLM) 在各种复杂任务上表现出色，人们越来越关注这些模型是否最终可以反映人类智能。然而，现有的基准主要侧重于评估任务性能，例如识别对象属性的准确性。结合发达的认知科学来理解 MLLM 超越表面成就的智能仍未得到充分探索。为此，我们引入了第一个认知驱动的多语言和多模态基准来评估 MLLM 的一般智能能力，称为 M3GIA。具体来说，我们根据公认的 Cattell-Horn-Carrol (CHC) 智能模型确定了五个关键认知因素，并提出了一种新颖的评估指标。此外，由于大多数 MLLM 都接受过使用不同语言的训练，因此自然会出现一个问题：语言是影响 MLLM 认知能力的关键因素吗？因此，我们不仅局限于英语，还根据其他语言的流行程度，将中文、法语、西班牙语、葡萄牙语和韩语纳入其中，以构建我们的 M3GIA。我们确保所有与文化背景相关的数据都是从其母语环境中收集的，以避免以英语为中心的偏见。我们从人类参与者那里收集了大量数据，结果显示，最先进的 MLLM 达到了人类英语智力的最低限度。然而，在评估的其他五种语言中仍然存在明显差异。我们还揭示了一个有趣的赢家通吃现象，这与认知研究的发现一致。我们的基准将是开源的，旨在促进 MLLM 认知能力的提升。]]></description>
      <guid>https://arxiv.org/abs/2406.05343</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>LEMMA-RCA：用于根本原因分析的大型多模式多领域数据集</title>
      <link>https://arxiv.org/abs/2406.05375</link>
      <description><![CDATA[arXiv:2406.05375v1 公告类型：新
摘要：根本原因分析 (RCA) 对于提高复杂系统的可靠性和性能至关重要。然而，由于缺乏为 RCA 量身定制的大规模开源数据集，该领域的进展受到了阻碍。为了弥补这一差距，我们引入了 LEMMA-RCA，这是一个专为跨多个领域和模式的各种 RCA 任务而设计的大型数据集。LEMMA-RCA 具有来自 IT 和 OT 操作系统的各种真实故障场景，涵盖微服务、供水和水处理系统，涉及数百个系统实体。我们通过在不同设置（包括离线和在线模式以及单一和多种模式）下测试该数据集上八种基线方法的性能来评估 LEMMA-RCA 的质量。我们的实验结果证明了 LEMMA-RCA 的高质量。该数据集可在 https://lemma-rca.github.io/ 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2406.05375</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>MLLM-SR：基于对话符号回归的多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2406.05410</link>
      <description><![CDATA[arXiv:2406.05410v1 Announce Type: new 
摘要：公式是人类与自然沟通的语言，从观测数据中寻找能够反映数据中各个变量之间关系的表达式是人工智能的一个重要研究课题，这就是符号回归问题。现有的符号回归方法都是根据给定的观测数据直接生成表达式，无法要求算法根据已知的先验知识生成满足特定要求的表达式，比如表达式需要包含$\sin$或者对称等，即使可以，也往往需要非常复杂的操作，非常不方便。本文基于多模态大型语言模型，提出了一种对话式符号回归方法MLLM-SR，只需用自然语言指令描述需求，就能生成满足要求的表达式。通过在Nguyen数据集上的实验，我们可以证明MLLM-SR在拟合性能上领先于最先进的基线。更值得注意的是，我们通过实验证明了 MLLM-SR 能够很好地理解我们添加到自然语言指令中的先验知识。而且，先验知识的添加可以有效地指导 MLLM-SR 生成正确的表达。]]></description>
      <guid>https://arxiv.org/abs/2406.05410</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>基于多属性拍卖的车辆元宇宙双胞胎迁移资源分配：基于 GPT 的 DRL 方法</title>
      <link>https://arxiv.org/abs/2406.05418</link>
      <description><![CDATA[arXiv:2406.05418v1 公告类型：新 
摘要：车辆元宇宙的开发旨在通过在联网车辆和路边基础设施（例如路边单元（RSU））之间提供沉浸式和安全的体验来增强现代汽车行业。为了与虚拟空间无缝同步，车辆双胞胎（VT）被构建为物理实体的数字表示。然而，资源密集型的 VT 更新和车辆的高移动性需要密集的计算、通信和存储资源，尤其是对于它们在覆盖范围有限的 RSU 之间的迁移。为了解决这些问题，我们提出了一种基于属性感知拍卖的机制，通过考虑价格和非货币属性（例如位置和声誉）来优化 VT 迁移期间的资源分配。在该机制中，我们提出了一种在多属性资源市场中为车辆用户和元宇宙服务提供商进行的两阶段匹配。首先，资源属性匹配算法获得资源属性完美匹配，即买家和卖家可以参与双重荷兰式拍卖（DDA）。然后，我们使用基于生成预训练变压器 (GPT) 的深度强化学习 (DRL) 算法训练 DDA 拍卖师，以便在拍卖过程中有效地调整拍卖时钟。我们将社会福利和拍卖信息交换成本的表现与不同设置下最先进的基线进行比较。模拟结果表明，我们提出的基于 GPT 的 DRL 拍卖方案比其他方案具有更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.05418</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:07 GMT</pubDate>
    </item>
    <item>
      <title>LLM 增强型贝叶斯优化，用于高效模拟布局约束生成</title>
      <link>https://arxiv.org/abs/2406.05250</link>
      <description><![CDATA[arXiv:2406.05250v1 公告类型：新
摘要：模拟布局综合由于依赖手动流程、大量时间要求和性能不稳定而面临重大挑战。当前基于贝叶斯优化 (BO) 的模拟布局综合技术尽管具有自动化潜力，但收敛速度慢且数据需求量大，限制了其实际应用。本文介绍了 \texttt{LLANA} 框架，这是一种利用大型语言模型 (LLM) 来增强 BO 的新方法，通过利用 LLM 的少量学习能力来更有效地生成与模拟设计相关的参数约束。实验结果表明，\texttt{LLANA} 不仅实现了与最先进 (SOTA) BO 方法相当的性能，而且由于 LLM 出色的上下文理解和学习效率，还可以更有效地探索模拟电路设计空间。代码可在 \url{https://github.com/dekura/LLANA} 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.05250</guid>
      <pubDate>Tue, 11 Jun 2024 06:27:06 GMT</pubDate>
    </item>
    </channel>
</rss>