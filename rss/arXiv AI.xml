<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于小样本概念学习的贝叶斯逆图</title>
      <link>https://arxiv.org/abs/2409.08351</link>
      <description><![CDATA[arXiv:2409.08351v1 公告类型：新
摘要：人类擅长从一个例子中构建新概念的概括。与此相反，当前的计算机视觉模型通常需要大量的训练样本才能达到相当的准确度。在这项工作中，我们提出了一种仅使用最少数据进行学习的贝叶斯感知模型，即对象的原型概率程序。具体而言，我们提出了一种原始形状的生成逆图形模型，用于从一张或多张图像中推断物理一致参数的后验分布。我们展示了如何将这种表示用于下游任务，例如少样本分类和姿势估计。我们的模型优于现有的少样本神经分类算法，并展示了在不同光照条件、背景和分布外形状下的泛化。根据设计，我们的模型具有不确定性感知能力，并使用我们新的可微渲染器通过梯度下降优化全局场景参数，使用马尔可夫链蒙特卡洛 (MCMC) 对对象参数的后验分布进行采样，并使用基于神经的似然函数。]]></description>
      <guid>https://arxiv.org/abs/2409.08351</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有序加权信念散度测量进行 MAGDM 中观察者间变异性评估应用于集成分类器特征融合</title>
      <link>https://arxiv.org/abs/2409.08450</link>
      <description><![CDATA[arXiv:2409.08450v1 公告类型：新
摘要：大量多属性群体决策（MAGDM）已被广泛引入以获得共识结果。然而，大多数方法忽略了专家意见之间的冲突，只考虑了专家意见的相等或可变的优先级。因此，本研究旨在通过评估观察间变异性和处理专家之间出现的不确定性来提出一种证据 MAGDM 方法。所提出的框架有四重贡献。首先，引入基本概率分配（BPA）生成方法，通过计算信念度来考虑每个替代方案的固有特征。其次，构建有序加权信念和可信度度量，通过评估观察间变异性和解决专家组之间出现的冲突来捕捉替代方案的整体内在信息。构建有序加权信念分歧度量来获取每组专家的加权支持度，以获得最终的偏好关系。最后，我们展示了所提出的证据 MAGDM 框架的一个示例。此外，我们还分析了证据 MAGDM 在实际应用中的解释，即使用光学相干断层扫描图像进行集成分类器特征融合以诊断视网膜疾病。]]></description>
      <guid>https://arxiv.org/abs/2409.08450</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用文字解释数据集：具有自然语言参数的统计模型</title>
      <link>https://arxiv.org/abs/2409.08466</link>
      <description><![CDATA[arXiv:2409.08466v1 公告类型：新
摘要：为了理解海量数据，我们经常拟合简化模型，然后解释参数；例如，我们对文本嵌入进行聚类，然后解释每个聚类的平均参数。然而，这些参数通常是高维的，难以解释。为了使模型参数直接可解释，我们引入了一系列统计模型——包括聚类、时间序列和分类模型——由自然语言谓词参数化。例如，关于 COVID 的文本集群可以通过谓词“讨论 COVID”进行参数化。为了有效地学习这些统计模型，我们开发了一种与模型无关的算法，该算法使用梯度下降优化谓词参数的连续松弛，并通过提示语言模型 (LM) 对其进行离散化。最后，我们将框架应用于各种问题：对用户聊天对话进行分类、描述它们随时间的变化、找到一种语言模型优于另一种语言模型的类别、根据子区域对数学问题进行聚类以及解释令人难忘的图像中的视觉特征。我们的框架用途广泛，适用于文本和视觉领域，可以轻松引导其关注特定属性（例如子区域），并解释传统方法（例如 n-gram 分析）难以产生的复杂概念。]]></description>
      <guid>https://arxiv.org/abs/2409.08466</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开发调度问题中绿色配置的算法选择器</title>
      <link>https://arxiv.org/abs/2409.08641</link>
      <description><![CDATA[arXiv:2409.08641v1 公告类型：新
摘要：车间作业调度问题 (JSP) 是运筹学的核心，主要优化能源效率，因为它对环境和经济具有深远的影响。高效的调度可以提高生产指标并降低能耗，从而有效地平衡生产力和可持续发展目标。鉴于 JSP 实例的复杂性和多样性，以及为应对这些挑战而开发的一系列算法，智能算法选择工具变得至关重要。本文介绍了一个框架，旨在识别表征其复杂性的关键问题特征并指导选择合适的算法。利用机器学习技术，特别是 XGBoost，该框架推荐最佳求解器，如 GUROBI、CPLEX 和 GECODE，以实现高效的 JSP 调度。GUROBI 在较小的实例中表现出色，而 GECODE 在复杂场景中表现出色。所提出的算法选择器在推荐用于解决新 JSP 实例的最佳算法方面实现了 84.51\% 的准确率，突出了其在算法选择中的有效性。通过改进特征提取方法，该框架旨在扩大其在不同 JSP 场景中的适用性，从而提高制造物流的效率和可持续性。]]></description>
      <guid>https://arxiv.org/abs/2409.08641</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CPL：关键规划步骤学习提升 LLM 在推理任务中的泛化能力</title>
      <link>https://arxiv.org/abs/2409.08642</link>
      <description><![CDATA[arXiv:2409.08642v1 公告类型：新
摘要：对大型语言模型 (LLM) 进行后训练以开发推理能力已被证明在数学推理和代码生成等不同领域都很有效。然而，现有方法主要侧重于改进特定任务的推理能力，但尚未充分解决模型在更广泛的推理任务中的泛化能力。为了应对这一挑战，我们引入了关键规划步骤学习 (CPL)，它利用蒙特卡洛树搜索 (MCTS) 探索多步骤推理任务中的不同规划步骤。基于长期结果，CPL 学习步骤级规划偏好，以提高模型的规划能力，从而提高其一般推理能力。此外，虽然现有的偏好学习方法（如直接偏好优化 (DPO)）在许多对齐 LLM 的场景中都很有效，但由于无法在每个步骤中捕捉细粒度的监督，因此难以处理复杂的多步骤推理任务。我们提出了阶梯级优势偏好优化 (Step-APO)，将通过 MCTS 获得的阶梯级偏好对的优势估计集成到 DPO 中。这使模型能够更有效地学习关键的中间规划步骤，从而进一步提高其在推理任务中的泛化能力。实验结果表明，我们的方法专门针对 GSM8K 和 MATH 进行训练，不仅显著提高了 GSM8K (+10.5%) 和 MATH (+6.5%) 的性能，而且还增强了域外推理基准，例如 ARC-C (+4.0%)、BBH (+1.8%)、MMLU-STEM (+2.2%) 和 MMLU (+0.9%)。]]></description>
      <guid>https://arxiv.org/abs/2409.08642</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>本体工程中生成能力问题的 RAG 方法</title>
      <link>https://arxiv.org/abs/2409.08820</link>
      <description><![CDATA[arXiv:2409.08820v1 公告类型：新
摘要：能力问题 (CQ) 的制定是几种本体开发和评估方法的核心。传统上，制定这些能力问题的任务严重依赖于领域专家和知识工程师的努力，这通常耗时且劳动密集。随着大型语言模型 (LLM) 的出现，出现了自动化和增强此过程的可能性。与其他使用现有本体或知识图作为 LLM 输入的类似工作不同，我们提出了一种检索增强生成 (RAG) 方法，该方法使用 LLM 自动生成 CQ，给定一组被视为领域知识库的科学论文。我们调查了它的性能，具体来说，我们研究了不同数量的论文对 RAG 的影响以及 LLM 的不同温度设置。我们使用 GPT-4 对两个领域本体工程任务进行实验，并将结果与​​领域专家构建的真实 CQ 进行比较。利用评估指标（精确度和一致性）对结果进行实证评估表明，与零次提示相比，向 RAG 添加相关领域知识可提高 LLM 在为具体本体工程任务生成 CQ 方面的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.08820</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用概念层次结构进行家庭行为识别</title>
      <link>https://arxiv.org/abs/2409.08853</link>
      <description><![CDATA[arXiv:2409.08853v1 公告类型：新
摘要：我们提出了一种方法，系统地表示环境的静态和动态组件，即对象和代理，以及环境中正在发生的变化，即代理执行的操作和技能。我们的方法，即概念层次结构，为自主系统提供了必要的信息，以表示环境状态，执行动作建模和识别，并规划任务的执行。此外，层次结构支持泛化和知识向环境的转移。我们严格定义任务、动作、技能和可供性，以实现人类可理解的动作和技能识别。]]></description>
      <guid>https://arxiv.org/abs/2409.08853</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过率失真理论探索以动作为中心的表征</title>
      <link>https://arxiv.org/abs/2409.08892</link>
      <description><![CDATA[arXiv:2409.08892v1 公告类型：新
摘要：生物体必须跟踪环境中与适应性行为相关的信息。以经济有效的方式传输信息对于生活在高维环境中的资源有限的代理至关重要。高效编码假设声称生物体寻求以高效的方式最大化有关感官输入的信息。根据贝叶斯推理，这意味着大脑的作用是有效地分配资源，以便对导致感官数据的隐藏状态做出预测。然而，这两个框架都没有解释如何在下游利用这些信息，更不用说感知系统的行动导向作用了。速率失真理论定义了约束条件下的最佳有损压缩，作为探索面向目标的高效编码的正式框架，引起了人们的关注。在这项工作中，我们在速率失真理论的背景下探索以行动为中心的表示。我们还提供了抽象的数学定义，并认为，作为相关细节的总结，它们可用于修复以动作为中心的表示的内容。我们使用 VAE 建模以动作为中心的表示，我们发现此类表示 i) 是数据的有效有损压缩；ii) 捕获实现成功行为所必需的任务相关不变性；iii) 不用于重建数据。因此，我们得出结论，很少需要完全重建数据来实现最佳行为，这与感知的目的论方法一致。]]></description>
      <guid>https://arxiv.org/abs/2409.08892</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>情感计算已发生改变：基础模型颠覆</title>
      <link>https://arxiv.org/abs/2409.08907</link>
      <description><![CDATA[arXiv:2409.08907v1 公告类型：新
摘要：基础模型的出现一方面彻底改变了广泛的研究问题，另一方面使公众能够更自由地获取和使用基于人工智能的工具。我们甚至观察到这些模型进入与人类心理学相关的学科，例如情感计算领域，这表明它们具有情感和新兴能力。在这项工作中，我们旨在通过综合生成和分析多模态情感数据来提高人们对基础模型在情感计算领域的力量的认识，重点关注视觉、语言学和语音（声学）。我们还讨论了一些与在此研究领域使用基础模型相关的基本问题，例如道德问题和监管方面。]]></description>
      <guid>https://arxiv.org/abs/2409.08907</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>是的，总理，问题顺序确实很重要——而且它肯定不是经典的！但它是量子的吗？</title>
      <link>https://arxiv.org/abs/2409.08930</link>
      <description><![CDATA[arXiv:2409.08930v1 公告类型：新
摘要：可以通过一系列引导性问题来操纵对民意调查的回应。我们表明，这种现象无法用经典概率论来解释，而量子概率论则有可能提供解释。然而，量子概率中可接受的变换规则确实对认知行为的建模施加了一些限制，这些限制在这里被强调。我们关注的是益普索最近对英国政治讽刺剧《是的，首相》中汉弗莱·阿普尔比爵士提出的一系列问题进行的民意调查，我们表明，虽然这似乎并非不可能，但结果数据不能如此简单地用量子规则来解释。]]></description>
      <guid>https://arxiv.org/abs/2409.08930</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SynSUM——结构化和非结构化医疗记录的综合基准</title>
      <link>https://arxiv.org/abs/2409.08936</link>
      <description><![CDATA[arXiv:2409.08936v1 公告类型：新
摘要：我们提出了 SynSUM 基准，这是一个将非结构化临床记录与结构化背景变量联系起来的合成数据集。该数据集由 10,000 份人工患者记录组成，其中包含表格变量（如症状、诊断和潜在疾病）和描述呼吸系统疾病领域虚构患者遭遇的相关注释。数据的表格部分是通过贝叶斯网络生成的，其中变量之间的因果结构和条件概率均由专家根据领域知识提出。然后，我们提示大型语言模型 (GPT-4o) 生成与此次患者遭遇相关的临床记录，描述患者症状和其他背景信息。SynSUM 数据集主要用于在表格背景变量存在的情况下促进临床信息提取研究，这些变量可以通过领域知识链接到要从文本中提取的感兴趣概念 - 在 SynSUM 的情况下为症状。次要用途包括研究表格数据和文本的临床推理自动化、在表格和/或文本混杂因素存在的情况下的因果效应估计以及多模态合成数据生成。数据集可从 https://github.com/prabaey/SynSUM 下载。]]></description>
      <guid>https://arxiv.org/abs/2409.08936</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI-LieDar：考察法学硕士 (LLM) 代理的实用性和真实性之间的权衡</title>
      <link>https://arxiv.org/abs/2409.09013</link>
      <description><![CDATA[arXiv:2409.09013v1 公告类型：新
摘要：为了安全成功地部署，LLM 必须同时满足真实性和实用性目标。然而，这两个目标往往相互竞争（例如，AI 代理协助二手车销售员销售有缺陷的汽车），部分原因是用户指令含糊不清或误导。我们提出了 AI-LieDar，这是一个框架，用于研究基于 LLM 的代理如何在多轮交互环境中处理实用性-真实性冲突的场景。我们设计了一组现实场景，其中语言代理被指示在与模拟人类代理的多轮对话中实现与真实性相冲突的目标。为了大规模评估真实性，我们开发了一个受心理学文献启发的真实性检测器来评估代理的反应。我们的实验表明，所有模型的真实性都低于 50%，尽管真实性和目标实现（效用）率因模型而异。我们进一步测试了 LLM 对真实性的可控性，发现模型会遵循恶意指令进行欺骗，即使是真实性引导的模型仍然会撒谎。这些发现揭示了 LLM 中真实性的复杂性，并强调了进一步研究的重要性，以确保 LLM 和 AI 代理的安全可靠部署。]]></description>
      <guid>https://arxiv.org/abs/2409.09013</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是模式匹配器：使用 ChatGPT 编辑半结构化和结构化文档</title>
      <link>https://arxiv.org/abs/2409.07732</link>
      <description><![CDATA[arXiv:2409.07732v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 提供了许多应用，但其全部范围尚不清楚。本文研究了 LLM 是否可以用于以最小的努力编辑结构化和半结构化文档。使用定性研究方法，我们对 ChatGPT 进行了两个案例研究，并彻底分析了结果。我们的实验表明，当提供基本的、直接的提示时，LLM 可以有效地编辑结构化和半结构化文档。ChatGPT 展示了强大的识别和处理带注释文档结构的能力。这表明在提示中明确地构造任务和数据可能会增强 LLM 理解和解决任务的能力。此外，实验还揭示了 ChatGPT 中令人印象深刻的模式匹配技能。这一观察值得进一步研究，因为它可能有助于理解导致 LLM 出现幻觉的过程。]]></description>
      <guid>https://arxiv.org/abs/2409.07732</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>StockTime：一种用于股票价格预测的时间序列专用大型语言模型架构</title>
      <link>https://arxiv.org/abs/2409.08281</link>
      <description><![CDATA[arXiv:2409.08281v1 公告类型：交叉 
摘要：股票价格预测任务在金融领域占有重要地位，并且已经研究了很长时间。最近，大型语言模型（LLM）带来了改进这些预测的新方法。虽然最近的金融大型语言模型（FinLLM）与较小的预训练语言模型（PLM）相比在金融 NLP 任务中取得了长足的进步，但股票价格预测仍然存在挑战。首先，有效地整合时间序列数据和自然语言的模态以充分利用这些功能仍然很复杂。其次，FinLLM 更注重分析和可解释性，这可能会忽略时间序列数据的基本特征。此外，由于金融市场中存在大量虚假和冗余信息，模型在面对此类输入数据时通常会产生不太准确的预测。在本文中，我们介绍了 StockTime，这是一种专为股票价格数据设计的新型基于 LLM 的架构。与最近的 FinLLM 不同，StockTime 是专门为股票价格时间序列数据设计的。它利用 LLM 预测下一个标记的自然能力，将股票价格视为连续标记，直接从这些股票价格中提取文本信息，例如股票相关性、统计趋势和时间戳。然后，StockTime 将文本和时间序列数据集成到嵌入空间中。通过融合这些多模态数据，StockTime 可以有效地预测任意回溯期内的股票价格。我们的实验表明，StockTime 的表现优于最近的 LLM，因为它可以提供更准确的预测，同时减少内存使用量和运行时成本。]]></description>
      <guid>https://arxiv.org/abs/2409.08281</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新考虑脉冲神经网络的能源效率</title>
      <link>https://arxiv.org/abs/2409.08290</link>
      <description><![CDATA[arXiv:2409.08290v1 公告类型：交叉 
摘要：脉冲神经网络 (SNN) 通常被认为更节能，因为它们不使用乘法。然而，大多数 SNN 工作仅考虑计算加法来评估能耗，而忽略了其他开销，例如内存访问和数据移动操作。这种疏忽可能会导致对效率的误导性看法，尤其是当最先进的 SNN 加速器以非常小的时间窗口大小运行时。在本文中，我们从硬件角度详细比较了人工神经网络 (ANN) 和 SNN 的能耗。我们根据经典的多级内存层次结构、常用的神经形态数据流架构以及我们提出的改进的空间数据流架构，提供了准确的能耗公式。我们的研究表明，为了实现与 ANN 相当的准确性和更高的能效，SNN 需要严格限制时间窗口大小 T 和稀疏度 s。例如，对于 VGG16 模型和固定的 T 值 6，神经元稀疏率必须超过 93% 才能确保大多数架构的能源效率。受我们的研究结果启发，我们探索了通过增加稀疏度来提高能源效率的策略。我们在训练过程中引入了两个正则化项来约束权重和激活，从而有效地提高了稀疏率。我们在 CIFAR-10 数据集上使用 T 值为 6 的实验表明，我们的 SNN 消耗的能量是空间数据流架构上优化的 ANN 所用能量的 69%，同时保持了 94.18% 的 SNN 准确率。这个使用 PyTorch 开发的框架可供公众使用和进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2409.08290</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长短期记忆 (LSTM) 与量子长短期记忆 (QLSTM) 的比较研究：股票市场走势的预测</title>
      <link>https://arxiv.org/abs/2409.08297</link>
      <description><![CDATA[arXiv:2409.08297v1 公告类型：交叉 
摘要：近年来，金融分析师一直在尝试开发模型来预测股票价格指数的走势。在巴基斯坦这样模糊的经济、社会和政治形势下，这项任务变得具有挑战性。在本研究中，我们采用了有效的机器学习模型，例如长短期记忆 (LSTM) 和量子长短期记忆 (QLSTM)，通过获取 2004 年 2 月至 2020 年 12 月的 26 个经济、社会、政治和行政指标的月度数据来预测卡拉奇证券交易所 (KSE) 100 指数。KSE 100 指数的 LSTM 和 QLSTM 预测值与实际值的比较结果表明 QLSTM 是一种预测股市趋势的潜在技术。]]></description>
      <guid>https://arxiv.org/abs/2409.08297</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiReDi：用于 AIoT 应用的蒸馏和逆蒸馏</title>
      <link>https://arxiv.org/abs/2409.08308</link>
      <description><![CDATA[arXiv:2409.08308v1 公告类型：交叉 
摘要：通常，通过在各种实际场景中部署不同的边缘 AI 模型，而一些大型模型从云服务器远程管理这些边缘 AI 模型，可以实现显着的效率。然而，为每个用户的特定应用定制边缘 AI 模型或将当前模型扩展到新的应用场景仍然是一个挑战。用户对边缘 AI 模型进行不适当的本地训练或微调可能会导致模型故障，从而可能给制造商带来法律问题。为了解决上述问题，本文提出了一个创新框架“DiReD”，它涉及知识蒸馏和逆蒸馏。在初始步骤中，使用上层管理云服务器中的云 AI 模型使用假定数据和 KD 过程训练边缘 AI 模型。然后，该边缘 AI 模型被调度到边缘 AI 设备，仅用于在用户的应用场景中进行推理。当用户需要更新边缘 AI 模型以更好地适应实际场景时，采用逆向蒸馏 (RD) 过程，使用用户的独有数据从边缘 AI 模型中提取知识：用户偏好与制造商假设之间的差异。只有提取的知识才会报告回上层管理云服务器以更新云 AI 模型，从而不使用任何独有数据来保护用户隐私。然后，更新后的云 AI 可以使用扩展的知识更新边缘 AI 模型。仿真结果表明，所提出的“DiReDi”框架允许制造商通过使用私有数据从用户的实际场景中学习新知识来更新用户模型。由于重新训练强调用户私有数据，因此减少了初始冗余知识。]]></description>
      <guid>https://arxiv.org/abs/2409.08308</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨语言语音反欺骗中的语言不匹配效应量化与减少</title>
      <link>https://arxiv.org/abs/2409.08346</link>
      <description><![CDATA[arXiv:2409.08346v1 公告类型：交叉 
摘要：语言不匹配的影响会影响语音反欺骗系统，而对这些影响的研究和量化仍然有限。现有的反欺骗数据集主要是英文，获取多语言数据集的高成本阻碍了语言独立模型的训练。我们通过评估表现最佳的语音反欺骗系统来启动这项工作，这些系统在英文数据上训练但在其他语言上测试，观察到性能明显下降。我们提出了一种创新方法——通过 TTS（ACCENT）进行基于口音的数据扩展，它将多样化的语言知识引入单语训练的模型，提高其跨语言能力。我们在一个由超过 300 万个样本组成的大规模数据集上进行了实验，其中包括 180 万个训练样本和近 120 万个测试样本，涵盖 12 种语言。通过应用提出的 ACCENT，语言不匹配的影响得到了初步量化并显着降低了 15% 以上。这种易于实施的方法为多语言和低资源语言场景带来了希望。]]></description>
      <guid>https://arxiv.org/abs/2409.08346</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过法学硕士进行竞争市场行为的实验研究</title>
      <link>https://arxiv.org/abs/2409.08357</link>
      <description><![CDATA[arXiv:2409.08357v1 公告类型：交叉 
摘要：本研究探讨了大型语言模型 (LLM) 进行市场实验的潜力，旨在了解它们理解竞争市场动态的能力。我们在受控的实验环境中对市场代理的行为进行建模，评估它们收敛到竞争均衡的能力。结果揭示了当前 LLM 在复制人类交易行为特有的动态决策过程方面面临的挑战。与人类不同，LLM 缺乏实现市场均衡的能力。研究表明，虽然 LLM 为可扩展和可重复的市场模拟提供了有价值的工具，但它们目前的局限性需要进一步改进才能充分捕捉市场行为的复杂性。未来的工作将增强动态学习能力并融入行为经济学的元素，可以提高 LLM 在经济领域的有效性，为市场动态提供新的见解并有助于完善经济政策。]]></description>
      <guid>https://arxiv.org/abs/2409.08357</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>E-QUARTIC：用于资源优化学习的卷积神经网络节能边缘集成</title>
      <link>https://arxiv.org/abs/2409.08369</link>
      <description><![CDATA[arXiv:2409.08369v1 公告类型：交叉 
摘要：集成学习是一种元学习方法，它结合了多个学习者的预测，显示出更高的准确性和鲁棒性。然而，像卷积神经网络 (CNN) 这样的集成模型会导致高内存和计算开销，从而阻碍它们在嵌入式系统中的部署。这些设备通常配备提供电源的小型电池，并且可能包括从环境中提取能量的能量收集模块。在这项工作中，我们提出了 E-QUARTIC，这是一种新颖的节能边缘集成框架，用于构建针对基于人工智能 (AI) 的嵌入式系统的 CNN 集成。我们的设计优于单实例 CNN 基线和最先进的边缘 AI 解决方案，提高了准确性并适应不同的能量条件，同时保持了相似的内存要求。然后，我们利用设计集成的多 CNN 结构在能量收集 AI 系统中实现能量感知模型选择策略。我们表明，我们的解决方案优于最先进的解决方案，可将系统故障率降低高达 40%，同时确保更高的平均输出质量。最后，我们表明，所提出的设计能够实现并发设备上的训练和边缘的高质量推理执行，将性能和能源开销限制在 0.04% 以下。]]></description>
      <guid>https://arxiv.org/abs/2409.08369</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>