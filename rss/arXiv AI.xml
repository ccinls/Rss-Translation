<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 25 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 CSRNet 和模糊逻辑技术控制智能清真寺圆顶的运动</title>
      <link>https://arxiv.org/abs/2410.18123</link>
      <description><![CDATA[arXiv:2410.18123v1 公告类型：新
摘要：清真寺是真主的礼拜场所，必须保持清洁、整洁，为信徒提供一切舒适。沙特阿拉伯麦地那的先知清真寺是穆斯林最重要的清真寺之一。它仅次于沙特阿拉伯麦加的神圣清真寺，那里总是挤满了穆斯林，他们来参观先知穆罕默德的坟墓。本文旨在提出一种智能圆顶模型，利用人工智能技术来保持新鲜空气并让阳光进入清真寺。所提出的模型根据天气状况和清真寺的拥挤率来控制圆顶的运动。数据来自两个不同的资源，第一个来自沙特阿拉伯天气历史数据库，另一个来自上海技术数据库。拥堵场景识别网络 (CSRNet) 和模糊技术已应用 Python 编程语言来控制圆顶在特定时间内打开和关闭，以更新清真寺内的空气。此外，该模型由几个部分组成，这些部分相互连接，用于根据天气数据和清真寺拥挤情况控制打开/关闭圆顶的机制。最后，本文的主要目标已经实现，所提出的模型运行高效，并指定了每小时自动打开圆顶几分钟的确切持续时间。]]></description>
      <guid>https://arxiv.org/abs/2410.18123</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 作为对抗引擎来提高 NLP 安全性</title>
      <link>https://arxiv.org/abs/2410.18215</link>
      <description><![CDATA[arXiv:2410.18215v1 公告类型：新
摘要：本立场文件提出了一种新方法，即利用大型语言模型 (LLM) 作为生成各种对抗性攻击的引擎来提高 NLP 安全性。基于最近的工作证明 LLM 在创建词级对抗性示例方面的有效性，我们主张扩展这一概念以涵盖更广泛的攻击类型，包括对抗性补丁、通用扰动和有针对性的攻击。我们假设 LLM 复杂的语言理解和生成能力可以在各种领域和分类器架构中产生更有效、语义连贯和类似人类的对抗性示例。对抗性 NLP 的这种范式转变具有深远的影响，可能会增强模型的稳健性，发现新的漏洞，并推动防御机制的创新。通过探索这一新领域，我们旨在为关键应用开发更安全、更可靠、更值得信赖的 NLP 系统做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.18215</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图像隐写术的神经覆盖选择</title>
      <link>https://arxiv.org/abs/2410.18216</link>
      <description><![CDATA[arXiv:2410.18216v1 公告类型：新
摘要：在隐写术中，选择最佳封面图像（称为封面选择）对于有效隐藏消息至关重要。传统方法通常采用穷举搜索来识别符合特定感知或复杂性指标的图像。然而，这些指标与图像的实际消息隐藏效果之间的关系尚不清楚，通常会产生不太理想的隐写结果。受生成模型最新进展的启发，我们引入了一种新颖的封面选择框架，该框架涉及在预训练生成模型的潜在空间内进行优化以识别最合适的封面图像，从而将其与传统的穷举搜索方法区分开来。我们的方法在消息恢复和图像质量方面显示出显着的优势。我们还对生成的封面图像进行了信息论分析，揭示了消息隐藏主要发生在低方差像素中，反映了并行高斯通道中的注水算法原理。我们的代码可以在以下位置找到：https://github.com/karlchahine/Neural-Cover-Selection-for-Image-Steganography。]]></description>
      <guid>https://arxiv.org/abs/2410.18216</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化基于 LLM 的口头文档摘要系统中人工评估的作用</title>
      <link>https://arxiv.org/abs/2410.18218</link>
      <description><![CDATA[arXiv:2410.18218v1 公告类型：新
摘要：强大的 LLM 的出现导致了口头文档抽象摘要的范式转变。使 LLM 如此有价值的特性——创造力、流利讲话的能力以及从大型语料库中提取信息的能力——也为评估其内容带来了新的挑战。快速、经济高效的自动评估（例如 ROUGE 和 BERTScore）很有前景，但与人工评估相比，尚未显示出有竞争力的性能。我们借鉴社会科学的方法，提出了一种专门针对生成式 AI 内容的口头文档摘要评估范式。我们提供详细的评估标准和最佳实践指南，以确保实验设计的稳健性、可复制性和人工评估研究的可信度。此外，我们还包括两个案例研究，展示了这些人工在环评估方法是如何在一家美国大型科技公司实施的。]]></description>
      <guid>https://arxiv.org/abs/2410.18218</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动自适应啮齿动物训练的数据增强</title>
      <link>https://arxiv.org/abs/2410.18221</link>
      <description><![CDATA[arXiv:2410.18221v1 公告类型：新
摘要：完全优化啮齿类动物等实验室动物行为训练方案的自动化一直是研究人员梦寐以求的目标。这是一个劳动密集型且耗时的过程，需要动物和研究人员之间的密切互动。在这项工作中，我们使用数据驱动的方法来优化啮齿类动物在实验室中的训练方式。为了实现我们的目标，我们研究了数据增强，这是一种在数据匮乏的环境中可以很好地扩展的技术。利用数据增强，我们建立了几个人工啮齿动物模型，这些模型反过来将用于构建一个高效的自动训练器。然后，我们基于动作概率分布开发了一种新的相似性度量，以衡量我们的模型与真实啮齿动物的行为相似性。]]></description>
      <guid>https://arxiv.org/abs/2410.18221</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多步骤意图实现不完全信息博弈中的人机协调</title>
      <link>https://arxiv.org/abs/2410.18242</link>
      <description><![CDATA[arXiv:2410.18242v1 公告类型：新
摘要：在信息不完整的情况下，自主代理与人类伙伴之间的战略协调可以建模为回合制合作游戏。我们扩展了信息不完整下的回合制游戏，即共享控制游戏，以允许玩家每回合采取多个动作而不是单个动作。该扩展允许使用多步骤意图，我们假设这将提高长期任务的性能。为了在这个扩展游戏中为代理合成合作策略，我们提出了一种方法，该方法具有用于运行环境动态概率信念的内存模块和一种称为 IntentMCTS 的在线规划算法。该算法通过利用通过奖励增强传达的任何多步骤意图，同时考虑当前信念，从战略上选择下一个动作。Gnomes at Night 测试平台中的代理到代理模拟表明，与基线方法相比，IntentMCTS 需要更少的步骤和控制开关。一项人类代理用户研究证实了这些发现，结果显示与启发式基线相比，成功率高出 18.52%，与之前的单步工作相比，成功率提高了 5.56%。参与者还报告称，认知负荷和挫败感较低，对 IntentMCTS 代理伙伴的满意度较高。]]></description>
      <guid>https://arxiv.org/abs/2410.18242</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>秒速后门：通过模型编辑解锁大型预训练模型中的漏洞</title>
      <link>https://arxiv.org/abs/2410.18267</link>
      <description><![CDATA[arXiv:2410.18267v1 公告类型：新
摘要：大型预训练模型在一系列下游任务中取得了显著的成功。然而，最近的研究表明，一种对抗性攻击（即后门攻击）可以通过污染训练数据集来操纵机器学习模型的行为，对大型预训练模型的实际应用构成重大威胁，尤其是对那些定制模型。因此，解决探索预训练模型漏洞的独特挑战至关重要。通过对大型预训练模型（例如 ViT）中执行后门攻击能力的实证研究，我们发现攻击大型预训练模型面临以下独特挑战：1）无法操纵甚至访问大型训练数据集，2）训练或微调这些模型需要大量的计算资源。为了应对这些挑战，我们为在大型预训练模型背景下有效且可行的后门攻击建立了新标准。根据这些标准，我们引入了 EDT 模型，这是一种高效、无数据、无训练的后门攻击方法。受模型编辑技术的启发，EDT 将基于编辑的轻量级码本注入大型预训练模型的后门，用目标图像替换中毒图像的嵌入，而不会毒害训练数据集或训练受害者模型。我们的实验在各种预训练模型（如 ViT、CLIP、BLIP 和稳定扩散）以及下游任务（包括图像分类、图像字幕和图像生成）上进行，证明了我们方法的有效性。我们的代码可在补充材料中找到。]]></description>
      <guid>https://arxiv.org/abs/2410.18267</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>1-2-3-Go！通过决策树学习和泛化实现参数化马尔可夫决策过程的策略合成</title>
      <link>https://arxiv.org/abs/2410.18293</link>
      <description><![CDATA[arXiv:2410.18293v1 公告类型：新
摘要：尽管概率模型检查取得了进展，但验证方法的可扩展性仍然有限。特别是，当实例化参数化马尔可夫决策过程 (MDP) 时，即使使用中等值，状态空间也经常变得非常大。合成这种 \emph{huge} MDP 的策略超出了现有工具的范围。我们提出了一种基于学习的方法来为这种巨大的 MDP 获得合理的策略。
这个想法是使用决策树学习将通过模型检查小实例获得的最佳策略推广到更大的实例。因此，我们的方法绕过了对大型模型进行显式状态空间探索的需要，为状态空间爆炸问题提供了实用的解决方案。我们通过对定量验证基准集的相关模型进行大量实验来证明我们方法的有效性。实验结果表明，即使模型的大小超出了最先进的分析工具的范围，我们的策略也能很好地执行。]]></description>
      <guid>https://arxiv.org/abs/2410.18293</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>肯尼亚手语（KSL）数据集：利用人工智能（AI）弥合聋哑学习者之间的沟通障碍</title>
      <link>https://arxiv.org/abs/2410.18295</link>
      <description><![CDATA[arXiv:2410.18295v1 公告类型：新
摘要：肯尼亚手语 (KSL) 是肯尼亚聋人社区使用的主要语言。它是聋人从学前班到大学的教学媒介，促进了他们的教育和学业成就。肯尼亚手语用于肯尼亚聋人之间的社交互动、表达需求、提出请求和一般交流。然而，肯尼亚的聋人和听力正常的人之间存在语言障碍。因此，AI4KSL 的创新是消除沟通障碍的关键。KSL 的人工智能是一个为期两年的研究项目 (2023-2024)，旨在创建一个数字开放获取的人工智能，其中包含来自肯尼亚聋人社区代表性样本的自发和诱导数据。本研究的目的是开发将英语翻译成 KSL 的人工智能辅助技术数据集，以此来促进肯尼亚聋人学习者的包容性和弥合语言障碍。具体目标是：为口语英语和视频录制的肯尼亚手语建立 KSL 数据集，并将 KSL 手势转录为手语的语音级界面。本文介绍了构建数据集的方法。数据来自 48 名聋哑学习者的教师和辅导员以及 400 名聋哑学习者。参与者主要通过阅读和唱歌从事手语引出任务。数据集的结果包括约 14,000 个英语句子和相应的 KSL 注释，这些句子来自约 4000 个单词和约 20,000 个手语 KSL 视频，这些视频是手语单词或句子。第二级数据结果包括 10,000 个拆分和分段的 KSL 视频。数据集的第三个结果包括根据 HamNoSys 系统转录成五个发音参数的 4,000 个单词。]]></description>
      <guid>https://arxiv.org/abs/2410.18295</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>几何特征增强知识图谱嵌入和空间推理</title>
      <link>https://arxiv.org/abs/2410.18345</link>
      <description><![CDATA[arXiv:2410.18345v1 公告类型：新
摘要：地理空间知识图谱 (GeoKG) 以互联的方式对地理实体（例如地点和自然特征）和空间关系进行建模，为地理应用（包括数据检索、问答和空间推理）提供强大的知识支持。然而，现有的 GeoKG 挖掘和推理方法，例如流行的知识图谱嵌入 (KGE) 技术，缺乏地理意识。本研究旨在通过开发新策略和集成空间关系的几何特征（包括拓扑、方向和距离）来增强通用 KGE，从而将地理直觉注入嵌入过程。新模型在下游链接预测任务上进行了测试，结果表明，几何特征（尤其是拓扑和方向）的加入提高了地理实体和空间关系的预测准确性。我们的研究为将空间概念和原理集成到 GeoKG 挖掘过程中提供了新的视角，为地理空间挑战提供了定制的 GeoAI 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.18345</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用上下文偏差来改善领域特定自定义词汇音频转录，无需对耳语模型进行显式微调</title>
      <link>https://arxiv.org/abs/2410.18363</link>
      <description><![CDATA[arXiv:2410.18363v1 公告类型：新
摘要：OpenAI 的 Whisper 自动语音识别模型擅长跨不同数据集和领域进行推广。然而，这种广泛的适应性可能会导致在需要识别特定词汇的任务中性能下降。解决这一挑战通常涉及对模型进行微调，这需要大量标记的音频数据，而这些数据通常难以获取且特定领域无法获得。在本研究中，我们提出了一种使用相对较小的训练数据集来提高转录准确性的方法，而无需明确微调或改变模型参数。我们的方法利用上下文偏差，通过集成神经符号前缀树结构来指导模型的转录输出，将 Whisper 模型的输出引导到特定词汇。为了验证我们的方法，我们使用验证数据集进行了实验，该验证数据集包含在模拟训练环境中收集的海事数据。将原始 Whisper 模型（参数大小各异）与我们的偏置模型进行比较，可以发现转录单词错误率显著降低，下游应用程序的性能也得到提升。我们的研究结果表明，这种方法有望在词汇量有限的领域提高语音转文本的翻译性能。]]></description>
      <guid>https://arxiv.org/abs/2410.18363</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>整合典型神经单元和多尺度训练实现手写文本识别</title>
      <link>https://arxiv.org/abs/2410.18374</link>
      <description><![CDATA[arXiv:2410.18374v1 公告类型：新
摘要：针对手写文本识别的无分割研究工作可分为三类：连接时间分类 (CTC)、隐马尔可夫模型和编码器-解码器方法。在本文中，受上述三种建模方法的启发，我们提出了一种新的识别网络，该网络使用一种新颖的三维 (3D) 注意模块和全局-局部上下文信息。基于最后一个卷积层的特征图，分割出一系列具有不同分辨率的 3D 块。然后，将这些 3D 块输入 3D 注意模块以生成连续的视觉特征。最后，通过整合视觉特征和相应的全局-局部上下文特征，可以获得精心设计的表示。主要的典型神经单元包括注意机制、全连接层、循环单元和卷积层，被有效地组织成一个网络，并可以通过 CTC 损失和交叉熵损失进行联合训练。在最新的中文手写文本数据集（SCUT-HCCDoc和SCUT-EPT）以及英文手写文本数据集（IAM）上的实验表明，所提方法可以创造新的里程碑。]]></description>
      <guid>https://arxiv.org/abs/2410.18374</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>链接、合成、检索：用于零样本信息检索的通用文档链接</title>
      <link>https://arxiv.org/abs/2410.18385</link>
      <description><![CDATA[arXiv:2410.18385v1 公告类型：新
摘要：尽管信息检索 (IR) 取得了最近的进展，但零样本 IR 仍然是一项重大挑战，尤其是在处理新领域、语言和缺乏现有用户历史查询流量的新发布用例时。对于这种情况，通常使用查询增强，然后在与合成查询配对的文档数据上对预训练模型进行微调。在这项工作中，我们提出了一种新颖的通用文档链接 (UDL) 算法，该算法链接相似的文档以增强跨具有不同特征的多个数据集的合成查询生成。UDL 利用熵来选择相似性模型，并利用命名实体识别 (NER) 使用相似性分数对文档进行链接决策。我们的实证研究证明了 UDL 在不同数据集和 IR 模型中的有效性和通用性，在零样本情况下超越了最先进的方法。可重复性的开发代码包含在 https://github.com/eoduself/UDL 中]]></description>
      <guid>https://arxiv.org/abs/2410.18385</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Skywork-Reward：法学硕士 (LLM) 奖励建模的窍门</title>
      <link>https://arxiv.org/abs/2410.18451</link>
      <description><![CDATA[arXiv:2410.18451v1 公告类型：新
摘要：在本报告中，我们介绍了一系列增强 LLM 奖励建模的方法，特别关注以数据为中心的技术。我们提出了有效的数据选择和过滤策略，用于整理高质量的开源偏好数据集，最终形成了 Skywork-Reward 数据集合，它仅包含 80K 个偏好对——比现有数据集小得多。使用这个精选的数据集，我们开发了 Skywork-Reward 模型系列——Skywork-Reward-Gemma-27B 和 Skywork-Reward-Llama-3.1-8B——前者目前在 RewardBench 排行榜上名列前茅。值得注意的是，我们的技术和数据集直接增强了 RewardBench 上许多排名靠前的模型的性能，凸显了我们的贡献在现实世界偏好学习应用中的实际影响。]]></description>
      <guid>https://arxiv.org/abs/2410.18451</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越多项选择题的准确性：在医疗保健领域实施大型语言模型的现实挑战</title>
      <link>https://arxiv.org/abs/2410.18460</link>
      <description><![CDATA[arXiv:2410.18460v1 公告类型：新
摘要：大型语言模型 (LLM) 因其人类级别的能力而在医学领域引起了广泛关注，从而导致人们更加努力地探索其在各种医疗保健应用中的潜力。然而，尽管前景如此光明，但在实际环境中的实际使用中仍然存在多重挑战和障碍。这项工作从四个独特的方面讨论了 LLM 在医疗应用中面临的关键挑战：操作漏洞、道德和社会考虑、绩效和评估困难以及法律和法规遵从性。应对这些挑战对于充分利用 LLM 的潜力并确保其负责任地融入医疗保健至关重要。]]></description>
      <guid>https://arxiv.org/abs/2410.18460</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基因-代谢物关联预测与交互式知识转移增强图用于代谢物生产</title>
      <link>https://arxiv.org/abs/2410.18475</link>
      <description><![CDATA[arXiv:2410.18475v1 公告类型：新
摘要：在快速发展的代谢工程领域，寻求高效、精确的基因靶标识别以增强代谢物生产提出了重大挑战。由于研究文献规​​模庞大以及基因组规模代谢模型 (GEM) 模拟的近似性质，传统方法（无论是基于知识还是基于模型）都非常耗时且劳动密集。因此，我们提出了一项新任务，即基于代谢图的基因-代谢物关联预测，以自动化给定一对代谢物和候选相关基因的候选基因发现过程，并提出第一个基准，其中包含两种常用微生物酿酒酵母 (SC) 和东方伊萨酵母 (IO) 的 2474 种代谢物和 1947 个基因。由于代谢图的不完整性和不同代谢之间的异质性，这项任务具有挑战性。为了克服这些限制，我们提出了一种基于代谢图 (IKT4Meta) 的交互式知识转移机制，通过整合来自不同代谢图的知识来提高关联预测的准确性。首先，为了在两个图之间搭建知识转移的桥梁，我们利用具有基因和代谢物外部知识的预训练语言模型 (PLM) 来帮助生成图间链接，显著减轻异质性的影响。其次，我们使用图间链接作为锚点来传播来自不同代谢图的图内链接。最后，我们基于丰富的代谢图进行基因-代谢物关联预测，该图整合了来自多种微生物的知识。在两种生物体上进行的实验表明，我们提出的方法在各种链接预测框架中的表现都比基线高出 12.3%。]]></description>
      <guid>https://arxiv.org/abs/2410.18475</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 作为敏捷模型驱动开发中的代码生成器</title>
      <link>https://arxiv.org/abs/2410.18489</link>
      <description><![CDATA[arXiv:2410.18489v1 公告类型：新 
摘要：利用 GPT4 等大型语言模型 (LLM) 自动生成代码代表了一项重大进步，但也存在挑战。软件自然语言描述中固有的歧义对生成可部署的结构化工件构成了重大障碍。这项研究倡导模型驱动开发 (MDD) 作为克服这些挑战的可行策略，提出了一种使用 GPT4 作为代码生成器的敏捷模型驱动开发 (AMDD) 方法。这种方法增强了代码自动生成过程的灵活性和可扩展性，并提供了允许无缝适应模型或部署环境变化的灵活性。我们通过使用统一建模语言 (UML) 对多智能体无人车队 (UVF) 系统进行建模来说明这一点，通过集成对象约束语言 (OCL) 用于代码结构元建模，以及 FIPA 本体语言用于通信语义元建模，显着减少了模型歧义。应用 GPT4 自动生成功能可生成分别与 JADE 和 PADE 框架兼容的 Java 和 Python 代码。我们对自动生成的代码进行了全面评估，验证了它与预期行为的一致性，并确定了代理交互中的增强功能。从结构上讲，我们评估了仅受 OCL 元模型约束的模型派生的代码的复杂性，以及受 OCL 和 FIPA 本体元模型影响的代码的复杂性。结果表明，本体约束的元模型会产生本质上更复杂的代码，但其圈复杂度仍在可管理的水平内，这表明可以合并额外的元模型约束而不会超过复杂性的高风险阈值。]]></description>
      <guid>https://arxiv.org/abs/2410.18489</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于心脏分割的 SFB-net：通过注意力机制弥合语义鸿沟</title>
      <link>https://arxiv.org/abs/2410.18503</link>
      <description><![CDATA[arXiv:2410.18503v1 公告类型：新
摘要：在过去的几年中，深度学习算法已广泛用于心脏图像分割。然而，这些架构中的大多数依赖于几乎无法建模长距离依赖关系的卷积，从而限制了它们提取上下文信息的能力。为了解决这个问题，本文介绍了 Swin 过滤块网络 (SFB-net)，它利用了传统和 Swin 变压器层。前者用于在网络底部引入空间注意力，而后者用于关注编码器和解码器之间的高级语义丰富特征。在 ACDC 数据集上获得了 92.4 的平均 Dice 分数。据我们所知，这个结果优于该数据集上的任何其他工作。在 M\&amp;M 数据集上获得的平均 Dice 分数为 87.99，表明所提出的方法可以很好地推广到来自不同供应商和中心的数据。]]></description>
      <guid>https://arxiv.org/abs/2410.18503</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ERTMS 环境下基于 GNSS 的解决方案性能分析框架</title>
      <link>https://arxiv.org/abs/2410.18510</link>
      <description><![CDATA[arXiv:2410.18510v1 公告类型：新摘要：背景基于 GNSS 的解决方案在铁路应用中的引入进展 GNSS（全球导航卫星系统）现在用于我们的大多数旅行和我们的每个智能手机应用程序。大多数用途都不是安全关键的。但欧洲确定 GNSS 用于更多应用，并将其作为工具集的一部分集成到铁路中，以帮助铁路减少运输碳足迹。为了增加欧洲运输中火车的使用，铁路必须提高其对乘客和货物的吸引力，同时还要通过降低资本支出和运营成本来提高可靠性、可用性和效率。GNSS 是全球货运数字化计划的一部分，旨在为客户提供有关准确到达时间、持续监测运输条件（温度、湿度......）的附加值。但一个主要的挑战将是达到严格的应用，特别是，GNSS 今天被视为 ERTMS（欧洲铁路交通管理系统）未来的现实和严肃的游戏规则改变者。如今，定位功能由里程表和应答器共同执行。里程表提供相对于参考点的连续列车位置。但是，由于磨损和车轮滑动，里程表提供的距离会随着距离的增加而出现越来越大的偏差，因此使用轨道应答器可以减少这种误差。未来的系统将基于带有 GNSS 接收器的车载定位解决方案。它将允许开发移动闭塞、虚拟耦合和自动化的新概念。还研究了它在列车完整性方面的应用。但是，轨道和周围环境条件（即隧道、密集的城市地区或植被）通常会降低定位性能，从而降低其效率和安全性。事实上，GNSS 卫星在移动，它们的可见性（可用性和与接收器的相对位置）随时间而变化。此外，为了获得最佳性能，系统需要开阔的天空环境，这是大多数航空用途的情况，但不是火车用途的情况。列车经常在信号接收可能受到干扰（多径、有意或无意干扰）的区域运行，因此性能会下降。虽然过去几年在开发更强大的接收器 [Puccitelli，2022]、多传感器解决方案 [CLUG 网站] 或缺失的工具（例如数字地图 [Crespillo，2023]）方面取得了许多进展，但在 Shift2Rail 项目 X2Rail-5 或 CLUG 等项目中，仍然存在一些问题，特别是与性能评估相关的问题。我们如何评估动态环境（火车、卫星、障碍物）中的性能？我们如何确保每个配置都经过了测试？故障（不准确、漏检）对操作有何影响？欧洲铁路资助的正在进行的 R2DATO 项目解决了其中一些问题。]]></description>
      <guid>https://arxiv.org/abs/2410.18510</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在文本上扩展掩蔽扩散模型</title>
      <link>https://arxiv.org/abs/2410.18514</link>
      <description><![CDATA[arXiv:2410.18514v1 公告类型：新
摘要：掩蔽扩散模型 (MDM) 在语言建模方面表现出色，但它们在核心语言任务（例如文本生成和语言理解）中的可扩展性和有效性仍未得到充分探索。本文建立了 MDM 的第一个缩放定律，展示了与自回归模型 (ARM) 相当的缩放率和相对较小的计算差距。受其可扩展性的启发，我们训练了一系列具有多达 11 亿 (B) 个参数的 MDM，以系统地评估它们与同等或更大尺寸的 ARM 相比的性能。充分利用 MDM 的概率公式，我们提出了一种简单而有效的 \emph{无监督无分类器指导}，可有效利用大规模未配对数据，提高条件推理的性能。在语言理解方面，1.1B MDM 表现出了极具竞争力的结果，在八个零样本基准测试中的四个中都优于更大的 1.5B GPT-2 模型。在文本生成方面，与使用 KV 缓存的 ARM 相比，MDM 提供了灵活的权衡：MDM 的性能与 ARM 相当，但速度却快 1.4 倍，或者以更高的计算成本实现比 ARM 更高的质量。此外，MDM 通过有效处理双向推理和适应数据的时间变化来解决 ARM 面临的挑战性任务。值得注意的是，1.1B MDM 打破了数据和计算量明显更多的大型 ARM 所遇到的 \emph{反向诅咒​​}，例如 Llama-2 (13B) 和 GPT-3 (175B)。我们的代码可在 \url{https://github.com/ML-GSAI/SMDM} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.18514</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>