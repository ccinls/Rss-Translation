<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>最好的N是最好的吗？推理时间对齐中的覆盖范围，缩放和最佳性</title>
      <link>https://arxiv.org/abs/2503.21878</link>
      <description><![CDATA[ARXIV：2503.21878V1公告类型：新 
摘要：推理时间计算为缩放语言模型性能提供了一个重要的轴，但是通过诸如$ n $采样之类的技术来缩放计算会导致由于奖励黑客入侵而导致性能降低。为了对如何最好地利用额外计算的理论理解，我们专注于推理时间对齐，我们将其正式化为改善预培训的政策的响应以提高感兴趣的问题，鉴于可以访问不完善的奖励模型。我们根据（i）响应质量和（ii）计算推理时间对齐算法的性能，并提供新的结果，以突出预训练的政策对性能和计算缩放的高质量响应的重要性：
  1。我们表明，最佳的$ n $对齐方式与$ n $的理想选择可以在严格的覆盖范围下实现最佳性能，但是当$ n $较大时，在奖励黑客范围内遭受了奖励，并且在更现实的覆盖条件下未能实现紧张的保证。
  2。我们介绍了$ \ texttt {pebleenceTime-pessimism} $，一种新算法，通过故意使用推理时间计算来减轻奖励黑客，在面对不确定性通过拒绝采样时实施悲观原则；我们证明它的性能是最佳的，并且不会随$ n $而降级，这意味着它是缩放单调的。
  我们通过实验评估来补充理论结果，该结果证明了$ \ texttt {pebleenceTime -pessimismism} $在各种任务和模型中的好处。]]></description>
      <guid>https://arxiv.org/abs/2503.21878</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Analigner：一个全面的模块化和稳健的Python工具包，用于本体对齐</title>
      <link>https://arxiv.org/abs/2503.21902</link>
      <description><![CDATA[ARXIV：2503.21902V1公告类型：新 
摘要：本体对齐（OA）对于在各种知识系统之间实现语义互操作性至关重要。我们介绍了Analigner，这是一种用于本体一致性的全面，模块化和健壮的Python工具包，旨在通过从业者面临的现有工具来解决当前局限性。现有工具的可伸缩性，模块化和与最近的AI进步的集成易用性。 Onaligner提供了一种灵活的体系结构，该体系结构集成了现有的轻量级OA技术，例如模糊匹配，但通过支持以检索功能增强的生成和大型OA模型来支持当代方法。该框架优先考虑可扩展性，使研究人员能够整合自定义对齐算法和数据集。本文详细介绍了对Alagigner的设计原理，体系结构和实现，并通过标准OA任务的基准来证明其实用性。我们的评估强调了Analigner的能力在提供高对齐质量的同时，有效地使用几行代码来处理大规模本体论。通过制作Alagigner开放源代码，我们旨在提供一种资源，以促进OA社区内的创新和协作，从而通过使用可再现的OA研究和现实世界应用的工具包为研究人员和从业人员提供权力。]]></description>
      <guid>https://arxiv.org/abs/2503.21902</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型模型的多任务语义通信</title>
      <link>https://arxiv.org/abs/2503.22064</link>
      <description><![CDATA[ARXIV：2503.22064V1公告类型：新 
摘要：人工智能（AI）有望改变下一代通信系统的设计，优化和管理。在本文中，我们通过利用其多模式数据处理和发电能力来探讨大型AI模型（LAM）与语义通信（SEMCOM）的集成。尽管LAM带来了前所未有的能力，可以从原始数据中提取语义，但这种集成需要多方面的挑战，包括高资源需求，模型复杂性以及跨不同方式和任务的适应性需求。为了克服这些挑战，我们提出了一种基于LAM的多任务SEMCOM（MTSC）体系结构，其中包括一种自适应模型压缩策略和一种联合的拆分微调方法，以促进资源限制网络中基于LAM的语义模型的有效部署。此外，实施了一种检索增强的生成方案，以综合最新的本地和全球知识库，以提高语义提取和内容生成的准确性，从而提高推理性能。最后，仿真结果证明了拟议的基于LAM的MTSC体系结构的功效，突出了不同通道条件下各种下游任务的性能增强。]]></description>
      <guid>https://arxiv.org/abs/2503.22064</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sharpe比率引导的主动学习以在RLHF中优化优化</title>
      <link>https://arxiv.org/abs/2503.22137</link>
      <description><![CDATA[ARXIV：2503.22137V1公告类型：新 
摘要：从人类反馈中学习（RLHF）已成为大型语言模型（LLMS）的培训和对齐管道的基石。最近的进步，例如直接偏好优化（DPO），简化了偏好学习步骤。但是，收集偏好数据仍然是一个具有挑战性且昂贵的过程，通常需要专家注释。可以通过仔细选择注释的数据点来减轻此费用。在这项工作中，我们提出了一种积极的学习方法，以使用基于夏普比率的风险评估策略有效地选择快速和偏好对。为了解决注释前未知偏好的挑战，我们的方法评估了所有潜在偏好注释的梯度，以评估其对模型更新的影响。这些基于梯度的评估可以使数据点的风险评估无关注释结果。通过利用DPO损失派生，我们得出了一个封闭形式的表达式，用于以每个材料计算这些Sharpe比率，从而确保我们的方法保持可触觉和计算效率。我们还介绍了我们方法的两个变体，每个变体都对先验信息做出了不同的假设。实验结果表明，我们的方法在几种语言模型和现实世界中的人类偏好数据中，我们的方法的获胜率最高为5％。]]></description>
      <guid>https://arxiv.org/abs/2503.22137</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以代理为中心的个性化多模式LLM的个性化多重聚类</title>
      <link>https://arxiv.org/abs/2503.22241</link>
      <description><![CDATA[ARXIV：2503.22241V2公告类型：新 
摘要：个性化的多个聚类旨在基于不同特定于用户特定方面而不是单个聚类来生成数据集的各种分区。它最近引起了用于适应不同用户偏好的研究兴趣。最近的方法主要使用带有代理学习的剪辑嵌入来提取偏向用户群集偏好的表示形式。但是，剪辑主要集中在粗糙的图像文本对齐方式上，缺乏对用户兴趣的深刻上下文理解。为了克服这些局限性，我们提出了一个以代理为中心的个性化聚类框架，该框架利用多模式大型语言模型（MLLM）作为代理，以全面地穿越关系图，以根据用户兴趣搜索群集。由于MLLM的高级推理机制，所获得的群集与用户定义的标准比从基于夹的表示的标准更紧密地与用户定义的标准保持一致。为了减少计算开销，我们通过使用MLLM提取的用户利益偏置的嵌入来构建关系图来缩短代理的遍历路径。可以根据嵌入相似性过滤大量弱连接的边缘，从而有助于对代理进行有效的遍历搜索。实验结果表明，所提出的方法在卡订单和卡套装基准上分别达到0.9667和0.9481的NMI得分，在很大程度上将SOTA模型提高了140％以上。]]></description>
      <guid>https://arxiv.org/abs/2503.22241</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CPPO：加速基于基于策略优化的团体相对策略的推理模型的培训</title>
      <link>https://arxiv.org/abs/2503.22342</link>
      <description><![CDATA[ARXIV：2503.22342V1公告类型：新 
摘要：本文介绍了完成修剪政策优化（CPPO），以加快基于小组相对策略优化（GRPO）的推理模型的培训。 GRPO虽然有效，但由于需要为每个问题进行多次完成，因此会产生高培训费用。我们的实验和理论分析表明，完成的数量会影响模型的准确性，但培训时间增加了，并不是所有的完成都对政策培训产生了同等贡献 - 它们的贡献取决于他们的相对优势。为了解决这些问题，我们提出了CPPO，该CPPO的绝对优势较低，可以大大减少梯度计算和更新所需的数量。此外，我们引入了动态完成分配策略，以通过纳入其他问题，进一步提高培训效率来最大化GPU利用率。实验结果表明，与原始GRPO相比，CPPO在GSM8K上达到了高达$ 8.32 \ times $加速，在保留甚至增强准确性的同时，数学上的$ 3.51 \ times $。我们在https://github.com/lzhxmu/cppo上发布代码。]]></description>
      <guid>https://arxiv.org/abs/2503.22342</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>独角兽：视觉语言模型培训的仅文本数据综合</title>
      <link>https://arxiv.org/abs/2503.22655</link>
      <description><![CDATA[ARXIV：2503.22655V1公告类型：新 
摘要：训练视觉模型（VLM）通常需要大规模的高质量图像 - 文本对，但是收集或合成此类数据是昂贵的。相比之下，文本数据很丰富且廉价，提示了一个问题：高质量的多模式训练数据是否纯粹是从文本中综合的？为了解决这个问题，我们提出了一个跨集成的三阶段多模式数据综合框架，该框架生成了两个数据集：Unicorn-1.2m和Unicorn-471K-Instruction。在第1阶段：不同的字幕数据综合，我们通过使用大语言模型（LLM）扩展稀疏字幕种子来构建120万种语义上的高质量字幕。在第2阶段：指令调整数据生成中，我们将471K字幕进一步处理为多转弯指令策划任务，以支持复杂的推理。最后，在第3阶段：模态表示转移中，这些文本标题表示形式被转换为视觉表示，从而导致了多样化的合成图像表示。这个三阶段的过程使我们能够在不依赖真实图像的情况下构建用于训练和独角兽-471k的指导进行预处理和独角兽-471k的指导。通过消除对真实图像的依赖，同时保持数据质量和多样性，我们的框架为VLMS培训提供了一种经济高效且可扩展的解决方案。代码可在https://github.com/yu-xm/unicorn.git上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.22655</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ActionStudio：用于数据和培训大型动作模型的轻量级框架</title>
      <link>https://arxiv.org/abs/2503.22673</link>
      <description><![CDATA[ARXIV：2503.22673V2公告类型：新 
摘要：动作模型对于使自主代理执行复杂的任务至关重要。但是，由于代理环境的多样性和代理数据的复杂性，训练大型动作模型仍然具有挑战性。尽管兴趣越来越大，但现有的基础设施为可扩展的特定于特定代理的微调提供了有限的支持。我们提出ActionStudio，这是为大型动作模型设计的轻巧且可扩展的数据和培训框架。 ActionStudio通过标准化的格式统一了异构代理轨迹，支持包括Lora，完整的微调和分布式设置在内的各种训练范式，并集成了强大的预处理和验证工具。我们验证了其在公共和现实行业的基准中的有效性，表明了强大的性能和实践可扩展性。我们在https://github.com/salesforceairesearch/xlam上开放代码和数据，以促进社区的研究。]]></description>
      <guid>https://arxiv.org/abs/2503.22673</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QuestBench：LLM可以提出正确的问题来获取推理任务中的信息吗？</title>
      <link>https://arxiv.org/abs/2503.22674</link>
      <description><![CDATA[ARXIV：2503.22674V1公告类型：新 
摘要：最近，大量工作重点是改善大型语言模型（LLMS&#39;）在推理基准（例如数学和逻辑）上的性能。但是，过去的工作在很大程度上假定任务定义明确。在现实世界中，对LLM的疑问通常被指定，只能通过获取丢失的信息来解决。我们将其形式化为丢失的变量分配的约束满意度问题（CSP）。使用这种形式主义的特殊情况，只有一个必要的变量分配丢失，我们可以严格评估LLM确定每个问题的难度水平轴的最小必要问题的能力。 We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q，其中单词问题被人类注释者翻译成方程。 LLM的任务是从选项列表中选择正确的澄清问题。尽管最新的模型在GSM-Q和GSME-Q上表现出色，但其准确性在Logic-Q和Planning-Q上仅为40-50％。分析表明，解决良好指定的推理问题的能力可能不足以在我们的基准上取得成功：模型很难识别正确的问题，即使他们可以解决问题的完全指定版本。此外，在规划Q领域中，LLMS倾向于不进行对冲，即使明确提出了预测``不确定&#39;&#39;的选择。这突出了对模型信息采集功能进行更深入的研究的需求。]]></description>
      <guid>https://arxiv.org/abs/2503.22674</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mamba-3d作为掩盖自动编码器，用于对医学超声视频进行准确和数据效率分析</title>
      <link>https://arxiv.org/abs/2503.20258</link>
      <description><![CDATA[ARXIV：2503.20258V1公告类型：交叉 
摘要：超声视频是临床成像数据的重要形式，基于深度学习的自动化分析可以提高诊断准确性和临床效率。但是，标记数据的稀缺性和视频分析的固有挑战阻碍了相关方法的发展。在这项工作中，我们介绍了E-VIM $^3 $，这是一个数据有效的视觉MAMBA网络，可保留视频数据的3D结构，增强了远程依赖性和电感偏见，以更好地模型时空相关性。借助我们的外壳全球令牌（EGT），该模型比竞争方法更有效地捕获和汇总全球功能。为了进一步提高数据效率，我们采用了蒙版的视频建模来进行自我监督的预训练，并采用拟议的时空链式链接（STC）掩盖策略，旨在适应各种视频场景。实验表明，e-Vim $^3 $在四个不同大小的数据集中执行了两个高级语义分析任务的最先进：echonet-dynamic，camus，miccai-buv和whbus。此外，我们的模型通过有限的标签来实现竞争性能，突出了其对现实世界临床应用的潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2503.20258</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从深度学习到LLM：定量投资的AI调查</title>
      <link>https://arxiv.org/abs/2503.21422</link>
      <description><![CDATA[ARXIV：2503.21422V1公告类型：交叉 
摘要：定量投资（QUANT）是一种新兴的，技术驱动的资产管理方法，这是由人工智能的进步所塑造的。最新的深度学习和大型语言模型（LLMS）的量化融资已改进了预测性建模和启用基于代理的自动化，这表明该领域的潜在范式转移。在这项调查中，以Alpha策略为代表性的例子，我们探讨了AI如何为定量投资管道做出贡献。我们首先研究了Quant研究的早期阶段，该阶段以人工制作的特征和传统统计模型为中心，并具有既定的Alpha管道。然后，我们讨论深度学习的兴起，从数据处理到订单执行，可以在整个管道上进行可扩展的建模。在此基础上，我们强调了LLM在将AI扩展到超越预测中的新兴作用，赋予自主代理来处理非结构化数据，生成alpha和支持自我读物工作流。]]></description>
      <guid>https://arxiv.org/abs/2503.21422</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三月疯狂锦标赛预测模型：一种数学建模方法</title>
      <link>https://arxiv.org/abs/2503.21790</link>
      <description><![CDATA[ARXIV：2503.21790V1公告类型：交叉 
Abstract: This paper proposes a model to predict the outcome of the March Madness tournament based on historical NCAA basketball data since 2013. The framework of this project is a simplification of the FiveThrityEight NCAA March Madness prediction model, where the only four predictors of interest are Adjusted Offensive Efficiency (ADJOE), Adjusted Defensive Efficiency (ADJDE), Power Rating, and Two-Point Shooting Percentage Allowed.上述指标用于产生特定团队赢得每场比赛的概率的逻辑回归。然后，开发了锦标赛模拟并将其与现实世界的Mard Madness Brackets进行比较，以确定模型的准确性。使用幼稚的方法和Spearman等级相关系数计算出绩效的准确性。]]></description>
      <guid>https://arxiv.org/abs/2503.21790</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>输入触发的硬件特洛伊木马对尖峰神经网络的攻击</title>
      <link>https://arxiv.org/abs/2503.21793</link>
      <description><![CDATA[ARXIV：2503.21793V1公告类型：交叉 
摘要：基于峰值神经网络（SNN）的神经形态计算正在成为传统人工神经网络（ANN）的有前途的替代方案，在低功耗方面具有独特的优势。但是，与其ANN同行相比，SNN的安全性方面的探索不足。随着对AI系统的越来越依赖伴随着独特的安全风险和挑战，理解脆弱性和威胁景观至关重要，因为神经形态计算的成熟是必不可少的。在这项工作中，我们提出了一种针对SNN的新型输入触发的硬件Trojan（HT）攻击。 HT机制在一个神经元的区域中凝结。触发机制是在尖峰域中精心设计的输入消息，因此所选神经元会产生恶意的尖峰火车，在正常设置中未达到。这种尖峰列车触发神经元中的恶意修饰，迫使其饱和，永久发射，即使输入活动停止，也无法恢复到其静止状态。过度的尖峰污染了网络并产生误导性决定。我们提出了一种方法来选择适当的神经元并生成触发HT有效载荷的输入模式。通过对神经形态社区的三个流行基准进行模拟来说明了这一攻击。我们还为模拟尖峰神经元和数字SNN加速器提出了硬件实现，表明HT具有微不足道的区域和功率足迹，因此很容易逃避检测。]]></description>
      <guid>https://arxiv.org/abs/2503.21793</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息架构</title>
      <link>https://arxiv.org/abs/2503.21794</link>
      <description><![CDATA[ARXIV：2503.21794V1公告类型：交叉 
摘要：本文探讨了一种构建正式神经元和多层人工神经网络（ANN）的能量景观的方法。他们的分析使得确定分类ANN（例如MLP或CNN）和生成ANN模型的概念限制是可能的。对形式神经元和ANN模型中信息和热力学熵的研究得出了有关信息熵的能量性质的结论。 Gibbs Free Energy概念的应用允许表示ANN的输出信息为焓的结构化部分。将ANN作为能量系统进行建模，可以将其内部能量的结构解释为外部世界的内部模型，该模型根据系统的内部能量组件的相互作用进行自组织。该模型的自组织和演化过程的控制是基于还原算子的能量函数（类似于Lyapunov函数）进行的。这使得引入一种新的方法来通过直接学习来构建自组织和进化的ANN，这不需要其他外部算法。提出的研究使得可以根据系统的内部和外部能量之间的相互作用过程来制定信息的形式定义。]]></description>
      <guid>https://arxiv.org/abs/2503.21794</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>峰值网络中的阈值适应能够使最短的路径发现和放置歧义</title>
      <link>https://arxiv.org/abs/2503.21795</link>
      <description><![CDATA[ARXIV：2503.21795V1公告类型：交叉 
摘要：有效的空间导航是哺乳动物大脑的标志，激发了模仿生物学原理的神经形态系统的发展。尽管取得了进展，但在生物启发的尖峰神经网络中实施诸如背面追踪和处理歧义之类的关键操作仍然是一个开放的挑战。这项工作提出了一种在任意单向尖峰神经元图中进行反向追踪活动的机制。我们扩展了峰值分层时间内存（S-HTM）的现有重播机制，该机制通过我们的峰值定时依赖性阈值适应（STDTA），这使我们能够在尖峰神经元网络中执行路径计划。我们进一步提出了一个歧义依赖性阈值适应（ADTA），以识别歧义性较小的环境中的位置，从而增强了代理的本地化估计。这些方法结合在一起，可以有效地识别通往明确目标的最短路径。我们的实验表明，经过序列训练的网络可靠地计算出比到达目标所需的步骤更少的重播路径。我们进一步表明，我们可以在多个相似的环境中识别出歧义性降低的地方。这些贡献推进了生物学启发的顺序学习算法（如S-HTM）在神经形态定位和导航中的实际应用。]]></description>
      <guid>https://arxiv.org/abs/2503.21795</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个新颖的两阶段合作共同进化框架，用于大规模全局优化，并具有复杂的重叠</title>
      <link>https://arxiv.org/abs/2503.21797</link>
      <description><![CDATA[ARXIV：2503.21797V1公告类型：交叉 
摘要：通过问题空间的分解，合作的共同进化是解决大规模全球优化问题的主要方法。通常，当子空间是不相交的时，与非分解算法相比，算法表现出显着的有效性和效率。但是，重叠变量的存在使分解过程复杂化，并对合作共同进化的表现产生不利影响。在这项研究中，我们提出了一个新型的两阶段合作共同进化框架，以解决复杂重叠的大规模全球优化问题。分解基于其数学特性的重叠问题的有效方法嵌入了框架中。此外，引入了重叠问题的可自定义基准，以扩展现有基准并促进实验。广泛的实验表明，在我们的框架内实例化的算法大大优于现有算法。结果揭示了重叠问题的特征，并突出了合作共同进化和非分解算法的不同优势。我们的工作是开源的，可访问：https：//github.com/gmc-drl/hcc。]]></description>
      <guid>https://arxiv.org/abs/2503.21797</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>榆树：从病理报告中预测肿瘤组的语言模型合奏</title>
      <link>https://arxiv.org/abs/2503.21800</link>
      <description><![CDATA[ARXIV：2503.21800V1公告类型：交叉 
摘要：基于人群的癌症注册表（PBCRS）在手动从非结构化病理报告中提取数据时面临着重要的瓶颈，这是诸如肿瘤组分配等任务至关重要的过程，该任务可以消耗900个人小时的时间，以供大约100,000个报告。为了解决这个问题，我们介绍了ELM（语言模型的集合），这是一种基于新颖的集合方法，利用小语言模型（SLM）和大语言模型（LLMS）。 Elm使用了六个微型SLM，其中三个SLM使用病理报告的顶部，三个SLM使用底部。这样做是为了最大程度地提高报告覆盖范围。 ELM需要进行五分之一的肿瘤组分类一致。分歧是由LLM和经过精心策划的提示进行仲裁的。我们在十九个肿瘤组中进行的评估表明，ELM的平均精度和回忆为0.94，表现优于单模型和合奏 - 无数方法。 ELM部署在不列颠哥伦比亚省癌症注册表中，展示了如何成功地应用于PBCR环境中的LLM，以实现最先进的结果并显着提高了运营效率，从而节省了数百人小时。]]></description>
      <guid>https://arxiv.org/abs/2503.21800</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的多个未来代币的联合预测</title>
      <link>https://arxiv.org/abs/2503.21801</link>
      <description><![CDATA[Arxiv：2503.21801V1公告类型：交叉 
摘要：在此简短的报告中，我们引入了联合多言预测（JTP），这是对旨在通过共同预测多个将来的代币来丰富隐藏状态表示的标准下一个预测的轻巧修改。与以前的多言预测方法不同，JTP通过精心设计的表示瓶颈策略性地采用了教师的强迫，从而使模型可以在培训期间用最小的计算开销来编码丰富的预测信息。我们表明，JTP方法实现了短暂的信念状态表示，而多token预测的流行替代方案未能做到这一点。我们证明了我们的方法对来自Bachmann和Nagarajan [2024]的合成星导航任务的有效性，突出了对现有方法的显着性能改善。该手稿提出了有希望的初步结果，旨在刺激进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2503.21801</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯正规化神经网络在Fuego火山的预测火山辐射能力（VPR）</title>
      <link>https://arxiv.org/abs/2503.21803</link>
      <description><![CDATA[arxiv：2503.21803v1公告类型：交叉 
摘要：预测火山活动对于危害评估和减轻风险至关重要。来自热遥感数据的火山辐射功率（VPR）是火山活动的重要指标。在这项研究中，我们采用贝叶斯正规化神经网络（BRNN）根据Fuego火山的历史数据来预测未来的VPR值，将其与缩放的共轭梯度（SCG）和Levenberg-Marquardt（LM）模型进行了比较。结果表明，BRNN胜过SCG和LM，达到了最低平方误差（1.77E+16）和最高的R平方值（0.50）（0.50），这表明其捕获VPR变异性的卓越能力，同时最小化过度拟合。尽管这些有希望的结果，但仍在提高模型的预测准确性方面仍然存在挑战。未来的研究应着重于整合其他地球物理参数，例如地震和气体排放数据，以提高预测精度。这些发现突出了机器学习模型，尤其是BRNN的潜力，可以预测火山活动，这有助于更有效的火山危害预警系统。]]></description>
      <guid>https://arxiv.org/abs/2503.21803</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>元数据表示模型的知识图嵌入模型的比较</title>
      <link>https://arxiv.org/abs/2503.21804</link>
      <description><![CDATA[ARXIV：2503.21804V2公告类型：交叉 
摘要：超关系知识图（HRKGS）将传统的KG扩展到二进制关系之外，从而可以在域中的上下文，出处和时间信息的表示，例如历史事件，传感器数据，视频内容和叙述。可以使用多种元数据表示模型（MRMS）来构建HRKG，包括重新化（REF），Singleton属性（SGP）和RDF-Star（RDR）。但是，不同MRM对KG嵌入（KGE）和链接预测（LP）模型的影响尚不清楚。这项研究在LP任务的背景下评估了MRM，确定了现有评估框架的局限性，并引入了一项新任务，以确保MRM的公平比较。此外，我们提出了一个有效反映潜在空间中三个MRM的知识表示的框架。在两种类型的数据集上进行的实验表明，REF在简单的HRKG中表现良好，而SGP的效率较低。但是，在复杂的HRKG中，LP任务中MRM的差异很小。我们的发现有助于LP任务中HRKG的最佳知识表示策略。]]></description>
      <guid>https://arxiv.org/abs/2503.21804</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>