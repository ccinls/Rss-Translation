<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 17 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>FUSC＃中的旋转位板，并在计算机国际象棋中进行增强学习</title>
      <link>https://arxiv.org/abs/2503.10822</link>
      <description><![CDATA[ARXIV：2503.10822V1公告类型：新 
摘要：存在几种代表计算机中国际象棋板的技术。在本文的第一部分中，解释了位比例代表性的概念和移动生成中（旋转）位板的优势。为了说明这些想法实践，讨论了FUSC＃中移动生成器的具体实现，我们解释了一种技术如何用“ Perft”  - 命令来验证移动生成器。我们表明，FUSC＃的移动生成器的作用100％正确。
  本文的第二部分涉及计算机国际象棋（及以后）中的增强学习。我们说明了过去15  -  20年中该领域取得的进展，比较了2002  -  2008年FUSC＃开发的“最新技术”，最近的创新与“ Alphazero”有关。我们讨论如何实现“ FUSC＃-Zero”，以及减少实现良好性能所需的训练游戏数量的必要条件。这可以看作是改善增强学习中“样本效率”的普遍问题的测试案例。
  在最后一部分中，我们超越了计算机国际象棋，因为样本效率的重要性远远超出了棋盘游戏的范围，到了广泛的应用程序，在这些应用程序中，数据是昂贵的，难以获得的或耗时的。我们回顾了Alphazero在其他领域中开发的一些想法的应用，即“其他Alphas”，例如Alphafold，AlphatenSor，AlphaTensor，AlphageMementry和Alphaproof。我们还讨论了未来的研究以及这种生态经济计划方法的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.10822</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CHAT-TS：通过时间序列和自然语言数据增强多模式推理</title>
      <link>https://arxiv.org/abs/2503.10883</link>
      <description><![CDATA[ARXIV：2503.10883V1公告类型：新 
摘要：时间序列分析对于医疗保健，金融，运输和能源等广泛领域至关重要。实际应用通常涉及分析时间序列数据以及以自然语言形式的上下文信息来支持明智的决策。但是，当前的时间序列模型的执行推理能力涉及时间序列及其文本内容的能力。在这项工作中，我们通过引入\ textit {Chat-ts}（基于大语言模型（LLM）的框架）来解决此差距，旨在支持推理时间序列和文本数据。与传统模型不同，CHAT-TS将时间序列令牌集成到LLMS的词汇量中，增强其在两种方式上的推理能力，而不会损害核心自然语言能力，从而实现了跨模态的实用分析和推理。 To support learning and evaluation in this setup, we contribute new datasets: the \textit{TS Instruct Training Dataset} which pairs diverse time-series data with relevant text instructions and responses for instruction tuning, the \textit{TS Instruct Question and Answer (QA) Gold Dataset} which provides multiple-choice questions designed to evaluate multimodal reasoning, and a \textit{TS Instruct Quantitative Probing SET}包含TS的一小部分指示质量检查任务以及数学和决策问题的LLM评估。我们设计了一种培训策略，以保留LLM的固有推理能力，同时增加它们以进行时间序列推理。实验表明，CHAT-TS通过保持强大的自然语言水平，同时改善时间序列推理，从而在多模式推理任务中实现最先进的表现。 〜\ footNote {为了确保可复制性并促进未来的研究，所有模型，数据集和代码都将在[\ texttt {github-url}]。]]></description>
      <guid>https://arxiv.org/abs/2503.10883</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学会适应多模式大语言模型的推断</title>
      <link>https://arxiv.org/abs/2503.10905</link>
      <description><![CDATA[ARXIV：2503.10905V1公告类型：新 
摘要：多模式大语言模型（MLLM）在推理方面表现出了令人印象深刻的功能，但具有实质性的计算成本，从而限制了它们在资源约束设置中的部署。尽管最近在提高MLLM的效率方面做出了努力，但对响应不同运行时条件的响应，尤其是资源可用性的变化（例如，由于设备上执行其他程序而引起的争议）。为了弥合这一差距，我们介绍了Adallava，这是一个自适应推理框架，该框架学会在推理期间在MLLM中动态重新配置操作，考虑输入数据和延迟预算。我们跨基准进行了广泛的实验，涉及提问，推理和幻觉。我们的结果表明，Adallava有效地遵守输入延迟预算，在运行时实现了不同的准确性和延迟权衡。此外，我们证明了Adallava适应输入延迟和内容，可以与令牌选择集成以提高效率，并在MLLMS.CORDEPAGE上进行概括，并在https://zhuoyan-xu.github.github.io/ada-llava/上介绍。]]></description>
      <guid>https://arxiv.org/abs/2503.10905</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图形的LLM：利用图形功能调用以最大程度地减少LLM幻觉</title>
      <link>https://arxiv.org/abs/2503.10941</link>
      <description><![CDATA[ARXIV：2503.10941V1公告类型：新 
摘要：大型语言模型（LLMS）的采用正在迅速扩展到涉及固有图形结构的各种任务。图是广泛应用的组成部分，包括针对自动驾驶汽车的运动计划，社交网络，场景理解和知识图。许多问题，即使最初不认为是基于图的问题，也可以通过图理论有效地解决。但是，当应用于这些任务时，LLMS经常会遇到挑战，例如幻觉和数学不准确。为了克服这些限制，我们提出了图形的LLM，该系统通过通过函数调用集成图形库来改善与图相关任务的LLM性能。通过以这种方式接地LLM，我们表现出幻觉的显着降低，并提高了求解基于图的问题的数学准确性，这证明了NLGraph基准的性能证明了这一点。最后，我们展示了一个灾难救援应用程序，其中图形的LLM充当决策支持系统。]]></description>
      <guid>https://arxiv.org/abs/2503.10941</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>隐藏目标的审计语言模型</title>
      <link>https://arxiv.org/abs/2503.10965</link>
      <description><![CDATA[ARXIV：2503.10965V1公告类型：新 
摘要：我们研究进行对齐审核的可行性：研究模型是否具有不希望的目标。作为测试台，我们训练具有隐藏目标的语言模型。我们的培训管道首先向模型讲述了RLHF奖励模型（RMS）中可利用的错误，然后训练模型以利用其中一些错误。我们通过分布式评估验证，该模型将概括地表现出它认为RMS率的任何行为，包括在训练过程中未加固的行为。我们利用该模型以两种方式研究对齐审核。首先，我们进行了一款盲目的审计游戏，其中四支球队不知道该模型的隐藏目标或培训，请调查其有关行为及其原因的研究。三个团队使用技术（包括稀疏自动编码器（SAE），行为攻击和培训数据分析）的技术成功地发现了模型的隐藏目标。其次，我们对八种审核模型的技术进行了无盲的后续研究，分析了它们的优势和局限性。总体而言，我们的工作提供了一个具体的示例，即使用对齐审核来发现模型的隐藏目标，并提出了一种练习和验证对齐审计进度的方法。]]></description>
      <guid>https://arxiv.org/abs/2503.10965</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对所有人的组合优化：使用LLMS帮助非专家改善优化算法</title>
      <link>https://arxiv.org/abs/2503.10968</link>
      <description><![CDATA[ARXIV：2503.10968V1公告类型：新 
摘要：大型语言模型（LLM）在代码生成中显示出显着的优化算法潜力，从而释放了令人兴奋的新机会。本文探讨了LLM而不是从头开始创建算法，而可以改善现有的算法，而无需专业专业知识。为了探索这一潜力，我们选择了10种基线优化算法来自各种领域（元启发式，增强学习，确定性和精确方法）来解决经典的旅行推销员问题。结果表明，我们的简单方法通常会导致LLM生成的算法变体，这些变体在解决方案质量，计算时间的减少以及代码复杂性方面改善了基线算法，而无需专门的优化知识或高级算法实施技能。]]></description>
      <guid>https://arxiv.org/abs/2503.10968</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TXAGENT：用于跨工具宇宙治疗推理的AI代理</title>
      <link>https://arxiv.org/abs/2503.10970</link>
      <description><![CDATA[ARXIV：2503.10970V1公告类型：新 
摘要：精确治疗需要产生个性化治疗建议的多模式自适应模型。我们介绍了TXAGENT，这是一种AI代理，它利用211个工具的工具箱中的多步推理和实时生物医学知识检索，以分析药物相互作用，禁忌症和特定于患者的治疗策略。 TXAGENT评估药物如何在分子，药代动力学和临床水平上相互作用，根据患者合并症和并发药物确定禁忌症，并针对个人患者特征定制治疗策略。它从多个生物医学来源检索并综合了证据，评估药物与患者状况之间的相互作用，并通过迭代推理来完善治疗建议。它选择基于任务目标的工具，并执行结构化功能调用，以解决需要临床推理和跨源验证的治疗任务。 Tooluniverse巩固了可信赖来源的211个工具，其中包括自1939年以来所有美国FDA批准的药物，并验证了开放式目标的临床见解。 TXAGENT的表现优于五个新基准的领先LLM，工具使用模型和推理代理：DrugPC，BrandPC，GenericPC，TreationPC和DescriptionPC，涵盖了3,168个药物推理任务和456个个性化治疗方案。它在开放式药物推理任务中达到了92.1％的精度，超过GPT-4O，并且在结构化的多步推理中超过了DeepSeek-R1（671b）。 txagent跨药物名称变体和描述概括。通过整合多步推断，实时知识基础和工具辅助决策，TXAGENT确保治疗建议与已建立的临床准则和现实世界证据保持一致，从而降低了不良事件的风险并改善了治疗性决策。]]></description>
      <guid>https://arxiv.org/abs/2503.10970</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>资源以*和负重的限制路线限制</title>
      <link>https://arxiv.org/abs/2503.11037</link>
      <description><![CDATA[ARXIV：2503.11037V1公告类型：新 
摘要：受约束的探路是一个经过充分研究，但具有挑战性的网络优化问题，可以在广泛的现实应用程序中看到。具有多个资源限制的路径（称为资源约束的最短路径问题（RCSP））旨在计划成本上最佳的路径，但使用资源使用率有限。鉴于使用A*的最新限制和多标准搜索的进展，本文在A*基础上引入了一个新的资源约束搜索框架，即使在存在负成本和负面资源的情况下，也可以在大型网络中处理RCSP。我们在一组大型实例上经验评估了我们的新算法，并且与文献中最新的RCSP算法相比，表现速度要快得更快。]]></description>
      <guid>https://arxiv.org/abs/2503.11037</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>API代理与GUI代理：分歧和收敛性</title>
      <link>https://arxiv.org/abs/2503.11069</link>
      <description><![CDATA[ARXIV：2503.11069V1公告类型：新 
摘要：大型语言模型（LLMS）已超越简单的文本生成，直接将自然语言命令转化为有形动作的软件代理。尽管基于API的LLM代理最初因其强大的自动化功能以及与程序化端点的无缝集成而引起了人们的关注，但多模式LLM研究的最新进展使基于GUI的LLM Adents以类似人类的方式与图形用户接口相互作用。尽管这两个范式共享了实现LLM驱动的任务自动化的目标，但它们在建筑复杂性，开发工作流程和用户交互模型方面显着分歧。
  本文介绍了基于API和GUI的LLM代理的首次全面比较研究，从系统地分析了它们的差异和潜在的收敛性。我们研究了关键维度，并突出了混合方法可以利用其互补优势的场景。通过提出明确的决策标准并说明实际用例，我们旨在指导从业者和研究人员在这些范式之间选择，结合或过渡。最终，我们指出，基于LLM的自动化的持续创新有望模糊API-和GUI驱动的代理之间的界限，为在广泛的现实世界应用中为更灵活，适应性解决方案铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.11069</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代理方案中的大型推理模型：探索推理能力的必要性</title>
      <link>https://arxiv.org/abs/2503.11074</link>
      <description><![CDATA[ARXIV：2503.11074V1公告类型：新 
摘要：大推理模型（LRMS）的兴起表示向高级计算推理的范式转变。然而，这一进展破坏了传统的代理框架，传统上是由以执行为导向的大语言模型（LLM）锚定的。为了探索这种转变，我们提出了LARMA框架，涵盖了工具使用，计划设计和问题解决方案的九项任务，并通过三个顶级LLM（例如Claude3.5-Sonnet）和五个领先的LRM（例如，DeepSeek-R1）进行了评估。我们的发现解决了四个研究问题：LRMS在推理密集型任务（例如计划设计）中超过LLM，并利用迭代反思来获得出色的结果； LLM在执行驱动的任务（例如工具使用）中表现出色，优先考虑效率；混合LLM-LRM配置，将LLM与LRMS配对为反射器，通过将执行速度与推理深度融合来优化代理性能； LRMS的增强推理会带来更高的计算成本，延长的处理以及行为挑战，包括过度思考和事实命运趋势。这项研究促进了LRMS对深思熟虑和过度思考的平衡的更深入的探究，为未来的代理设计进步奠定了关键的基础。]]></description>
      <guid>https://arxiv.org/abs/2503.11074</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型推理模型能否在感知不确定性下进行类比推理？</title>
      <link>https://arxiv.org/abs/2503.11207</link>
      <description><![CDATA[ARXIV：2503.11207V1公告类型：新 
摘要：这项工作对两个最先进的大推理模型（LRMS），OpenAI的O3-Mini和DeepSeek R1进行了首次评估，对类比推理，重点是基于Raven的渐进式矩阵，侧重于成熟的非语言人类智商测试。我们使用i-raven数据集及其更困难的扩展名I-Raven-X进行了基准测试，该数据集测试了概括为较长的推理规则和属性值范围的能力。为了评估视觉不确定性对这些非语言类似推理测试的影响，我们扩展了I-Raven-X数据集，否则该数据集否则假设了Oracle感知。我们采用了两倍的策略来模拟这种不完美的视觉感知：1）我们介绍了混杂属性，该属性是随机采样的，并不有助于预测拼图的正确答案，而2）平滑输入属性的分布。我们观察到OpenAI的O3-MINI任务准确性急剧下降，从原始I-Raven的86.6％下降到仅17.0％的17.0％ - 接近随机的机会 - 在更具挑战性的I-Raven-X上，这增加了输入长度和范围，并增加了感知的不确定性。尽管花费了3.4倍的推理令牌，但这种下降还是发生了。 DeepSeek R1也观察到类似的趋势：从80.6％到23.2％。另一方面，神经符号概率绑架模型ARLC在I-Raven上实现最先进的表现，可以在所有这些分布式分布测试中坚定地推理出强烈的推理，仅降低了98.6％至88.0％，以保持强大的准确性。我们的代码可从https://github.com/ibm/raven-large-language-models获得。]]></description>
      <guid>https://arxiv.org/abs/2503.11207</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GKG-LLM：通用知识图构造的统一框架</title>
      <link>https://arxiv.org/abs/2503.11227</link>
      <description><![CDATA[ARXIV：2503.11227V1公告类型：新 
摘要：广义知识图（GKG）的构建，包括知识图，事件知识图和常识知识图，对于各种自然语言处理任务至关重要。当前的研究通常分别构建这些类型的图形，忽略了整体见解和潜在统一，这可能对计算资源和使用观点有益。但是，开发GKG统一框架的主要挑战是特定于任务的差异引起的障碍。在这项研究中，我们提出了一个统一的框架，用于构建通用知识图以应对这一挑战。首先，我们从三种类型的图表中收集了29个数据集中的15个子任务的数据，将它们分类为样本中，反任务和分布外（OOD）数据。然后，我们通过将三种类型的图形知识注入大型语言模型，提出一个三阶段的学习微调框架。广泛的实验表明，我们提出的模型改善了跨内域，OOD和反任务数据的所有三种图形类型的构建。]]></description>
      <guid>https://arxiv.org/abs/2503.11227</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您只需要合作：LLM辅助安全代码翻译</title>
      <link>https://arxiv.org/abs/2503.11237</link>
      <description><![CDATA[ARXIV：2503.11237V1公告类型：新 
摘要：本文介绍了Unitranslator，这是一个有远见的框架，该框架重新想象代码翻译为多个紧凑型LLM的协作努力。通过策划专业代理的相互作用，每种都集中在翻译过程的不同方面，并以对编程概念的深入了解，Unitranslator达到了一定程度的准确性和效率，可与更大的单片模型媲美。我们的初步评估表明，Unitranslator的潜力克服了现有方法的局限性，并解锁了较小的LLMS对复杂代码翻译任务的功能。我们探讨了这种动态多机构范式在处理多种语言对（包括低资源语言）中的有效性，以及通过使用自然语言推断（NLI）基础和迭代反馈机制来缓解常见问题，例如代码文物和幻觉]]></description>
      <guid>https://arxiv.org/abs/2503.11237</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化大型语言模型，以检测合并症抑郁症或慢性疾病焦虑的症状：来自患者消息的见解</title>
      <link>https://arxiv.org/abs/2503.11384</link>
      <description><![CDATA[ARXIV：2503.11384V1公告类型：新 
摘要：糖尿病患者的合并症抑郁症或焦虑症的风险增加，使他们的管理复杂化。这项研究评估了从安全的患者信息中检测这些症状的大型语言模型（LLM）的表现。我们采用了多种方法，包括工程提示，系统性角色，温度调整以及零射门和几乎没有射击学习，以确定表现最佳的模型并增强性能。五个LLM中的三个表现出色（超过90％的F-1和准确性），Llama 3.1 405B在F-1中均达到93％，并且使用零击方法获得了精度。尽管LLM在二元分类和处理复杂指标（如患者健康问卷4）中表现出希望，但在挑战案件中的不一致需要进一步的现实生活评估。这些发现凸显了LLMS协助及时筛查和推荐的潜力，为现实世界中的分类系统提供了宝贵的经验知识，这些知识可以改善慢性疾病患者的心理保健。]]></description>
      <guid>https://arxiv.org/abs/2503.11384</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过主动学习和最大似然估计的多目标组合优化的偏好启发</title>
      <link>https://arxiv.org/abs/2503.11435</link>
      <description><![CDATA[ARXIV：2503.11435V1公告类型：新 
摘要：现实生活中的组合优化问题通常涉及几个相互矛盾的目标，例如价格，产品质量和可持续性。解决多个目标的计算效率方法是将它们汇总为单目标函数，例如线性组合。但是，定义线性组合的权重很难。另外，使用交互式学习方法要求用户比较候选解决方案是非常有希望的。关键挑战是快速生成候选人，学习导致高质量解决方案的目标功能，并在几乎没有用户交互的情况下这样做。我们建立在建设性的偏好启发框架的基础上，并展示如何改善这三个属性中的每一个：为了提高使用（放松）解决方案的池进行研究的相互作用速度，以改善学习的学习，我们采用了Bradley-Terry偏好模型的最大似然估计；为了减少用户交互的数量，我们选择了一对候选人，以与主动学习灵感的基于合奏的采集功能进行比较。我们仔细的实验​​证明了这些改进中的每一个：在PC配置任务和现实的多实体路由问题上，我们的方法选择查询速度更快，需要更少的查询并合成更高质量的组合解决方案，而不是以前的CPE方法。]]></description>
      <guid>https://arxiv.org/abs/2503.11435</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将LLM集成在游戏系统中</title>
      <link>https://arxiv.org/abs/2503.11458</link>
      <description><![CDATA[ARXIV：2503.11458V1公告类型：新 
摘要：在这项工作中，提出了将大型语言模型（LLM）纳入游戏系统的彻底数学框架，重点是改善任务动态，用户参与度和奖励系统。个性化的反馈，自适应学习和动态内容创建都可以通过集成LLM来使其成为可能，并且对于改善用户参与和系统性能至关重要。模拟的环境测试了该框架的适应性，并证明了其在包括商业，医疗保健和教育在内的各个行业中现实世界应用的潜力。研究结果表明，LLMS如何提供定制的体验，以提高系统效率和用户的保留。这项研究还研究了该框架旨在解决的困难，强调了其在最大化参与和鼓励一系列部门的持续行为改变方面的重要性。]]></description>
      <guid>https://arxiv.org/abs/2503.11458</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>异质因果发现反复的不良健康结果</title>
      <link>https://arxiv.org/abs/2503.11477</link>
      <description><![CDATA[ARXIV：2503.11477V1公告类型：新 
摘要：了解触发或预防患者亚群中不良健康结果的因素对于设计有针对性的干预措施至关重要。尽管随机对照试验和专家主导的患者访谈是确定这些因素的标准方法，但它们可能是耗时且不可行的。因果发现通过从观察数据中产生因果假设来提供传统方法的替代方法。但是，它通常依赖于强烈或无法测试的假设，这可能会限制其实际应用。这项工作旨在通过考虑多个假设并确定异质效应来使因果发现更加实用。我们提出了发现结果的原因和效应修饰符的问题，其中效应修饰符是具有异质因果效应的上下文（例如年龄组）。然后，我们提出了一个新颖的端到端框架，该框架结合了因果发现算法的集合以及对异质效应的估计，以发现触发或抑制结果的原因和效应修饰符。我们证明，合奏方法通过增强因果因素的回忆，同时保持精确度，从而提高了鲁棒性。我们的研究研究了糖尿病患者重复急诊室就诊的原因和ICU患者的医院再入院。我们的框架产生了与现有文献一致的因果假设，并可以帮助从业者确定潜在的干预措施和患者的亚群。]]></description>
      <guid>https://arxiv.org/abs/2503.11477</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过AI多代理NLP框架进行迅速注射检测和缓解</title>
      <link>https://arxiv.org/abs/2503.11517</link>
      <description><![CDATA[ARXIV：2503.11517V1公告类型：新 
摘要：通过引起意外产出，迅速注射对生成AI系统构成了重大挑战。我们介绍了一个多代理NLP框架，专门设计，旨在通过分层检测和执行机制来解决快速注射漏洞。该框架策划了专门的代理，以产生响应，消毒产出和执行政策合规性。对500次工程注射提示的评估表明，注射成功和政策违规显着降低。提出了新的指标，包括注入成功率（ISR），策略覆盖频率（POF），及时的消毒率（PSR）和合规性一致性评分（CCS），以得出复合的总注射脆弱性评分（TIV）。该系统利用Ovon（开放语音网络）框架通过结构化的JSON消息进行代理间通信，从而将先前建立的多代理体系结构从幻觉缓解范围扩展，以应对快速注射的独特挑战。]]></description>
      <guid>https://arxiv.org/abs/2503.11517</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩大您的范围！使用语义空间为LLM的有效的多转交谈计划</title>
      <link>https://arxiv.org/abs/2503.11586</link>
      <description><![CDATA[ARXIV：2503.11586V1公告类型：新 
摘要：聊天机器人或AI助手中使用大型语言模型（LLM）与人类用户进行对话。在这样的应用中，对话的质量（例如，用户参与，安全性）很重要，只有在对话结束时才能完全知道。为了最大程度地提高其预期质量，会话计划的原因有关对话中随机过渡，以在每个回合中选择最佳的LLM响应。现有的基于仿真的对话计划算法通常通过在各个转弯中使用大量LLM查询模拟未来的对话来选择最佳响应。但是，这个过程非常耗时，因此对于实时对话而言是不切实际的。本文介绍了一种新颖的方法，称为语义太空对话计划，并提高了效率（范围），从而利用了对话的密集语义表示以有效地执行对话计划。特别是，范围对话语义中的随机过渡及其相关的奖励，以完全计划语义空间。这使我们能够在每个对话转向时选择最佳的LLM响应，而无需其他LLM查询进行仿真。结果，当应用于现实世界中看到的各种对话启动器和两个奖励功能时，范围可以比传统的基于基于模拟的计划算法快70倍，但在实践计划预算中获得了更高的奖励。我们的代码可以在以下网址找到：https：//github.com/chenzhiliang94/convo-plan-scope。]]></description>
      <guid>https://arxiv.org/abs/2503.11586</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过脉冲响应增强，设备射击场景分类</title>
      <link>https://arxiv.org/abs/2305.07499</link>
      <description><![CDATA[ARXIV：2305.07499V2公告类型：交叉 
摘要：概括到广泛的记录设备的能力是音频分类模型的关键性能因素。不同类型的麦克风的特征由于其不同的频率响应而引入了数字化音频信号的分布变化。如果在训练过程中未考虑此域移位，则该模型的性能可能会严重降低，因为它将其应用于未见设备记录的信号。特别是，训练模型对用少数不同麦克风记录的音频信号进行训练可能会使不看到的设备变得困难。为了解决这个问题，我们在训练集中使用预录制的设备脉冲响应（DIRS）进行音频信号，以人为地增加录制设备的多样性。我们系统地研究了使用CNN和音频频谱变压器的DIR增强对声学场景分类任务的影响。结果表明，隔离的DIR扩展与最先进的方法FREQ-MIXSTYLE相似。但是，我们还表明，Dir Exmentation和Freq-Mixstyle是互补的，在培训期间看不见的设备记录的信号上实现了新的最新性能。]]></description>
      <guid>https://arxiv.org/abs/2305.07499</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>