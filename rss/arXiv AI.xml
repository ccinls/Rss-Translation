<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>评估医疗保健应用中数字推理任务中大型语言模型的计算准确性</title>
      <link>https://arxiv.org/abs/2501.13936</link>
      <description><![CDATA[arXiv:2501.13936v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为医疗保健领域的变革性工具，在自然语言理解和生成方面表现出卓越的能力。然而，它们在数字推理方面的能力，特别是在临床应用等高风险领域，仍未得到充分探索。数值推理在医疗保健应用中至关重要，影响患者结果、治疗计划和资源分配。本研究调查了 LLM 在医疗保健环境中的数字推理任务中的计算准确性。使用 1,000 个数值问题的精选数据集，涵盖剂量计算和实验室结果解释等现实场景，评估了基于 GPT-3 架构的精炼 LLM 的性能。该方法包括快速工程、事实核查管道的集成以及正则化技术的应用，以提高模型的准确性和泛化能力。使用精度、召回率和 F1 分数等关键指标来评估模型的有效性。结果表明，总体准确率为 84.10%，在简单的数字任务和多步骤推理挑战中的表现都有所提高。事实核查流程的集成将准确率提高了 11%，凸显了验证机制的重要性。这项研究强调了 LLM 在医疗保健数字推理方面的潜力，并确定了进一步改进的途径，以支持临床环境中的关键决策。研究结果旨在促进开发可靠、可解释且与上下文相关的医疗保健 AI 工具。]]></description>
      <guid>https://arxiv.org/abs/2501.13936</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的蒙特卡洛树搜索，用于缓解大型模型中的幻觉</title>
      <link>https://arxiv.org/abs/2501.13942</link>
      <description><![CDATA[arXiv:2501.13942v1 Announce Type: new 
摘要：随着人工智能领域大模型的快速发展，如何增强其在科研领域处理复杂问题的应用能力仍然是一个有待解决的具有挑战性的问题。本研究提出了一种基于提示词的改进蒙特卡洛树搜索（MCTS）方法，在模拟搜索阶段引入探索参数的动态调整和自适应选择策略，可以更好地平衡探索和开发，从而减少幻觉现象。本文以SciEval数据集的四个子集为测试对象，将Glm-4-flash+Improved MCTS方法与几种现有模型的方法进行了比较，结果表明Improved MCTS方法表现更佳，为大模型在科研领域的应用提供了新的思路和方法。]]></description>
      <guid>https://arxiv.org/abs/2501.13942</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人机协同影响人工智能辅助决策的效用</title>
      <link>https://arxiv.org/abs/2501.14035</link>
      <description><![CDATA[arXiv:2501.14035v1 公告类型：新
摘要：每当使用 AI 模型预测 AI 辅助决策中的相关（二元）结果时，人们普遍认为，模型应该与每个预测一起提供 AI 置信度值。然而，目前尚不清楚为什么决策者往往难以形成良好的判断力，何时应该信任使用 AI 置信度值的预测。最近，Corvelo Benz 和 Gomez Rodriguez 认为，对于理性的决策者来说，AI 辅助决策的效用本质上受到 AI 置信度值与决策者对自己预测的信心之间的一致程度的限制。在这项工作中，我们通过实证研究了一致程度在多大程度上实际上影响了 AI 辅助决策的效用。为此，我们设计并运行了一项大规模的人类受试者研究（n=703），参与者在具有可控一致度的 AI 模型的帮助下解决一个简单的决策任务——在线纸牌游戏。我们的结果表明，一致性程度与 AI 辅助决策的效用之间存在正相关关系。此外，我们的结果还表明，对 AI 置信度值进行后处理以实现与参与者对自己预测的信心相关的多重校准，可以同时提高一致性程度和 AI 辅助决策的效用。]]></description>
      <guid>https://arxiv.org/abs/2501.14035</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多模式基础模型的分布式多智能体协调</title>
      <link>https://arxiv.org/abs/2501.14189</link>
      <description><![CDATA[arXiv:2501.14189v1 公告类型：新
摘要：分布式约束优化问题 (DCOP) 为多智能体协调提供了强大的框架，但通常依赖于劳动密集型的手动问题构建。为了解决这个问题，我们引入了 VL-DCOP，这是一个利用大型多模态基础模型 (LFM) 自动从视觉和语言指令生成约束的框架。然后，我们介绍了一系列用于解决 VL-DCOP 的代理原型：从将一些算法决策委托给 LFM 的神经符号代理，到完全依赖 LFM 进行协调的完全神经代理。我们使用最先进的 LLM（大型语言模型）和 VLM（视觉语言模型）在三个新颖的 VL-DCOP 任务上评估这些代理原型，并比较它们各自的优缺点。最后，我们讨论了这项工作如何扩展到 DCOP 文献中更广泛的前沿挑战。]]></description>
      <guid>https://arxiv.org/abs/2501.14189</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代理神经图数据库面临的十大挑战</title>
      <link>https://arxiv.org/abs/2501.14224</link>
      <description><![CDATA[arXiv:2501.14224v1 公告类型：新
摘要：Neo4j 和 TigerGraph 等图形数据库 (GDB) 擅长处理互连数据，但缺乏高级推理能力。神经图形数据库 (NGDB) 通过集成图形神经网络 (GNN) 对不完整或嘈杂数据进行预测分析和推理来解决此问题。然而，NGDB 依赖于预定义的查询，缺乏自主性和适应性。本文介绍了 Agentic 神经图形数据库 (Agentic NGDB)，它通过三个核心功能扩展了 NGDB：自主查询构建、神经查询执行和持续学习。我们确定了实现 Agentic NGDB 的十大关键挑战：语义单元表示、溯因推理、可扩展查询执行以及与大型语言模型 (LLM) 等基础模型的集成。通过应对这些挑战，Agentic NGDB 可以为现代数据驱动的应用程序提供智能、自我改进的系统，为适应性强、自主的数据管理解决方案铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2501.14224</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>快速图谱思考：知识图谱上大型语言模型更广泛、更深、更快的推理</title>
      <link>https://arxiv.org/abs/2501.14300</link>
      <description><![CDATA[arXiv:2501.14300v1 公告类型：新
摘要：图检索增强生成 (GRAG) 是一种新颖的范式，它通过将图信息（例如知识图谱 (KG)）集成到大规模语言模型 (LLM) 中以减轻幻觉，从而使朴素的 RAG 系统更进一步。然而，现有的 GRAG 仍然遇到限制：1) 由于从 KG 捕获的相关性狭窄且浅显，简单的范式通常无法解决复杂的问题 2) 如果图很密集，与 KG 强耦合的方法往往计算成本高且耗时。在本文中，我们提出了快速图谱思考 (FastToG)，这是一种创新范式，可使 LLM 能够在 KG 中“逐个社区”地思考。为此，FastToG 采用社区检测来更深入地捕获相关性，并采用两阶段社区修剪 - 粗剪和细剪以实现更快的检索。此外，我们还开发了两种社区到文本的方法，将社区的图结构转换为文本形式，以便 LLM 更好地理解。实验结果证明了 FastToG 的有效性，与之前的研究相比，它具有更高的准确性、更快的推理速度和更好的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2501.14300</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MASTER：具有 LLM 专门 MCTS 的多智能体系统</title>
      <link>https://arxiv.org/abs/2501.14304</link>
      <description><![CDATA[arXiv:2501.14304v1 公告类型：新 
摘要：大型语言模型 (LLM) 越来越多地被用于解决问题。然而，它们的战略规划能力往往受到怀疑。最近的研究结合了蒙特卡洛树搜索 (MCTS) 算法来增强 LLM 的规划能力。尽管 MCTS 具有潜力，但它依赖于广泛的抽样模拟来近似真实的奖励分布，这导致了两个主要问题。首先，MCTS 对于围棋等任务很有效，其中模拟结果可以产生客观奖励（例如，获胜为 1，失败为 0）。然而，对于问答等任务，模拟的结果就是问题的答案，如果没有基本事实，就无法获得客观奖励。其次，获得具有统计意义的奖励估计通常需要超过 30 次模拟的样本量，从而导致过多的 token 使用和时间消耗。为了应对这些挑战，我们提出了使用 LLM 专用 MCTS (MASTER) 进行战术执行和推理的多智能体系统，这是一种使用 LLM 专用 MCTS 协调智能体招募和通信的新型框架。该系统根据任务复杂性自动调整智能体数量，并确保智能体之间进行有针对性的通信。在各种任务中进行的综合实验证明了我们提出的框架的有效性。它在 HotpotQA 上的准确率达到 76%，在 WebShop 上的准确率达到 80%，在这些数据集上创下了新的最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2501.14304</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索人工智能困境的可持续扩展：企业人工智能环境影响的投射研究</title>
      <link>https://arxiv.org/abs/2501.14334</link>
      <description><![CDATA[arXiv:2501.14334v1 公告类型：新
摘要：人工智能（AI），尤其是大型语言模型（LLM）的快速发展引发了人们对其全球环境影响的担忧，这种影响不仅限于温室气体排放，还包括对硬件制造和报废过程的考虑。主要供应商的不透明性阻碍了公司评估其与人工智能相关的环境影响和实现净零目标的能力。在本文中，我们提出了一种方法来估计公司人工智能产品组合对环境的影响，提供可行的见解，而无需广泛的人工智能和生命周期评估（LCA）专业知识。结果证实，大型生成人工智能模型比传统模型消耗的能量高达 4600 倍。我们的建模方法考虑了人工智能使用率的提高、硬件计算效率以及与 IPCC 情景一致的电力结构变化，预测到 2030 年人工智能的用电量。在高采用率情景下，受生成式人工智能和与日益复杂的模型和框架相关的代理的广泛采用推动，人工智能用电量预计将增加 24.4 倍。到 2030 年减轻生成式人工智能对环境的影响需要整个人工智能价值链的协调努力。仅在硬件效率、模型效率或电网改进方面采取孤立措施是不够的。我们提倡标准化的环境评估框架、提高价值链所有参与者的透明度以及引入“环境回报”指标，以使人工智能发展与净零目标保持一致。]]></description>
      <guid>https://arxiv.org/abs/2501.14334</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们信任系统对齐！通过投影可解释对齐</title>
      <link>https://arxiv.org/abs/2501.14360</link>
      <description><![CDATA[arXiv:2501.14360v1 公告类型：新
摘要：对齐是一种众所周知的流程挖掘技术，用于协调系统日志和规范流程模型。实际系统中某些行为的证据可能仅存在于一种表示形式中 - 日志或模型 - 而不存在于另一种表示形式中。由于对于涉及多个实体（如对象和资源）的流程，它们的交互会影响行为，因此在对齐中必须考虑这些交互。
此外，记录和建模的现实表示可能不精确，并且仅部分代表其中一些实体，但不是全部。在本文中，我们通过对齐投影引入了“放松”的概念，以处理部分正确的模型和日志。放松对齐有助于区分两种表示形式（日志和模型）的可信和不可信内容，以更好地理解底层流程并揭示质量问题。]]></description>
      <guid>https://arxiv.org/abs/2501.14360</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VERUS-LM：将法学硕士与符号推理相结合的多功能框架</title>
      <link>https://arxiv.org/abs/2501.14540</link>
      <description><![CDATA[arXiv:2501.14540v1 公告类型：新
摘要：神经符号推理的最新方法是明确结合大型语言模型 (LLM) 和符号求解器的优势来解决复杂的推理任务。然而，当前的方法面临着重大的局限性，包括由于任务特定的提示导致的通用性差、由于知识和查询之间缺乏分离而导致的效率低下以及推理能力受限。这些缺点阻碍了它们在不同领域的可扩展性和适用性。在本文中，我们介绍了 VERUS-LM，这是一个旨在应对这些挑战的新框架。VERUS-LM 采用通用提示机制，将领域知识与查询明确分开，并支持各种不同的逻辑推理任务。该框架增强了适应性，降低了计算成本，并允许更丰富的推理形式，例如优化和约束满足。我们表明，我们的方法在新的数据集上成功进行了多样化推理，明显优于 LLM。此外，与其他最先进的方法相比，我们的系统在常见推理基准上取得了有竞争力的结果，并在困难的 AR-LSAT 数据集上明显超越了它们。通过突破混合推理的界限，VERUS-LM 代表着朝着更通用的神经符号 AI 系统迈出了重要一步]]></description>
      <guid>https://arxiv.org/abs/2501.14540</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合量子-经典多智能体寻路</title>
      <link>https://arxiv.org/abs/2501.14568</link>
      <description><![CDATA[arXiv:2501.14568v1 公告类型：新
摘要：多智能体路径查找 (MAPF) 专注于确定多个智能体在共享空间中导航以到达指定目标位置的无冲突路径。这个问题在计算上具有挑战性，特别是在处理大量智能体时，这在协调自动驾驶汽车等实际应用中经常遇到。量子计算 (QC) 是克服这种限制的有希望的候选者。然而，目前的量子硬件仍处于起步阶段，因此在计算能力和错误鲁棒性方面受到限制。在这项工作中，我们提出了第一个基于分支切割奖励的最优混合量子经典 MAPF 算法。QC 是通过基于冲突图迭代解决 QUBO 问题来集成的。在实际量子硬件上的实验和基准数据上的结果表明，我们的方法优于以前的 QUBO 公式和基线 MAPF 求解器。]]></description>
      <guid>https://arxiv.org/abs/2501.14568</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 提取问题结构以优化 SAT 局部搜索</title>
      <link>https://arxiv.org/abs/2501.14630</link>
      <description><![CDATA[arXiv:2501.14630v1 公告类型：新
摘要：本地搜索预处理通过提供高质量的起点使冲突驱动子句学习 (CDCL) 求解器更快，现代 SAT 求解器已将这种技术纳入其预处理步骤中。然而，这些工具依赖于基本策略，而这些策略会忽略问题中的结构模式。我们提出了一种应用大型语言模型 (LLM) 来分析基于 Python 的编码代码的方法。这揭示了问题如何转换为 SAT 的隐藏结构模式。我们的方法会自动生成专门的本地搜索算法，找到这些模式并使用它们来创建强大的初始分配。这适用于来自相同编码类型的任何问题实例。我们的测试显示了令人鼓舞的结果，与基线预处理系统相比，解决了更快的问题。]]></description>
      <guid>https://arxiv.org/abs/2501.14630</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐可行的策略：将分析框架与决策启发式相结合的语义方法</title>
      <link>https://arxiv.org/abs/2501.14634</link>
      <description><![CDATA[arXiv:2501.14634v1 公告类型：新
摘要：我们提出了一种通过语义分析将战略框架与决策启发式相结合来推荐可行战略的新方法。虽然战略框架为评估和规划提供了系统模型，而决策启发式则编码了经验知识，但这些传统在历史上一直是分开的。我们的方法使用先进的自然语言处理 (NLP) 弥补了这一差距，通过将 6C 模型与三十六计等框架相结合来证明这一点。该方法采用向量空间表示和语义相似性计算将框架参数映射到启发式模式，并由结合深度语义处理和大型语言模型的受限使用的计算架构支持。通过将主要内容和次要元素（图表、矩阵）作为互补的语言表示来处理，我们通过企业战略案例研究证明了其有效性。该方法推广到各种分析框架和启发式集，最终形成一种即插即用架构，用于生成推荐系统，从而将战略框架和决策启发式方法紧密结合，形成可操作的指导。]]></description>
      <guid>https://arxiv.org/abs/2501.14634</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GaussMark：语言模型结构水印的实用方法</title>
      <link>https://arxiv.org/abs/2501.13941</link>
      <description><![CDATA[arXiv:2501.13941v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展已导致自然语言处理任务的显着改进，但它们生成人类质量文本的能力在需要识别给定文本是否由人类生成的环境中引发了重大的道德和操作问题。 因此，最近的工作重点是开发用于 LLM 生成的文本水印的技术，即引入几乎不可察觉的信号，使配备密钥的提供者能够确定给定的文本是否由他们的模型生成。 当前的水印技术通常不实用，因为担心生成延迟、检测时间、文本质量下降或鲁棒性。 这些缺点中的许多来自于对标记级水印的关注，而这忽略了文本的固有结构。在本研究中，我们引入了一种新方案 GaussMark，该方案实施起来简单高效，具有正式的统计保证，不会影响生成延迟，并将水印嵌入模型本身的权重中，从而提供结构化水印。我们的方法基于高斯独立性测试，并受到最近的经验观察的启发，即 LLM 权重的轻微附加损坏可能会导致模型质量相同（甚至更高）。我们表明，通过在给定 LLM 的权重中添加少量高斯噪声，我们可以以一种可由保留密钥的提供者统计检测到的方式对模型进行水印。我们为程序的有效性和功效提供了正式的统计界限。通过一系列广泛的实验，我们证明了 GaussMark 可靠、高效，并且对插入、删除、替换和往返翻译等损坏具有相对强的鲁棒性，并且可以在基本不损失模型质量的情况下实例化。]]></description>
      <guid>https://arxiv.org/abs/2501.13941</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言表征有利于零样本跨领域认知诊断</title>
      <link>https://arxiv.org/abs/2501.13943</link>
      <description><![CDATA[arXiv:2501.13943v1 公告类型：交叉 
摘要：认知诊断旨在根据学生的历史反应日志推断他们的掌握水平。然而，现有的依赖于 ID 嵌入的认知诊断模型 (CDM) 通常必须在特定领域训练特定模型。这种限制可能会阻碍它们在各种目标领域的直接实际应用，例如不同的学科（例如数学、英语和物理）或不同的教育平台（例如 ASSISTments、Junyi Academy 和 Khan Academy）。为了解决这个问题，本文提出了语言表示偏爱的零样本跨领域认知诊断 (LRCD)。具体来说，LRCD 首先分析学生、练习和概念在不同领域的行为模式，然后使用文本描述来描述学生、练习和概念的概况。通过最近的高级文本嵌入模块，这些概况可以转换为统一语言空间中的向量。此外，为了解决语言空间和认知诊断空间之间的差异，我们在 LRCD 中提出了语言认知映射器来学习从前者到后者的映射。然后，这些配置文件可以轻松高效地与现有的 CDM 集成和训练。大量实验表明，在真实世界数据集上训练 LRCD 可以在不同目标域上实现值得称赞的零样本性能，在某些情况下，它甚至可以实现与在目标域上的完整响应数据上训练的一些经典 CDM 相媲美的性能。值得注意的是，我们惊讶地发现 LRCD 还可以提供对不同学科（如人文和科学）和来源（如小学和中学教育）之间差异的有趣见解。]]></description>
      <guid>https://arxiv.org/abs/2501.13943</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Fanar：以阿拉伯语为中心的多模态生成 AI 平台</title>
      <link>https://arxiv.org/abs/2501.13944</link>
      <description><![CDATA[arXiv:2501.13944v1 公告类型：交叉 
摘要：我们介绍了 Fanar，这是一个以阿拉伯语为中心的多模态生成 AI 系统平台，支持语言、语音和图像生成任务。Fanar 的核心是 Fanar Star 和 Fanar Prime，这两个功能强大的阿拉伯语大型语言模型 (LLM) 在同类模型的成熟基准中名列前茅。Fanar Star 是一个 7B（十亿）参数模型，从头开始训练近 1 万亿个干净且去重的阿拉伯语、英语和代码标记。Fanar Prime 是一个 9B 参数模型，在相同的 1 万亿个标记集上持续训练 Gemma-2 9B 基础模型。这两个模型同时部署，旨在通过定制的编排器透明地解决不同类型的提示。 Fanar 平台还提供许多其他功能，包括用于处理宗教提示的定制伊斯兰检索增强生成 (RAG) 系统、用于总结预训练数据截止日期后发生的当前或近期事件信息的 Recency RAG。该平台提供额外的认知功能，包括支持多种阿拉伯方言的内部双语语音识别、经过微调以更好地反映区域特征的语音和图像生成。最后，Fanar 提供归因服务，可用于验证基于事实的生成内容的真实性。
Fanar 的设计、开发和实施完全由哈马德·本·哈利法大学的卡塔尔计算研究所 (QCRI) 进行，并由卡塔尔通信和信息技术部赞助，以支持自主 AI 技术开发。]]></description>
      <guid>https://arxiv.org/abs/2501.13944</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社交 AI 代理中的自我解释</title>
      <link>https://arxiv.org/abs/2501.13945</link>
      <description><![CDATA[arXiv:2501.13945v1 公告类型：交叉 
摘要：社交 AI 代理与社区成员互动，从而改变社区的行为。例如，在在线学习中，AI 社交助手可以连接学习者，从而增强社交互动。这些社交 AI 助手也需要解释自己，以增强透明度和与学习者的信任。我们提出了一种自我解释的方法，该方法使用对 AI 社交助手的自我模型进行自省。自我模型被视为一个功能模型，该模型指定代理的方法如何使用知识来完成其任务。生成自我解释的过程使用思想链来反思自我模型，并使用 ChatGPT 来提供有关其功能的解释。我们评估 AI 社交助手的自我解释的完整性和正确性。我们还报告了它在现场课堂上的部署情况。]]></description>
      <guid>https://arxiv.org/abs/2501.13945</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Agentic AI 基于自然语言的框架缓解幻觉</title>
      <link>https://arxiv.org/abs/2501.13946</link>
      <description><![CDATA[arXiv:2501.13946v1 公告类型：交叉 
摘要：幻觉仍然是当前生成式 AI 模型面临的重大挑战，它破坏了人们对 AI 系统及其可靠性的信任。本研究调查了如何协调多个专门的人工智能代理来帮助缓解这种幻觉，重点是利用自然语言处理 (NLP) 促进无缝代理交互的系统。为了实现这一点，我们设计了一个管道，将三百多个专门设计用于诱发幻觉的提示引入前端代理。然后，第二级和第三级代理系统地审查和完善输出，每个代理都采用不同的大型语言模型和量身定制的策略来检测未经证实的声明、纳入明确的免责声明和澄清推测内容。此外，我们引入了一组专门用于评估幻觉评分水平的新关键绩效指标 (KPI)。专门的第四级 AI 代理用于评估这些 KPI，提供详细的评估并确保准确量化幻觉相关行为的变化。这项研究的核心部分是使用 OVON（开放语音网络）框架，该框架依赖于通用的基于 NLP 的接口在代理之间传输上下文信息。通过结构化的 JSON 消息，每个代理传达其对幻觉可能性的评估以及可疑内容背后的原因，从而使后续阶段能够在不丢失上下文的情况下完善文本。结果表明，使用能够通过基于 NLP 的代理框架相互交互的多个专门代理可以在缓解幻觉方面取得有希望的结果，最终增强人工智能社区内的信任。]]></description>
      <guid>https://arxiv.org/abs/2501.13946</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型与基于知识的方法相结合的综合调查</title>
      <link>https://arxiv.org/abs/2501.13947</link>
      <description><![CDATA[arXiv:2501.13947v1 公告类型：交叉 
摘要：人工智能的快速发展为该领域带来了实质性的进步。一个有希望的方向是将大型语言模型 (LLM) 与结构化知识系统相结合。这种方法旨在通过将 LLM 的生成语言理解与结构化系统的精确知识表示相结合来增强 AI 能力。本调查探讨了 LLM 与知识库之间的协同作用，重点关注现实世界的应用并解决相关的技术、操作和道德挑战。通过全面的文献综述，该研究确定了关键问题并评估了现有的解决方案。本文强调了将生成 AI 与知识库相结合的好处，包括改进数据情境化、提高模型准确性和更好地利用知识资源。研究结果详细概述了当前的研究状况，确定了关键差距并提出了可行的建议。这些见解有助于推进人工智能技术并支持它们在各个领域的实际部署。]]></description>
      <guid>https://arxiv.org/abs/2501.13947</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 对好莱坞电影对话进行纵向滥用和情感分析</title>
      <link>https://arxiv.org/abs/2501.13948</link>
      <description><![CDATA[arXiv:2501.13948v1 公告类型：交叉 
摘要：在过去的几十年里，人们越来越担心好莱坞电影中辱骂和暴力内容的普遍性。本研究使用大型语言模型 (LLM) 探索 1950 年至 2024 年好莱坞奥斯卡和大片电影对话的纵向辱骂和情感分析。通过使用微调的 LLM，我们分析了分为四种类型的一千多部电影的字幕，以研究过去七十年情感和辱骂内容的趋势和变化。我们的研究结果揭示了电影对话的重大时间变化，反映了更广泛的社会和文化影响。总体而言，电影中的情感倾向是多种多样的，对辱骂内容的检测也表现出显着的波动。结果显示，近几十年来辱骂内容逐渐增加，反映了社会规范和监管政策的变化。惊悚片等类型仍然呈现出更高的辱骂内容频率，强调了暴力和冲突的持续叙事作用。与此同时，大部分电影中仍充斥着幽默、乐观等积极情绪。此外，过去二十年，电影对白中的辱骂性内容逐渐增多，奥斯卡提名电影取代了十大卖座大片。]]></description>
      <guid>https://arxiv.org/abs/2501.13948</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>