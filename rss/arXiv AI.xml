<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>可解释人工智能研究综述</title>
      <link>https://arxiv.org/abs/2407.17484</link>
      <description><![CDATA[arXiv:2407.17484v1 公告类型：交叉 
摘要：人工智能 (AI) 越来越多地融入日常生活，因此必须以一种所有用户（包括残障人士）都能理解的方式来解释基于人工智能的决策。无障碍解释至关重要，因为技术的无障碍促进了数字包容性，并允许每个人，无论其身体、感官或认知能力如何，都能有效地使用这些技术。本文对可解释人工智能 (XAI) 可访问性的研究进行了系统的文献综述，特别考虑了视力丧失的人。我们的方法包括使用搜索词搜索多个学术数据库，以捕捉 XAI 和可访问性之间的交集。本次调查的结果突出了对无障碍 XAI (AXAI) 研究的缺乏，并强调了将残疾人群体纳入 XAI 开发以促进数字包容性和可访问性并消除障碍的重要性。大多数 XAI 技术依赖于视觉解释，例如热图或图表，而盲人或视力低下的人无法访问这些解释。因此，有必要通过非视觉方式开发解释方法，例如听觉和触觉反馈、视力低下人士可以使用的视觉方式以及满足个人（包括多重残疾者）需求的个性化解决方案。我们进一步强调将通用设计原则融入人工智能开发实践的重要性，以确保每个人都能使用人工智能技术。]]></description>
      <guid>https://arxiv.org/abs/2407.17484</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:03 GMT</pubDate>
    </item>
    <item>
      <title>人机团队中的集体注意力</title>
      <link>https://arxiv.org/abs/2407.17489</link>
      <description><![CDATA[arXiv:2407.17489v1 公告类型：交叉 
摘要：AI 助手的存在如何影响团队的集体注意力？我们研究了 20 个由 3-4 人组成的人类团队，这些团队在完成一项具有挑战性的拼图任务时与一名仅使用语音的 AI 助手配对。团队被随机分配给一个 AI 助手，该助手的声音听起来像人类或机器人，提供有关任务的有用或误导性信息。将每个单独的 AI 感叹词视为治疗干预，我们确定了 AI 对涉及语言使用的动态群体过程的因果影响。我们的研究结果表明，AI 显著影响团队讨论的内容、讨论方式以及他们的心理模型的一致性。团队采用 AI 引入的语言来描述与任务直接相关的术语和外围术语，即使他们 (a) 认识到 AI 的无用性质，(b) 不认为 AI 是真正的团队成员，以及 (c) 不信任 AI。尽管对 AI 的能力存在怀疑，但语言适应的过程似乎是自动的。人工智能助手的存在会通过调节共享认知的各个方面显著影响团队集体注意力。这项研究强调集体注意力是团队环境中人工智能系统影响团队绩效的核心机制，为人机协作研究做出了贡献。了解这一机制将有助于 CSCW 研究人员设计人工智能系统，通过优化集体注意力来增强团队集体智慧。]]></description>
      <guid>https://arxiv.org/abs/2407.17489</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:03 GMT</pubDate>
    </item>
    <item>
      <title>LLM4PM：在企业组织中使用大型语言模型进行流程建模的案例研究</title>
      <link>https://arxiv.org/abs/2407.17478</link>
      <description><![CDATA[arXiv:2407.17478v1 公告类型：交叉 
摘要：我们研究使用大型语言模型 (LLM) 支持组织环境中的流程模型创建的潜力。具体来说，我们进行了一项案例研究，其中我们在跨国公司 Hilti Group 开发和测试了基于 LLM 的聊天机器人 PRODIGY（PROcess moDellIng Guidance for You）。我们特别感兴趣的是了解 LLM 如何帮助（人类）建模者创建流程流程图。为此，我们首先与来自 Hilti 的专业流程建模者进行初步用户研究（n=10），询问他们在日常工作中遇到的各种痛点。然后，我们使用他们的回答来设计和实施 PRODIGY。最后，我们通过让用户研究的参与者使用 PRODIGY 来评估 PRODIGY，然后询问他们对 PRODIGY 优缺点的看法。我们将结果汇总为可操作的要点。通过我们的研究，我们展示了 LLM 在现实世界中流程建模的第一个实际应用，阐明了行业如何利用 LLM 来增强其业务流程管理活动。]]></description>
      <guid>https://arxiv.org/abs/2407.17478</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:02 GMT</pubDate>
    </item>
    <item>
      <title>通用近似理论：基于深度学习的计算机视觉模型的基本理论</title>
      <link>https://arxiv.org/abs/2407.17480</link>
      <description><![CDATA[arXiv:2407.17480v1 公告类型：交叉 
摘要：计算机视觉（CV）是人工智能中最重要的领域之一。近年来，各种基于卷积神经网络（CNN）和Transformer的深度学习模型被设计出来以解决CV中的各种问题。这些算法已经在机器人和面部识别等领域找到了实际应用。尽管目前的CV模型的威力越来越大，但仍有几个基本问​​题尚未解决：为什么CNN需要深层？什么保证了CNN的泛化能力？为什么基于残差的网络比VGG等全卷积网络表现更好？基于残差的CNN和基于Transformer的网络之间的根本区别是什么？为什么CNN可以利用LoRA和剪枝技术？这些问题的根本原因在于CV中的深度学习模型缺乏坚实的理论基础。为了解决这些关键问题和技术，我们利用通用近似定理 (UAT) 为 CV 中的卷积和基于 Transformer 的模型提供理论基础。通过这样做，我们旨在从理论角度阐明这些问题。]]></description>
      <guid>https://arxiv.org/abs/2407.17480</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:02 GMT</pubDate>
    </item>
    <item>
      <title>从人类反馈中进行强化学习：谁的文化、谁的价值观、谁的观点？</title>
      <link>https://arxiv.org/abs/2407.17482</link>
      <description><![CDATA[arXiv:2407.17482v1 公告类型：交叉 
摘要：我们主张在大型语言模型 (LLM) 背景下的强化学习人类反馈 (RLHF) 中多元化的认知和伦理优势。借鉴社会认识论和多元科学哲学，我们提出了使 RHLF 更能满足人类需求的方法，以及我们如何应对这一过程中的挑战。本文最后提出了一项变革议程，即改进 LLM 发展的具体、可操作的步骤。]]></description>
      <guid>https://arxiv.org/abs/2407.17482</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:02 GMT</pubDate>
    </item>
    <item>
      <title>“我的女人”：通过平均理论和欧盟法律分析人工智能中的性别刻板印象</title>
      <link>https://arxiv.org/abs/2407.17474</link>
      <description><![CDATA[arXiv:2407.17474v1 公告类型：交叉 
摘要：本研究深入研究了性别分类系统，揭示了社会刻板印象与算法决定之间的相互作用。借鉴“平均理论”，该理论表明面部吸引力与人类确定其性别的能力之间存在关系，我们探索了人类偏见在人工智能 (AI) 系统中的潜在传播。利用 AI 模型 Stable Diffusion 2.1，我们创建了一个包含各种吸引力内涵的数据集，以测试在人类认知中观察到的吸引力与性别分类准确性之间的相关性是否在 AI 中持续存在。我们的研究结果表明，与人类动态类似，AI 系统根据吸引力表现出性别分类准确性的变化，反映了其算法决策中的社会偏见和刻板印象。这一发现强调了考虑人类感知对数据收集的影响的迫切需要，并强调了采用多学科和交叉方法进行 AI 开发和 AI 数据训练的必要性。通过结合认知心理学和女权主义法律理论，我们研究了在《人工智能法案》和《GDPR》的范围内，用于人工智能训练的数据如何促进性别多样性和公平性，重申了心理学和女权主义法律理论如何为确保人工智能系统中性别平等和非歧视的保护提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.17474</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:01 GMT</pubDate>
    </item>
    <item>
      <title>一种检测 CodeWorkout 数据集异常提交的方法</title>
      <link>https://arxiv.org/abs/2407.17475</link>
      <description><![CDATA[arXiv:2407.17475v1 公告类型：交叉 
摘要：学生在学习环境中解决问题时的互动（即日志数据）通常用于支持学生学习。例如，研究人员使用日志数据开发系统，可以根据学生的知识水平为他们提供个性化的问题建议。然而，学生日志数据中的异常，例如作弊解决编程问题，可能会在日志数据中引入隐藏的偏差。因此，这些系统可能会提供不准确的问题建议，从而达不到目的。经典的作弊检测方法，如 MOSS，可用于检测代码抄袭。然而，这些方法无法检测到其他异常事件，例如学生在系统中多次尝试对特定编程问题进行类似的解决方案。本文提出了一项初步研究，以分析带有异常的日志数据。我们工作的目标是在编程学习环境中建模可个性化建议时克服异常情况。]]></description>
      <guid>https://arxiv.org/abs/2407.17475</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:01 GMT</pubDate>
    </item>
    <item>
      <title>ORCDF：在线教育系统中学生学习的抗过度平滑认知诊断框架</title>
      <link>https://arxiv.org/abs/2407.17476</link>
      <description><![CDATA[arXiv:2407.17476v1 公告类型：交叉 
摘要：认知诊断模型（CDM）旨在利用学生的反应日志来了解他们的掌握水平。CDM 在在线教育系统中起着重要作用，因为它们对教师指导和计算机化自适应测试等下游应用有重大影响。尽管现有的 CDM 取得了成功，但我们发现它们存在一个棘手的问题，即学习到的学生掌握水平太相似。这个问题，我们称之为过度平滑，可能会降低 CDM 在下游任务中的有效性。CDM 包括两个核心部分：学习学生的掌握水平和通过拟合响应日志来评估掌握水平。本文认为过度平滑问题源于现有的 CDM 很少在学习部分的练习中使用响应信号，而只在评估部分将其用作标签。为此，本文提出了一个抗过度平滑的认知诊断框架 (ORCDF)，通过在学习部分利用响应信号来增强现有的 CDM。具体而言，ORCDF 引入了一种新颖的响应图，将响应信号固有地合并为边的类型。然后，ORCDF 设计了一个定制的响应感知图卷积网络 (RGC)，可以有效地捕获响应图中的关键响应信号。通过 ORCDF，现有的 CDM 得到增强，方法是用 RGC 的结果替换输入嵌入，从而允许在学习部分考虑练习上的响应信号。在真实数据集上进行的大量实验表明，ORCDF 不仅可以帮助现有的 CDM 缓解过度平滑问题，而且还显着提高了模型的预测和可解释性性能。此外，ORCDF 的有效性在计算机化自适应测试的下游任务中得到了验证。]]></description>
      <guid>https://arxiv.org/abs/2407.17476</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:01 GMT</pubDate>
    </item>
    <item>
      <title>基于 Shapley 值的对比对齐用于多模态信息提取</title>
      <link>https://arxiv.org/abs/2407.17854</link>
      <description><![CDATA[arXiv:2407.17854v1 公告类型：新
摘要：社交媒体的兴起和多模态通信的迅猛增长需要先进的多模态信息提取 (MIE) 技术。然而，现有的方法主要依赖于直接的图像-文本交互，这种范式由于图像和文本之间的语义和模态差距而经常面临重大挑战。在本文中，我们介绍了一种新的图像-上下文-文本交互范式，其中利用大型多模态模型 (LMM) 来生成描述性文本上下文以弥合这些差距。根据这一范式，我们提出了一种基于 Shapley 值的新型对比对齐 (Shap-CA) 方法，该方法可以对齐上下文-文本和上下文-图像对。Shap-CA 最初应用合作博弈论中的 Shapley 值概念来评估上下文、文本和图像集合中每个元素对总语义和模态重叠的个体贡献。在进行定量评估之后，我们采用对比学习策略来增强上下文-文本/图像对中的交互贡献，同时最小化这些对之间的影响。此外，我们设计了一个自适应融合模块，用于选择性跨模态融合。在四个 MIE 数据集上进行的大量实验表明，我们的方法明显优于现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2407.17854</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 Tseitin-Awareness 修剪布尔 d-DNNF 电路</title>
      <link>https://arxiv.org/abs/2407.17951</link>
      <description><![CDATA[arXiv:2407.17951v1 公告类型：新
摘要：d-DNNF 形式的布尔电路可实现易处理的概率推理。然而，作为这项工作的一个关键见解，我们表明常用的 d-DNNF 编译方法引入了不相关的子电路。我们将这些子电路称为 Tseitin 伪影，因为它们是由于 Tseitin 转换步骤引入的——这是一种成熟的程序，可将任何电路转换为几个 d-DNNF 知识编译器所需的 CNF 格式。我们讨论了如何检测和删除 Tseitin 变量和 Tseitin 伪影，从而产生更简洁的电路。我们通过经验观察到，当同时删除 Tseitin 变量和伪影时，平均尺寸减少了 77.5%。Tseitin 伪影的额外修剪平均将尺寸减少了 22.2%。这显著改善了受益于更简洁的电路的下游任务，例如概率推理任务。]]></description>
      <guid>https://arxiv.org/abs/2407.17951</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:00 GMT</pubDate>
    </item>
    <item>
      <title>边缘辅助车辆的个性化和情境感知路线规划</title>
      <link>https://arxiv.org/abs/2407.17980</link>
      <description><![CDATA[arXiv:2407.17980v1 公告类型：新
摘要：传统的路线规划服务通常为所有驾驶员提供相同的路线，主要关注一些标准化因素，例如行驶距离或时间，而忽略了驾驶员的个人偏好。随着未来几年自动驾驶汽车的出现，车辆将依赖于此类规划人员决定的路线，因此需要结合每位驾驶员的特定偏好，确保个性化的导航体验。在这项工作中，我们提出了一种基于图神经网络 (GNN) 和深度强化学习 (DRL) 的新方法，旨在定制适合个人偏好的路线。通过分析个人驾驶员的历史轨迹，我们对他们的驾驶行为进行分类，并将其与相关道路属性相关联，作为驾驶员偏好的指标。GNN 能够有效地将道路网络表示为图形结构数据，而 DRL 能够利用奖励机制做出决策，以优化路线选择，并考虑旅行成本、拥堵程度和驾驶员满意度等因素。我们使用现实世界的道路网络评估了我们提出的基于 GNN 的 DRL 框架，并展示了其适应驾驶员偏好的能力，为每位驾驶员提供了一系列量身定制的路线选择。结果表明，与通用路线规划器相比，我们的框架可以选择适合驾驶员偏好的路线，效率最高可提高 17%，并且与基于最短距离的方法相比，可将行程时间缩短 33%（下午）和 46%（晚上）。]]></description>
      <guid>https://arxiv.org/abs/2407.17980</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:00 GMT</pubDate>
    </item>
    <item>
      <title>流畅的师生红队合作</title>
      <link>https://arxiv.org/abs/2407.17447</link>
      <description><![CDATA[arXiv:2407.17447v1 公告类型：交叉 
摘要：许多公开可用的语言模型都经过了安全调整，以降低出现有毒或引起责任的文本的可能性。用户或安全分析师试图通过对抗性提示来越狱或红队这些模型，从而导致遵守请求。一种攻击方法是将离散优化技术应用于提示。然而，产生的攻击字符串通常是乱码文本，由于测量的困惑度高，很容易被防御者过滤，并且可能在看不见的任务和/或调整良好的模型上失败。在这项工作中，我们改进了现有的算法（主要是 GCG 和 BEAST），以开发对 Llama-2 和 Phi-3 等安全调整模型的强大而流畅的攻击。我们的技术围绕一种新的基于蒸馏的方法，该方法鼓励受害者模型模拟有毒的微调，无论是在输出概率方面还是在内部激活方面。为了鼓励人类流畅攻击，我们在目标中添加了多模型困惑度惩罚和重复惩罚。我们还通过允许插入令牌、交换令牌和删除令牌以及使用更长的攻击序列来增强优化器强度。由此产生的过程能够使用与人类编写的提示类似的提示可靠地越狱最困难的目标模型。在 Advbench 上，我们对 Llama-2-7B、Llama-3-8B 和 Vicuna-7B 的攻击成功率达到 $&gt;93$%，同时保持模型测量的困惑度 $&lt;33$；我们对 Phi-3 的攻击成功率为 $95$%，尽管困惑度更高。我们还发现了一个通用优化的单一流畅提示，它在 Llama-2-7B、Phi-3-mini 和 Vicuna-7B 上对以前未见过的任务产生了 $&gt;88$% 的合规性，并转移到其他黑盒模型。]]></description>
      <guid>https://arxiv.org/abs/2407.17447</guid>
      <pubDate>Fri, 26 Jul 2024 06:29:00 GMT</pubDate>
    </item>
    <item>
      <title>通过世界动态建模增强代理学习</title>
      <link>https://arxiv.org/abs/2407.17695</link>
      <description><![CDATA[arXiv:2407.17695v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 越来越多地应用于语言理解和交互式决策任务，但它们令人印象深刻的表现很大程度上归功于其中嵌入的全面而深入的领域知识。然而，这种知识的程度在不同的领域可能有所不同。现有的方法通常假设 LLM 已经拥有对其环境的全面而深入的了解，而忽略了它们对实际世界动态的理解中的潜在差距。为了解决这一差距，我们引入了发现、验证和进化 (DiVE)，这是一个框架，它可以从少量演示中发现世界动态，验证这些动态的正确性，并根据当前情况开发新的、先进的动态。通过广泛的评估，我们分析了每个组件对性能的影响，并将 DiVE 自动生成的动态与人类注释的世界动态进行比较。我们的结果表明，由 DiVE 指导的 LLM 可以做出更好的决策，在 Crafter 环境中获得与人类玩家相当的回报。]]></description>
      <guid>https://arxiv.org/abs/2407.17695</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>病理学视觉和语言分析的经济高效的教学学习</title>
      <link>https://arxiv.org/abs/2407.17734</link>
      <description><![CDATA[arXiv:2407.17734v1 公告类型：新
摘要：视觉语言模型的出现促进了人工智能模型与人类之间的互动对话。然而，将这些模型应用于临床必须应对大规模训练数据、财务和计算资源方面的艰巨挑战。在这里，我们提出了一种经济高效的对话病理学教学学习框架，称为 CLOVER。CLOVER 仅训练轻量级模块并使用指令调整，同时冻结大型语言模型的参数。我们没有使用昂贵的 GPT-4，而是在 GPT-3.5 上提出了精心设计的提示来构建基于生成的指令，强调了从互联网源获得的病理知识的实用性。为了增加指令的使用，我们在数字病理学的背景下构建了一组高质量的基于模板的指令。从两个基准数据集中，我们的研究结果揭示了混合形式指令在病理学视觉问答中的强度。大量结果表明，CLOVER 在回答开放式和封闭式问题时都具有成本效益，其中 CLOVER 的表现优于拥有 37 倍训练参数并使用 GPT-4 生成的指令数据的强大基线。通过指令调整，CLOVER 在外部临床数据集中表现出少量学习的稳健性。这些发现表明，CLOVER 的经济高效建模可以加速快速对话应用程序在数字病理学领域的采用。]]></description>
      <guid>https://arxiv.org/abs/2407.17734</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>研究人工神经网络中独立于学习的抽象推理</title>
      <link>https://arxiv.org/abs/2407.17791</link>
      <description><![CDATA[arXiv:2407.17791v1 公告类型：新
摘要：人类能够解决复杂的抽象推理测试。这种能力是否反映了一种适用于任何新奇未学问题的独立于学习的推理机制，或者它是否是一生中大量训练的表现，这还是一个悬而未决的问题。在人类中解决这个问题具有挑战性，因为不可能控制他们之前的训练。然而，假设人工神经网络 (ANN) 和人类的认知处理相似，ANN 的抽象推理所需的训练程度对于人类的这个问题很有启发。先前的研究表明，ANN 可以解决抽象推理测试。然而，这种成功需要大量的训练。在这项研究中，我们研究了 ANN 独立于学习的抽象推理。具体来说，我们在没有任何预训练的情况下评估了它们的性能，ANN 的权重是随机初始化的，并且只在解决问题的过程中发生变化。我们发现，简单的 ANN 模型可以解决非平凡的视觉推理测试，类似于用于评估人类学习独立推理的测试。我们进一步研究了支持这种能力的机制。我们的结果表明，独立于学习的抽象推理是可能的，不需要大量训练。]]></description>
      <guid>https://arxiv.org/abs/2407.17791</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>网约车平台的长期公平性</title>
      <link>https://arxiv.org/abs/2407.17839</link>
      <description><![CDATA[arXiv:2407.17839v1 公告类型：新
摘要：网约车等双边市场中的匹配最近受到了广泛关注。然而，现有的网约车研究主要侧重于优化效率，而忽视了网约车中的公平性问题。网约车中的公平性问题，包括司机之间的显著收入差异和不同地点乘客等待时间的差异，对经济和道德方面都有潜在影响。最近关注网约车公平性的研究利用传统的优化方法和马尔可夫决策过程来平衡效率和公平性。然而，这些现有研究中存在一些问题，例如传统优化的短期决策短视以及传统优化和基于马尔可夫决策过程的方法在相对较长的时间内不稳定性。为了解决这些问题，我们提出了一个动态马尔可夫决策过程模型来缓解网约车目前面临的公平性问题，并在效率和公平之间寻求平衡，该模型具有两个独特的特点：（i）预测模块，用于预测未来从不同位置提出的请求数量，以允许所提出的方法基于整个时间线考虑长期公平性，而不是仅基于历史和当前数据模式考虑公平性；（ii）针对多目标多智能体 Q 学习的定制标量化函数，旨在平衡效率和公平性。在公开可用的真实世界数据集上进行的大量实验表明，我们提出的方法优于现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2407.17839</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>基于行动阶段聚类的驾驶模式解释</title>
      <link>https://arxiv.org/abs/2407.17518</link>
      <description><![CDATA[arXiv:2407.17518v1 公告类型：新 
摘要：当前识别驾驶异质性的方法面临着从潜在驾驶行为机制的角度理解基本模式的挑战。我们之前的工作提出了行动阶段的概念，它捕捉了具有物理意义的驾驶特征的多样性。本研究提出了一个新颖的框架，通过无监督的方式对行动阶段进行分类，进一步解释驾驶模式。在这个框架中，首先应用重采样和下采样方法 (RDM) 来标准化行动阶段的长度。然后迭代应用聚类校准程序，包括“特征选择”、“聚类分析”、“差异/相似性评估”和“行动阶段重新提取”，直到所有聚类之间的差异和聚类内的相似性都达到预定标准。将该框架应用于真实世界数据集后，发现 I80 数据集中有六种驾驶模式，分别标记为“追赶”、“保持距离”和“保持距离”，同时具有“稳定”和“不稳定”状态。值得注意的是，不稳定模式比稳定模式更多。在稳定模式中，“保持距离”是最常见的。这些观察结果与驾驶的动态性质相符。US101 数据集中缺少两种模式“稳定保持距离”和“不稳定追赶”，这符合我们的预期，因为之前显示该数据集的异质性较低。这表明驾驶模式在描述驾驶异质性方面的潜力。所提出的框架有望在解决监督学习中的标签稀缺问题和增强驾驶行为建模和驾驶轨迹预测等任务方面发挥优势。]]></description>
      <guid>https://arxiv.org/abs/2407.17518</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:58 GMT</pubDate>
    </item>
    <item>
      <title>绘制技术未来：社交媒体话语中的话题、情绪和情感分析</title>
      <link>https://arxiv.org/abs/2407.17522</link>
      <description><![CDATA[arXiv:2407.17522v1 公告类型：新
摘要：目前，全世界的人们都面临着许多技术挑战，这些挑战是不确定性的重要来源。社交媒体广泛讨论了技术（例如人工智能）的波动性和不可预测性及其潜在后果所带来的不确定性。这项研究使用 BERTopic 建模以及对 2021 年至 2023 年 150 万条推文的情绪和情感分析来识别预期的技术驱动未来，并捕捉 400 位关键意见领袖 (KOL) 传达的情感。研究结果表明，积极情绪明显超过消极情绪，积极的预期情绪占主导地位。具体而言，“希望”得分比“焦虑”得分中位数高出约 10.33%。KOL 强调“乐观”和好处，而不是“悲观”和挑战。该研究强调了在技术不确定时期，KOL 通过预期话语和情感基调塑造未来愿景所发挥的重要作用。]]></description>
      <guid>https://arxiv.org/abs/2407.17522</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:58 GMT</pubDate>
    </item>
    <item>
      <title>LAMBDA：基于大型模型的数据代理</title>
      <link>https://arxiv.org/abs/2407.17535</link>
      <description><![CDATA[arXiv:2407.17535v1 公告类型：新
摘要：我们推出了“LAMBDA”，这是一种新颖的开源、无代码的多代理数据分析系统，它利用了大型模型的强大功能。LAMBDA 旨在通过使用创新设计的数据代理来解决复杂数据驱动应用程序中的数据分析挑战，这些代理使用自然语言进行迭代和生成操作。LAMBDA 的核心是两个关键代理角色：程序员和检查员，它们被设计为无缝协作。具体来说，程序员根据用户的指令和特定领域的知识生成代码，并通过高级模型进行增强。同时，检查员会在必要时调试代码。为了确保稳健性和处理不利情况，LAMBDA 具有一个用户界面，允许用户直接干预操作循环。此外，LAMBDA 可以通过我们的知识集成机制灵活地集成外部模型和算法，满足定制数据分析的需求。LAMBDA 在各种机器学习数据集上都表现出色。它有潜力通过无缝集成人类和人工智能来增强数据科学实践和分析范式，使其对来自不同背景的个人来说更容易获得、更有效、更高效。LAMBDA 在解决数据科学问题方面的强大性能在几个案例研究中得到了证明，这些案例研究在 \url{https://www.polyu.edu.hk/ama/cmfai/lambda.html} 中进行了介绍。]]></description>
      <guid>https://arxiv.org/abs/2407.17535</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:58 GMT</pubDate>
    </item>
    <item>
      <title>多智能体动态认知系统的过程代数框架</title>
      <link>https://arxiv.org/abs/2407.17537</link>
      <description><![CDATA[arXiv:2407.17537v1 公告类型：新
摘要：本文将经典的标记转换系统模型与知识推理的认知模型相结合。结果是一个用于建模和分析多代理、基于知识的动态系统的统一框架。在建模方面，我们提出了一种过程代数、面向代理的规范语言，使这种框架易于用于实际目的。在验证方面，我们定义了一个包含时间和认知运算符的模态逻辑。]]></description>
      <guid>https://arxiv.org/abs/2407.17537</guid>
      <pubDate>Fri, 26 Jul 2024 06:28:58 GMT</pubDate>
    </item>
    </channel>
</rss>