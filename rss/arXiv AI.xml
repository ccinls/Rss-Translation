<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 05 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>TradExpert：通过专家法学硕士的混合来革新交易</title>
      <link>https://arxiv.org/abs/2411.00782</link>
      <description><![CDATA[arXiv:2411.00782v1 公告类型：新
摘要：人工智能 (AI) 在金融领域的整合为量化交易开辟了新途径，特别是通过使用大型语言模型 (LLM)。然而，有效地综合来自不同数据源的见解并整合结构化和非结构化数据的挑战仍然存在。本文介绍了 TradeExpert，这是一个采用混合专家 (MoE) 方法的新框架，使用四个专门的 LLM，每个 LLM 分析不同的财务数据来源，包括新闻文章、市场数据、alpha 因子和基本数据。这些专家 LLM 的见解由通用专家 LLM 进一步综合，以做出最终的预测或决策。通过特定提示，TradeExpert 可以在预测模式和排名模式之间切换，分别用于股票走势预测和量化股票交易。除了现有的基准之外，我们还发布了一个大型金融数据集，以全面评估 TradeExpert 的有效性。我们的实验结果表明 TradeExpert 在所有交易场景中都表现出色。]]></description>
      <guid>https://arxiv.org/abs/2411.00782</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于直觉模糊集的模式识别中证据可靠性评估</title>
      <link>https://arxiv.org/abs/2411.00848</link>
      <description><![CDATA[arXiv:2411.00848v1 Announce Type: new 
摘要：确定证据源的可靠性是 Dempster-Shafer 理论 (DST) 中的一个重要课题。先前的方法使用折扣方法解决了证据源之间的高冲突问题，但这些方法可能无法确保分类模型的高效率。在本文中，我们考虑 DS 理论和直觉模糊集 (IFS) 的结合，并提出一种量化证据源可靠性的算法，称为模糊可靠性指数 (FRI)。FRI 算法基于从 IFS 派生的决策量化规则，定义不同 BPA 对正确决策的贡献，并从这些贡献中得出证据可靠性。所提出的方法有效地增强了证据源可靠性估计的合理性，使其特别适用于复杂场景中的分类决策问题。随后与基于 DST 的算法和经典机器学习算法的比较证明了 FRI 算法的优越性和通用性。 FRI算法为未来决策概率转换、证据源可靠性分析提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2411.00848</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半强解：引领计算机完美游戏的新定义</title>
      <link>https://arxiv.org/abs/2411.01029</link>
      <description><![CDATA[arXiv:2411.01029v1 公告类型：新
摘要：解决组合游戏一直是人工智能领域的经典研究课题，因为解决方案可以提供改进游戏玩法的重要信息。对于“解决游戏”存在几种定义，但它们在计算成本和得出的见解的细节方面存在明显差异。在本研究中，我们引入了一个称为“半强解”的新定义，并提出了一种有效实现此类解决方案的算法。由于其中等计算成本和解决方案的质量，这个新定义解决了现有的差距。为了展示我们方法的潜力，我们在简单条件下推导出我们算法的理论计算复杂度，并将其应用于半强解 6x6 Othello 游戏。这项研究提出了该研究领域的许多新研究目标。]]></description>
      <guid>https://arxiv.org/abs/2411.01029</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于规则的语言模型安全奖励</title>
      <link>https://arxiv.org/abs/2411.01111</link>
      <description><![CDATA[arXiv:2411.01111v1 公告类型：新
摘要：基于强化学习的大型语言模型 (LLM) 根据人类偏好进行微调已被证明可以增强其能力和安全行为。然而，在与安全相关的情况下，如果没有对人类注释者的精确指示，收集的数据可能会导致模型变得过于谨慎，或以不良方式做出反应，例如判断性反应。此外，随着模型能力和使用模式的发展，可能需要花费高昂的成本来添加或重新标记数据以修改安全行为。我们提出了一种新颖的偏好建模方法，该方法利用人工智能反馈，只需要少量的人类数据。我们的方法，基于规则的奖励 (RBR)，使用一组规则来表示期望或不期望的行为（例如，拒绝不应带有判断性）以及 LLM 评分器。与之前使用 AI 反馈的方法相比，我们的方法在 RL 训练中直接使用细粒度、可组合、LLM 分级的少量提示作为奖励，从而提高控制力、准确性和更新的便利性。我们表明，RBR 是一种有效的训练方法，其 F1 得分为 97.1，而人类反馈基线为 91.7，通过更好地平衡实用性和安全性，可以大大提高安全行为的准确性。]]></description>
      <guid>https://arxiv.org/abs/2411.01111</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>初级代理：一款集成工具、逻辑驱动且具有经济高效 API 使用的代理</title>
      <link>https://arxiv.org/abs/2411.01114</link>
      <description><![CDATA[arXiv:2411.01114v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 具有令人印象深刻的功能，但它们目前表现出两个主要限制，\textbf{\uppercase\expandafter{\romannumeral 1}}：它们难以\textbf{自主解决现实世界的工程问题}。 \textbf{\uppercase\expandafter{\romannumeral 2}}：它们仍然\textbf{在通过复杂的逻辑问题进行推理方面面临挑战}。为了应对这些挑战，我们开发了\textsc{Infant Agent}，集成了任务感知功能、运算符、分层管理系统和内存检索机制。这些组件共同使大型语言模型能够维持扩展的推理过程并有效处理复杂的多步骤任务，同时显著降低 API 成本。使用 \textsc{Infant Agent}，GPT-4o 在 SWE-bench-lite 数据集上的准确率从 $\mathbf{0.33\%}$ 上升到 $\mathbf{30\%}$，而在 AIME-2024 数学竞赛中，它将 GPT-4o 的准确率从 $\mathbf{13.3\%}$ 提升到 $\mathbf{37\%}$。]]></description>
      <guid>https://arxiv.org/abs/2411.01114</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态大型语言模型的推理局限性。Bongard 问题案例研究</title>
      <link>https://arxiv.org/abs/2411.01173</link>
      <description><![CDATA[arXiv:2411.01173v1 公告类型：新
摘要：抽象视觉推理 (AVR) 包含一系列任务，其解决需要能够通过类比过程发现图片集背后的共同概念，类似于人类智商测试。1968 年提出的 Bongard 问题 (BP) 构成了该领域的一项基本挑战，主要是因为它们需要结合视觉推理和口头描述。这项工作提出了一个问题：本质上设计用于结合视觉和语言的多模态大型语言模型 (MLLM) 是否能够解决 BP。为此，我们提出了一套适用于 MLLM 的多种策略来解决 BP 问题，并研究了四种流行的专有 MLLM：GPT-4o、GPT-4 Turbo、Gemini 1.5 Pro 和 Claude 3.5 Sonnet，以及四种开放模型：InternVL2-8B、LLaVa-1.6 Mistral-7B、Phi-3.5-Vision 和 Pixtral 12B。在三个 BP 数据集上比较了上述 MLLM：一组依赖于合成的、基于几何的图像的原始 BP 实例和两个基于真实世界图像的最新数据集，即 Bongard-HOI 和 Bongard-OpenWorld。实验揭示了 MLLM 在解决 BP 问题方面存在重大局限性。特别是，尽管这些模型在视觉上很简单，但它们很难解决经典的合成 BP 集。尽管它们在 Bongard-HOI 和 Bongard-OpenWorld 中表达的现实世界概念上的表现有所改善，但这些模型仍然难以利用新信息来改进其预测，以及有效地利用对话上下文窗口。为了捕捉合成和现实世界 AVR 领域之间性能差异的原因，我们提出了 Bongard-RWR，这是一个由现实世界图像组成的新 BP 数据集，可将概念从手工制作的合成 BP 转换为现实世界概念。MLLM 在 Bongard-RWR 上的结果表明，它们在经典 BP 上的表现不佳不是由于领域特异性，而是反映了它们普遍的 AVR 局限性。]]></description>
      <guid>https://arxiv.org/abs/2411.01173</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过具有逻辑奖励塑造的分层框架指导多智能体多任务强化学习</title>
      <link>https://arxiv.org/abs/2411.01184</link>
      <description><![CDATA[arXiv:2411.01184v1 公告类型：新
摘要：多智能体分层强化学习（MAHRL）已被研究作为解决复杂和大规模环境中的智能决策问题的有效手段。然而，目前大多数MAHRL算法遵循强化学习中使用奖励函数的传统方式，这限制了它们在单个任务中的使用。本研究旨在设计一种具有逻辑奖励塑造（LRS）的多智能体合作算法，该算法使用更灵活的奖励设置方式，允许有效完成多任务。LRS使用线性时间逻辑（LTL）来表达复杂任务中子任务的内部逻辑关系。然后，它根据设计的奖励结构评估LTL表达式的子公式是否得到满足。这有助于代理通过遵守LTL表达式来学习有效地完成任务，从而提高其决策的可解释性和可信度。为了增强多个代理之间的协调与合作，设计了一种价值迭代技术来评估每个代理采取的行动。在此评估的基础上，形成一个用于协调的奖励函数，使每个智能体能够评估自己的状态，并通过经验学习完成剩余的子任务。在类似 Minecraft 的环境中对各种类型的任务进行了实验。结果表明，所提出的算法可以提高多智能体在学习完成多任务时的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.01184</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高制造业的能源效率：一种新颖的专家系统外壳</title>
      <link>https://arxiv.org/abs/2411.01272</link>
      <description><![CDATA[arXiv:2411.01272v1 公告类型：新
摘要：专家系统是自动识别制造业能源效率潜力的有效工具，从而对全球气候目标做出重大贡献。这些系统分析能源数据，查明效率低下之处，并推荐优化措施以降低能源消耗。除了开发专家系统的系统方法之外，还迫切需要简单快速的软件实施解决方案。专家系统外壳有助于快速开发和部署专家系统，是此过程中的关键工具。它们提供了一个模板，简化了专家系统的创建和集成到现有制造流程中的过程。本文对现有专家系统外壳在提高能源效率方面的适用性进行了全面比较，强调了重大差距和局限性。为了解决这些不足之处，我们引入了一个在 Jupyter Notebook 中实现的新型专家系统外壳，它为专家系统开发提供了灵活且易于集成的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.01272</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>差异图中的因果推理</title>
      <link>https://arxiv.org/abs/2411.01292</link>
      <description><![CDATA[arXiv:2411.01292v1 公告类型：新
摘要：在流行病学中，了解不同人群的因果机制对于设计有效的公共卫生干预措施至关重要。最近，差异图已被引入作为一种工具，以直观地表示两个不同人群之间的因果变化。虽然通过因果发现方法从数据中推断这些图表已经取得了进展，但在系统地利用其潜力增强因果推理方面仍然存在差距。本文通过建立使用差异图和观察数据识别因果变化和影响的条件来解决这一差距。它特别侧重于在非参数框架中识别总因果变化和总效应，以及在线性环境中识别直接因果变化和直接效应。通过这样做，它提供了一种新颖的因果推理方法，对各种公共卫生应用都有潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.01292</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不断发展的多智能体交互系统的在线关系推理</title>
      <link>https://arxiv.org/abs/2411.01442</link>
      <description><![CDATA[arXiv:2411.01442v1 公告类型：新
摘要：我们引入了一个新颖的框架，即在线关系推理 (ORI)，旨在使用流数据有效地识别不断发展的多智能体交互系统中的隐藏交互图。与依赖固定训练集的传统离线方法不同，ORI 采用在线反向传播，使用每个新数据点更新模型，从而使其能够实时适应不断变化的环境。一项关键创新是使用邻接矩阵作为可训练参数，通过一种名为 AdaRelation 的新自适应学习率技术进行优化，该技术根据解码器对交互图变化的历史敏感度进行调整。此外，引入了一种名为 Trajectory Mirror (TM) 的数据增强方法，通过将模型暴露于不同的轨迹模式来提高泛化能力。在合成数据集和真实世界数据（用于人体运动的 CMU MoCap）上的实验结果表明，与现有方法相比，ORI 显着提高了动态设置中关系推理的准确性和适应性。这种方法与模型无关，能够与各种神经关系推理 (NRI) 架构无缝集成，并为复杂不断发展的系统中实时应用提供强大的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.01442</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可辨别性驱动的强化学习中目标选择的多样性进展</title>
      <link>https://arxiv.org/abs/2411.01521</link>
      <description><![CDATA[arXiv:2411.01521v1 公告类型：新
摘要：非均匀目标选择有可能比均匀随机选择提高技能的强化学习 (RL)。在本文中，我们介绍了一种在内在动机目标条件 RL 中学习目标选择策略的方法：“多样性进步”（DP）。学习者根据观察到的可辨别性在其目标集上的改进来制定课程。我们提出的方法适用于可辨别性激励的代理类，其中内在奖励是根据代理遵循所追求的真正目标的确定性来计算的。这种奖励可以激励代理学习一组不同的技能，而无需外在奖励。我们通过经验证明，DP 激励的代理可以比以前的方法更快地学习一组可区分的技能，并且不会遭受目标分布崩溃的影响——这是一些先前方法的已知问题。最后，我们制定了继续推进这一概念验证的计划。]]></description>
      <guid>https://arxiv.org/abs/2411.01521</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DELE：演绎 $\mathcal{EL}^{++} \thinspace $ 嵌入用于知识库补全</title>
      <link>https://arxiv.org/abs/2411.01574</link>
      <description><![CDATA[arXiv:2411.01574v1 公告类型：新
摘要：本体嵌入将本体中的类、关系和个体映射到 $\mathbb{R}^n$，并且在 $\mathbb{R}^n$ 内可以计算实体之间的相似性或推断新的公理。对于描述逻辑 $\mathcal{EL}^{++}$ 中的本体，已经开发了几种嵌入方法，可以明确生成本体的模型。然而，这些方法存在一些局限性；它们没有区分不可证明和可证明错误的陈述，因此它们可能使用蕴涵陈述作为否定。此外，它们不利用本体的演绎闭包来识别推断但未断言的陈述。我们评估了一组用于 $\mathcal{EL}^{++}$ 本体的嵌入方法，并结合了旨在利用本体演绎闭包的几种修改。具体来说，我们设计了新颖的负损失，既考虑了演绎闭包，又考虑了不同类型的负损失，并制定了知识库完成的评估方法。我们证明了我们的嵌入方法比知识库或本体完成任务中的基线本体嵌入有所改进。]]></description>
      <guid>https://arxiv.org/abs/2411.01574</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行本体填充</title>
      <link>https://arxiv.org/abs/2411.01612</link>
      <description><![CDATA[arXiv:2411.01612v1 公告类型：新
摘要：知识图谱 (KG) 越来越多地用于数据集成、表示和可视化。虽然 KG 人口至关重要，但成本往往很高，尤其是当必须从自然语言的非结构化文本中提取数据时，这会带来诸如歧义和复杂解释等挑战。大型语言模型 (LLM) 为此类任务提供了有希望的功能，在自然语言理解和内容生成方面表现出色。然而，它们的“幻觉”倾向会产生不准确的输出。尽管存在这些限制，但 LLM 可以快速且可扩展地处理自然语言数据，并且通过及时的工程和微调，它们可以在提取和构造 KG 数据方面达到接近人类水平的性能。本研究调查了 LLM 对 KG 人口的有效性，重点关注 Enslaved.org Hub 本体。在本文中，我们报告说，与基本事实相比，当在提示中提供模块化本体作为指导时，LLM 可以提取约 90％ 的三元组。]]></description>
      <guid>https://arxiv.org/abs/2411.01612</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EcoAct：经济主体决定何时登记什么行动</title>
      <link>https://arxiv.org/abs/2411.01643</link>
      <description><![CDATA[arXiv:2411.01643v1 公告类型：新
摘要：最近的进展使大型语言模型 (LLM) 能够充当代理，可以使用外部工具执行操作。这需要在采取行动之前注册，即将工具信息集成到 LLM 上下文中。当前的方法不加区分地将所有候选工具合并到代理的上下文中，并在多个推理步骤中保留它们。这个过程对 LLM 代理来说仍然是不透明的，并且没有集成到它们的推理过程中，导致由于不相关工具增加上下文长度而导致效率低下。为了解决这个问题，我们引入了 EcoAct，这是一种使用算法的工具，允许 LLM 根据需要有选择地注册工具，从而优化上下文使用。通过将工具注册过程集成到推理过程中，EcoAct 在保持性能的同时，在多步骤推理任务中将计算成本降低了 50% 以上，这已通过大量实验得到证明。此外，只需对提示进行少量修改，它就可以插入任何推理管道，使其现在和将来都适用于 LLM 代理。]]></description>
      <guid>https://arxiv.org/abs/2411.01643</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>向前思考与向后思考：使用大型语言模型进行有效的向后规划</title>
      <link>https://arxiv.org/abs/2411.01790</link>
      <description><![CDATA[arXiv:2411.01790v1 公告类型：新
摘要：大型语言模型 (LLM) 表现出卓越的推理和规划能力。该领域的大多数先前工作都使用 LLM 来推理从初始状态到目标状态或标准的步骤，从而有效地向前推理。尽管如此，许多规划问题都表现出固有的不对称性，因此从目标向后规划要容易得多——例如，如果存在接近目标的瓶颈。我们从这一观察中获得灵感，并证明这种偏见也适用于 LLM 规划：一个方向的规划性能与该方向问题的规划复杂性相关。然而，我们的实验也揭示了系统性偏见，导致向后规划不佳。有了这些知识，我们提出了一种 LLM 的向后规划算法，该算法首先翻转问题，然后在翻转的问题中向前规划。这有助于避免后向偏差，生成更加多样化的候选计划，并利用规划问题中前向和后向之间的不对称性——我们发现将双向规划与自我验证相结合可以将三个规划领域的总体规划成功率提高 4-24%。]]></description>
      <guid>https://arxiv.org/abs/2411.01790</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>受限的人机合作：包容性具象社会智能挑战</title>
      <link>https://arxiv.org/abs/2411.01796</link>
      <description><![CDATA[arXiv:2411.01796v2 公告类型：新
摘要：我们引入了受限人机合作 (CHAIC)，这是一项包容性的具身社会智能挑战，旨在测试具身代理的社会感知和合作。在 CHAIC 中，目标是让具有自我中心观察能力的具身代理协助可能在身体限制下（例如无法到达高处或被限制在轮椅上）的人尽可能高效地执行常见的家庭或户外任务。为了实现这一目标，成功的助手必须：(1) 通过跟随人类并观察他们的行为来推断人类的意图和限制（社会感知），以及 (2) 制定适合人类伙伴的合作计划，以团队合作的方式尽快解决任务（合作规划）。为了对这一挑战进行基准测试，我们创建了四个具有真实物理约束的新代理和八个长期任务，这些任务具有室内和室外场景，具有各种约束、紧急事件和潜在风险。我们对挑战中的规划和学习基线进行了基准测试，并引入了一种利用大型语言模型和行为建模的新方法。实证评估证明了我们的基准测试在系统评估机器社交智能的关键方面方面的有效性。我们的基准测试和代码可在 https://github.com/UMass-Foundation-Model/CHAIC 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.01796</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式移动代理的基础和最新趋势：一项调查</title>
      <link>https://arxiv.org/abs/2411.02006</link>
      <description><![CDATA[arXiv:2411.02006v1 公告类型：新
摘要：移动代理对于在复杂和动态的移动环境中自动执行任务至关重要。随着基础模型的发展，对能够实时适应和处理多模态数据的代理的需求也在增长。本调查全面回顾了移动代理技术，重点介绍了增强实时适应性和多模态交互的最新进展。最近的评估基准已经开发得更好，可以捕捉移动任务的静态和交互式环境，从而更准确地评估代理的性能。然后，我们将这些进步分为两种主要方法：基于提示的方法，利用大型语言模型 (LLM) 执行基于指令的任务，以及基于训练的方法，针对特定于移动的应用程序微调多模态模型。此外，我们还探索了增强代理性能的互补技术。通过讨论关键挑战并概述未来的研究方向，本调查为推进移动代理技术提供了宝贵的见解。完整的资源列表可在 https://github.com/aialt/awesome-mobile-agents 上找到]]></description>
      <guid>https://arxiv.org/abs/2411.02006</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SibylSat：使用 SAT 作为 Oracle 对 TOHTN 规划进行贪婪搜索</title>
      <link>https://arxiv.org/abs/2411.02035</link>
      <description><![CDATA[arXiv:2411.02035v1 公告类型：新
摘要：本文介绍了 SibylSat，这是一种基于 SAT 的新型方法，旨在有效解决全序 HTN 问题 (TOHTN)。与采用广度优先搜索策略的现行基于 SAT 的 HTN 规划器不同，SibylSat 采用贪婪搜索方法，使其能够识别有希望进行扩展的分解。选择过程由从解决放松问题（也表示为 SAT 问题）中得出的启发式方法促进。我们的实验评估表明，在大多数 IPC 基准测试中，SibylSat 在运行时间和计划质量方面均优于现有的基于 SAT 的 TOHTN 方法，同时还解决了更多问题。]]></description>
      <guid>https://arxiv.org/abs/2411.02035</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于网格的空间数据投影到知识图谱中</title>
      <link>https://arxiv.org/abs/2411.02309</link>
      <description><![CDATA[arXiv:2411.02309v1 公告类型：新
摘要：空间知识图谱 (SKG) 正被越来越多地采用，作为对现实世界实体进行建模的一种手段，在危机管理和城市规划等领域尤其有价值。考虑到 RDF 规范对有效管理空间信息的支持有限，通常的做法是将几何特征（例如多边形和线条）的基于文本的序列化作为字符串文字包含在知识图中。因此，空间知识图谱 (SKG) 通常依赖于能够解析、解释和索引此类序列化的地理 RDF 存储。在本文中，我们利用网格单元作为 SKG 的基础元素，并展示如何有效地将现实世界实体及其属性的空间特征编码到知识图中。此外，我们介绍了一种在知识图中表示街道网络的新方法，不同于单独捕获每个街道段的传统做法。相反，我们的方法是基于使用网格单元对街道网络进行细分，并创建一个可用于各种路线和导航任务的简化表示，完全依赖于 RDF 规范。]]></description>
      <guid>https://arxiv.org/abs/2411.02309</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能否像人类一样概括类比求解？</title>
      <link>https://arxiv.org/abs/2411.02348</link>
      <description><![CDATA[arXiv:2411.02348v1 公告类型：新
摘要：当我们解决类比时，我们会通过抽象规则和关系相似性将信息从已知上下文转移到新上下文。在人类中，解决“身体：脚：桌子：？”等类比的能力在童年时期出现，并且似乎很容易转移到其他领域，例如视觉领域“（：）：&lt;：？”。最近的研究表明，大型语言模型（LLM）可以解决各种形式的类比。但是，LLM 能否像人类一样将类比解决推广到新领域？为了研究这个问题，我们让儿童、成人和 LLM 解决拉丁字母、近转移域（希腊字母）和远转移域（符号列表）中的一系列字母字符串类比（例如，a b：a c :: j k：？）。正如预期的那样，儿童和成人很容易将他们的知识推广到不熟悉的领域，而 LLM 却没有。人类和人工智能表现之间的这一关键差异证明这些 LLM 仍然难以实现像人类一样强大的类比迁移。]]></description>
      <guid>https://arxiv.org/abs/2411.02348</guid>
      <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>