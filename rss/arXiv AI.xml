<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description></description>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过信息内容扩展来检查两个HOP推理</title>
      <link>https://arxiv.org/abs/2502.03490</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03490</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Yinyang-Align：基准矛盾的目标并提出基于多目标优化的DPO，用于文本对象对齐</title>
      <link>https://arxiv.org/abs/2502.03512</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03512</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03544</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03544</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03948</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03948</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>好的，我会自己合并：自动模型合并的多保真框架</title>
      <link>https://arxiv.org/abs/2502.04030</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.04030</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.04058</link>
      <description><![CDATA[ARXIV：2502.04058V1公告类型：新 
摘要：我们调查了算法决策问题，代理可以对决策者（DM）模型进行战略性响应。 DMS到（潜在战略性）代理商对明确和可行的解释的需求继续增加。尽管先前的工作通常将解释视为完整模型披露，但实践中的解释可能只传达部分信息，这可能导致误解和有害的回应。当对预测模型的完全披露既不是可行的也不是可取的时，一个关键的开放问题是，DMS如何使用解释来最大化其实用性，而无需损害代理的福利。在这项工作中，我们探讨了众所周知的本地和全球解释方法，并建立了必要的条件，以防止误导代理人进入自我伤害行动。此外，通过有条件的同质性，我们确定了行动建议（AR）的解释足以进行无害的响应，类似于信息设计的启示原则。为了实现基于AR的解释，我们提出了一种简单的算法，以共同优化预测模型和AR策略，以平衡DM结果与代理福利。我们的经验结果证明了这种方法的好处是在算法决策中对安全有效的部分模型披露的更精致的策略。]]></description>
      <guid>https://arxiv.org/abs/2502.04058</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.04249</link>
      <description><![CDATA[ARXIV：2502.04249V1公告类型：新 
摘要：我们研究自由能原理是衡量代理和多代理系统风险的基础。从这些原则中，我们引入了一个累积的风险暴露度量，该指标在不同的环境和需求中灵活。我们将其与其他流行的AI理论进行对比，该理论取决于大量数据或描述任意复杂的世界模型。在我们的框架中，利益相关者只需要指定他们对系统结果的偏好，从而为风险治理和缓解措施提供直接且透明的决策规则。该框架自然说明了世界模型和偏好模型中的不确定性，从而可以在认识论和公理上谦虚，简约和未来的决策。我们在简化的自动驾驶汽车环境中展示了这种新颖的方法，其驾驶政策是由守门人介导的，这些驾驶政策是由网上方式评估其附近集体安全风险的，并在适当的情况下介入了每辆车的政策。我们表明，即使在较低的渗透率下，也可以在系统安全性提高方面引入守门人，即使在低渗透率下也可以产生显着的积极外部性。]]></description>
      <guid>https://arxiv.org/abs/2502.04249</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.04302</link>
      <description><![CDATA[ARXIV：2502.04302V1公告类型：新 
摘要：我们调查了在答案集编程的扩展框架内具有约束的概念。如果非正式地说，在任何情况下它们具有相同的含义，则认为两组规则是强烈的等效物。我们证明，在某些假设下，在此扩展设置中规则集之间的强大等价性可以精确地以它们在此处的逻辑中的等效性为特征。此外，我们提出了从几个基于克林戈的答案集求解器的语言中的翻译，这些求解器将约束限制到这里的语言以及受到约束。这种翻译使我们能够利用这里和在这些求解器中有强大等价的理由的逻辑。我们还探讨了在这种情况下确定强相等性的计算复杂性。]]></description>
      <guid>https://arxiv.org/abs/2502.04302</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI保证可能会出错的地方：关键系统工程的初始课程</title>
      <link>https://arxiv.org/abs/2502.03467</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03467</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI伦理的能力方法</title>
      <link>https://arxiv.org/abs/2502.03469</link>
      <description><![CDATA[ARXIV：2502.03469V1公告类型：交叉 
摘要：我们通过能力方法提出了AI伦理的概念化和实施。我们的目的是表明，通过能力方法概念化AI伦理学对AI伦理作为纪律具有两个主要优势。首先，它有助于阐明AI工具的道德维度。其次，它为在AI工具的设计中实施道德考虑提供了指导。我们通过展示了基于伦理学的医学工具在医学上的AI工具的背景下说明这些优势，从而可以从我们基于能力的方法中受益匪浅。]]></description>
      <guid>https://arxiv.org/abs/2502.03469</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03482</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03482</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03487</link>
      <description><![CDATA[ARXIV：2502.03487V1公告类型：交叉 
摘要：本文报告了一项研究的结果，研究了法律和非法律大语言模型使用问题规则 - 申请解决框架进行法律分析的能力。对LLM进行了针对涉及规则分析和类比推理的法律推理任务的测试。结果表明，LLM可以进行基本的IRAC分析，但受到缺乏细节的简短答复的限制，无法提交答案，虚假的信心和幻觉。该研究比较了法律和非法律学士学位，确定了缺点，并探讨了可能会阻碍他们像律师一样思考的特征。它还讨论了对法律教育和实践的影响，强调了未来律师中批判性思维技能的需求以及对人工智能AI过度依赖的潜在陷阱，从而导致逻辑，推理和批判性思维技能的丧失。]]></description>
      <guid>https://arxiv.org/abs/2502.03487</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03492</link>
      <description><![CDATA[ARXIV：2502.03492V1公告类型：交叉 
摘要：教导大语模型（LLMS）批评和完善其产出对于可以迭代改进的建筑系统至关重要，但是它在根本上受到提供准确的判断和可行建议的能力的限制。在这项工作中，我们研究了代码生成的LLM评论家，并提出$ \ texttt {ctrl} $，$ \ texttt {c} $ ritic $ \ texttt {t} $通过$ \ texttt {r texttt {r} \ texttt {l} $ ginning，该奖励模型生成反馈，该反馈最大程度地提高了固定发电机模型的校正性能，而无需人工监督。我们的结果表明，经过$ \ texttt {ctrl} $培训的评论家显着提高了通过率，并减轻基本和更强的发电机模型的复合错误。此外，我们表明这些评论家模型充当准确的生成奖励模型，并通过迭代批判性革命进行测试时间扩展，从而在挑战性的代码生成基准中实现了高达106.1％的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2502.03492</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03499</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03499</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03500</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03500</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03502</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03502</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03503</link>
      <description><![CDATA[ARXIV：2502.03503V1公告类型：交叉 
摘要：我们在上下文学习（ICL）任务中检查了两个在变压器模型的数学和测试设置中的数学功能。我们的研究通过表明小型变压器（甚至只有注意层的模型）可以近似任意多项式函数，因此在某些条件下连续函数来概括对线性函数的工作。我们的模型还可以近似以前看不见的多项式函数以及复杂函数的零。我们的模型在此任务上的表现要比GPT4等LLM好得多，并在提供合适的培训数据和方法时涉及复杂的推理。我们的模型也有重要的局限性；他们无法在培训分布之外概括，因此不要学习班级的功能。我们解释了为什么是这样。]]></description>
      <guid>https://arxiv.org/abs/2502.03503</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03504</link>
      <description><![CDATA[ARXIV：2502.03504V1公告类型：交叉 
摘要：这项工作反映了从人工智能（AI）的角度来看，沉浸式的含义。利用身临其境的学习理论的角度，它试图了解这种新观点是否支持AI参与认知生态的方法。通过将AI视为参与者而不是工具，它探讨了其他参与者（人类和其他AIS）在AI可以有意义地参与并为认知生态贡献的环境中需要考虑的内容，以及对这些学习环境设计的含义。从沉浸式的三个概念化维度（系统，叙事和代理）中汲取灵感 - 这项工作在沉浸式学习环境中重新诠释了AIS。它概述了设计学习环境的实践含义，在这些学习环境中，AI被外部数字服务包围，可以解释数据中的起源，变化和结构发展的叙述，并动态响应，从而做出塑造人类协作的操作和战术决策。最后，这项工作表明，这些见解可能如何影响AI培训的未来，并提出身临其境的学习理论可以为AIS的发展提供了能够超越静态模型的发展。本文为理解AI作为身临其境的学习者和参与者的参与者铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.03504</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03505</link>
      <description><![CDATA[]]></description>
      <guid>https://arxiv.org/abs/2502.03505</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://arxiv.org/abs/2502.03508</link>
      <description><![CDATA[ARXIV：2502.03508V1公告类型：交叉 
摘要：本文着重于阐明非人类交流代理的关系和后验证理论（ANHC）的意识概念。具体而言，我们探讨了托马斯·梅辛格（Thomas Metzinger）的自我模型理论的贡献，凯瑟琳·海尔斯（Katherine Hayles复杂计算系统的新兴现象是由其无机物质的适当组织引起的。基于与非人类认知剂的互动，除其他因素外，社会技术系统的解释性挑战了现代哲学和科学的人文常识。各种方法的这种批判性整合最终质疑与意识相关的其他概念，例如自主，自由和相互责任。目的是为设计新的理解框架做出必要的讨论，以铺平道德和务实的方法，以解决与ANHC设计，调节和互动中当代挑战的方法。反过来，这种框架可以使在一个相互联系的世界中对代理的更具包容性和关系性理解。]]></description>
      <guid>https://arxiv.org/abs/2502.03508</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>