<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MARS：一种用于可解释药物发现的神经符号方法</title>
      <link>https://arxiv.org/abs/2410.05289</link>
      <description><![CDATA[arXiv:2410.05289v1 公告类型：新
摘要：神经符号 (NeSy) 人工智能描述了逻辑或基于规则的技术与神经网络的结合。与神经方法相比，NeSy 方法通常具有增强的可解释性，这对于药物发现等生物医学应用尤其有前景。然而，由于可解释性定义广泛，因此没有明确的指导方针来评估模型解释的生物学合理性。为了评估药物发现背景下的可解释性，我们设计了一种新的预测任务，称为药物作用机制 (MoA) 反卷积，以及相关的定制知识图 (KG)，MoA-net。然后，我们开发了 MoA 检索系统 (MARS)，这是一种用于药物发现的 NeSy 方法，它利用具有学习规则权重的逻辑规则。结合这一可解释特性和领域知识，我们发现 MARS 和其他 NeSy 方法在 KG 上容易受到推理捷径的影响，其中真实标签的预测由“度偏差”而不是基于领域的规则驱动。随后，我们展示了识别和缓解这种情况的方法。此后，MARS 实现了与当前最先进模型相当的性能，同时产生了与已知 MoA 一致的模型解释。]]></description>
      <guid>https://arxiv.org/abs/2410.05289</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>第一届知识表示和推理下一代语言模型国际研讨会论文集（NeLaMKRR 2024）</title>
      <link>https://arxiv.org/abs/2410.05339</link>
      <description><![CDATA[arXiv:2410.05339v1 公告类型：新
摘要：推理是人类智能的重要组成部分，因为它在我们批判性思考、支持负责任的决策和解决具有挑战性的问题的能力中起着根本性的作用。传统上，人工智能在基于逻辑的知识表示的背景下处理推理。然而，随着基于转换器的语言模型的出现，自然语言处理领域最近的飞跃暗示了这些模型表现出推理能力的可能性，特别是当它们规模扩大并在更多数据上进行训练时。尽管关于语言模型中的推理是什么的讨论仍在继续，但仍然很难确定这些模型实际上在多大程度上能够推理。
本次研讨会的目标是为来自不同学科和/或人工智能视角的研究人员创建一个平台，探索方法和技术，旨在协调使用转换器和使用基于逻辑的表示的语言模型之间的推理。具体目标包括分析与 KR 方法一起测量的语言模型的推理能力、将 KR 式推理能力注入语言模型（包括通过神经符号方法），以及形式化语言模型执行的推理类型。这项探索旨在揭示语言模型如何有效地集成和利用知识和推理，从而提高其在精度和可靠性是关键要求的领域的应用和效用。]]></description>
      <guid>https://arxiv.org/abs/2410.05339</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型引导搜索合成可解释的控制策略</title>
      <link>https://arxiv.org/abs/2410.05406</link>
      <description><![CDATA[arXiv:2410.05406v1 公告类型：新
摘要：大型语言模型 (LLM)、系统评估和进化算法的结合使得组合优化和科学发现取得了突破。我们建议将这种强大的组合扩展到动态系统的控制，生成能够执行复杂行为的可解释控制策略。通过我们的新方法，我们将控制策略表示为 Python 等标准语言中的程序。我们在模拟中评估候选控制器，并使用预先训练的 LLM 对其进行改进。与依赖黑盒神经网络来编码控制策略的传统基于学习的控制技术不同，我们的方法增强了透明度和可解释性。我们仍然利用大型 AI 模型的强大功能，但在策略设计阶段利用它，确保所有系统组件在运行时保持可解释且易于验证。此外，使用标准编程语言使人类能够根据他们的专业知识和直觉直接微调或调整控制器。我们通过将该方法应用于钟摆摆动和杯中球任务的可解释控制策略的合成来说明我们的方法。我们将代码发布在 https://github.com/muellerlab/synthesizing_interpretable_control_policies.git]]></description>
      <guid>https://arxiv.org/abs/2410.05406</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>树形结构概率电路的表达能力</title>
      <link>https://arxiv.org/abs/2410.05465</link>
      <description><![CDATA[arXiv:2410.05465v1 公告类型：新
摘要：概率电路 (PC) 已成为一个强大的框架，可以紧凑地表示概率分布，从而实现高效和精确的概率推理。已经证明，具有一般有向无环图 (DAG) 结构的 PC 可以理解为指数级（在其高度上）许多组件的混合，每个组件都是单变量边际的乘积分布。然而，现有的 PC 结构学习算法通常生成树形电路或使用树形电路作为中间步骤将它们压缩为 DAG 结构电路。这引出了一个有趣的问题，即对于 PC 结构，DAG 和树之间是否存在指数差距。在本文中，我们通过证明对于 $n$ 个变量，在计算相同概率分布的等效树的大小上存在亚指数上限 $n^{O(\log n)}$，对这个猜想提供了一个否定的答案。另一方面，我们还表明，给定树的深度限制，树结构 PC 和 DAG 结构 PC 之间存在超多项式分离。我们的工作朝着理解树结构 PC 的表达能力迈出了重要的一步，我们的技术可能对研究 PC 的结构学习算法具有独立意义。]]></description>
      <guid>https://arxiv.org/abs/2410.05465</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>确保：减少预测中的认知不确定性的解释</title>
      <link>https://arxiv.org/abs/2410.05479</link>
      <description><![CDATA[arXiv:2410.05479v1 公告类型：新
摘要：本文解决了可解释人工智能的一个重大差距：解释模型解释中的认知不确定性的必要性。尽管当前的方法主要侧重于解释预测，其中一些包括不确定性，但它们未能提供如何减少这些预测中固有的不确定性的指导。为了克服这一挑战，我们引入了专门针对认知不确定性的新类型的解释。这些包括确保解释，强调可以减少不确定性的特征修改，以及不确定解释的分类反潜能、半潜能和超潜能，探索替代方案。我们的工作强调，认知不确定性为解释质量增加了一个关键维度，要求评估不仅基于预测概率，还基于不确定性减少。我们引入了一个新指标，即确保排名，旨在通过平衡不确定性、概率和相互竞争的替代解释之间的权衡来帮助用户识别最可靠的解释。此外，我们扩展了校准解释方法，加入了一些工具，可以直观地展示特征值的变化如何影响认知不确定性。这一增强功能可以更深入地洞察模型行为，提高可解释性和在涉及不确定预测的场景中的适当信任度。]]></description>
      <guid>https://arxiv.org/abs/2410.05479</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>妥协的直觉：功利主义与契约主义</title>
      <link>https://arxiv.org/abs/2410.05496</link>
      <description><![CDATA[arXiv:2410.05496v1 公告类型：新
摘要：在不同的人重视不同事物的情况下，最好的妥协是什么？在行为和社会科学、决策理论、哲学和人工智能开发等领域，回答这个问题最普遍接受的方法就是将与不同选项相关的效用加起来，然后选择总和最大的解决方案。这种“功利主义”方法似乎是解决问题的显而易见的、理论中立的方法。但有一种重要的、但经常被忽视的替代方案：一种“契约主义”方法，它主张一种以协议为导向的决策方法。值得注意的是，没有研究提供直接比较这两种方法的直观合理性的实证证据。在本文中，我们系统地探讨了每种算法（“功利主义总和”和契约主义“纳什积”）提出的建议，使用一种范式将这些算法应用于在社会决策环境中聚合群体偏好。虽然到目前为止，价值聚合的主导方法一直是功利主义，但我们发现人们强烈倾向于契约主义算法推荐的聚合。最后，我们将大型语言模型 (LLM) 的判断与我们（人类）参与者的判断进行比较，发现模型和人类偏好之间存在重大不一致。]]></description>
      <guid>https://arxiv.org/abs/2410.05496</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用于多轮交互代理的多功能运动语言模型</title>
      <link>https://arxiv.org/abs/2410.05628</link>
      <description><![CDATA[arXiv:2410.05628v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展极大地增强了它们生成自然和上下文相关文本的能力，使 AI 交互更加像人类。然而，由于对这些协调交互进行建模的复杂性，生成和理解两个人进行协调运动的交互式类人运动仍然是一项挑战。此外，需要一个多功能模型来处理各种交互场景，例如遵循用户指令或适应其分配的角色同时调整交互动态的聊天系统。为了解决这个问题，我们引入了 VIM，即多功能交互式运动语言模型的缩写，它集成了语言和运动模式，以有效地理解、生成和控制多轮对话环境中的交互式运动。为了解决多轮交互式运动数据的稀缺问题，我们引入了一个合成数据集 INERT-MT2，我们在其中利用预先训练的模型来创建具有交互式运动的多样化教学数据集。我们的方法首先训练一个运动标记器，将交互式运动编码为残差离散标记。在预训练阶段，模型学习将运动和文本表示与这些离散标记对齐。在指令微调阶段，VIM 使用 INTER-MT2 数据集适应多轮对话。我们评估了我们的方法在与运动相关的任务、运动到文本、文本到运动、反应生成、运动编辑和运动序列推理方面的多功能性。结果突出了所提出方法在处理复杂交互式运动合成方面的多功能性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.05628</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对顺序决策的建模能力</title>
      <link>https://arxiv.org/abs/2410.05656</link>
      <description><![CDATA[arXiv:2410.05656v1 公告类型：新
摘要：大型预训练模型在不同模式下的推理和规划任务中表现出越来越好的性能，为利用它们解决复杂的顺序决策问题提供了可能性。在本文中，我们研究了大型语言模型 (LLM) 在各种交互领域中用于强化学习 (RL) 的能力。我们评估了它们制定决策策略的能力，无论是直接通过生成动作，还是间接通过首先生成奖励模型来训练具有 RL 的代理。我们的结果表明，即使没有针对特定任务的微调，LLM 也在奖励建模方面表现出色。特别是，通过人工智能 (AI) 反馈制定奖励产生了最普遍适用的方法，并且可以通过改进信用分配和探索来提高性能。最后，在具有不熟悉动态的环境中，我们探索如何使用合成数据微调 LLM 可以显着提高其奖励建模能力，同时减轻灾难性遗忘，从而进一步扩大其在顺序决策任务中的效用。]]></description>
      <guid>https://arxiv.org/abs/2410.05656</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACPBench：关于行动、变革和规划的推理</title>
      <link>https://arxiv.org/abs/2410.05669</link>
      <description><![CDATA[arXiv:2410.05669v1 公告类型：新
摘要：越来越多的研究使用大型语言模型 (LLM) 作为代理来协调工作流程并在需要规划和多步骤推理的领域做出决策。因此，必须根据规划所需的核心技能评估 LLM。在这项工作中，我们提出了 ACPBench，这是一个评估规划领域推理任务的基准。该基准包括 13 个规划领域的 7 个推理任务。该集合由用形式语言描述的规划域构成。这使我们能够在许多任务和领域中综合具有可证明正确解决方案的问题。此外，它使我们无需额外的人力即可实现规模化，即可以自动创建许多额外的问题。我们对 22 个开源和前沿 LLM 的广泛评估凸显了 LLM 推理能力的巨大差距。在这些任务上表现最好的前沿 LLM 之一 GPT-4o 的平均准确率可以低至 52.50% ACPBench 集合可在 https://ibm.github.io/ACPBench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.05669</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过概念格减少模糊关系方程</title>
      <link>https://arxiv.org/abs/2410.05728</link>
      <description><![CDATA[arXiv:2410.05728v1 公告类型：新
摘要：本文利用模糊关系方程 (FRE) 和概念格之间的关系，介绍了一种在不丢失信息的情况下减少 FRE 的程序。具体来说，考虑了面向属性和面向对象的概念格中的属性约简理论，以提出一种检测冗余方程的机制。作为第一个结果，可解 FRE 的整个解集的计算减少了。此外，我们还将介绍一种新方法，用于计算与具有不确定性/不精确数据的（真实）数据集相关的不可解 FRE 的近似解。]]></description>
      <guid>https://arxiv.org/abs/2410.05728</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自下而上随时发现知识图谱的广义多模态图模式</title>
      <link>https://arxiv.org/abs/2410.05839</link>
      <description><![CDATA[arXiv:2410.05839v1 公告类型：新
摘要：大量异构知识以知识图谱的形式公开，通常将以前从未在一起的多个数据源链接在一起，从而使学者能够回答许多新的研究问题。然而，人们通常事先并不知道数据可能对哪些问题有答案，这可能会让许多有趣和新颖的见解未被发现。为了支持学者在这个科学工作流程中，我们引入了一种随时算法，用于自下而上地发现知识图中的广义多模态图模式。每个模式都是二进制语句与（数据）类型变量、常量和/或值模式的结合。发现后，模式将转换为 SPARQL 查询并与元数据和出处信息一起显示在交互式方面浏览器中，使学者能够探索、分析和共享查询。我们在人文领域专家的帮助下从用户的角度评估我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.05839</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>部分可观测随机应急计划的启发式方法</title>
      <link>https://arxiv.org/abs/2410.05870</link>
      <description><![CDATA[arXiv:2410.05870v1 公告类型：新
摘要：在随机部分可观测领域中完成任务是人工智能中的一个重要问题，通常被表述为基于目标的 POMDP。基于目标的 POMDP 可以使用 RTDP-BEL 算法来解决，该算法通过从初始信念到目标运行前向轨迹来运行。这些轨迹可以由启发式方法引导，更准确的启发式方法可以显著加快收敛速度​​。在本文中，我们开发了一种启发式函数，它利用领域模型的结构化表示。我们在宽松的空间中计算实现目标的计划，同时考虑到信息的价值以及随机效应。我们提供的实验表明，虽然我们的启发式方法计算速度较慢，但​​在收敛之前需要的轨迹要少一个数量级。总的来说，它因此加快了 RTDP-BEL 的速度，特别是在需要大量信息收集的问题中。]]></description>
      <guid>https://arxiv.org/abs/2410.05870</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Athanor：抽象约束规范的局部搜索</title>
      <link>https://arxiv.org/abs/2410.05937</link>
      <description><![CDATA[arXiv:2410.05937v1 公告类型：新
摘要：局部搜索是解决组合优化问题的常用方法。我们专注于通用的局部搜索求解器，它接受约束模型作为输入 - 由一组约束下的一组决策变量组成的问题的声明性描述。现有方法通常以独立于求解器的约束建模语言（如 MiniZinc）编写的模型作为输入。我们在此描述的 Athanor 求解器的不同之处在于，它从抽象约束规范语言 Essence 中的问题规范开始，该语言通过支持一组丰富的抽象类型，允许在不承诺低级建模决策的情况下描述问题。从 Essence 出发的优势在于，可以利用问题简洁、抽象规范中明显的结构来自动生成高质量的邻域，从而避免在等效约束模型中识别该结构的艰巨任务。基于从高级类型派生的邻域和通过直接搜索这些类型而获得的可扩展性的双重优势，我们的实证结果在实践中表现出相对于现有解决方法的强大性能。]]></description>
      <guid>https://arxiv.org/abs/2410.05937</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与他人共同进化：通过顺序协作多智能体强化学习对 LLM 进行微调</title>
      <link>https://arxiv.org/abs/2410.06101</link>
      <description><![CDATA[arXiv:2410.06101v1 公告类型：新
摘要：强化学习 (RL) 已成为针对特定任务微调大型语言模型 (LLM) 的关键技术。然而，现行的 RL 微调方法主要依赖于 PPO 及其变体。虽然这些算法在一般的 RL 设置中是有效的，但它们在应用于 LLM 的微调时通常表现出次优性能和分布崩溃的脆弱性。在本文中，我们提出了 CORY，将 LLM 的 RL 微调扩展为顺序协作多智能体强化学习框架，以利用多智能体系统固有的共同进化和突发能力。在 CORY 中，要微调的 LLM 最初被复制为两个自主智能体：一个先驱者和一个观察者。先驱者根据查询生成响应，而观察者使用查询和先驱者的响应生成响应。这两个智能体一起训练。在训练过程中，代理会定期交换角色，促进它们之间的合作和共同进化。实验分别在 IMDB Review 和 GSM8K 数据集上，通过主观和客观奖励函数对 GPT-2 和 Llama-2 进行微调，以评估 CORY 的性能。结果表明，CORY 在策略优化性、抗分布崩溃性和训练稳健性方面优于 PPO，从而凸显了其作为在实际应用中改进 LLM 的卓越方法的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.06101</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ConceptAgent：LLM 驱动的前提条件基础和树搜索，实现稳健的任务规划和执行</title>
      <link>https://arxiv.org/abs/2410.06108</link>
      <description><![CDATA[arXiv:2410.06108v1 公告类型：新
摘要：由于状态空间巨大且任务实施高度可变，开放世界环境中的机器人规划和执行是一个复杂的问题。感知算法的最新进展与大型语言模型 (LLM) 相结合，为规划提供了有希望的解决方案，因为 LLM 的常识推理能力为有效搜索动作空间提供了强大的启发式方法。然而，先前的工作未能解决 LLM 产生幻觉的可能性，这导致无法执行计划的操作，主要是由于高级或低级的逻辑谬误。为了应对由于这种幻觉导致的自动化失败，我们引入了 ConceptAgent，这是一个自然语言驱动的机器人平台，专为在非结构化环境中执行任务而设计。我们重点关注 LLM 复杂状态和动作空间规划的可扩展性和可靠性，并提出了旨在限制这些缺陷的创新，包括 1) 谓词基础，以防止和恢复不可行动作，以及 2) 具有自我反思的 LLM 引导蒙特卡洛树搜索的具体版本。在模拟实验中，ConceptAgent 在三个房间布局和 30 个简单级别的具体任务中实现了 19% 的任务完成率，优于其他最先进的 LLM 驱动推理基线，后者在同一基准上得分为 10.26% 和 8.11%。此外，对中等到困难的具体任务的消融研究表明，从基线代理到完全增强的 ConceptAgent，任务完成率提高了 20%，突出了谓词基础和 LLM 引导树搜索的单独和组合贡献，使复杂状态和动作空间中的自动化更加强大。]]></description>
      <guid>https://arxiv.org/abs/2410.06108</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式情境安全</title>
      <link>https://arxiv.org/abs/2410.06172</link>
      <description><![CDATA[arXiv:2410.06172v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 正在迅速发展，作为与人类及其环境交互的多模态助手，展现出令人印象深刻的能力。然而，这种日益复杂的情况带来了重大的安全问题。在本文中，我们首次评估和分析了一种名为多模态情境安全的新安全挑战，该挑战探讨了安全考虑因素如何根据用户或代理所处的具体情况而变化。我们认为，为了让 MLLM 安全地做出响应，无论是通过语言还是行动，它通常需要评估语言查询在其相应的视觉环境中的安全影响。为了评估这种能力，我们开发了多模态情境安全基准 (MSSBench) 来评估当前 MLLM 的情境安全性能。数据集包含 1,820 个语言查询-图像对，其中一半的图像环境是安全的，另一半是不安全的。我们还开发了一个评估框架，用于分析关键的安全方面，包括明确的安全推理、视觉理解以及至关重要的情境安全推理。我们的研究结果表明，当前的 MLLM 在遵循指令的环境中难以解决这种细微的安全问题，并且难以一次性解决这些情境安全挑战，这突出了未来研究的一个关键领域。此外，我们开发了多智能体管道来协调解决安全挑战，这表明与原始 MLLM 响应相比，安全性得到了持续改善。代码和数据：mssbench.github.io。]]></description>
      <guid>https://arxiv.org/abs/2410.06172</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测：通过评估从候选轨迹推断出的分解偏好进行偏好推理</title>
      <link>https://arxiv.org/abs/2410.06273</link>
      <description><![CDATA[arXiv:2410.06273v1 公告类型：新
摘要：适应人类偏好对于创建提供个性化和有效交互的 AI 代理至关重要。最近的研究表明，LLM 具有从用户交互中推断偏好的潜力，但它们通常会产生广泛而通用的偏好，无法捕捉人类偏好的独特和个性化性质。本文介绍了 PREDICT，一种旨在提高推断偏好的精度和适应性的方法。PREDICT 包含三个关键要素：（1）推断偏好的迭代细化，（2）将偏好分解为组成部分，以及（3）跨多个轨迹验证偏好。我们在两个不同的环境中评估 PREDICT：网格世界设置和新的文本域环境（PLUME）。PREDICT 更准确地推断出细微的人类偏好，比现有基线提高了 66.2%（网格世界环境）和 41.0%（PLUME）。]]></description>
      <guid>https://arxiv.org/abs/2410.06273</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从游戏 AI 角度对收藏类卡牌游戏进行分类</title>
      <link>https://arxiv.org/abs/2410.06299</link>
      <description><![CDATA[arXiv:2410.06299v1 公告类型：新
摘要：集换式卡牌游戏是一种具有挑战性、广受欢迎的游戏，近年来受到人工智能研究界越来越多的关注。尽管取得了重大突破，但该领域仍然存在许多未解决的挑战。这项工作旨在通过从游戏人工智能研究的角度分析集换式卡牌游戏的规则、机制和游戏模式，提出一种集换式卡牌游戏的分类法，以帮助进一步研究该类型。为此，我们研究了一组流行的游戏，并对其特点进行了深入的讨论。]]></description>
      <guid>https://arxiv.org/abs/2410.06299</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识汇编图中的布尔最近邻语言</title>
      <link>https://arxiv.org/abs/2410.06332</link>
      <description><![CDATA[arXiv:2410.06332v1 公告类型：新
摘要：Hajnal、Liu 和 Turan 最近引入了布尔函数的布尔最近邻 (BNN) 表示。$f$ 的 BNN 表示是一对布尔向量集 (称为正原型和负原型) (P,N)，其中对于每个正原型 $x \in P$，$f(x)=1$，对于所有负原型 $x \in N$，$f(x)=0$，而对于 $x \not\in P \cup N$，$f(x)$ 的值由最近原型的类型决定。本文的主要目的是确定 BNN 语言在知识汇编图 (KCM) 中的位置。为此，我们得出了将 BNN 语言与 KCM 中的几种标准语言的简洁性进行比较的结果，并确定了 BNN 输入的大多数标准查询和转换的复杂性状态。]]></description>
      <guid>https://arxiv.org/abs/2410.06332</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型增强的化学计算验证科学文献</title>
      <link>https://arxiv.org/abs/2410.06384</link>
      <description><![CDATA[arXiv:2410.06384v1 公告类型：新
摘要：Chemputation 是使用通用符号语言对化学机器人进行实验编程的过程，但由于歧义，文献可能容易出错且难以阅读。大型语言模型 (LLM) 在各个领域都表现出卓越的能力，包括自然语言处理、机器人控制以及最近的化学。尽管在标准化合成化学数据的报告和收集方面取得了重大进展，但报告的合成的自动再现仍然是一项劳动密集型任务。在这项工作中，我们介绍了一种基于 LLM 的化学研究代理工作流程，旨在自动验证合成文献程序。我们的工作流程可以从大量文档中自主提取合成程序和分析数据，将这些程序转换为通用 XDL 代码，在特定于硬件的设置中模拟程序的执行，并最终在 XDL 控制的合成化学机器人系统上执行该程序。这证明了基于 LLM 的工作流程在使用化学计算机进行自主化学合成方面的潜力。由于 XDL 的抽象性，这种方法是安全、可靠且可扩展的，因为幻觉不会进行化学计算，并且 XDL 既可以验证也可以加密。与以前的努力不同，以前的努力要么只解决工作流程的有限部分，要么依赖于不灵活的硬编码规则，要么缺乏物理系统中的验证，我们的方法提供了四个直接从合成文献中执行的合成的真实示例。我们预计，我们的工作流程将显著提高机器人驱动的合成化学研究的自动化程度，简化数据提取，提高合成和实验化学的可重复性、可扩展性和安全性。]]></description>
      <guid>https://arxiv.org/abs/2410.06384</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>