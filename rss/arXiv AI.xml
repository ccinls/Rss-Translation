<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 27 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>增强不完全信息纸牌游戏的评论策略：《关单评论》大型语言模型研究</title>
      <link>https://arxiv.org/abs/2406.17807</link>
      <description><![CDATA[arXiv:2406.17807v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展释放了生成高质量游戏评论的潜力。然而，为信息不完整的复杂游戏制作富有洞察力和吸引力的评论仍然是一项重大挑战。在本文中，我们介绍了一种结合强化学习 (RL) 和 LLM 的新型评论方法，专门针对中国纸牌游戏 \textit{关丹}。我们的系统利用 RL 生成复杂的纸牌游戏场景，并使用 LLM 生成相应的评论文本，有效地模仿专业评论员的战略分析和叙事能力。该框架包括一个状态评论指南、一个基于心智理论 (ToM) 的策略分析器和一个风格检索模块，它们无缝协作以在中文环境中提供详细且与上下文相关的游戏评论。我们为 LLM 赋予 ToM 功能，并改进检索和信息过滤机制。这有助于生成个性化的评论内容。我们的实验结果显示，所提出的评论框架应用于开源 LLM 时取得了显著的性能提升，在多个评估指标上超越了 GPT-4 的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.17807</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>带有级联 KV 缓存的滑动窗口上下文的免训练指数扩展</title>
      <link>https://arxiv.org/abs/2406.17808</link>
      <description><![CDATA[arXiv:2406.17808v1 公告类型：交叉 
摘要：Transformer 中的上下文窗口为当前任务提供了一种活动内存形式，这对于小样本学习和条件生成非常有用，这两者都严重依赖于先前的上下文标记。但是，随着上下文长度的增加，计算成本会成倍增加。最近的研究表明，在基于 Transformer 的大型语言模型 (LLM) 中，保存一些初始标记以及固定大小的滑动窗口可以实现具有线性复杂度的稳定流式生成。但是，它们通过天真地将所有标记从键值 (KV) 缓存中无条件地逐出，一旦它们到达窗口末尾，它们就会对固定窗口的使用不尽如人意，导致标记被遗忘并且不再能够影响后续预测。为了克服这一限制，我们提出了一种新颖的机制，通过保留单独的级联子缓存缓冲区来存储具有相同总缓存大小的更长的滑动窗口上下文，其中每个后续缓冲区有条件地接受从前一个缓冲区逐出的相对更重要的标记的一小部分。我们的方法可以生成动态 KV 缓存，与固定的静态滑动窗口方法相比，它可以存储更久远的标记。我们的实验表明，在给定相同固定缓存大小的情况下，使用 LLM，长上下文生成 (LongBench) 的改进为 5.6%，流式困惑度 (PG19) 的改进为 1.2%，语言理解 (MMLU STEM) 的改进为 0.6%。此外，我们还提供了一种高效的实现，将 KV 缓存延迟从每次缓存操作 1.33 毫秒缩短至 0.54 毫秒，比以前的工作速度提高了 59%。]]></description>
      <guid>https://arxiv.org/abs/2406.17808</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>PIC2O-Sim：一种受物理启发的因果关系感知动态卷积神经算子，用于超快速光子器件 FDTD 模拟</title>
      <link>https://arxiv.org/abs/2406.17810</link>
      <description><![CDATA[arXiv:2406.17810v1 公告类型：交叉 
摘要：有限差分时域 (FDTD) 方法在光子硬件设计流程中非常重要，被广泛用于求解时域麦克斯韦方程。然而，FDTD 以其高昂的运行成本而闻名，模拟单个设备需要几分钟到几小时的时间。最近，人工智能已被用于实现偏微分方程 (PDE) 求解的数量级加速。然而，基于人工智能的光子器件 FDTD 求解器尚未明确制定。直接应用现成的模型来预测光场动力学显示出不令人满意的保真度和效率，因为模型基元与麦克斯韦方程的独特物理性质无关，并且缺乏算法定制。在本研究中，我们深入研究了神经算子设计与麦克斯韦方程物理性质之间的协同作用，并引入了受物理启发的基于人工智能的 FDTD 预测框架 PIC2O-Sim，该框架以因果关系感知动态卷积神经算子为骨干模型，通过精心的感受野配置来遵守时空因果关系约束，并通过高效的动态卷积算子明确捕获介电常数相关的光传播行为。同时，我们通过自回归预测中的多阶段分区时间捆绑技术探索预测可扩展性、保真度和效率之间的权衡。引入了多种关键技术来减轻迭代误差累积，同时保持自回归场预测期间的效率优势。对三个具有挑战性的光子器件模拟任务的广泛评估表明了我们的 PIC2O-Sim 方法的优越性，其推出预测误差降低了 51.2%，参数比最先进的神经算子少了 23.5 倍，模拟速度比开源 FDTD 数值求解器高 300-600 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.17810</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>CATBench：用于黑盒优化的编译器自动调优基准测试套件</title>
      <link>https://arxiv.org/abs/2406.17811</link>
      <description><![CDATA[arXiv:2406.17811v1 公告类型：交叉 
摘要：贝叶斯优化是一种自动调整编译器的强大方法。自动调整的复杂环境为黑盒优化器提供了大量很少考虑的结构性挑战，而且缺乏标准化的基准测试限制了该领域内贝叶斯优化的研究。为了解决这个问题，我们提出了 CATBench，这是一个全面的基准测试套件，可以捕获编译器自动调整的复杂性，从离散、条件和排列参数类型到已知和未知的二进制约束，以及多保真度和多目标评估。CATBench 中的基准测试涵盖了一系列面向机器学习的计算，从张量代数到图像处理和聚类，并使用最先进的编译器，例如 TACO 和 RISE/ELEVATE。 CATBench 提供统一的界面来评估贝叶斯优化算法，通过易于使用、完全容器化的替代和真实编译器优化任务设置来促进可重复性和创新。我们在几种最先进的算法上验证了 CATBench，揭示了它们的优点和缺点，并展示了该套件在推进贝叶斯优化和编译器自动调优研究方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.17811</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>MoleculeCLA：通过计算配体-靶标结合分析重新思考分子基准</title>
      <link>https://arxiv.org/abs/2406.17797</link>
      <description><![CDATA[arXiv:2406.17797v1 公告类型：交叉 
摘要：分子表征学习对于与药物发现相关的各种分子特性预测任务至关重要。稳健而准确的基准对于改进和验证当前​​方法至关重要。然而，现有的来自湿实验的分子特性基准面临着数据量限制、标签分布不均衡和标签噪声等限制。为了解决这些问题，我们构建了一个包含约 140,000 个小分子的大规模精确分子表征数据集，经过精心设计，可捕捉广泛的化学、物理和生物特性，这些特性是通过稳健的计算配体-靶标结合分析管道得出的。我们对各种深度学习模型进行了广泛的实验，证明我们的数据集提供了重要的物理化学可解释性来指导模型开发和设计。值得注意的是，数据集的属性与结合亲和力指标相关联，为模型在药物-靶标相互作用任务中的表现提供了额外的见解。我们相信该数据集将成为分子表征学习更准确、更可靠的基准，从而加快人工智能驱动的药物发现领域的进展。]]></description>
      <guid>https://arxiv.org/abs/2406.17797</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>了解用户资料在大型语言模型个性化中的作用</title>
      <link>https://arxiv.org/abs/2406.17803</link>
      <description><![CDATA[arXiv:2406.17803v1 公告类型：交叉 
摘要：利用用户配置文件对大型语言模型 (LLM) 进行个性化处理已被证明可以提高各种任务的性能。然而，用户配置文件的确切作用及其对 LLM 的影响机制仍不清楚。本研究首先证实了用户配置文件的有效性主要归因于个性化信息而不是语义信息。此外，我们研究了用户配置文件如何影响 LLM 的个性化。在用户配置文件中，我们发现用户生成或批准的历史个性化响应在 LLM 的个性化中起着关键作用。这一发现释放了 LLM 在有限输入长度的限制内整合更多用户配置文件的潜力。至于用户配置文件的位置，我们观察到集成到输入上下文不同位置的用户配置文件对个性化的贡献并不相同。相反，更接近开头的用户配置文件对 LLM 的个性化影响更大。我们的研究结果揭示了用户资料在 LLM 个性化中的作用，并展示了整合用户资料如何影响性能，从而提供了有效利用用户资料的洞察力。]]></description>
      <guid>https://arxiv.org/abs/2406.17803</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能否使用无数据提示生成可视化效果？</title>
      <link>https://arxiv.org/abs/2406.17805</link>
      <description><![CDATA[arXiv:2406.17805v1 公告类型：交叉 
摘要：大型语言模型的最新进展彻底改变了信息访问方式，因为这些模型利用网络上可用的数据来解决复杂的查询，成为许多用户的首选信息来源。在某些情况下，查询是关于公开可用的数据的，可以通过数据可视化有效地回答。在本文中，我们研究了大型语言模型为响应此类查询提供准确数据和相关可视化的能力。具体来说，我们研究了 GPT-3 和 GPT-4 生成无数据提示的可视化的能力，其中查询不附带任何数据。我们通过将模型的结果与可视化专家创建的可视化备忘单进行比较来评估模型的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.17805</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>MOSSBench：您的多模式语言模型是否对安全查询过于敏感？</title>
      <link>https://arxiv.org/abs/2406.17806</link>
      <description><![CDATA[arXiv:2406.17806v1 公告类型：交叉 
摘要：人类容易出现认知扭曲——偏见的思维模式会导致对特定刺激做出夸张的反应，尽管是在非常不同的背景下。本文表明，先进的多模态大型语言模型 (MLLM) 表现出类似的趋势。虽然这些模型旨在在安全机制下响应查询，但它们有时会在某些视觉刺激的情况下拒绝无害的查询，而忽略其上下文的良性性质。作为调查这种行为的第一步，我们确定了三种触发现有 MLLM 过度敏感的刺激类型：夸大风险、否定危害和违反直觉的解释。为了系统地评估 MLLM 对这些刺激的过度敏感性，我们提出了多模态过度敏感基准 (MOSSBench)。该工具包包含 300 个手动收集的良性多模态查询，并由第三方审阅者 (AMT) 进行交叉验证。使用 MOSSBench 对 20 个 MLLM 进行的实证研究揭示了以下几点见解：(1)。过度敏感在 SOTA MLLM 中普遍存在，无害查询的拒绝率高达 76%。(2)。更安全的模型更过度敏感：提高安全性可能会无意中提高模型响应的谨慎性和保守性。(3)。不同类型的刺激往往会在 MLLM 响应过程的特定阶段（感知、意图推理和安全判断）导致错误。这些发现强调了对完善安全机制的需求，该机制可在谨慎性和适合情境的响应之间取得平衡，从而提高 MLLM 在实际应用中的可靠性。我们的项目可在 https://turningpoint-ai.github.io/MOSSBench/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.17806</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>通过人类反馈进行强化学习实现人工智能对齐？矛盾与局限性</title>
      <link>https://arxiv.org/abs/2406.18346</link>
      <description><![CDATA[arXiv:2406.18346v1 公告类型：新
摘要：本文批判性地评估了通过强化学习反馈 (RLxF) 方法将人工智能 (AI) 系统（尤其是大型语言模型 (LLM)）与人类价值观和意图保持一致的尝试，这些方法涉及人类反馈 (RLHF) 或人工智能反馈 (RLAIF)。具体来说，我们展示了广泛追求的诚实、无害和乐于助人的对齐目标的缺点。通过多学科的社会技术批判，我们研究了 RLxF 技术的理论基础和实际实施，揭示了它们在捕捉人类伦理复杂性和促进人工智能安全方面存在重大局限性。我们强调了 RLxF 目标中固有的紧张和矛盾。此外，我们讨论了在关于对齐和 RLxF 的讨论中往往被忽视的道德相关问题，其中包括用户友好性和欺骗性、灵活性和可解释性以及系统安全性之间的权衡。最后，我们敦促研究人员和从业人员批判性地评估 RLxF 的社会技术影响，倡导采取更细致入微、更具反思性的方法将其应用于人工智能开发。]]></description>
      <guid>https://arxiv.org/abs/2406.18346</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型估计人类色彩概念的细粒度关联</title>
      <link>https://arxiv.org/abs/2406.17781</link>
      <description><![CDATA[arXiv:2406.17781v1 公告类型：交叉 
摘要：概念（无论是抽象的还是具体的）都会在感知色彩空间中引起关联强度的分布，这会影响从对象识别到信息可视化解释等视觉认知的各个方面。虽然先前的研究假设颜色概念关联可以从跨模态经验统计结构中学习，但目前尚不清楚自然环境是否具有这种结构，如果是，学习系统是否能够在没有强大先验约束的情况下发现和利用它。我们通过研究 GPT-4（一种多模态大型语言模型）在无需任何额外训练的情况下估计类似人类的颜色概念关联的能力来解决这些问题。从人类对 71 个颜色集（涵盖感知色彩空间 (\texttt{UW-71})）和抽象程度各异的概念的颜色概念关联评分开始，我们评估了 GPT-4 生成的关联评分对预测人类评分的效果如何。 GPT-4 评分与人类评分相关，其性能可与自动从图像中估计颜色概念关联的最先进方法相媲美。GPT-4 在不同概念上的表现差异可以通过概念的颜色概念关联分布的特殊性来解释。这项研究表明，在互联网的自然环境中表达的语言和感知之间的高阶协方差包含足够的信息来支持学习类似人类的颜色概念关联，并提供了一个存在性证明，即学习系统可以在没有初始约束的情况下编码此类关联。这项研究进一步表明，GPT-4 可用于有效估计广泛概念的颜色关联分布，可能成为设计有效且直观的信息可视化的关键工具。]]></description>
      <guid>https://arxiv.org/abs/2406.17781</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>西班牙语和 LLM 基准：MMLU 是否在翻译中丢失了？</title>
      <link>https://arxiv.org/abs/2406.17789</link>
      <description><![CDATA[arXiv:2406.17789v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的评估是其持续改进过程中的关键要素，并且已经开发了许多基准来评估 LLM 在不同任务和主题中的表现。随着 LLM 在世界范围内被采用，用英语以外的语言对它们进行评估变得越来越重要。然而，大多数 LLM 基准只是使用自动化工具翻译，然后在目标语言中运行。这意味着结果不仅取决于该语言的 LLM 性能，还取决于翻译的质量。在本文中，我们考虑了著名的大规模多任务语言理解 (MMLU) 基准的情况。使用 Azure Translator 和 ChatGPT4 将基准的选定类别翻译成西班牙语并在 ChatGPT4 上运行。接下来，对结果进行处理以识别在西班牙语和英语中产生不同答案的测试项目。然后手动分析这些内容以了解自动翻译是否导致了变化。结果表明，不及格试题的很大一部分可以归因于基准翻译中的错误。这些结果有力地证明了改进英语以外语言的基准的必要性，至少需要修改试题的翻译，最好由专家根据目标语言调整测试。]]></description>
      <guid>https://arxiv.org/abs/2406.17789</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>面向通用具体代理的多模态基础世界模型</title>
      <link>https://arxiv.org/abs/2406.18043</link>
      <description><![CDATA[arXiv:2406.18043v1 公告类型：新
摘要：学习能够解决不同领域中大量任务的通用具身代理是一个长期存在的问题。强化学习 (RL) 很难扩展，因为它需要为每个任务设计复杂的奖励。相比之下，语言可以以更自然的方式指定任务。由于领域差距很大，当前的基础视觉语言模型 (VLM) 通常需要微调或其他调整才能发挥作用。然而，这些领域缺乏多模态数据，这对开发具身应用的基础模型构成了障碍。在这项工作中，我们通过提出多模态基础世界模型来克服这些问题，该模型能够将基础 VLM 的表示与 RL 的生成世界模型的潜在空间连接和对齐，而无需任何语言注释。由此产生的代理学习框架 GenRL 允许人们通过视觉和/或语言提示指定任务，将其置于具身领域的动态中，并在想象中学习相应的行为。通过大规模多任务基准测试评估，GenRL 在多个运动和操作领域表现出强大的多任务泛化性能。此外，通过引入无数据 RL 策略，它为通用具身代理的基于基础模型的 RL 奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2406.18043</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>从零开始：三重集预测用于自动知识图谱补全</title>
      <link>https://arxiv.org/abs/2406.18166</link>
      <description><![CDATA[arXiv:2406.18166v1 公告类型：新
摘要：知识图谱 (KG) 补全旨在找出 KG 中缺失的三元组。一些任务，如链接预测和实例补全，已被提出用于 KG 补全。它们是三级任务，给定缺失三元组中的一些元素来预测三元组中缺失的元素。然而，提前知道缺失三元组的某些元素并不总是现实的。在本文中，我们提出了一种新的图级自动 KG 补全任务，称为三元组集预测 (TSP)，它假设缺失三元组中的任何元素都没有给出。TSP 是给定一组已知三元组来预测一组缺失的三元组。为了正确准确地评估这项新任务，我们提出了 4 个评估指标，包括 3 个分类指标和 1 个排名指标，同时考虑了部分开放世界和封闭世界假设。此外，为了处理需要预测的大量候选三元组，我们提出了一种新颖且高效的基于子图的方法 GPHT，可以快速预测三元组集。为了公平地比较 TSP 结果，我们还提出了两类方法 RuleTensor-TSP 和 KGE-TSP，它们将现有的基于规则和嵌入的 TSP 方法作为基线。在实验中，我们根据我们提出的关系相似性部分开放世界假设，在从 Wikidata 中提取的两个数据集上评估了所提出的方法，并创建了一个完整的家族数据集，以根据封闭世界假设评估 TSP 结果。结果证明，这些方法可以成功生成一组缺失三元组并在新任务上获得合理的分数，并且 GPHT 的表现优于基线，预测时间明显缩短。实验的数据集和代码可在 https://github.com/zjukg/GPHT-for-TSP 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.18166</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>Knightian 不确定性游戏作为 AGI 测试平台</title>
      <link>https://arxiv.org/abs/2406.18178</link>
      <description><![CDATA[arXiv:2406.18178v2 公告类型：新
摘要：可以说，在 20 世纪后期和 21 世纪初期，游戏被视为人工智能的果蝇。游戏是一组令人兴奋的试验台，其解决方案（就识别最佳玩家而言）将导致机器拥有某种形式的通用智能，或者至少帮助我们获得构建智能机器的见解。在围棋、国际象棋和扑克等传统棋盘游戏以及 Atari 2600 系列等视频游戏取得令人瞩目的成功之后，显然情况并非如此。游戏已经成功受到攻击，但我们距离 AGI 开发还差得很远（或者，正如更严厉的批评者可能会说的那样，有用的 AI 开发！）。在这篇简短的愿景论文中，我们认为，要使游戏研究再次与 AGI 途径相关，我们需要能够解决游戏背景下的 \textit{Knightian 不确定性}，即代理需要能够在没有任何警告、没有先前数据、也没有模型访问的情况下随时适应游戏规则的快速变化。]]></description>
      <guid>https://arxiv.org/abs/2406.18178</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>PlaMo：在丰富的 3D 物理环境中规划和移动</title>
      <link>https://arxiv.org/abs/2406.18237</link>
      <description><![CDATA[arXiv:2406.18237v1 公告类型：新
摘要：在复杂的物理模拟世界中控制人形机器人是一项长期存在的挑战，在游戏、模拟和视觉内容创作中有着广泛的应用。在我们的设置中，给定一个丰富而复杂的 3D 场景，用户提供由目标位置和运动类型组成的指令列表。为了解决这个任务，我们提出了 PlaMo，一个场景感知路径规划器和一个强大的基于物理的控制器。路径规划器会生成一系列运动路径，考虑到场景对运动施加的各种限制，例如位置、高度和速度。作为规划器的补充，我们的控制策略会根据规划生成丰富而逼真的物理运动。我们展示了这两个模块的组合如何能够以多种形式穿越复杂景观，同时响应环境中的实时变化。视频：https://youtu.be/wWlqSQlRZ9M。]]></description>
      <guid>https://arxiv.org/abs/2406.18237</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>通过人类层面的指令实现人与物体的交互</title>
      <link>https://arxiv.org/abs/2406.17840</link>
      <description><![CDATA[arXiv:2406.17840v1 公告类型：新
摘要：智能代理需要在上下文环境中自主导航和交互，以根据人类指令执行各种日常任务。这些代理需要对世界有基本的了解，结合常识和知识来解释这些指令。此外，他们必须具备精确的低级移动和交互技能，才能执行从这些指令中得出的详细任务计划。在这项工作中，我们解决了在人类指令的指导下，在上下文环境中合成连续的人机交互以操纵大型物体的任务。我们的目标是生成同步的物体运动、全身人体运动和详细的手指运动，这些都是实现真实交互所必需的。我们的框架由一个大型语言模型 (LLM) 规划模块和一个低级运动生成器组成。我们使用 LLM 来推断空间对象关系，并设计一种方法来准确确定它们在目标场景布局中的位置和方向。此外，LLM 规划器概述了一个详细的任务计划，指定了一系列子任务。该任务规划与目标物体姿势一起作为我们低级运动生成器的输入，该生成器可在导航和交互模块之间无缝切换。我们提出了第一个完整的系统，该系统可以根据人类指令同时合成物体运动、全身运动和手指运动。我们的实验证明了我们的高级规划器在生成合理的目标布局方面的有效性，以及我们的低级运动生成器在为各种物体合成逼真的交互方面的有效性。请参阅我们的项目页面以了解更多结果：https://hoifhli.github.io/。]]></description>
      <guid>https://arxiv.org/abs/2406.17840</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>规划是什么类型的推理？</title>
      <link>https://arxiv.org/abs/2406.17863</link>
      <description><![CDATA[arXiv:2406.17863v1 公告类型：新
摘要：概率图形模型有多种类型的推理，例如边际、最大后验，甚至边际最大后验。研究人员在谈论“规划即推理”时指的是哪一种？文献中没有一致性，使用了不同类型的推理，并且它们进行规划的能力与特定的近似值或附加约束进一步纠缠在一起。在这项工作中，我们使用变分框架来表明，所有常用的推理类型都对应于变分问题中熵项的不同权重，并且规划与一组不同的权重完全对应。这意味着变分推理的所有技巧都可以很容易地应用于规划。我们开发了一种循环信念传播的模拟，使我们能够在分解状态马尔可夫决策过程中执行近似规划，而不会因指数级大的状态空间而产生难解性。变分视角表明，之前的规划推理类型仅适用于随机性较低的环境，并允许我们根据每种类型的优点对其进行描述，从而将推理类型与其实际使用所需的额外近似值区分开来。我们在国际规划竞赛中提出的合成 MDP 和任务上对这些结果进行了实证验证。]]></description>
      <guid>https://arxiv.org/abs/2406.17863</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>即时消除偏见：以解释为导向的机器学习系统决策的人工监督</title>
      <link>https://arxiv.org/abs/2406.17906</link>
      <description><![CDATA[arXiv:2406.17906v1 公告类型：新
摘要：机器学习系统在招聘、金融和医疗保健等关键领域得到广泛采用，这引发了人们对其基于受保护属性进行歧视性决策的可能性的担忧。虽然确保开发过程中的公平性至关重要，但它们使部署的机器学习系统在运行过程中容易出现歧视。为了解决这一差距，我们提出了一个新颖的框架，用于实时跟踪和纠正部署的机器学习系统中的歧视。利用反事实解释，该框架持续监控机器学习系统的预测并标记歧视性结果。标记后，与原始预测和反事实替代方案相关的事后解释将呈现给人类审阅者进行实时干预。这种人机互动方法使审阅者能够接受或推翻机器学习系统的决策，从而实现动态环境下公平、负责任的机器学习操作。虽然需要进一步验证和改进，但该框架为减轻歧视和建立对广泛领域部署的机器学习系统的信任提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2406.17906</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>迈向科学的外皮层</title>
      <link>https://arxiv.org/abs/2406.17809</link>
      <description><![CDATA[arXiv:2406.17809v1 公告类型：新
摘要：人工智能 (AI) 方法有望彻底改变智力工作，生成式 AI 可实现文本分析、文本生成和简单决策或推理的自动化。对科学的影响才刚刚开始，但机会是巨大的，因为科学研究从根本上依赖于认知工作的扩展链。在这里，我们回顾了代理 AI 系统的最新进展，并讨论了如何扩展这些方法以对科学产生更大的影响。我们建议开发外皮层，即人类认知的合成延伸。科学外皮层可以设计为一群 AI 代理，每个代理单独简化特定的研究人员任务，并且它们的相互交流会导致突发行为，从而大大扩展研究人员的认知和意志。]]></description>
      <guid>https://arxiv.org/abs/2406.17809</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能预言机在科学领域的探索</title>
      <link>https://arxiv.org/abs/2406.17836</link>
      <description><![CDATA[arXiv:2406.17836v1 公告类型：新
摘要：诺贝尔奖获得者 Philip Anderson 和 Elihu Abrahams 曾经说过，“即使机器确实为常规科学做出了贡献，我们也看不到它们能够创造库恩革命并从而建立新物理定律的机制。” 在本观点中，我们借鉴了科学哲学和人工智能 (AI) 的见解，提出了产生革命性数学理论的这种机制的必要条件。人工智能的最新进展表明，机器满足所提出的必要条件可能是合理的；因此，我们提出的必要条件也定义了一项登月挑战。我们还提出了数学理论可理解性的启发式定义，以加速机器理论家的发展。]]></description>
      <guid>https://arxiv.org/abs/2406.17836</guid>
      <pubDate>Fri, 28 Jun 2024 03:23:15 GMT</pubDate>
    </item>
    </channel>
</rss>