<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Markov Senior——学习马尔可夫初级文法来生成用户指定的内容</title>
      <link>https://arxiv.org/abs/2408.05959</link>
      <description><![CDATA[arXiv:2408.05959v1 公告类型：新
摘要：Markov Junior 是一种概率编程语言，用于跨各个领域的程序内容生成。然而，它依赖于手工制作和调整的概率规则集（也称为语法），这带来了严重的瓶颈，与允许从示例中进行规则学习的方法不同。在本文中，我们提出了一种新颖的解决方案，即引入一种基于遗传编程的优化框架来自动学习分层规则集。我们提出的方法“Markov Senior”专注于从单个输入样本中提取位置和距离关系，以构建 Markov Junior 使用的概率规则。使用基于 Kullback-Leibler 散度的适应度测量，我们搜索语法以生成与给定样本一致的内容。为了增强可扩展性，我们引入了一种分而治之的策略，可以高效地生成大规模内容。我们通过生成基于图像的内容和超级马里奥关卡的实验验证了我们的方法，证明了其灵活性和有效性。通过这种方式，“高级马尔可夫”允许将初级马尔可夫更广泛地应用于可能有示例但无法设计生成规则集的任务。]]></description>
      <guid>https://arxiv.org/abs/2408.05959</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:13 GMT</pubDate>
    </item>
    <item>
      <title>BI-MDRG：在多模式对话响应生成中桥接图像历史</title>
      <link>https://arxiv.org/abs/2408.05926</link>
      <description><![CDATA[arXiv:2408.05926v1 公告类型：新
摘要：多模态对话响应生成 (MDRG) 是一项最近提出的任务，其中模型需要根据对话上下文生成文本、图像或两者混合的响应。由于缺乏专门用于此任务的大规模数据集以及利用强大的预训练模型的好处，以前的工作依赖于文本模态作为模型图像输入和输出的中间步骤，而不是采用端到端方法。然而，这种方法可能会忽略有关图像的关键信息，阻碍 1) 基于图像的文本响应和 2) 图像响应中对象的一致性。在本文中，我们提出了 BI-MDRG，它连接了响应生成路径，以便利用图像历史信息来增强文本响应与图像内容的相关性以及连续图像响应中对象的一致性。通过对多模态对话基准数据集的大量实验，我们表明 BI-MDRG 可以有效提高多模态对话的质量。此外，认识到评估多模式对话中图像一致性的基准数据集中的差距，我们创建了一组精选的 300 个对话，并进行注释以跟踪对话中的对象一致性。]]></description>
      <guid>https://arxiv.org/abs/2408.05926</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:12 GMT</pubDate>
    </item>
    <item>
      <title>利用基于知识图谱的类人记忆系统解决部分可观察的马尔可夫决策过程</title>
      <link>https://arxiv.org/abs/2408.05861</link>
      <description><![CDATA[arXiv:2408.05861v1 公告类型：新
摘要：人类在任何时候都只能观察其环境的一部分，但由于我们的长期记忆系统，仍然可以做出复杂的长期决策。为了测试人工智能如何学习和利用其长期记忆系统，我们开发了一个部分可观察马尔可夫决策过程 (POMDP) 环境，其中代理必须在迷宫中导航时回答问题。该环境完全基于知识图谱 (KG)，其中隐藏状态是动态 KG。KG 既可人读又可机读，因此很容易看到代理记住和忘记的内容。我们训练和比较具有不同记忆系统的代理，以阐明人类大脑在管理自己的记忆系统时的工作方式。通过将给定的学习目标重新用于学习记忆管理策略，我们能够捕捉到最可能的信念状态，这不仅可以解释，而且可以重复使用。]]></description>
      <guid>https://arxiv.org/abs/2408.05861</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:11 GMT</pubDate>
    </item>
    <item>
      <title>城市区域预训练和提示：基于图的方法</title>
      <link>https://arxiv.org/abs/2408.05920</link>
      <description><![CDATA[arXiv:2408.05920v1 公告类型：新
摘要：城市区域表示对于各种城市下游任务至关重要。然而，尽管方法激增且取得了成功，但获取一般的城市区域知识并适应不同的任务仍然具有挑战性。以前的工作往往忽略了实体之间的空间结构和功能布局，限制了它们捕获跨区域可转移知识的能力。此外，这些方法难以有效地适应特定的下游任务，因为它们没有充分解决不同下游任务所需的独特特征和关系。在本文中，我们提出了一种基于$\textbf{G}$图的$\textbf{U}$rban $\textbf{R}$egion $\textbf{P}$re-training 和 $\textbf{P}$rompting 框架 ($\textbf{GURPP}$) 用于区域表示学习。具体而言，我们首先构建一个集成详细空间实体数据的城市区域图，以实现更有效的城市区域表示。然后，我们开发了一个以子图为中心的城市区域预训练模型，以捕捉实体之间异构且可转移的交互模式。为了进一步增强这些嵌入对不同任务的适应性，我们设计了两种基于图的提示方法来整合显式/隐藏的任务知识。对各种城市区域预测任务和不同城市的大量实验证明了我们的 GURPP 框架的卓越性能。实现可在此存储库中找到：https://anonymous.4open.science/r/GURPP。]]></description>
      <guid>https://arxiv.org/abs/2408.05920</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:11 GMT</pubDate>
    </item>
    <item>
      <title>可解释性的认知革命：从解释行为到解释表征和算法</title>
      <link>https://arxiv.org/abs/2408.05859</link>
      <description><![CDATA[arXiv:2408.05859v1 公告类型：新
摘要：长期以来，人工神经网络一直被理解为“黑匣子”：尽管我们知道它们的计算图和学习参数，但它们执行的这些权重和函数所编码的知识本质上并不是可解释的。因此，从深度学习的早期开始，人们就一直在努力解释这些模型的行为并从内部理解它们；最近，机械可解释性 (MI) 已成为一个独特的研究领域，研究大型语言模型等基础模型学习到的特征和隐式算法。在这项工作中，我们旨在将 MI 置于认知科学的背景下，认知科学长期以来一直在研究和解释人类大脑等“黑匣子”智能系统的行为时遇到类似的问题。我们利用认知科学历史上的几个重要思想和发展来解开 MI 中的不同目标并指明前进的道路。首先，我们认为，当前的方法已经成熟，可以促进深度学习解释的转变，这与 20 世纪心理学的“认知革命”相呼应，这场革命将人类心理学的研究从纯粹的行为主义转向了心理表征和处理。其次，我们提出了一个反映计算神经科学中关键相似点的分类法，以描述 MI 研究的两大类，即语义解释（学习和使用哪些潜在表征）和算法解释（对表征执行哪些操作），以阐明它们不同的目标和研究对象。最后，我们阐述了这两个类别中各种方法之间的相似之处和区别，分析了代表性作品各自的优缺点，阐明了基本假设，概述了关键挑战，并讨论了将这些解释模式统一在一个共同框架下的可能性。]]></description>
      <guid>https://arxiv.org/abs/2408.05859</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:10 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习进行因果发现，对交付风险进行根本原因归因</title>
      <link>https://arxiv.org/abs/2408.05860</link>
      <description><![CDATA[arXiv:2408.05860v1 公告类型：新
摘要：本文通过将因果发现与强化学习相结合，提出了一种对供应链内交付风险的根本原因进行归因的新方法。随着供应链变得越来越复杂，传统的根本原因分析方法难以捕捉各种因素之间错综复杂的相互关系，往往导致虚假相关性和次优决策。我们的方法通过利用因果发现来识别操作变量之间的真正因果关系，并利用强化学习来迭代细化因果图来解决这些挑战。该方法能够准确识别延迟交付的关键驱动因素，例如运输方式和交付状态，并为优化供应链绩效提供可行的见解。我们将我们的方法应用于现实世界的供应链数据集，证明了它在揭示交付延迟的根本原因和提供缓解这些风险的策略方面的有效性。这些发现对于提高供应链的运营效率、客户满意度和整体盈利能力具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2408.05860</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:10 GMT</pubDate>
    </item>
    <item>
      <title>规则挖掘的神经符号方法</title>
      <link>https://arxiv.org/abs/2408.05773</link>
      <description><![CDATA[arXiv:2408.05773v1 公告类型：新
摘要：在本章中，我们将讨论规则挖掘问题，首先介绍基本背景信息，包括规则质量的衡量标准。然后，我们将探讨各种规则挖掘方法，这些方法分为三类：归纳逻辑编程、路径采样和泛化以及线性编程。接下来，我们将深入研究神经符号方法，涵盖深度学习与规则的集成、嵌入在规则学习中的使用以及大型语言模型在规则学习中的应用等主题。]]></description>
      <guid>https://arxiv.org/abs/2408.05773</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:09 GMT</pubDate>
    </item>
    <item>
      <title>HateSieve：用于检测和细分多模态模因中的仇恨内容的对比学习框架</title>
      <link>https://arxiv.org/abs/2408.05794</link>
      <description><![CDATA[arXiv:2408.05794v1 公告类型：新
摘要：随着大型多模态模型 (LMM) 的兴起及其在生成和解释复杂内容方面的广泛应用，传播有偏见和有害模因的风险仍然很大。当前的安全措施通常无法检测到“混杂模因”中巧妙整合的仇恨内容。为了解决这个问题，我们引入了 \textsc{HateSieve}，这是一个旨在增强模因中仇恨元素检测和分割能力的新框架。 \textsc{HateSieve} 具有一个新颖的对比模因生成器，可创建语义配对的模因、用于对比学习的定制三元组数据集，以及一个图像文本对齐模块，可生成上下文感知嵌入以实现准确的模因分割。在仇恨模因数据集上进行的经验实验表明，\textsc{HateSieve} 不仅在可训练参数更少的情况下在性能上超越了现有的 LMM，而且还提供了一种精确识别和隔离仇恨内容的强大机制。\textcolor{red}{警告：包含仇恨言论的学术讨论；建议观众谨慎观看。}]]></description>
      <guid>https://arxiv.org/abs/2408.05794</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Delta-Engine 缩放虚拟世界</title>
      <link>https://arxiv.org/abs/2408.05842</link>
      <description><![CDATA[arXiv:2408.05842v1 Announce Type: new 
摘要：本文重点关注 \emph{虚拟世界}，即人们可以生活的网络空间。理想的虚拟世界与我们的现实世界非常相似。其中一个关键方面是其不断发展的性质，反映在个人成长并进而影响客观世界的能力上。这种动态是不可预测的，超出了现有系统的范围。为此，我们提出了一种称为 \emph{Delta-Engine} 的特殊引擎来驱动这个虚拟世界。$\Delta$ 将世界的演变与引擎的扩展联系起来。delta 引擎由基本引擎和神经代理组成。给定一个观察结果，代理通过 \emph{增量预测} 过程基于基本引擎生成新代码。
本文对 delta 引擎进行了全栈介绍。 delta 引擎的关键特性是它可扩展到世界上未知的元素，从技术上讲，它源于神经代理和基础引擎的完美协同工作，以及与高质量数据的对齐。我们提出了一种面向引擎的微调方法，将基础引擎嵌入到代理中。然后，我们讨论了一种人机协作设计流程，以高效地生成新颖有趣的数据。最后，我们提出了三个评估原则来全面评估 delta 引擎的性能：朴素评估、增量评估和对抗性评估。我们的代码、数据和模型在 \url{https://github.com/gingasan/delta-engine} 上开源。]]></description>
      <guid>https://arxiv.org/abs/2408.05842</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:09 GMT</pubDate>
    </item>
    <item>
      <title>Top Pass：通过 Pass@k-Maximized Code Ranking 改进代码生成</title>
      <link>https://arxiv.org/abs/2408.05715</link>
      <description><![CDATA[arXiv:2408.05715v1 公告类型：新
摘要：最近，大型语言模型 (LLM) 的重大进步极大地增强了代码生成。然而，这种基于 LLM 的代码生成方法在面对复杂问题时仍然难以在几次尝试中生成无错误的代码。为了解决这个问题，流行的策略是对大量候选程序进行抽样，希望其中任何一个都能起作用。然而，代码生成系统的用户通常希望通过审查或测试少量代码候选来找到正确的程序。否则，系统将毫无用处。在本文中，我们提出了 Top Pass，这是一种代码排名方法，可从大量候选中识别出潜在的正确解决方案。Top Pass 直接优化 pass@k 损失函数，提高候选列表顶部的质量。这使用户能够在尽可能少的尝试中找到正确的解决方案。四个基准测试的实验结果表明，我们的 Top Pass 方法通过产生更好的排名结果提高了代码生成模型的可用性，特别是与最先进的排名方法相比，在 CodeContests 上的 pass@1 实现了 32.9% 的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2408.05715</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:08 GMT</pubDate>
    </item>
    <item>
      <title>通过知识蒸馏实现低维联合知识图谱嵌入</title>
      <link>https://arxiv.org/abs/2408.05748</link>
      <description><![CDATA[arXiv:2408.05748v1 公告类型：新
摘要：联合知识图谱嵌入 (FKGE) 旨在促进跨多个客户端从分布式知识图谱 (KG) 中协作学习实体和关系嵌入，同时保护数据隐私。训练具有更高维度的 FKGE 模型通常受到青睐，因为它们有可能实现卓越的性能。然而，高维嵌入在存储资源和推理速度方面带来了重大挑战。与传统的 KG 嵌入方法不同，FKGE 涉及多轮客户端-服务器通信，其中通信效率至关重要。现有的传统 KG 嵌入压缩方法可能不直接适用于 FKGE，因为它们通常需要多次模型训练，这可能会产生大量的通信成本。在本文中，我们提出了一个基于知识蒸馏 (KD) 的轻量级组件，名为 FedKD，专门针对 FKGE 方法量身定制。在客户端本地训练期间，FedKD 使用 KL 散度损失使低维学生模型模仿高维教师模型的三元组分数分布。与传统 KD 方法不同，FedKD 自适应地学习温度来缩放正三元组的分数，并使用预定义的温度分别调整相应负三元组的分数，从而缓解教师过度自信问题。此外，我们动态调整 KD 损失的权重以优化训练过程。在三个数据集上进行的大量实验证明了 FedKD 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.05748</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:08 GMT</pubDate>
    </item>
    <item>
      <title>针对扩展形式游戏的上下文开发工具</title>
      <link>https://arxiv.org/abs/2408.05575</link>
      <description><![CDATA[arXiv:2408.05575v1 公告类型：新
摘要：纳什均衡 (NE) 因其稳定性而成为博弈论中广泛采用的解决方案概念。然而，我们观察到 NE 策略可能并不总是产生最佳结果，尤其是对不遵守 NE 策略的对手。基于这一观察，我们提出了一个新的游戏解决问题：我们能否学习一个可以利用任何对手（甚至是 NE）来最大化自身效用的模型？在这项工作中，我们首次尝试通过情境学习来研究这个问题。具体来说，我们引入了一种新方法，即情境利用器 (ICE)，来训练一个可以充当游戏中的任何玩家并通过情境学习完全自适应地利用对手的单一模型。我们的 ICE 算法包括生成不同的对手策略、通过强化学习算法收集交互式历史训练数据以及在精心设计的课程学习框架内训练基于变压器的代理。最后，全面的实验结果验证了我们的 ICE 算法的有效性，展示了其在上下文中学习的能力，可以利用任何未知对手，从而积极回答我们最初的游戏解决问题。]]></description>
      <guid>https://arxiv.org/abs/2408.05575</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:07 GMT</pubDate>
    </item>
    <item>
      <title>并行贪婪最佳优先搜索的单独生成和评估</title>
      <link>https://arxiv.org/abs/2408.05682</link>
      <description><![CDATA[arXiv:2408.05682v1 公告类型：新
摘要：贪婪最佳优先搜索 (GBFS) 的并行化一直很困难，因为直接并行化会导致搜索行为与顺序 GBFS 有很大不同，探索顺序 GBFS 不会使用任何决胜策略探索的状态。最近的研究提出了一类并行 GBFS 算法，该算法将搜索限制在对 BTS (BTS) 的探索上，BTS 是 GBFS 在某些决胜策略下可以扩展的状态集。然而，强制执行此约束的成本很高，因为这种 BTS 约束算法被迫花费大量时间等待，以便只有保证在 BTS 中的状态才会扩展。我们提出了一种并行搜索的改进方法，将状态生成和状态评估分离，并显着提高状态评估率，从而提高搜索性能。]]></description>
      <guid>https://arxiv.org/abs/2408.05682</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:07 GMT</pubDate>
    </item>
    <item>
      <title>可解释人工智能的 MCTS 结构与简化</title>
      <link>https://arxiv.org/abs/2408.05488</link>
      <description><![CDATA[arXiv:2408.05488v1 公告类型：新
摘要：复杂的顺序决策规划问题，覆盖无限状态空间，已被证明可以通过 AlphaZero 类型的算法解决。这种训练神经模型同时用蒙特卡洛树搜索算法模拟未来预测的方法被证明适用于现实生活中的规划问题。因此，与由此产生的行为策略交互的工程师和用户可能会受益于离线或在线获得有关这些规划者决策的自动解释。本文重点介绍蒙特卡洛树搜索数据结构中的信息。鉴于其构造，这些信息包含了顺序决策算法的大部分推理，对于其可解释性至关重要。我们展示了使用信息理论工具简化和减少蒙特卡洛树搜索和提取信息的新方法。这些信息可以直接用于构建人类可理解的解释。我们展示了基本可解释性量可以用有限的额外计算成本来计算，作为蒙特卡洛树搜索构建过程的一个组成部分。我们专注于理论和算法方面，并提供示例，说明如何使用此处介绍的方法构建人类可理解的解释。]]></description>
      <guid>https://arxiv.org/abs/2408.05488</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:06 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的元认知近视</title>
      <link>https://arxiv.org/abs/2408.05568</link>
      <description><![CDATA[arXiv:2408.05568v1 公告类型：新
摘要：大型语言模型 (LLM) 表现出潜在的有害偏见，这些偏见会强化文化固有的刻板印象、模糊道德判断或放大对多数群体的积极评价。先前的解释主要将 LLM 中的偏见归因于人类注释者和训练数据的选择。因此，它们通常通过自下而上的方法来解决，例如强化学习或去偏语料库。然而，这些方法仅通过间接影响模型架构来处理 LLM 偏见的影响，但并未解决计算过程中的根本原因。在这里，我们提出元认知近视作为一种认知生态框架，可以解释一系列已建立和新出现的 LLM 偏见，并提供解决强大但脆弱的工具中问题的杠杆。我们的理论框架认为，缺乏元认知的两个组成部分，即监控和控制，会导致 LLM 中出现五种元认知短视症状：整合无效标记和嵌入、易受冗余信息影响、忽视条件计算中的基准率、基于频率的决策规则以及嵌套数据结构的不适当的高阶统计推断。因此，LLM 会产生错误的输出，影响到人类日常的高风险决策。通过在 LLM 中引入元认知调节过程，工程师和科学家可以为这些偏见的根本原因开发出精确的补救措施。我们的理论为有缺陷的人机交互提供了新的见解，并引发了人们对组织结构中越来越多、不谨慎地实施 LLM 的道德担忧。]]></description>
      <guid>https://arxiv.org/abs/2408.05568</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:06 GMT</pubDate>
    </item>
    <item>
      <title>重新审视多模式法学硕士评估</title>
      <link>https://arxiv.org/abs/2408.05334</link>
      <description><![CDATA[arXiv:2408.05334v1 公告类型：新 
摘要：随着多模态大型语言模型 (MLLM) 的出现，用于视觉问答 (VQA) 和指称表达理解的数据集出现了复苏。然而，用于评估 MLLM 的最流行的数据集是一些最早创建的数据集，它们存在许多已知问题，包括极端偏见、虚假相关性以及无法进行细粒度分析。在本文中，我们率先在旨在解决早期 MLLM 弱点的数据集上评估了最近的 MLLM（LLaVA 1.5、LLaVA-NeXT、BLIP2、InstructBLIP、GPT-4V 和 GPT-4o）。我们评估了三个 VQA 数据集：1) TDIUC，允许对 12 种问题类型进行细粒度分析；2) TallyQA，它有简单和复杂的计数问题； 3) DVQA，需要光学字符识别才能理解图表。我们还研究了 VQDv1，这是一个需要识别满足给定查询的所有图像区域的数据集。我们的实验揭示了许多以前未曾报道过的 MLLM 的弱点。我们的代码集成到广泛使用的 LAVIS 框架中，用于 MLLM 评估，从而能够快速评估未来的 MLLM。项目网页：https://kevinlujian.github.io/MLLM_Evaluations/]]></description>
      <guid>https://arxiv.org/abs/2408.05334</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:05 GMT</pubDate>
    </item>
    <item>
      <title>SHIELD：电动汽车电池供应链中断预测分析的 LLM 驱动模式归纳</title>
      <link>https://arxiv.org/abs/2408.05357</link>
      <description><![CDATA[arXiv:2408.05357v1 公告类型：新
摘要：电动汽车 (EV) 电池供应链易受中断影响，因此需要高级预测分析。我们提出了 SHIELD（基于模式的 EV 供应链中断分层归纳），这是一个将大型语言模型 (LLM) 与领域专业知识相结合的系统，用于 EV 电池供应链风险评估。SHIELD 结合了：(1) LLM 驱动的模式学习来构建一个全面的知识库，(2) 一个中断分析系统，利用微调语言模型进行事件提取、多维相似性匹配进行模式匹配，以及具有逻辑约束的图卷积网络 (GCN) 进行预测，以及 (3) 一个用于可视化结果并结合专家反馈以增强决策的交互式界面。 SHIELD 对来自 365 个来源（2022-2023 年）的 12,070 个段落进行了评估，在中断预测方面优于基线 GCN 和 LLM+prompt 方法（例如 GPT-4o）。这些结果证明了 SHIELD 在将 LLM 功能与领域专业知识相结合以增强供应链风险评估方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.05357</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:05 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉语言模型进行多智能体规划</title>
      <link>https://arxiv.org/abs/2408.05478</link>
      <description><![CDATA[arXiv:2408.05478v1 公告类型：新
摘要：大型语言模型 (LLM) 和视觉语言模型 (VLM) 因其在各个领域和任务中不断提高的性能和应用而受到越来越多的关注。然而，LLM 和 VLM 可能会产生错误的结果，尤其是在需要深入了解问题领域时。例如，当需要同时进行规划和感知时，这些模型通常会因为难以合并多模态信息而陷入困境。为了解决这个问题，通常使用经过微调的模型，并在代表环境的专门数据结构上进行训练。这种方法的有效性有限，因为它会使处理环境变得过于复杂。在本文中，我们提出了一种用于具体任务规划的多智能体架构，该架构无需特定数据结构作为输入即可运行。相反，它使用环境的单一图像，通过利用常识知识来处理自由格式域。我们还介绍了一种新颖的全自动评估程序 PG2S，旨在更好地评估计划的质量。我们使用广受认可的 ALFRED 数据集验证了我们的方法，将 PG2S 与现有的 KAS 指标进行比较，以进一步评估生成的计划的质量。]]></description>
      <guid>https://arxiv.org/abs/2408.05478</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:05 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的电动汽车充电行为模拟代理框架</title>
      <link>https://arxiv.org/abs/2408.05233</link>
      <description><![CDATA[arXiv:2408.05233v1 公告类型：新
摘要：本文介绍了一种基于 LLM 的新代理框架，用于模拟电动汽车 (EV) 充电行为，整合用户偏好、心理特征和环境因素以优化充电过程。该框架包含多个模块，可实现复杂的自适应模拟。动态决策由持续的反思和记忆更新支持，确保与用户期望保持一致并提高效率。该框架生成个性化用户资料和实时决策的能力为城市电动汽车充电管理提供了重大进步。未来的工作可以集中在整合更复杂的场景和扩展数据源以提高预测准确性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.05233</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:04 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯预言机可以防止代理造成伤害吗？</title>
      <link>https://arxiv.org/abs/2408.05284</link>
      <description><![CDATA[arXiv:2408.05284v1 公告类型：新
摘要：有没有一种方法可以基于机器学习方法设计强大的人工智能系统，以满足概率安全保证？为了获得适用于每种情况的概率保证，我们考虑估计违反给定安全规范的概率的上下文相关界限。这种风险评估需要在运行时执行，以提供对人工智能危险行为的保护。注意到关于世界的不同合理假设可能会产生非常不同的结果，而且由于我们不知道哪一个是正确的，我们得出了在真实但未知的假设下预测的安全违规概率的界限。这样的界限可以用来拒绝潜在的危险行为。我们的主要结果涉及寻找谨慎但合理的假设，这些假设是通过涉及假设的贝叶斯后验的最大化获得的。我们考虑了该结果的两种形式，即独立同分布的情况和非独立同分布的情况，并得出了将这些理论结果转化为实用的 AI 护栏的开放性问题。]]></description>
      <guid>https://arxiv.org/abs/2408.05284</guid>
      <pubDate>Wed, 14 Aug 2024 03:25:04 GMT</pubDate>
    </item>
    </channel>
</rss>