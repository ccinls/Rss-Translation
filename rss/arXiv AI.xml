<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 31 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>百家：大型中国历史人物角色扮演代理语料库</title>
      <link>https://arxiv.org/abs/2412.20024</link>
      <description><![CDATA[arXiv:2412.20024v1 公告类型：新
摘要：我们引入了一个全面的大型角色扮演代理语料库，称为 BaiJia，其中包含各种中国历史人物。该语料库值得注意的是，它是低资源数据的开创性汇编，可用于大型语言模型 (LLM) 以参与 AI 驱动的历史角色扮演代理。BaiJia 解决了不同形式和模态的碎片化历史文本记录方面的挑战，整合了各种人物的信息，包括他们的传记、文学、家庭关系、历史事件等。我们进行了广泛的实验，以证明我们的 BaiJia 代理语料库在增强各种基础 LLM 的角色扮演能力方面的有效性，并促进了 LLM 在历史角色扮演任务背景下的开发和评估。代理语料库可在 baijia.online 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.20024</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过共享情景记忆进行的高保真社交学习可通过助记符融合增强协作觅食</title>
      <link>https://arxiv.org/abs/2412.20271</link>
      <description><![CDATA[arXiv:2412.20271v1 公告类型：新
摘要：社会学习是文化进化的基石，它使个人能够通过观察和模仿他人来获取知识。其功效的核心是情景记忆，它编码特定的行为序列以促进学习和决策。本研究探讨了集体觅食中情景记忆与社会学习之间的相互关系。使用能够共享情景记忆中存储的完整行为序列的顺序情景控制 (SEC) 代理，我们研究了社会学习的频率和保真度变化如何影响协作觅食表现。此外，我们分析了社会学习对整个群体中情景记忆的内容和分布的影响。高保真度的社会学习可以持续提高资源收集效率和分配，并且好处在记忆长度内持续存在。相比之下，低保真度学习无法胜过非社会学习，传播了多样但无效的助记模式。使用助记指标的新分析表明，高保真度的社会学习也促进了助记符组的对齐和公平的资源分配，而低保真度条件则增加了助记符的多样性，但并没有转化为绩效提升。此外，我们确定了此任务中情景记忆长度的最佳范围，超过此范围，绩效就会停滞。这些发现强调了社会学习对助记符组对齐和分布的关键影响，并强调了神经计算模型在探索推动文化进化的认知机制方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.20271</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可靠的法律人工智能综合框架：结合专业专家系统和自适应细化</title>
      <link>https://arxiv.org/abs/2412.20468</link>
      <description><![CDATA[arXiv:2412.20468v1 公告类型：新
摘要：本文讨论了人工智能 (AI) 在法律行业中不断演变的角色，重点关注其简化文件审查、研究和合同起草等任务的潜力。然而，挑战依然存在，特别是人工智能模型中出现“幻觉”，它们会产生不准确或误导性的信息，从而破坏其在法律背景下的可靠性。为了解决这个问题，本文提出了一个新颖的框架，将专家系统与基于知识的架构相结合，以提高人工智能驱动的法律服务的精确度和上下文相关性。该框架利用专门的模块，每个模块都专注于特定的法律领域，并结合结构化的操作指南来增强决策能力。此外，它还利用先进的人工智能技术，如检索增强生成 (RAG)、知识图谱 (KG) 和从人类反馈中进行强化学习 (RLHF) 来提高系统的准确性。所提出的方法比现有的 AI 模型有显著改进，在法律任务中表现出色，并提供了可扩展的解决方案，以提供更易于访问且价格合理的法律服务。本文还概述了法律领域 AI 应用未来研究的方法、系统架构和有前景的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.20468</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>规划、生活和判断：基于多代理法学硕士的循环城市规划框架</title>
      <link>https://arxiv.org/abs/2412.20505</link>
      <description><![CDATA[arXiv:2412.20505v1 公告类型：新
摘要：城市再生在城市化背景下提出了重大挑战，需要采用适应性方法来应对不断变化的需求。利用大型语言模型 (LLM) 的进步，我们提出了循环城市规划 (CUP)，这是一种新范式，可以在闭环中不断生成、评估和完善城市规划。具体来说，我们基于多智能体 LLM 的框架由三个关键部分组成：(1) 规划，其中 LLM 智能体根据上下文数据生成和完善城市规划；(2) 生活，其中智能体模拟居民的行为和互动，模拟城市环境中的生活；(3) 判断，包括评估计划的有效性并提供迭代反馈以进行改进。循环过程可以实现动态且响应迅速的规划方法。在真实世界数据集上进行的实验证明了我们的框架作为持续且自适应的规划过程的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.20505</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强化和模仿学习对连续任务的内在动机</title>
      <link>https://arxiv.org/abs/2412.20573</link>
      <description><![CDATA[arXiv:2412.20573v1 公告类型：新
摘要：这项发展认知机器人领域的工作旨在设计一个连接强化学习和模仿学习的新领域，并建立学习代理在导师指导下学习多项任务（包括连续任务）的内在动机模型。主要贡献是提出了一种基于经验进步的内在动机的通用公式，让学习代理通过主动选择简单或连续任务的学习策略来自动选择其学习课程：学习哪个任务、在自主探索或模仿学习之间、在低级动作或任务分解之间、在多个导师之间。独创性在于设计一个学习者，它不仅可以被动地从导师提供的数据中受益，还可以主动选择何时请求辅导以及询问什么和向谁询问。因此，学习者对辅导质量的适应性更强，并且用更少的演示更快地学习。我们开发了社会引导的内在动机框架，使用机器学习算法通过利用人类演示的普遍性，以被动方式或主动方式学习多项任务，通过向最佳导师请求演示来完成简单和组合子任务。后者依赖于为构建过程提出的子任务组合表示，该表示应通过用于分析人类运动和日常生活活动的观察过程的表示进行细化。从与导师进行类似语言的交流的角度出发，我们研究了连续感觉运动空间和使用内在动机的任务的符号表示的出现。我们在强化学习框架内提出了一种奖励函数，用于与导师互动，以实现多任务学习中的自动课程学习。]]></description>
      <guid>https://arxiv.org/abs/2412.20573</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用更柔和的替代方法预测长期顺序策略值</title>
      <link>https://arxiv.org/abs/2412.20638</link>
      <description><![CDATA[arXiv:2412.20638v1 公告类型：新
摘要：在教育、医疗保健和在线商务中进行政策评估可能具有挑战性，因为它可能需要等待大量时间才能在期望的关注范围内观察结果。虽然在某些情况下可以使用离线评估方法根据历史数据估计新决策策略的性能，但当新策略涉及新操作或在可能具有不同动态的新决策过程中运行时，这种方法会遇到困难。在这里，我们考虑如何仅使用新策略的短期数据和不同行为策略的历史全视野数据来估计新决策策略的全视野值。我们为此设置引入了两个新的估计量，包括一个双重稳健估计量，并对其属性进行了正式分析。我们对艾滋病毒治疗和败血症治疗两个现实模拟器的实证结果表明，我们的方法通常可以比等待整个视野快十倍地提供新决策政策的信息估计，强调可能快速识别涉及新行动的新决策政策是否比现有的过去政策更好或更差。]]></description>
      <guid>https://arxiv.org/abs/2412.20638</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HUNYUANPROVER：一种可扩展的数据合成框架和用于自动定理证明的引导树搜索</title>
      <link>https://arxiv.org/abs/2412.20735</link>
      <description><![CDATA[arXiv:2412.20735v1 公告类型：新
摘要：我们介绍了 HunyuanProver，这是一种从 Hunyuan 7B 微调而来的语言模型，用于使用 LEAN4 进行交互式自动定理证明。为了缓解数据稀疏性问题，我们设计了一个可扩展的框架，以低成本迭代合成数据。此外，引导树搜索算法旨在实现证明器的有效“系统 2 思维”。HunyuanProver 在主要基准测试中实现了最先进 (SOTA) 的性能。具体来说，它在 miniF2F 测试中的通过率为 68.4%，而目前的 SOTA 结果为 65.9%。它在 miniF2F 测试中证明了 4 个 IMO 语句（imo_1960_p2、imo_1962_p2}、imo_1964_p2 和 imo_1983_p6）。为了造福社区，我们将开源一个包含 30k 个合成实例的数据集，其中每个实例包含自然语言中的原始问题、通过自动形式化转换后的语句以及 HunyuanProver 的证明。]]></description>
      <guid>https://arxiv.org/abs/2412.20735</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Wikidata 架构的 LLM 基于本体的自动知识图谱构建</title>
      <link>https://arxiv.org/abs/2412.20942</link>
      <description><![CDATA[arXiv:2412.20942v1 公告类型：新 
摘要：我们提出了一种基于本体的知识图谱 (KG) 构建方法，该方法使用知识库上的大型语言模型 (LLM)。通过在知识库上生成能力问题 (CQ) 来发现知识范围，从 CQ 中提取关系，并尝试用 Wikidata 中的对应关系替换等效关系，从而创建本体。为了确保生成的 KG 的一致性和可解释性，我们根据提取的关系将 KG 的生成与创作的本体相结合。基准数据集上的评估表明，知识图谱构建任务具有竞争力。我们的工作为可扩展的 KG 构建流程提供了一个有希望的方向，只需最少的人为干预，即可产生高质量且人类可解释的 KG，这些 KG 可与 Wikidata 语义互操作，从而实现潜在的知识库扩展。]]></description>
      <guid>https://arxiv.org/abs/2412.20942</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UnrealZoo：为具身人工智能打造照片般逼真的虚拟世界</title>
      <link>https://arxiv.org/abs/2412.20977</link>
      <description><![CDATA[arXiv:2412.20977v1 公告类型：新
摘要：我们介绍了 UnrealZoo，这是一个基于虚幻引擎构建的丰富逼真的 3D 虚拟世界集合，旨在反映开放世界的复杂性和多变性。此外，我们还为具身 AI 代理提供了各种可玩实体。基于 UnrealCV，我们为各种潜在应用提供了一套易于使用的 Python API 和工具，例如数据收集、环境增强、分布式训练和基准测试。我们优化了 UnrealCV 的渲染和通信效率，以支持高级应用，例如多代理交互。我们的实验在各种复杂场景中对代理进行了基准测试，重点关注视觉导航和跟踪，这是具身视觉智能的基本功能。结果为强化学习 (RL) 代理的多样化训练环境的优势以及当前具身视觉代理（包括基于 RL 和大型视觉语言模型 (VLM) 的代理）在开放世界中面临的挑战提供了宝贵的见解。这些挑战涉及动态场景中闭环控制的延迟以及非结构化地形中 3D 空间结构的推理。]]></description>
      <guid>https://arxiv.org/abs/2412.20977</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论并行外部存储器双向搜索</title>
      <link>https://arxiv.org/abs/2412.21104</link>
      <description><![CDATA[arXiv:2412.21104v1 公告类型：新
摘要：并行化和外部存储器 (PEM) 技术显著增强了搜索算法在解决大规模问题时的能力。之前对 PEM 的研究主要集中在单向算法上，只有一篇关于双向 PEM 的出版物侧重于中间相遇 (MM) 算法。在此基础上，本文提出了一个将单向和双向最佳优先搜索算法集成到该框架中的框架。然后，我们开发了最先进的双向启发式搜索 (\BiHS) 算法 BAE* (PEM-BAE*) 的 PEM 变体。由于之前对 \BiHS 的研究并未关注扩展问题规模，因此这项工作使我们能够评估双向算法在难题上的表现。实证评估表明，PEM-BAE* 优于 A* 和 MM 算法的 PEM 变体以及 IDA* 的并行变体。这些发现标志着一个重要的里程碑，揭示了双向搜索算法在多个领域的表现明显优于单向搜索算法，即使配备了最先进的启发式方法。]]></description>
      <guid>https://arxiv.org/abs/2412.21104</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Aviary：训练语言代理完成具有挑战性的科学任务</title>
      <link>https://arxiv.org/abs/2412.21154</link>
      <description><![CDATA[arXiv:2412.21154v1 公告类型：新
摘要：解决复杂的现实世界任务需要一系列的行动和观察。在科学领域尤其如此，因为任务需要许多分析、工具使用和实验的循环。语言代理有望实现科学领域的智力任务自动化，因为它们可以通过自然语言或代码与工具交互。然而，它们的灵活性给软件实现带来了概念和实践上的挑战，因为代理可能包含非标准组件，例如内部推理、规划、工具使用以及温度采样语言模型的固有随机性。在这里，我们介绍了 Aviary，一个可扩展的语言代理中心。我们将代理形式化为解决基于语言的部分可观察马尔可夫决策过程的策略，我们称之为语言决策过程。然后，我们实现了五个环境，包括三个具有挑战性的科学环境：(1) 操纵 DNA 结构进行分子克隆，(2) 通过访问科学文献来回答研究问题，以及 (3) 工程蛋白质稳定性。之所以选择这些环境，是因为它们专注于多步推理，并且与当代生物学研究相关。最后，通过在线训练和扩展推理时间计算，我们表明，由开源、非前沿 LLM 支持的语言代理可以在多个任务上匹敌甚至超越前沿 LLM 代理和人类专家，而推理成本最多可降低 100 倍。]]></description>
      <guid>https://arxiv.org/abs/2412.21154</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>exLong：使用大型语言模型生成出色的行为测试</title>
      <link>https://arxiv.org/abs/2405.14619</link>
      <description><![CDATA[arXiv:2405.14619v3 公告类型：交叉 
摘要：许多流行的编程语言，包括 C#、Java 和 Python，都支持异常。如果发生不需要的事件，例如，使用非法参数值调用方法，则会在程序执行期间抛出异常。软件开发人员编写异常行为测试 (EBT) 来检查他们的代码是否检测到不需要的事件并抛出适当的异常。先前的研究表明了 EBT 的重要性，但这些研究也强调开发人员将大部分精力放在“快乐路径”上，例如没有不需要的事件的路径。为了帮助开发人员填补这一空白，我们提出了第一个自动生成 EBT 的框架，称为 exLong。exLong 是一个从 CodeLlama 微调的大型语言模型指令，嵌入了关于导致抛出语句的跟踪、保护抛出语句的条件表达式以及执行类似跟踪的非异常行为测试的推理。我们将 exLong 与最先进的测试生成模型 (CAT-LM) 和最强大的基础模型之一 (GPT-4o) 以及基于分析的测试生成工具 (Randoop 和 EvoSuite) 进行了比较。我们的结果表明，exLong 的表现优于现有模型和工具。此外，我们向开源项目贡献了多个拉取请求，exLong 生成的 23 个 EBT 已被接受。]]></description>
      <guid>https://arxiv.org/abs/2405.14619</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能驱动的自动化是幸福的先决条件</title>
      <link>https://arxiv.org/abs/2412.19808</link>
      <description><![CDATA[arXiv:2412.19808v1 公告类型：交叉 
摘要：围绕“工作的未来”的争论充斥着关于失去工作这一内在价值活动的危言耸听的警告。相反，本博士研究从人类繁荣（幸福）的角度来探讨这一争论。它表达了一种新亚里士多德式的解释，根据这种解释，大规模人工智能驱动的自动化前景远非威胁，而是令人向往的，因为它促进了人类的繁荣，并进而促进了他们参与休闲活动。借鉴美德法学，本研究进一步探讨了这种可取性对当前法律秩序可能意味着什么。]]></description>
      <guid>https://arxiv.org/abs/2412.19808</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>链接：面向6G数字孪生网络的大型语言模型集成管理</title>
      <link>https://arxiv.org/abs/2412.19811</link>
      <description><![CDATA[arXiv:2412.19811v1 公告类型：交叉 
摘要：在数字孪生 (DT) 和 6G 网络快速发展的背景下，大型语言模型 (LLM) 的集成为网络管理提供了一种新颖的方法。本文探讨了 LLM 在管理 6G 赋能的 DT 网络中的应用，重点是优化智能城市场景中的数据检索和通信效率。所提出的框架利用 LLM 以完全自主的方式进行智能 DT 问题分析和无线电资源管理 (RRM)，无需任何人工干预。我们提出的框架 LINKs 建立了一种延迟加载策略，可以通过有选择地检索相关数据来最大限度地减少传输延迟。基于数据检索计划，LLM 将检索任务转换为数值优化问题，并利用求解器构建最佳 RRM，确保整个网络的有效通信。模拟结果证明了数据规划和网络管理性能的改进，凸显了 LLM 增强 DT 和 6G 技术集成的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.19811</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 预测人类大脑状态</title>
      <link>https://arxiv.org/abs/2412.19814</link>
      <description><![CDATA[arXiv:2412.19814v1 公告类型：交叉 
摘要：人脑是一个复杂且高度动态的系统，我们目前对其功能机制的了解仍然非常有限。幸运的是，通过功能性磁共振成像（fMRI），我们可以观察到血氧水平依赖性（BOLD）变化，反映神经活动，从而推断大脑状态和动态。在本文中，我们提出了一个问题：区域大脑 fMRI 所代表的大脑状态是否可以预测。由于自注意力和 transformer 架构在顺序自回归问题（例如语言建模或音乐生成）中的成功，我们探索了使用 transformer 预测人脑静息状态的可能性，该预测基于来自人类连接组项目 (HCP) 的大规模高质量 fMRI 数据。目前的结果表明，我们的模型可以准确预测长达 5.04 秒的大脑状态，而之前的预测为 21.6 秒。此外，即使预测误差在较长时间段的预测中累积，生成的 fMRI 大脑状态仍反映了功能连接组的结构。这些有希望的初步结果表明，使用自注意力开发 fMRI 数据生成模型的可能性，该模型可以学习人类大脑的功能组织。我们的代码可在以下网址获取：https://github.com/syf0122/brain_state_pred。]]></description>
      <guid>https://arxiv.org/abs/2412.19814</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChipAlign：通过测地线插值实现芯片设计中大型语言模型的指令对齐</title>
      <link>https://arxiv.org/abs/2412.19819</link>
      <description><![CDATA[arXiv:2412.19819v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展已将其应用扩展到各个领域，包括芯片设计，其中出现了像 ChipNeMo 这样的领域适应性芯片模型。然而，这些模型通常在指令对齐方面存在困难，这是 LLM 的一项关键能力，涉及遵循明确的人类指令。这种限制阻碍了芯片 LLM 的实际应用，包括充当硬件设计工程师的助手聊天机器人。在这项工作中，我们介绍了 ChipAlign，这是一种采用无训练模型合并策略的新方法，结合了通用指令对齐 LLM 和芯片特定 LLM 的优势。通过考虑权重空间中的底层流形，ChipAlign 采用测地线插值来有效地融合输入 LLM 的权重，从而产生一个合并模型，该模型从各自的指令和芯片 LLM 继承了强大的指令对齐和芯片专业知识。我们的结果表明，ChipAlign 显著增强了现有芯片 LLM 的指令跟踪能力，在 IFEval 基准测试中实现了高达 26.6% 的提升，同时在芯片领域保持了相当的专业性。指令对齐方面的这种改进还转化为指令相关 QA 任务的显著提升，在 OpenROAD QA 基准测试中实现了 3.9% 的性能提升，在生产级芯片 QA 基准测试中实现了 8.25% 的性能提升，超越了最先进的基准。]]></description>
      <guid>https://arxiv.org/abs/2412.19819</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GaLore$+$：使用 Cross-Head Projection 提升 LLM 的低秩适应性</title>
      <link>https://arxiv.org/abs/2412.19820</link>
      <description><![CDATA[arXiv:2412.19820v1 公告类型：交叉 
摘要：最近的低秩训练方法，例如 GaLore，已显着减少了优化大型语言模型 (LLM) 所需的内存。然而，这些方法通常会受到耗时的低秩投影估计的影响。特别是，GaLore 中的奇异值分解 (SVD) 会消耗超过 80% 的总训练时间。为了解决这个问题，我们提出了 GaLore$+$，它使用跨头低秩投影来减少估计多头注意力低秩投影的大量时间消耗。此外，我们采用随机子空间迭代来实现快速 SVD。为了进一步提高性能，我们提出了稀疏编码残差来减少由优化器一阶和二阶矩和权重更新上的低秩近似引起的误差。我们在算术推理和自然语言生成数据集上评估了 GaLore$+$。我们的实验表明，与 vanilla GaLore 相比，GaLore$+$ 具有更优异的性能，同时实现了大约 $4\times$ 倍的微调速度。]]></description>
      <guid>https://arxiv.org/abs/2412.19820</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>纳米级浮点 (NxFP)：纳米尾数、自适应微指数和代码回收，用于大型语言模型的直接压缩</title>
      <link>https://arxiv.org/abs/2412.19821</link>
      <description><![CDATA[arXiv:2412.19821v1 公告类型：交叉 
摘要：随着尖端大型语言模型 (LLM) 继续改变各个行业，其快速增长的模型大小和序列长度导致了内存流量和容量挑战。最近，AMD、Arm、Intel、Meta、Microsoft、NVIDIA 和 Qualcomm 提出了微缩放标准 (Mx)，该标准使用微指数增强块浮点，以实现有希望的困惑度与占用空间的权衡。然而，在少于六位的现代 LLM 上，微缩放会遭受严重的困惑度下降。本文概述了现代 LLM，并确定了低位微缩放格式的三个主要挑战，即对异常值的跟踪不准确、量化级别空缺和二进制代码浪费。作为回应，Nanoscaling (NxFP) 提出了三种技术，即 NanoMantissa、自适应微指数和代码回收，以实现比最先进的 MxFP 更高的准确性和更小的内存占用。在各种现代 LLM 上进行的直接推理实验结果表明，我们提出的方法在 MMLU 基准测试中比最先进的 MxFP 的困惑度高出 0.64，准确度高出 30%。此外，NxFP 在实现与 MxFP 相当的困惑度的同时，将内存占用减少了 16%。]]></description>
      <guid>https://arxiv.org/abs/2412.19821</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通信、网络和服务管理大型语言模型调查：应用见解、挑战和未来方向</title>
      <link>https://arxiv.org/abs/2412.19823</link>
      <description><![CDATA[arXiv:2412.19823v1 公告类型：交叉 
摘要：近几十年来，通信网络的快速发展加剧了对先进网络和服务管理 (NSM) 策略的需求，以满足对这些网络的效率、可扩展性、增强性能和可靠性日益增长的需求。大型语言模型 (LLM) 因其在各种自然语言处理 (NLP) 任务中无与伦比的能力和产生情境感知洞察力而受到极大关注，为自动化各种通信 NSM 任务提供了变革潜力。与考虑单个网络域的现有调查相比，本调查研究了 LLM 在不同通信网络域中的集成，包括移动网络和相关技术、车辆网络、基于云的网络和基于雾/边缘的网络。首先，该调查提供了 LLM 的基础知识，明确详细说明了通用变压器架构、通用和特定于领域的 LLM、LLM 模型预训练和微调及其与通信 NSM 的关系。在网络监控和报告、人工智能驱动的网络规划、网络部署和分发以及持续网络支持的新分类法下，我们对每个不同网络域中 NSM 任务的 LLM 应用程序进行了广泛的分类，探索了现有文献及其迄今为止的贡献。然后，我们确定了 LLM 驱动的通信 NSM 的现有挑战和未解决的问题以及未来的研究方向，强调需要可扩展、适应性强且资源高效的解决方案，以适应通信网络的动态格局。我们设想这项调查将作为一份整体路线图，为利用 LLM 增强 NSM 提供关键见解。]]></description>
      <guid>https://arxiv.org/abs/2412.19823</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AnalogXpert：通过将电路设计专业知识融入大型语言模型来实现模拟拓扑合成的自动化</title>
      <link>https://arxiv.org/abs/2412.19824</link>
      <description><![CDATA[arXiv:2412.19824v1 公告类型：交叉 
摘要：模拟电路在现代电子系统中至关重要，其设计自动化引起了广泛的研究兴趣。主要挑战之一是拓扑合成，它决定了电路元件及其连接。最近的研究探索了用于拓扑合成的大型语言模型 (LLM)。然而，这些研究解决的场景与实际应用不太吻合。具体来说，现有的工作使用模糊的设计要求作为输入并输出理想模型，但详细的结构要求和设备级模型更为实用。此外，当前的方法要么将拓扑合成公式化为图形生成，要么将 Python 代码生成，而实际的拓扑设计是一个复杂的过程，需要广泛的设计知识。在这项工作中，我们提出了 AnalogXpert，这是一个基于 LLM 的代理，旨在通过将电路设计专业知识融入 LLM 来解决实际的拓扑合成问题。首先，我们将模拟拓扑表示为 SPICE 代码，并引入子电路库以减少设计空间，就像经验丰富的设计师一样。其次，我们通过使用 CoT 和上下文学习技术将问题分解为两个子任务（即块选择和块连接），以模拟实际设计过程。第三，我们引入了一种校对策略，允许 LLM 逐步纠正初始设计中的错误，类似于人类设计师迭代检查和调整初始拓扑设计以确保准确性。最后，我们构建了一个包含真实数据（30）和合成数据（2k）的高质量基准。AnalogXpert 在合成数据集和真实数据集上的成功率分别为 40% 和 23%，明显优于 GPT-4o（在合成数据集和真实数据集上均为 3%）。]]></description>
      <guid>https://arxiv.org/abs/2412.19824</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>