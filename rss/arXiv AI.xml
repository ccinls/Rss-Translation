<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Wed, 02 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于公理的地图集：通过基础证明向量对定理的结构映射</title>
      <link>https://arxiv.org/abs/2504.00063</link>
      <description><![CDATA[ARXIV：2504.00063V1公告类型：新 
摘要：基于公理的地图集是一个新颖的框架，在结构上代表数学定理作为基础公理系统的证明向量。通过将定理的逻辑依赖性映射到由公理索引的矢量上 - 例如希尔伯特几何，Peano算术或ZFC的逻辑依赖性，我们提供了一种新的方法来可视化，比较和分析数学知识。基于向量的形式主义不仅捕获了定理的逻辑基础，而且还可以在数学结果之间实现定量相似性指标（例如余弦距离），从而提供了一个新的分析层来进行结构比较。使用热图，向量聚类和AI辅助建模，该地图集可通过逻辑结构进行定理的分组，而不仅仅是通过数学域。我们还介绍了一个原型助理（ATLAS-GPT），该原型助理（ATLAS-GPT）解释了自然语言定理，并提出了可能的证明向量，支持未来的自动推理，数学教育和正式验证中的应用。
  这个方向部分受到Terence Tao最近对象征和结构数学融合的反思的启发。基于公理的地图集旨在提供一种可扩展的，可解释的数学推理模型，既可读又兼容AI，这有助于正式数学系统的未来景观。]]></description>
      <guid>https://arxiv.org/abs/2504.00063</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释AI的LLM：一项全面调查</title>
      <link>https://arxiv.org/abs/2504.00125</link>
      <description><![CDATA[ARXIV：2504.00125V1公告类型：新 
摘要：大型语言模型（LLMS）通过将复杂的机器学习输出转换为易于理解的叙述，使用户更容易获得模型预测，并帮助弥合复杂的模型行为和人类解释性之间的差距，从而提供了一种有希望的方法来增强可解释的AI（XAI）。 AI模型（例如最新的神经网络和深度学习模型）通常由于缺乏透明度而被视为“黑匣子”。由于用户无法完全了解模型如何得出结论，因此用户难以信任AI模型的决策，这会导致效率较低的决策过程，减少责任感和不明确的潜在偏见。开发可解释的AI（XAI）模型以获得用户的信任并提供有关模型如何生成其输出的洞察力的挑战。随着大型语言模型的开发，我们希望探索使用基于人类语言的模型LLM的模型解释能力的可能性。这项调查提供了有关XAI LLM的现有方法的全面概述，以及LLM生成的解释的评估技术，讨论了相应的挑战和局限性，并检查了现实世界中的应用程序。最后，我们通过强调对XAI通过LLM的更容易解释，自动化，以用户为中心和多学科的方法来讨论未来的方向。]]></description>
      <guid>https://arxiv.org/abs/2504.00125</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数字网中的大型语言模型：快速测试其数值推理能力</title>
      <link>https://arxiv.org/abs/2504.00226</link>
      <description><![CDATA[ARXIV：2504.00226V1公告类型：新 
摘要：人类数学推理的一个基本要素是我们的数字意义 - 对数字及其关系的抽象理解 - 这使我们能够使用有限的计算资源来解决涉及大量空间的问题。大型语言模型（LLMS）的数学推理通常经过高级问题（例如奥林匹克挑战，几何，单词问题和拼图）的测试，但是它们的低水平数字感觉仍然较少探索。我们介绍了“ Numberland”，这是一项100个问题测试，以评估基于LLM的代理的数值推理能力。这些任务 - 基本操作，高级计算（例如，指数，复数数字），质数检查和24场游戏 - 旨在测试基本技能及其在解决复杂和不确定问题的集成中。我们评估了五个基于LLM的代理：OpenAI的O1和O1-Mini，Google Gemini，Microsoft Copilot和Anthropic Claude。他们在前三个任务中得分74-95％，允许确定性步骤的解决方案。在需要试用和错误搜索的24场比赛中，性能下降到10-73％。我们在25个困难问题上测试了前24个求解器（O1，其精度为73％），其得分降至27％，确认搜索为瓶颈。这些结果以及错误的类型表明了脆弱的LLM，这有点令人惊讶，因为它们在具有挑战性的基准方面的能力。 LLM数值推理的限制突出了简单，有针对性测试的范围，以评估和解释LLM数学技能以确保安全使用。]]></description>
      <guid>https://arxiv.org/abs/2504.00226</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大规模异构数据中心的机架位置优化</title>
      <link>https://arxiv.org/abs/2504.00277</link>
      <description><![CDATA[ARXIV：2504.00277V1公告类型：新 
摘要：随着迅速增长的AI计算需求加速了对新硬件安装和维护的需求，这项工作通过平衡运营效率和错误的容忍度来探索最佳数据中心资源管理，通过考虑各种资源和位置的战略机架定位。传统的混合构成编程（MIP）方法通常在可扩展性方面遇到困难，而启发式方法可能会导致显着的次要性。为了解决这些问题，本文使用高级深钢筋学习（DRL）模型提出了一种新颖的两层优化框架，以指导基于低级的基于梯度的启发式启发式启发式启发式。高级DRL代理商对最佳机架类型排序采用领导者的奖励，而低级启发式有效地将机架映射到位置，最大程度地减少移动计数并确保耐故障资源分布。这种方法允许可扩展性超过100,000个位置和100种机架类型。我们的方法平均比基于梯度的启发式启发式高7％，而MIP求解器的目标值超过30 \％。与MIP的97.5％相比，它达到了100 \％的成功率（在20分钟的限制内），与MIP的1630分钟相比，它在短短2分钟内完成（即近4个数量级的提高了）。与MIP求解器不同，在时间限制下显示出性能变异性，我们的算法始终提供稳定，有效的结果 - 大规模数据中心管理的重要功能。]]></description>
      <guid>https://arxiv.org/abs/2504.00277</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散政策的非平稳任务进行探索和适应</title>
      <link>https://arxiv.org/abs/2504.00280</link>
      <description><![CDATA[ARXIV：2504.00280V1公告类型：新 
摘要：本文研究了扩散策略在非平稳的，基于视觉的RL设置中的应用，特别是针对任务动态和目标随时间发展的环境。我们的工作基于在动态现实世界中遇到的实际挑战，例如机器人组装线和自主导航，在该场景中，代理必须从高维视觉输入中调整控制策略。我们采用扩散策略 - 利用迭代的随机转化来完善包括Procgen和Dointmaze在内的基准环境的潜在动作表示。我们的实验表明，尽管计算需求增加，但扩散策略始终优于标准RL方法，例如PPO和DQN，从而获得了更高的均值和最大奖励，并且可变性降低。这些发现强调了该方法在不断变化的条件下生成连贯的，上下文相关的动作序列的能力，同时还突出了以进一步改善处理极端非平稳性的领域。]]></description>
      <guid>https://arxiv.org/abs/2504.00280</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与本地数据保护的协作LLM数值推理</title>
      <link>https://arxiv.org/abs/2504.00299</link>
      <description><![CDATA[ARXIV：2504.00299V1公告类型：新 
摘要：对文档的数值推理（要求上下文理解和逻辑推断）对于部署在计算受限设备上的低容量的本地模型来说是挑战。尽管可以将这种复杂的推理查询路由到强大的远程模型（例如GPT-4），但曝光本地数据会引起重大数据泄漏问题。现有的缓解方法生成问题描述或示例，以提供远程帮助。但是，数值推理的固有复杂性阻碍了本地模型生成逻辑等效的查询，并通过远程指导准确地推断答案。在本文中，我们提出了一个模型协作框架，具有两个关键的创新：（1）上下文感知的综合策略，可以改变查询域，同时保持逻辑一致性； （2）一种基于工具的答案重建方法，该方法可重复使用代码段的远程生成的问题解决模式。实验结果表明，与仅使用本地模型相比，与完全依赖远程模型相比，我们的方法可以达到更好的推理精度。此外，与现有的数据保护方法相比，我们的方法将准确性提高了16.2％-43.6％，同时将数据泄漏降低2.3％-44.6％。]]></description>
      <guid>https://arxiv.org/abs/2504.00299</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络机器人：通过本体论的检索增强一代实现可靠的网络安全教育</title>
      <link>https://arxiv.org/abs/2504.00389</link>
      <description><![CDATA[ARXIV：2504.00389V1公告类型：新 
摘要：大语言模型（LLMS）的进步已使智能教育工具的开发能够支持跨技术领域的基于查询的学习。在准确性和安全性至关重要的网络安全教育中，系统必须超越表面水平的相关性，以提供既值得信赖又适合领域的信息。为了应对这一挑战，我们介绍了Cyber​​bot，这是一种提问的聊天机器人，该聊天机器人利用检索功能的一代（RAG）管道来结合特定课程材料的上下文信息，并使用域特异性网络安全本体来验证回答。本体论是一个结构化的推理层，可约束和验证LLM生成的答案，从而降低了误导性或不安全指导的风险。 Cyber​​bot已在亚利桑那州立大学（ASU）的大型研究生课程中部署，其中一百多名学生通过专门的基于网络的平台积极与系统互动。实验室环境中的计算评估突出了网络机器人的潜在能力，即将进行的现场研究将评估其教学影响。通过将结构化领域推理与现代生成能力集成，网络机器人说明了在专门的教育环境中开发可靠和课程的AI应用的有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2504.00389</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>鹰眼：通过模型协作有效推理</title>
      <link>https://arxiv.org/abs/2504.00424</link>
      <description><![CDATA[ARXIV：2504.00424V1公告类型：新 
摘要：经营链（COT）推理在增强大语言模型（LLM）的推理能力方面表现出了出色的有效性。但是，由于产生过多的中间推理令牌，它的效率仍然是一个挑战，该代币引入了语义冗余和过度详细的推理步骤。此外，计算费用和延迟是重大问题，因为成本量表具有输出令牌的数量，包括这些中间步骤。在这项工作中，我们观察到大多数COT令牌是不必要的，并且仅保留其中的一小部分就足以产生高质量的响应。受此启发，我们提出了鹰眼，这是一种新型的训练后和推理框架，其中大型模型会产生简洁的COT指令，以指导较小的响应产生模型。鹰眼量化了COT推理中的冗余，并通过增强学习来提炼高密度信息。通过利用这些简洁的婴儿床，鹰眼可以扩大响应，同时大大降低令牌使用和计算成本。我们的评估表明，鹰眼只能使用35％的完整COTS实现可比的响应质量，同时将清晰度，连贯性和简洁性提高约10％。此外，鹰眼可以在复杂的数学任务上加速端到端推理，同时将推理成本降低高达60％。鹰眼将是开源的，车型将很快提供。]]></description>
      <guid>https://arxiv.org/abs/2504.00424</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于推理的朗诵：尖端的语言模型如何在小学级别的推理问题上失败？</title>
      <link>https://arxiv.org/abs/2504.00509</link>
      <description><![CDATA[ARXIV：2504.00509V1公告类型：新 
摘要：从小学级别到近年来LLM基准难度的前沿问题的快速升级为研究人员编织了一个奇迹，即我们距离超越人类智能只有几英寸的距离。但是，LLMS的非凡推理能力确实来自人类标准的真正智能，还是仅仅在互联网培训期间见证了解决方案？为了研究这个问题，我们提出了ROR Bench，这是一种新型的多模式基准测试，用于检测LLM的朗诵行为时，当被问及简单的推理问题，但条件巧妙地转移，并对我们的基准进行了经验分析。令人惊讶的是，我们发现现有的尖端LLM一致表现出极为严重的朗诵行为。通过在这种情况下更改一个短语，OpenAI-O1和DeepSeek-R1等顶级模型可能会遭受$ 60 \％$ $的性能损失，而小学级别的算术和推理问题。这样的发现是对LLM社区的警钟，迫使我们重新评估了尖端LLM的真正情报水平。]]></description>
      <guid>https://arxiv.org/abs/2504.00509</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM引导搜索删除校正代码</title>
      <link>https://arxiv.org/abs/2504.00613</link>
      <description><![CDATA[ARXIV：2504.00613V1公告类型：新 
摘要：查找最大尺寸的删除校正代码已成为70多年的开放问题，即使是单个删除也是如此。在本文中，我们提出了一种构建缺失校正代码的新方法。代码是满足某些约束的一组序列，我们通过根据优先级函数添加最高优先级序列来构造它。 To find good priority functions, we leverage FunSearch, a large language model (LLM)-guided evolutionary search proposed by Romera et al., 2024. FunSearch iteratively generates, evaluates, and refines priority functions to construct large deletion-correcting codes.对于单个删除，我们的进化搜索找到了构建符合已知最大尺寸的代码的函数，达到最大（猜想的最佳）varshamov-tenengolts代码的大小，其中最大值是未知的，并以等效形式独立地重新发现它们。对于两个删除，我们发现构造具有新最佳尺寸的代码代码长度\（n = 12，13 \）和\（16 \）的函数，建立了改进的下限。这些结果证明了LLM引导搜索信息理论和代码设计的潜力，并代表了此类方法用于构建错误校正代码的第一个应用。]]></description>
      <guid>https://arxiv.org/abs/2504.00613</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向负责任和值得信赖的教育数据挖掘：比较符号，亚符号和神经符号AI方法</title>
      <link>https://arxiv.org/abs/2504.00615</link>
      <description><![CDATA[ARXIV：2504.00615V1公告类型：新 
摘要：鉴于对教育负责任和值得信赖的AI的需求，本研究评估了符号，亚符号和神经符号AI（NSAI）的符合性和解释性。我们对爱沙尼亚小学生的平衡和不平衡的自我调节的学习数据集进行了广泛的实验，预测7年级数学国家测试表现表明，符号和亚符号方法在平衡数据上表现良好，但努力识别出不平衡数据集中表现低下的人。有趣的是，符号和亚符号方法在决策中强调了不同的因素：符号方法主要依赖于认知和动机因素，而亚肌脱符号方法则更多地集中在认知方面，学习知识和性别的人口统计学上 - 但两者都在很大程度上忽略了元认知因素。另一方面，NSAI方法的优势是：（i）在两个类别中（即使在不平衡的数据集中）都更具普遍性，因为其符号知识成分弥补了代表性不足的类别； （ii）在其决策中依靠一组更整合的因素，包括动机，（元）认知和学识，从而提供了一个全面且理论上扎根的可解释性框架。这些对比的发现突出了仅根据预测性能得出结论，需要对AI方法进行整体比较。他们还强调了以人为本的NSAI方法解决其他AI家庭的局限性的潜力，并使我们更接近负责的AI进行教育。具体而言，通过使利益相关者能够为AI设计做出贡献，Nsai与理论结构相结合，结合了动机和元认知等因素，并增强了教育数据挖掘的可信度和责任。]]></description>
      <guid>https://arxiv.org/abs/2504.00615</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于LLM的自主代理商的人格驱动的决策</title>
      <link>https://arxiv.org/abs/2504.00727</link>
      <description><![CDATA[ARXIV：2504.00727V1公告类型：新 
摘要：大型语言模型（LLM）嵌入自主代理中是一个快速发展的领域，可以实现动态，可配置的行为，而无需进行广泛的域特异性训练。在我们以前的工作中，我们介绍了桑德曼（Sandman），这是一种利用五因素海洋人格模型的欺骗性剂架构，这表明人格感应显着影响了代理人的任务计划。在这些发现的基础上，本研究提出了一种新的方法，用于测量和评估诱导人格特征如何影响基于LLM的代理商中的任务选择过程，特别是计划，调度和决策。我们的结果揭示了与诱导的海洋属性一致的不同任务选择模式，强调了设计高度合理的欺骗性药物以实现主动的网络防御策略的可行性。]]></description>
      <guid>https://arxiv.org/abs/2504.00727</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们真的需要这么多样本吗？多LLM重复采样有效扩展测试时间计算</title>
      <link>https://arxiv.org/abs/2504.00762</link>
      <description><![CDATA[ARXIV：2504.00762V1公告类型：新 
摘要：本文提出了一种简单，有效且具有成本效益的策略，可以通过扩展测试时间计算来提高LLM性能。我们的策略建立在重复采样到投票框架的基础上，这是一个新颖的转折：结合了多种模型，甚至更弱的模型，以利用其互补优势，这可能是由多样化的培训数据和范式产生的。通过将一致性用作信号，我们的策略在模型之间动态切换。理论分析强调了我们战略的效率和绩效优势。在六个数据集上进行的广泛实验表明，我们的策略不仅优于自符合性和最先进的多代理辩论方法，而且大大降低了推论成本。此外，ModelSwitch仅需要几个可比较的LLM即可实现最佳性能，并且可以通过验证方法扩展，这表明了在生成验证范式中利用多个LLM的潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.00762</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的基于AI的天气预测模型的接口系统</title>
      <link>https://arxiv.org/abs/2504.00795</link>
      <description><![CDATA[ARXIV：2504.00795V1公告类型：新 
摘要：机器学习（ML）在气象决策中越来越流行。尽管有关可解释的人工智能（XAI）的文献正在稳步增长，但以用户为中心的XAI研究尚未扩展到该领域。这项研究通过用户研究定义了气象学中黑盒模型的解释的三个要求：不同降雨场景的统计模型性能，以识别模型偏见，模型推理和模型输出的信心。适当的XAI方法映射到每个要求，并在定量和定性上对生成的解释进行测试。 XAI接口系统是根据用户反馈设计的。结果表明，解释会增加决策实用程序和用户信任。用户更喜欢直观的解释，而不是基于XAI算法的解释，即使对于潜在的易于识别的示例也是如此。这些发现可以为未来以用户为中心的XAI算法进行研究的证据，以及提高实践中AI系统可用性的基础。]]></description>
      <guid>https://arxiv.org/abs/2504.00795</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于示例的深度天气预测模型的概念分析框架</title>
      <link>https://arxiv.org/abs/2504.00831</link>
      <description><![CDATA[ARXIV：2504.00831V1公告类型：新 
摘要：为了提高AI模型的可信赖性，找到其推理过程的一致，可理解的表示是必不可少的。在高风险操作（例如天气预报）中，这种理解尤其重要，在天气预报上，鉴定潜在的气象机制与预测的准确性一样至关重要。尽管越来越多的文献通过可解释的AI解决了这个问题，但由于其以AI为中心的开发，其解决方案的适用性通常受到限制。为了填补这一空白，我们遵循以用户为中心的过程来开发基于示例的概念分析框架，该框架识别遵循与目标模型中目标实例相似的推理过程的案例，并以用户透明的格式呈现它们。我们的框架在视觉和概念上为用户提供了类似的示例，包括概念分配的概率来解决天气机制中的歧义。为了弥合从模型中确定的向量表示之间的差距和可理解的解释，我们编译了人类通知的概念数据集并实现用户界面，以帮助涉及框架开发的领域专家。]]></description>
      <guid>https://arxiv.org/abs/2504.00831</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调查大型语言模型，以诊断学生在数学问题解决方面的认知能力</title>
      <link>https://arxiv.org/abs/2504.00843</link>
      <description><![CDATA[ARXIV：2504.00843V1公告类型：新 
摘要：数学学习需要掌握内容知识和认知处理的认识，应用和推理。自动数学评估主要集中于通过查找文本证据（例如特定数字，公式和陈述）来对学生的内容知识进行评分。大语模型（LLMS）的问题解决，图像识别和推理能力的最新进展显示出对学生认知技能的细微评估的希望。诊断认知能力需要推断学生的思维过程超出文本证据，这是基于LLM的自动化评估中的一项无人展开的任务。在这项工作中，我们研究了最先进的LLM如何诊断学生在数学方面的认知能力。我们构建了MathCog，这是一个新颖的基准数据集，其中包括639个学生对110个专家策划的中学数学问题的回答，每个人都根据认知技能清单的详细教师的诊断注释。使用MathCog，我们评估了16个封闭和开放的LLM，该LLM的不同模型尺寸和供应商。我们的评估表明，即使是最先进的LLM在任务中都挣扎，所有F1的得分低于0.5，并且往往对不正确案例表现出强烈的错误信心（$ r_s = .617 $）。我们还发现，模型大小与诊断性能（$ r_s = .771 $）正相关。最后，我们讨论了这些发现的含义，过度自信的问题以及改善自动认知技能诊断的方向。]]></description>
      <guid>https://arxiv.org/abs/2504.00843</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Agent S2：用于计算机使用代理的组成通才特权框架</title>
      <link>https://arxiv.org/abs/2504.00906</link>
      <description><![CDATA[ARXIV：2504.00906V1公告类型：新 
摘要：计算机使用代理通过与计算机和移动设备上的图形用户界面（GUI）直接交互来自动化数字任务，从而通过完成用户查询的开放式空间来提高人类生产力。但是，当前的代理商面临重大挑战：GUI元素的不精确基础，长期任务计划的困难以及依靠单个通才模型来执行各种认知任务的绩效瓶颈。为此，我们介绍了Agent S2，这是一个新颖的构图框架，该框架将各种通才和专业模型的认知责任委托。我们提出了一种新型的地面技术，以实现精确的GUI定位，并在多个时间尺度上引入主动的分层计划，以响应不断发展的观测，在多个时间尺度上动态完善动作计划。评估表明，Agent S2在三个突出的计算机使用基准上建立了新的最先进（SOTA）性能。具体而言，代理S2在OSWORLD 15步骤和50步评估上的Claude计算机使用和UI-TAR等领先的基线代理（例如Claude Computer使用和UI-TARS）的相对改善达到18.9％和32.7％。此外，Agent S2有效地将其概括为其他操作系统和应用程序，在Windowsagentarena上超过了先前的最佳方法52.8％，而AndroidWorld相对较高。代码可在https://github.com/simular-ai/agent-s上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.00906</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将多模式LLM接地到要在增强学习方面寻求帮助的体现的代理</title>
      <link>https://arxiv.org/abs/2504.00907</link>
      <description><![CDATA[ARXIV：2504.00907V1公告类型：新 
摘要：在现实世界环境中运行的具体代理必须解释模棱两可的人类指示。有能力的家用机器人应认识到歧义并提出相关的澄清问题以准确推断用户意图，从而导致更有效的任务执行。为了研究此问题，我们介绍了询问任务，其中具体的代理必须在家庭环境中进行模棱两可的指导进行特定的对象实例。代理商必须从战略上提出最小但相关的澄清问题，以解决歧义，同时在部分可观察性下导航。为了解决这个问题，我们提出了一种新颖的方法，该方法是使用在线加强学习（RL）获得LLM生成的奖励的多模型大型语言模型（MLLM）作为视觉语言行动（VLA）策略。我们的方法消除了对大规模的人类示范或手动设计的奖励，以训练这种药物。我们在我们的任务上对抗包括GPT-4O在内的强大零射基线以及监督的微调MLLM的基准。我们的结果表明，我们的RL-Finetuned Mllm的表现要优于所有基准（$ 19.1 $  -  $ 40.3 \％$），从而很好地推广到新颖的场景和任务。据我们所知，这是将MLLM作为VLA代理的首次演示，可以采取行动并寻求使用LLM-Inered Rel的帮助。]]></description>
      <guid>https://arxiv.org/abs/2504.00907</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI设计中的法官：关于通过视觉模型实现人类专家等价的统计观点</title>
      <link>https://arxiv.org/abs/2504.00938</link>
      <description><![CDATA[ARXIV：2504.00938V1公告类型：新 
摘要：早期工程设计的主观评估，例如概念草图，传统上依赖于人类专家。但是，专家评估是耗时的，昂贵的，有时甚至不一致的。视觉模型（VLMS）的最新进展为自动化设计评估提供了潜力，但至关重要的是要确保这些AI``法官&#39;&#39;在与人类专家相当的情况下执行。但是，没有现有的框架评估专家对等。本文介绍了一个严格的统计框架，以确定AI法官的评级是否与人类专家的评级相匹配。我们在一个案例研究中应用此框架，该框架评估了四个基于VLM的法官（唯一性，创造力，实用性和绘画质量）的法官。这些AI法官采用了各种文本学习（ICL）技术，包括Uni-and-timodal提示和推理时间推理。相同的统计框架用于评估三个训练有素的新手，以实现专家等效性。结果表明，最佳表现的AI法官使用基于文本和图像的ICL进行推理，以实现专家级的协议，以实现唯一性和绘画质量，胜过所有指标的新手。在6/6的范围内，既有独特性和创造力，又有5/6的跑步，以绘制质量和实用性，其与专家的协议达到或超过了大多数受过训练的新手的同意。这些发现表明，推理支持的VLM模型可以在设计评估中实现人类专家的当量。这对教育和实践中的扩展设计评估具有影响，并提供了一个一般的统计框架，以验证需要主观内容评估的其他领域中的AI法官。]]></description>
      <guid>https://arxiv.org/abs/2504.00938</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们到了吗？ LLM应用程序效率的测量研究</title>
      <link>https://arxiv.org/abs/2504.00002</link>
      <description><![CDATA[ARXIV：2504.00002V1公告类型：交叉 
摘要：大语言模型（LLMS）的最新进展已引起人们对在移动设备上部署这些模型的兴趣，以启用新应用程序而不依赖云连接。但是，在资源有限的设备上部署LLM的效率限制带来了重大挑战。在本文中，我们进行了一项全面的测量研究，以评估基于移动的，基于边缘和基于云的LLM应用程序的效率折衷。我们实施了Autolifife-Lite，这是一种基于LLM的简化应用程序，该应用程序分析智能手机传感器数据以推断用户位置和活动上下文。我们的实验表明：（1）只有小规模的LLM（&lt;4B参数）可以在功能强大的移动设备上成功运行，尽管与较大的模型相比，它们具有质量限制； （2）模型压缩在降低硬件需求方面有效，但可能导致显着的性能降解； （3）在具有有意义输出的移动设备上运行LLM的延迟非常重要（&gt; 30秒），而云服务则表现出更好的时间效率（&lt;10秒）； （4）Edge部署提供了延迟和模型功能之间的中间权衡，在基于CPU的基于CPU和基于GPU的设置上有不同的结果。这些发现为系统设计人员提供了有关当前限制和未来方向的有价值的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.00002</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>