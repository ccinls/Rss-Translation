<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 17 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>论文评论：立场：重新思考基于事后搜索的神经方法来解决大规模旅行商问题</title>
      <link>https://arxiv.org/abs/2406.09441</link>
      <description><![CDATA[arXiv:2406.09441v1 公告类型：交叉 
摘要：我们发现 SoftDist 论文（Xia 等人）中存在两个主要问题：（1）未能在同一硬件环境中运行不同基线的所有步骤，以及（2）与其他基线进行比较时使用不一致的时间测量。这些问题导致结论有缺陷。当所有步骤都在同一硬件环境中执行时，SoftDist 中提出的主要主张不再受支持。]]></description>
      <guid>https://arxiv.org/abs/2406.09441</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:44 GMT</pubDate>
    </item>
    <item>
      <title>推进生物医学领域的高分辨率视觉语言模型</title>
      <link>https://arxiv.org/abs/2406.09454</link>
      <description><![CDATA[arXiv:2406.09454v1 公告类型：交叉 
摘要：多模态学习显著推动了生成式人工智能的发展，尤其是在视觉语言建模方面。GPT-4V 等创新和 LLaVA 等开源项目已经实现了能够完成零样本任务的强大对话代理。然而，将这些技术应用于生物医学领域面临着独特的挑战。最近的举措，如 LLaVA-Med，已经开始使用 PMC-15M 等大型数据集来调整生物医学环境中的指令调整。我们的研究有三个主要贡献：（i）我们提出了一个新的指令数据集，其中包含来自 Claude3-Opus 和 LLaMA3 70B 的医学图像-文本对；（ii）我们提出了一种使用分层表示的新型图像编码策略来改善细粒度的生物医学视觉理解；（iii）我们开发了 Llama3-Med 模型，该模型在生物医学视觉问答基准上实现了最先进的零样本性能，与以前的方法相比，平均性能提高了 10% 以上。这些进步为医疗专业人员提供了更准确、更可靠的工具，弥补了当前多模式对话助手的差距，并促进了医疗 AI 的进一步创新。]]></description>
      <guid>https://arxiv.org/abs/2406.09454</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:44 GMT</pubDate>
    </item>
    <item>
      <title>TRIP-PAL：通过结合大型语言模型和自动规划器提供有保障的旅行规划</title>
      <link>https://arxiv.org/abs/2406.10196</link>
      <description><![CDATA[arXiv:2406.10196v1 公告类型：新
摘要：旅行计划是一项复杂的任务，涉及生成与访问受约束的地方相关的一系列操作并最大化某些用户满意度标准。传统方法依赖于给定形式语言中的问题表述，从网络源中提取相关的旅行信息，并使用适当的问题求解器来生成有效的解决方案。作为替代方案，最近基于大型语言模型 (LLM) 的方法使用语言直接从用户请求中输出计划。尽管 LLM 拥有广泛的旅行领域知识并提供兴趣点和潜在路线等高级信息，但当前最先进的模型通常会生成缺乏连贯性的计划，无法完全满足约束条件，并且不能保证生成高质量的解决方案。我们提出了 TRIP-PAL，这是一种结合了 LLM 和自动规划器优势的混合方法，其中 (i) LLM 获取并将旅行信息和用户信息转换为可以输入规划器的数据结构；(ii) 自动规划器生成保证约束满足并优化用户效用的旅行计划。我们在各种旅行场景中进行的实验表明，TRIP-PAL 在制定旅行计划时的表现优于 LLM。]]></description>
      <guid>https://arxiv.org/abs/2406.10196</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:43 GMT</pubDate>
    </item>
    <item>
      <title>LooPIN：一种用于去中心化计算的 PinFi 协议</title>
      <link>https://arxiv.org/abs/2406.09422</link>
      <description><![CDATA[arXiv:2406.09422v1 公告类型：交叉 
摘要：网络计算能力是人工智能时代的关键实用工具。本文提出了一种新颖的物理基础设施金融 (PinFi) 协议，旨在以去中心化的方式促进网络内计算能力的分配。PinFi 协议解决了去中心化物理基础设施网络 (DePIN) 中协调、定价和流动性的核心挑战，引入了一种独特的动态定价机制。它使提供商能够将多余的计算资源分配给“耗散”PinFi 流动性池，不同于传统的 DeFi 流动性池，确保客户以公平的市场价格无缝访问。这种方法显着降低了访问计算能力的成本，与现有服务相比可能低至 1%，同时增强了安全性和可靠性。PinFi 协议有望改变计算能力网络中的供需动态，为效率和可访问性树立新标准。]]></description>
      <guid>https://arxiv.org/abs/2406.09422</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:43 GMT</pubDate>
    </item>
    <item>
      <title>通过基于嵌入的链接预测改进规则挖掘</title>
      <link>https://arxiv.org/abs/2406.10144</link>
      <description><![CDATA[arXiv:2406.10144v1 公告类型：新
摘要：知识图谱上的规则挖掘允许可解释的链接预测。相反，基于嵌入的链接预测方法以其泛化能力而闻名，但它们的预测是不可解释的。近年来，已经提出了几种结合这两类方法的方法。大多数由此产生的混合方法通常在统一的学习框架内进行训练，这通常会导致由于学习任务的复杂性而导致收敛问题。在这项工作中，我们提出了一种结合这两类方法的新方法。具体而言，我们在丰富的知识图谱上应用规则挖掘系统之前，通过其预训练的实体和关系嵌入来丰富给定的知识图谱。为了验证我们的方法，我们对七个基准数据集进行了广泛的实验。对我们方法生成的结果的分析表明，我们在丰富的图谱上发现了新的有价值的规则。我们在 https://github.com/Jean-KOUAGOU/EnhancedRuleLearning 上提供了我们方法的开源实现以及预训练的模型和数据集]]></description>
      <guid>https://arxiv.org/abs/2406.10144</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:42 GMT</pubDate>
    </item>
    <item>
      <title>从阿谀奉承到诡计多端：调查大型语言模型中的奖励篡改行为</title>
      <link>https://arxiv.org/abs/2406.10162</link>
      <description><![CDATA[arXiv:2406.10162v2 公告类型：新
摘要：在强化学习中，当 AI 系统学习由于错误指定的训练目标而获得高额奖励的不良行为时，就会发生规范游戏。规范游戏的范围从简单的行为（如阿谀奉承）到复杂而有害的行为（如奖励篡改，其中模型直接修改自己的奖励机制）。然而，这些更有害的行为可能过于复杂，无法通过探索发现。在本文中，我们研究了大型语言模型 (LLM) 助手是否会发现容易发现的规范游戏形式，从而推广到执行更罕见、更明显的形式，包括奖励篡改。我们构建了一个越来越复杂的可游戏环境课程，并发现在早期课程环境中进行训练会导致剩余环境中出现更多的规范游戏。令人惊讶的是，在一小部分但不可忽略的时间里，接受完整课程训练的 LLM 助手将零样本推广到直接重写自己的奖励函数。重新训练 LLM 使其不玩早期课程环境可以减轻但不会消除后期环境中的奖励篡改。此外，在可玩环境中添加无害训练并不能防止奖励篡改。这些结果表明，LLM 可以从常见的规范游戏形式推广到更有害的奖励篡改，并且这种行为可能很难消除。]]></description>
      <guid>https://arxiv.org/abs/2406.10162</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:42 GMT</pubDate>
    </item>
    <item>
      <title>细节决定成败：对象状态敏感的神经机器人任务规划</title>
      <link>https://arxiv.org/abs/2406.09988</link>
      <description><![CDATA[arXiv:2406.09988v1 公告类型：新 
摘要：物体的状态反映了其当前的状态或状况，对于机器人的任务规划和操作非常重要。然而，检测物体的状态并为机器人生成状态敏感的计划具有挑战性。最近，预先训练的大型语言模型 (LLM) 和视觉语言模型 (VLM) 在生成计划方面表现出了令人印象深刻的能力。然而，据我们所知，几乎没有任何关于 LLM 或 VLM 是否也可以生成对象状态敏感计划的研究。为了研究这个问题，我们引入了一个对象状态敏感代理 (OSSA)，这是一个由预训练的神经网络赋能的任务规划代理。我们为 OSSA 提出了两种方法：(i) 由预训练的视觉处理模块（密集字幕模型，DCM）和自然语言处理模型 (LLM) 组成的模块化模型，以及 (ii) 仅由 VLM 组成的单片模型。为了定量评估这两种方法的性能，我们使用桌面场景，其中的任务是清理桌面。我们提供了一个考虑对象状态的多模态基准数据集。我们的结果表明，这两种方法都可以用于对象状态敏感的任务，但整体方法优于模块化方法。OSSA 的代码可在 \url{https://github.com/Xiao-wen-Sun/OSSA} 获得]]></description>
      <guid>https://arxiv.org/abs/2406.09988</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:41 GMT</pubDate>
    </item>
    <item>
      <title>弥合沟通鸿沟：人工智能通过模仿学习手语</title>
      <link>https://arxiv.org/abs/2406.10043</link>
      <description><![CDATA[arXiv:2406.10043v1 公告类型：新
摘要：人工智能体，尤其是人形机器人，使用摄像头、执行器和物理存在与环境、物体和人进行交互。他们的沟通方式通常是预先编程的，限制了他们的行为和互动。我们的研究探索通过从演示中学习来获得非语言沟通技巧，并可能应用于手语理解和表达。特别是，我们专注于人工智能体的模仿学习，例如教授模拟人形美国手语。我们使用计算机视觉和深度学习从视频中提取信息，并使用强化学习使代理能够复制观察到的动作。与其他方法相比，我们的方法消除了获取信息的额外硬件的需求。我们展示了这些不同技术的组合如何提供一种学习手语的可行方法。我们的方法成功地教授了 5 种涉及上身（即手臂和手）的不同手势。这项研究为人工智能体的高级沟通技巧铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2406.10043</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:41 GMT</pubDate>
    </item>
    <item>
      <title>通过后继州措施学习多种技能的探索</title>
      <link>https://arxiv.org/abs/2406.10127</link>
      <description><![CDATA[arXiv:2406.10127v1 公告类型：新
摘要：执行不同技能的能力可以鼓励代理进行探索。在这项工作中，我们的目标是构建一组均匀覆盖状态空间的多样化技能。我们提出了对这种多样化技能搜索的形式化，基于状态和技能之间的相互信息建立先前的定义。我们考虑由以每种技能为条件的策略达到的状态分布，并利用后继状态度量来最大化这些技能分布之间的差异。我们将这种方法称为 LEADS：通过后继状态学习多样化技能。我们在一组迷宫导航和机器人控制任务上展示了我们的方法，这表明我们的方法能够构建一组多样化的技能，这些技能可以详尽地覆盖状态空间，而无需依赖奖励或探索奖励。我们的研究结果表明，这种新的形式化通过结合相互信息最大化和探索奖励来促进更稳健、更高效的探索。]]></description>
      <guid>https://arxiv.org/abs/2406.10127</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:41 GMT</pubDate>
    </item>
    <item>
      <title>SHMamba：用于视听问答的结构化双曲状态空间模型</title>
      <link>https://arxiv.org/abs/2406.09833</link>
      <description><![CDATA[arXiv:2406.09833v1 公告类型：新 
摘要：视听问答 (AVQA) 任务具有巨大的应用潜力。与传统的单峰方法相比，AVQA 的多峰输入使特征提取和融合过程更具挑战性。欧几里得空间难以有效表示数据的多维关系。特别是在提取和处理具有树结构或层次结构的数据时，欧几里得空间不适合作为嵌入空间。此外，Transformers 中的自注意力机制可以有效地捕捉序列中元素之间的动态关系。然而，自注意力机制在窗口建模和二次计算复杂度方面的局限性降低了其在长序列建模中的有效性。为了解决这些限制，我们提出了 SHMamba：结构化双曲状态空间模型，以整合双曲几何和状态空间模型的优点。具体而言，SHMamba 利用双曲空间的内在属性来表示视听数据中的层次结构和复杂关系。同时，状态空间模型通过对整个序列进行全局建模来捕捉随时间变化的动态变化。此外，我们引入了自适应曲率双曲率对齐模块和交叉融合模块，分别增强对层次结构的理解和跨模态信息的动态交换。大量实验表明，SHMamba 以更少的参数和计算成本优于以前的方法。我们的可学习参数减少了 78.12%，而平均性能提高了 2.53%。实验表明，我们的方法在当前所有主要方法中都表现出优越性，更适合实际应用场景。]]></description>
      <guid>https://arxiv.org/abs/2406.09833</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:40 GMT</pubDate>
    </item>
    <item>
      <title>在基础可视化编程中对计算思维测试中的生成模型进行基准测试</title>
      <link>https://arxiv.org/abs/2406.09891</link>
      <description><![CDATA[arXiv:2406.09891v1 公告类型：新
摘要：生成模型已经在编程、自然科学和常识等领域的各种基准测试中表现出了人类水平的熟练程度。尽管在竞争性基准测试中取得了这些令人鼓舞的结果，但它们在通常由小学学生执行的看似简单的问题解决任务中仍然举步维艰。最先进的模型在旨在评估学校计算思维和解决问题能力的标准化测试中表现如何？在本文中，我们策划了一个新颖的基准，涉及以基础可视化编程领域为基础的计算思维测试。我们的初步结果表明，GPT-4o 和 Llama3 等最先进的模型几乎无法与普通学校学生的表现相匹配。为了进一步提高这些模型的性能，我们使用一种新颖的合成数据生成方法对它们进行微调。关键思想是使用符号方法开发一个全面的数据集，以捕捉不同的技能水平，从视觉元素识别到多项选择测验再到综合式任务。我们展示了合成数据中符号信息的各个方面如何帮助提高微调模型的性能。我们将发布完整的实现和数据集，以促进进一步研究增强生成模型中的计算思维。]]></description>
      <guid>https://arxiv.org/abs/2406.09891</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:40 GMT</pubDate>
    </item>
    <item>
      <title>神经概念绑定</title>
      <link>https://arxiv.org/abs/2406.09949</link>
      <description><![CDATA[arXiv:2406.09949v1 公告类型：新
摘要：基于对象的视觉推理的挑战在于生成描述性但独特的概念表示。此外，以无监督的方式执行此操作需要人类用户理解模型的学习概念并可能修改错误概念。为了应对这一挑战，我们引入了神经概念绑定器，这是一个用于导出离散概念表示的新框架，从而产生我们所说的“概念槽编码”。这些编码利用通过以对象为中心的块槽编码的“软绑定”和通过基于检索的推理的“硬绑定”。神经概念绑定器有助于直接检查概念并直接整合外部知识，例如人类输入或来自其他 AI 模型（如 GPT-4）的见解。此外，我们证明加入硬绑定机制不会影响性能；相反，它可以无缝集成到神经和符号模块中以执行复杂的推理任务，正如我们新推出的 CLEVR-Sudoku 数据集的评估所证明的那样。]]></description>
      <guid>https://arxiv.org/abs/2406.09949</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:40 GMT</pubDate>
    </item>
    <item>
      <title>在巴西全国本科计算机科学考试中评估 ChatGPT-4 Vision</title>
      <link>https://arxiv.org/abs/2406.09671</link>
      <description><![CDATA[arXiv:2406.09671v1 公告类型：新
摘要：最近将视觉功能集成到大型语言模型 (LLM) 中有可能在科学和技术教育中发挥关键作用，其中图表、图表和表格等视觉元素通常用于改善学习体验。这项研究调查了 ChatGPT-4 Vision（OpenAI 在进行研究时最先进的视觉模型）在巴西 2021 年全国本科考试 (ENADE) 计算机科学学士部分的表现。通过以原始图像格式向模型呈现考试的开放式和多项选择题，并允许根据不同的答案键重新评估，我们能够在涉及文本和视觉内容的大规模学术评估中评估模型的推理和自我反思能力。ChatGPT-4 Vision 的表现明显优于普通考试参与者，位居前 10 名最佳分数百分位之内。虽然它在包含视觉元素的问题上表现出色，但它在问题解释、逻辑推理和视觉敏锐度方面也遇到了挑战。独立专家小组参与审查模型与答案不一致的情况，发现一些构造不良的问题包含模糊或含糊不清的陈述，这提醒人们注意未来考试中改进问题设计的迫切需要。我们的研究结果表明，虽然 ChatGPT-4 Vision 在多模态学术评估中显示出希望，但人工监督对于验证模型的准确性和确保高风险教育考试的公平性仍然至关重要。该论文的研究材料可在 https://github.com/nabormendonca/gpt-4v-enade-cs-2021 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2406.09671</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>混合 Q 学习用于车道变换：多智能体深度强化学习中的协作决策方法</title>
      <link>https://arxiv.org/abs/2406.09755</link>
      <description><![CDATA[arXiv:2406.09755v1 公告类型：新
摘要：车道变换决策对于自动驾驶车辆的路径规划至关重要，但由于规则约束和数据有限，它面临着实际挑战。深度强化学习因其在数据获取和可解释性方面的优势而成为主要的研究重点。然而，目前的模型往往忽视了协作，这不仅影响整体交通效率，而且从长远来看也会阻碍车辆自身的正常驾驶。为了解决上述问题，本文提出了一种混合 Q 学习车道变换 (MQLC) 的方法，该方法集成了混合价值 Q 网络，兼顾集体和个人利益，以实现更大的利益。在集体层面，我们的方法利用全局信息协调个体 Q 和全局 Q 网络。这使代理能够有效地平衡他们的个人利益和集体利益。在个体层面，我们将基于深度学习的意图识别模块集成到我们的观察中并增强了决策网络。这些变化为代理提供了更丰富的决策信息和更准确的特征提取，从而改善了车道变换决策。该策略使多智能体系统能够有效地学习和制定最佳决策策略。通过大量实验结果，我们的 MQLC 模型的表现令人印象深刻地优于其他最先进的多智能体决策方法，实现了更安全、更快速的换道决策。]]></description>
      <guid>https://arxiv.org/abs/2406.09755</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>OSPC：以大型语言模型为催化剂检测有害模因</title>
      <link>https://arxiv.org/abs/2406.09779</link>
      <description><![CDATA[arXiv:2406.09779v1 公告类型：新 
摘要：模因在互联网上迅速传播个人观点和立场，也对传播社会偏见和歧视构成重大挑战。本研究提出了一种检测有害模因的新方法，特别是在新加坡的多元文化和多语言背景下。我们的方法集成了图像字幕、光学字符识别 (OCR) 和大型语言模型 (LLM) 分析，以全面理解和分类有害模因。利用 BLIP 模型进行图像字幕、PP-OCR 和 TrOCR 进行多种语言的文本识别以及 Qwen LLM 进行细致的语言理解，我们的系统能够识别用英语、中文、马来语和泰米尔语创建的模因中的有害内容。为了提高系统的性能，我们通过利用使用 GPT-4V 标记的额外数据对我们的方法进行了微调，旨在将 GPT-4V 对有害模因的理解能力提炼到我们的系统中。我们的框架在 AI Singapore 主办的在线安全奖挑战赛公共排行榜上名列前茅，AUROC 为 0.7749，准确率为 0.7087，远远领先于其他团队。值得注意的是，我们的方法优于之前的基准，FLAVA 的 AUROC 为 0.5695，VisualBERT 的 AUROC 为 0.5561。]]></description>
      <guid>https://arxiv.org/abs/2406.09779</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>从表现到认知架构：一个可扩展的框架</title>
      <link>https://arxiv.org/abs/2406.09823</link>
      <description><![CDATA[arXiv:2406.09823v1 公告类型：新
摘要：人工智能领域充斥着优化方法。在本文中，我们将重点转向开发建模方法，目的是让我们更接近通用人工智能。为此，我们提出了一种新颖的方法，将现实解释为信息源，然后将其转化为能够捕获和表示此类信息的计算框架。该框架能够从仅处理空间分布式表示的简单原语开始，构建经典认知架构的元素，如长期记忆和工作记忆。此外，它以无缝可扩展的分层方式实现了这种垂直度。]]></description>
      <guid>https://arxiv.org/abs/2406.09823</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:39 GMT</pubDate>
    </item>
    <item>
      <title>CleanDiffuser：一个易于使用的模块化决策扩散模型库</title>
      <link>https://arxiv.org/abs/2406.09509</link>
      <description><![CDATA[arXiv:2406.09509v1 公告类型：新
摘要：利用扩散模型 (DM) 强大的生成能力来构建决策代理已取得广泛成功。然而，仍然需要一个易于使用且模块化的开源库，为基于 DM 的决策算法提供定制和高效的开发。在这项工作中，我们介绍了 CleanDiffuser，这是第一个专门为决策算法设计的 DM 库。通过重新审视 DM 在决策领域中的作用，我们确定了一组构成 CleanDiffuser 核心的基本子模块，允许使用简单灵活的构建块实现各种 DM 算法。为了证明 CleanDiffuser 的可靠性和灵活性，我们对使用 CleanDiffuser 在广泛任务中实现的各种 DM 算法进行了全面评估。分析实验提供了大量有价值的设计选择和见解，揭示了机遇和挑战，并为未来的研究奠定了坚实的基础。 CleanDiffuser 将为决策社区提供长期支持，提高可重复性并促进更强大解决方案的开发。CleanDiffuser 的代码和文档在 https://github.com/CleanDiffuserTeam/CleanDiffuser 上开源。]]></description>
      <guid>https://arxiv.org/abs/2406.09509</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:38 GMT</pubDate>
    </item>
    <item>
      <title>使用基于区域的图神经网络对知识图谱进行可区分推理</title>
      <link>https://arxiv.org/abs/2406.09529</link>
      <description><![CDATA[arXiv:2406.09529v1 公告类型：新
摘要：知识图谱 (KG) 补全方法需要捕获语义规律并使用这些规律推断未明确说明的合理知识。大多数基于嵌入的方法在它们可以捕获的规律类型方面是不透明的，尽管基于区域的 KG 嵌入模型已经成为一种更透明的替代方案。通过将关系建模为高维向量空间中的几何区域，此类模型可以根据这些区域的空间排列明确捕获语义规律。不幸的是，现有的基于区域的方法在它们可以捕获的规则类型方面受到严重限制。我们认为这种限制的出现是因为所考虑的区域被定义为二维区域的笛卡尔积。作为一种替代方案，在本文中，我们提出了 RESHUFFLE，这是一个基于排序约束的简单模型，它可以忠实地捕获比现有方法大得多的规则库类。此外，我们框架中的嵌入可以通过单调图神经网络 (GNN) 来学习，该网络可有效地充当可微分规则库。这种方法具有一个重要优势，即随着新知识添加到 KG，嵌入可以轻松更新。同时，由于生成的表示可以像标准 KG 嵌入一样使用，因此我们的方法比现有的可微分推理方法效率高得多。]]></description>
      <guid>https://arxiv.org/abs/2406.09529</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:38 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型自动生成和标记分子概念</title>
      <link>https://arxiv.org/abs/2406.09612</link>
      <description><![CDATA[arXiv:2406.09612v1 公告类型：新
摘要：人工智能 (AI) 正在显著改变科学研究。可解释的 AI 方法（例如基于概念的模型 (CM)）有望推动新的科学发现，因为它们基于有意义的概念进行预测并提供对预测过程的见解。然而，在分子科学中，与图神经网络 (GNN) 等黑盒模型相比，可解释的 CM 并不常见，主要是因为它们需要预定义的概念和每个实例的手动标记，这需要领域知识并且可能劳动密集型。本文介绍了一种用于自动分子概念 (AutoMolCo) 生成和标记的新框架。AutoMolCo 利用大型语言模型 (LLM) 中的知识自动生成预测分子概念并为每个分子标记它们。通过与 LLM 的迭代交互重复此类过程以细化概念，使精炼概念上的简单线性模型在多个基准测试中胜过 GNN 和 LLM 上下文学习。整个 AutoMolCo 框架都是自动化的，在概念生成、标记或细化过程中无需任何人类知识输入，从而超越了现有 CM 的局限性，同时保持了其可解释性并易于干预。通过在 MoleculeNet 和高通量实验 (HTE) 数据集上的系统实验，我们证明了 AutoMolCo 诱导的可解释 CM 对分子科学研究是有益且有前景的。]]></description>
      <guid>https://arxiv.org/abs/2406.09612</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:38 GMT</pubDate>
    </item>
    <item>
      <title>GPT-ology、计算模型、硅采样：我们应该如何看待认知科学的法学硕士？</title>
      <link>https://arxiv.org/abs/2406.09464</link>
      <description><![CDATA[arXiv:2406.09464v1 公告类型：新
摘要：大型语言模型席卷了认知科学界。现在也许是时候盘点一下用于对这些模型中的“认知”或人类认知进行科学推断的各种研究范式了。我们回顾了几种新兴的研究范式——GPT-ology、LLM 作为计算模型和“硅采样”——并回顾了最近在这些范式下使用 LLM 的论文。在此过程中，我们讨论了它们的主张以及在这些不同范式下对科学推断的挑战。我们重点介绍了几个关于 LLM 的未决问题，必须解决这些问题才能推动我们的科学向前发展：闭源与开源模型；（缺乏可见性）训练数据；以及 LLM 研究的可重复性，包括形成关于新任务“超参数”的约定，如指令和提示。]]></description>
      <guid>https://arxiv.org/abs/2406.09464</guid>
      <pubDate>Tue, 18 Jun 2024 03:23:37 GMT</pubDate>
    </item>
    </channel>
</rss>