<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 22 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在人机交互的背景下重新审视罗杰斯悖论</title>
      <link>https://arxiv.org/abs/2501.10476</link>
      <description><![CDATA[arXiv:2501.10476v1 公告类型：新
摘要：人类通过多种方式了解世界以及如何在世界上行动：从单独进行实验到观察和复制他人的行为。不同的学习策略伴随着不同的成本和成功学习更多世界的可能性。如果人们相互学习，任何一个人对如何学习的选择都会对整个群体的集体理解产生影响。艾伦·罗杰斯开发了一个代理群体的模拟来研究这些网络现象，代理可以在动态、不确定的世界中单独或社交地学习，并发现了一个令人困惑的结果：廉价的社交学习的可用性并没有给群体适应性带来比个人学习更好的好处。这一悖论引发了数十年的研究，试图理解和揭示促进社会学习相对好处的因素，而数百年来的人类行为表明这种好处是存在的。既然人类可以从人工智能系统中进行社交学习，而人工智能系统本身也在向我们进行社交学习，那么在这样的网络模型中会发生什么？我们在人机交互的背景下重新审视罗杰斯悖论，以探索人类和人工智能系统共同学习不确定世界的简化网络。我们提出并研究了几种学习策略对社会“集体世界模型”平衡质量的影响。我们考虑了参与单个人机交互的各个利益相关者可以采取的策略：人类、人工智能模型构建者以及交互周围的社会或监管者。然后，我们考虑了人类从人工智能中进行社交学习可能产生的负反馈循环：从人工智能中学习可能会影响我们自己了解世界的能力。我们以开放的方向结束本文，研究人类和人工智能系统的网络，这些网络可以在我们模拟框架的丰富版本中进行探索。]]></description>
      <guid>https://arxiv.org/abs/2501.10476</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ColorGrid：用于目标推理和辅助的多智能体非平稳环境</title>
      <link>https://arxiv.org/abs/2501.10593</link>
      <description><![CDATA[arXiv:2501.10593v1 公告类型：新
摘要：自主代理与人类的互动越来越注重适应他们不断变化的偏好，以改善对现实世界任务的帮助。有效的代理必须学会准确推断人类目标，而这些目标往往是隐藏的，才能很好地协作。然而，现有的多代理强化学习 (MARL) 环境缺乏严格评估这些代理学习能力所需的必要属性。为此，我们引入了 ColorGrid，这是一种具有可定制的非平稳性、不对称性和奖励结构的新型 MARL 环境。我们研究了 ColorGrid 中独立近端策略优化 (IPPO)（一种最先进的 (SOTA) MARL 算法）的性能，并通过广泛的消融发现，特别是在代表人类的“领导者”代理和“追随者”助理代理之间同时存在非平稳和不对称目标的情况下，IPPO 无法解决 ColorGrid。为了支持对未来 MARL 算法进行基准测试，我们在 https://github.com/andreyrisukhin/ColorGrid 发布了我们的环境代码、模型检查点和轨迹可视化。]]></description>
      <guid>https://arxiv.org/abs/2501.10593</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于连续处理观察数据的分布稳健策略评估和学习</title>
      <link>https://arxiv.org/abs/2501.10693</link>
      <description><![CDATA[arXiv:2501.10693v1 公告类型：新
摘要：使用离线观察数据进行政策评估和学习，决策者可以评估和学习将特征和干预措施联系起来的政策。大多数现有文献要么集中在离散处理空间上，要么假设策略学习和策略部署环境之间的分布没有差异。这些限制了在许多现实世界场景中的应用，在这些场景中，连续处理存在分布变化。为了克服这些挑战，本文重点研究在连续处理环境下开发一种分布稳健的策略。所提出的分布稳健估计量是使用从离散方法扩展而来的逆概率加权 (IPW) 方法建立的，用于连续处理下的策略评估和学习。具体而言，我们在所提出的 IPW 估计量中引入了一个核函数，以减轻标准 IPW 方法中可能出现的连续处理中的观察排除。然后，我们提供有限样本分析，以保证所提出的分布稳健策略评估和学习估计量的收敛。综合实验进一步验证了我们的方法在存在分布变化时的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.10693</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAPS：推进专家级物理科学中的多模态推理</title>
      <link>https://arxiv.org/abs/2501.10768</link>
      <description><![CDATA[arXiv:2501.10768v1 公告类型：新
摘要：当前的多模态大型语言模型 (MLLM) 在大量文本和图像语料库上进行了预训练，在一般视觉推理任务中表现出强大的能力。然而，它们在需要理解具有复杂物理结构的图表并基于多模态信息进行定量分析的物理领域中仍然表现不佳。为了解决这个问题，我们开发了一个基于 MLLM 的新框架，即具有物理感知和模拟的多模态科学推理 (MAPS)。MAPS 将专家级多模态推理任务分解为通过物理感知模型 (PPM) 的物理图理解和通过模拟器使用物理知识进行推理。PPM 模块是通过使用精心设计的合成数据与成对的物理图和相应的模拟语言描述对视觉语言模型进行微调而获得的。在推理阶段，MAPS 将 PPM 提供的输入图的仿真语言描述与通过链式仿真过程获得的结果与 MLLM 集成，以得出基本原理和最终答案。使用我们收集的大学级电路分析问题进行验证，MAPS 显著提高了 MLLM 的推理准确性，并且优于所有现有模型。结果证实，MAPS 为增强 MLLM 的多模态科学推理能力提供了一个有希望的方向。我们将在本文发表后发布用于实验的代码、模型和数据集。]]></description>
      <guid>https://arxiv.org/abs/2501.10768</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ML-SceGen：多层次场景生成框架</title>
      <link>https://arxiv.org/abs/2501.10782</link>
      <description><![CDATA[arXiv:2501.10782v1 公告类型：新
摘要：当前的科学研究见证了将大型语言模型应用于场景生成的各种尝试，但仅倾向于综合或危险场景。在本文中，我们试图构建一个三阶段框架，该框架不仅让用户重新获得对生成场景的控制权，而且还可以在不受控制的交叉路口环境中生成包含危险因素的综合场景。在第一阶段，LLM 代理将有助于将预期场景描述的关键组件转换为功能场景。对于第二阶段，我们使用答案集编程 (ASP) 求解器 Clingo 帮助我们在交叉路口内生成全面的逻辑流量。在最后一个阶段，我们使用 LLM 更新相关参数以提高具体场景的关键级别。]]></description>
      <guid>https://arxiv.org/abs/2501.10782</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有易腐性和非平稳性的医药供应链的经典和深度强化学习库存控制策略</title>
      <link>https://arxiv.org/abs/2501.10895</link>
      <description><![CDATA[arXiv:2501.10895v1 公告类型：新
摘要：我们研究医药供应链的库存控制政策，解决易腐性、产量不确定性和非平稳需求等挑战，以及批量约束、交货时间和销售损失。我们与百时美施贵宝 (BMS) 合作，开发了一个结合这些因素的真实案例研究，并使用近端策略优化 (PPO) 算法对三项政策——订单达到 (OUT)、预计库存水平 (PIL) 和深度强化学习 (DRL)——与基于人类专业知识的 BMS 基线进行基准测试。我们推导并验证了基于边界的程序来优化 OUT 和 PIL 策略参数，并提出了一种估计预计库存水平的方法，这些方法也与需求预测一起集成到 DRL 策略中，以改善非平稳性下的决策。与通过提高持有成本来避免销售损失的人为驱动政策相比，所有这三种实施的政策都实现了较低的平均成本，但成本变化更大。虽然 PIL 表现出稳健而一致的性能，但 OUT 在高额销售损失成本下却举步维艰，而 PPO 在复杂多变的场景中表现出色，但需要大量的计算工作。研究结果表明，虽然 DRL 显示出潜力，但它并没有在所有数值实验中胜过传统策略，这凸显了 1) 基于当前最先进的技术，需要整合各种策略才能有效应对制药挑战，以及 2) 该领域的实际问题似乎缺乏一个能够产生普遍可接受性能的单一策略类别。]]></description>
      <guid>https://arxiv.org/abs/2501.10895</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>细粒度的适当依赖：人机协作，采用多步骤透明决策工作流进行复杂任务分解</title>
      <link>https://arxiv.org/abs/2501.10909</link>
      <description><![CDATA[arXiv:2501.10909v1 公告类型：新
摘要：近年来，人工智能系统的快速发展带来了智能服务的好处，但也带来了对安全性和可靠性的担忧。通过培养用户对人工智能系统的适当依赖，可以实现团队绩效的互补和减少人力工作量。先前的实证研究广泛分析了任务、系统和人类行为等因素对单步决策背景下用户信任和适当依赖的影响。然而，在需要多步骤工作流的复杂语义任务中，用户对人工智能系统的依赖仍未得到充分探索。受最近关于使用大型语言模型进行任务分解的研究的启发，我们建议研究一种新颖的多步骤透明 (MST) 决策工作流对用户依赖行为的影响。我们对人工智能辅助决策在复合事实核查任务（即涉及多个子事实验证步骤的事实核查任务）中进行了实证研究（N = 233）。我们的研究结果表明，在特定情况下（例如，当 AI 系统的建议具有误导性时），使用 MST 决策工作流的人机协作可以胜过单步协作。对细粒度级别上适当依赖的进一步分析表明，当用户对中间步骤表现出相对较高的考虑时，MST 决策工作流可以有效。我们的工作强调，没有一种万能的决策工作流可以帮助获得最佳的人机协作。我们的见解有助于加深对决策工作流在促进适当依赖方面的作用的理解。我们综合了设计有效方法以促进在复合任务中对 AI 系统的适当依赖的重要意义，为以人为本的 AI 和更广泛的 HCI 社区创造了机会。]]></description>
      <guid>https://arxiv.org/abs/2501.10909</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理语言模型：蓝图</title>
      <link>https://arxiv.org/abs/2501.11223</link>
      <description><![CDATA[arXiv:2501.11223v1 公告类型：新
摘要：推理语言模型 (RLM)，也称为大型推理模型 (LRM)，例如 OpenAI 的 o1 和 o3、DeepSeek-V3 和阿里巴巴的 QwQ，通过使用高级推理机制扩展大型语言模型 (LLM)，重新定义了 AI 的解决问题能力。然而，它们的高成本、专有性质和复杂的架构——独特地结合了强化学习 (RL)、搜索启发式和 LLM——带来了可访问性和可扩展性挑战。为了解决这些问题，我们提出了一个全面的蓝图，该蓝图基于对所有 RLM 工作的调查和分析，将 RLM 组件组织成一个模块化框架。该蓝图融合了多种推理结构（链、树、图和嵌套形式）、推理策略（例如蒙特卡洛树搜索、波束搜索）、RL 概念（策略、价值模型等）和监督方案（基于输出和基于过程的监督）。我们还提供了详细的数学公式和算法规范，以简化 RLM 实施。通过展示 LLaMA-Berry、QwQ、Journey Learning 和 Graph of Thoughts 等方案如何作为特殊情况，我们展示了蓝图的多功能性和统一潜力。为了说明它的实用性，我们引入了 x1，这是一种用于快速 RLM 原型设计和实验的模块化实现。使用 x1 和文献综述，我们提供了关键见解，例如策略和价值模型的多阶段训练，以及熟悉的训练分布的重要性。最后，我们概述了 RLM 如何与更广泛的 LLM 生态系统（包括工具和数据库）集成。我们的工作揭开了 RLM 构建的神秘面纱，使高级推理能力民主化，并促进创新，旨在通过降低 RLM 开发和实验的障碍来缩小“富 AI”和“穷 AI”之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2501.11223</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Agent-R：通过迭代自训练训练语言模型代理进行反思</title>
      <link>https://arxiv.org/abs/2501.11425</link>
      <description><![CDATA[arXiv:2501.11425v1 公告类型：新
摘要：大型语言模型 (LLM) 代理在解决交互式环境中的复杂任务方面越来越重要。现有的工作主要侧重于通过从更强大的专家那里克隆行为来提高性能，但这种方法在实际应用中往往会失败，主要是因为无法从错误中恢复。然而，步骤级批评数据很难收集，而且成本高昂。因此，自动化和动态构建自我批评数据集对于赋予模型智能代理功能至关重要。在这项工作中，我们提出了一个迭代的自我训练框架 Agent-R，使语言代理能够即时反思。与传统的根据正确性奖励或惩罚行为的方法不同，Agent-R 利用 MCTS 来构建训练数据，从错误的轨迹中恢复正确的轨迹。代理反思的一个关键挑战在于及时修订的必要性，而不是等到推出结束。为了解决这个问题，我们引入了一种模型引导的批评构建机制：参与者模型识别失败轨迹中的第一个错误步骤（在其当前能力范围内）。从它开始，我们将其与相邻的正确路径拼接在一起，该路径在树中共享相同的父节点。这种策略使模型能够根据其当前策略学习反射，从而获得更好的学习效率。为了进一步探索这种自我改进范式的可扩展性，我们研究了纠错能力和数据集构建的迭代改进。我们的研究结果表明，Agent-R 不断提高模型从错误中恢复的能力，并能够及时纠正错误。在三个交互式环境中的实验表明，Agent-R 有效地使代理能够纠正错误操作，同时避免循环，与基线方法相比实现了卓越的性能（+5.59%）。]]></description>
      <guid>https://arxiv.org/abs/2501.11425</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解释游戏——重燃（扩展版）</title>
      <link>https://arxiv.org/abs/2501.11429</link>
      <description><![CDATA[arXiv:2501.11429v1 公告类型：新
摘要：最近的研究表明，目前在可解释人工智能 (XAI) 中使用 Shapley 值（即所谓的 SHAP 分数）存在严重缺陷。这些缺陷很重要，因为提供给人类决策者的分数可能会产生误导。尽管这些负面结果似乎表明不应该在 XAI 中使用 Shapley 值，但本文却持相反观点。具体而言，本文提出了一种克服现有缺陷的 SHAP 分数的新定义。此外，本文概述了一种实用有效的解决方案，用于严格估计新的 SHAP 分数。初步实验结果证实了我们的说法，并进一步强调了当前 SHAP 分数的缺陷。]]></description>
      <guid>https://arxiv.org/abs/2501.11429</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将干预因果关系分解为协同、冗余和独特的组成部分</title>
      <link>https://arxiv.org/abs/2501.11447</link>
      <description><![CDATA[arXiv:2501.11447v1 公告类型：新
摘要：我们引入了一种新颖的框架，用于将干预性因果效应分解为协同、冗余和独特的成分，该框架基于部分信息分解 (PID) 的直觉和 M\&quot;obius 反演原理。虽然最近的研究已经探索了对观察测量的类似分解，但我们认为适当的因果分解必须是干预性的。我们开发了一种数学方法，使用最近推导的冗余格 M\&quot;obius 函数的闭式表达式，系统地量化因果力量在系统中变量之间的分布情况。然后通过分解逻辑门、细胞自动机和化学反应网络中的因果力量来说明形式主义。我们的结果揭示了因果力量的分布如何依赖于上下文和参数。这种分解揭示了因果影响如何在多个变量之间共享和组合，从而为复杂系统提供了新的见解，其潜在应用范围包括法律或人工智能系统中的责任归因，以及生物网络或气候模型的分析。]]></description>
      <guid>https://arxiv.org/abs/2501.11447</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内在奖励对强化学习探索的影响</title>
      <link>https://arxiv.org/abs/2501.11533</link>
      <description><![CDATA[arXiv:2501.11533v1 公告类型：新
摘要：强化学习中尚未解决的挑战之一是稀疏奖励环境中的艰难探索问题。已经提出了各种类型的内在奖励来通过推动多样性来解决这一挑战。这种多样性可能施加在不同级别，有利于代理探索不同的状态、策略或行为（分别是状态、策略和技能水平多样性）。然而，多样性对代理行为的影响仍不清楚。在这项工作中，我们旨在通过研究内在奖励施加的不同程度的多样性对强化学习代理的探索模式的影响来填补这一空白。我们选择了四个内在奖励（状态计数、内在好奇心模块 (ICM)、最大熵和多样性就是你所需要的 (DIAYN)），每个奖励都推动不同的多样性水平。我们对 MiniGrid 环境进行了实证研究，以比较它们对探索的影响，同时考虑与代理探索相关的各种指标，即：情景回报、观察覆盖率、代理位置覆盖率、策略熵和达到稀疏奖励的时间范围。研究的主要结果是，在低维观测的情况下，状态计数可带来最佳探索性能。然而，在 RGB 观测的情况下，状态计数的性能会严重下降，主要是由于表示学习的挑战。相反，最大熵受到的影响较小，从而实现更稳健的探索，尽管它并不总是最佳的。最后，我们的实证研究表明，使用 DIAYN 学习多样化的技能（通常与提高稳健性和泛化能力有关）不会促进 MiniGrid 环境中的探索。这是因为：i) 学习技能空间本身可能具有挑战性，ii) 技能空间内的探索优先考虑区分行为，而不是实现统一的状态访问。]]></description>
      <guid>https://arxiv.org/abs/2501.11533</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SR-FoT：用于解决基于知识的推理任务的大型语言模型的三段论推理思维框架</title>
      <link>https://arxiv.org/abs/2501.11599</link>
      <description><![CDATA[arXiv:2501.11599v1 公告类型：新
摘要：演绎推理是一种重要的逻辑能力，可以帮助我们根据现有知识解决复杂问题。尽管通过思维链提示得到了增强，但大型语言模型 (LLM) 可能不会遵循正确的推理路径。增强 LLM 的演绎推理能力并利用其广泛的内置知识完成各种推理任务仍是一个悬而未决的问题。为了模仿人类的演绎推理范式，我们提出了一个多阶段的三段论推理思维框架 (SR-FoT)，使 LLM 能够执行三段论演绎推理来处理复杂的基于知识的推理任务。我们的 SR-FoT 首先解释问题，然后使用解释和原始问题提出合适的大前提。它通过分两个阶段生成和回答小前提问题来匹配小前提。最后，它指导 LLM 使用先前生成的大前提和小前提进行三段论演绎推理，以得出原始问题的答案。在基于知识的推理任务上进行的大量深入实验证明了我们的 SR-FoT 的有效性和优势。]]></description>
      <guid>https://arxiv.org/abs/2501.11599</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理的情景记忆存在风险，需要研究和缓解</title>
      <link>https://arxiv.org/abs/2501.11739</link>
      <description><![CDATA[arXiv:2501.11739v1 公告类型：新
摘要：大多数当前的人工智能模型几乎没有能力存储和稍后检索它们所做事情的记录或表示。在人类认知中，情景记忆在回忆过去和规划未来方面都发挥着重要作用。形成和使用情景记忆的能力同样可以使与世界互动并在世界中采取行动的人工智能代理具有广泛的改进能力。研究人员已经开始更加关注开发人工智能模型的记忆能力。因此，具有这种能力的模型很可能在不久的将来得到广泛应用。这在某种程度上有助于使此类人工智能代理更安全，使用户能够更好地监控、理解和控制他们的行为。然而，作为一种具有广泛应用的新功能，我们认为它也会带来重大的新风险，研究人员应该开始研究和解决这些风险。我们概述了这些风险和好处，并提出了四项原则来指导情景记忆能力的发展，以便这些原则能够增强而不是破坏保持人工智能安全和可信的努力。]]></description>
      <guid>https://arxiv.org/abs/2501.11739</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过论证和图形着色解决规范冲突的政策适应方法</title>
      <link>https://arxiv.org/abs/2501.11799</link>
      <description><![CDATA[arXiv:2501.11799v1 公告类型：新
摘要：在多智能体系统中，人们可以选择通过施加规范来管理智能体的行为，这些规范可作为智能体应如何始终或在特定情况下采取行动的指南。但是，对一个或多个智能体施加多个规范可能会导致这些规范与智能体应如何表现相冲突的情况。在任何存在规范冲突的系统中（例如安全强化模型或监控安全协议的系统），人们必须决定应遵循哪些规范，以便维护最重要和最相关的规范。我们引入了一种通过论证和图形着色解决规范冲突的新方法，该方法与各种规范冲突解决策略兼容。我们证明该方法在论证语义下始终创建一组可接受的论据，这意味着它会产生连贯的输出。我们还介绍了这种方法的更强大的变体，每种变体都以前者为基础来创建更出色的输出，并且我们进一步提供了它们连贯性的数学证明。我们最先进的变体使用了现有的限制概念，即一种规范可以取代另一种规范，但不会完全消除。我们引入的方法都与各种现有的解决规范冲突的政策兼容。我们还进行了实证评估，以将我们的算法相互比较，并与现有文献中的其他算法进行比较。]]></description>
      <guid>https://arxiv.org/abs/2501.11799</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过矢量符号架构中的多种关系表示进行系统溯因推理</title>
      <link>https://arxiv.org/abs/2501.11896</link>
      <description><![CDATA[arXiv:2501.11896v1 公告类型：新
摘要：在抽象视觉推理中，单片深度学习模型的可解释性和泛化性有限，而现有的神经符号方法在捕捉属性和关系表示的多样性和系统性方面存在不足。为了应对这些挑战，我们提出了一种具有多样化关系表示的系统溯因推理模型（Rel-SAR），该模型采用矢量符号架构（VSA）来解决瑞文渐进矩阵（RPM）。为了得出具有符号推理潜力的属性表示，我们不仅引入了表示数字、周期和逻辑语义的各种类型的原子向量，还引入了整个网格组件的结构化高维表示（SHDR）。对于系统推理，我们提出了新颖的数字和逻辑关系函数，并在集成这些关系表示的统一框架中执行规则溯因和执行。实验结果表明，Rel-SAR 在 RPM 任务上取得了显着的改进，并表现出强大的分布外泛化能力。 Rel-SAR 利用 HD 属性表示和符号推理之间的协同作用，实现具有可解释和可计算语义的系统溯因推理。]]></description>
      <guid>https://arxiv.org/abs/2501.11896</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弥合沟通鸿沟：评估人工智能标签实践以实现值得信赖的人工智能开发</title>
      <link>https://arxiv.org/abs/2501.11909</link>
      <description><![CDATA[arXiv:2501.11909v1 公告类型：新
摘要：随着人工智能 (AI) 成为经济和社会不可或缺的一部分，开发人员、用户和利益相关者之间的沟通差距阻碍了信任和明智的决策。受欧盟能源标签等框架的启发，高级 AI 标签已被提出，以使 AI 模型的属性更加透明。无需深厚的技术专业知识，它们就可以告知预测性能和资源效率之间的权衡。然而，AI 标签的实际好处和局限性仍未得到充分探索。本研究通过定性访谈对四个关键研究问题评估了 AI 标签。基于主题分析和归纳编码，我们发现广泛的从业者对 AI 标签感兴趣 (RQ1)。他们认为缓解沟通差距和帮助非专家决策者的好处，但也讨论了局限性、误解和改进建议 (RQ2)。与其他报告格式相比，受访者对标签复杂性的降低给予了积极评价，提高了整体可理解性 (RQ3)。信任度主要受可用性和负责任标签机构的可信度影响，人们对自我认证和第三方认证的偏好参差不齐（RQ4）。我们的洞察强调，AI 标签在简单性和复杂性之间需要权衡，可以通过开发可定制和交互式的标签框架来满足不同的用户需求。资源效率的透明标签也促使受访者在 AI 开发过程中更加关注可持续性方面。这项研究证实 AI 标签是增强 AI 信任和沟通的宝贵工具，为其改进和标准化提供了可行的指导方针。]]></description>
      <guid>https://arxiv.org/abs/2501.11909</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>充分利用测试信息：自动驾驶系统的集成加速测试和评估方法</title>
      <link>https://arxiv.org/abs/2501.11924</link>
      <description><![CDATA[arXiv:2501.11924v1 公告类型：新
摘要：测试评估是自动驾驶系统（ADS）大规模应用前的重要步骤。基于三级场景抽象理论，可以在逻辑场景内进行测试，然后进入评估阶段，输入从逻辑参数空间生成的各个具体场景的测试结果。在此过程中，产生了丰富的测试信息，有利于全面、准确地进行评估。为了充分利用测试信息，本文提出了一种集成加速测试与评估方法（ITEM）。基于前文提出的蒙特卡洛树搜索（MCTS）范式和双代理测试框架，本文将测试阶段生成的中间信息（即树结构，包括每个历史采样点与子空间的隶属关系以及子空间之间的父子关系）应用到评估阶段，实现准确的危险域识别。此外，为了更好地实现此目的，改进了UCB计算方法，使搜索算法更加关注危险域边界。此外，基于搜索算法的收敛性构造了停止条件。然后进行消融和对比实验，以验证改进的有效性和所提方法的优越性。实验结果表明，ITEM在低维和高维情况下都能很好地识别危险域，无论危险域的形状如何，都表明其在ADS安全性评估中的通用性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.11924</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接可视化和优化：基于图结构组合优化的多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2501.11968</link>
      <description><![CDATA[arXiv:2501.11968v1 公告类型：新
摘要：图结构组合挑战由于其非线性和复杂的性质而具有内在的困难性，这通常会导致传统计算方法无效或昂贵。然而，人类可以通过利用我们天生的空间推理能力的视觉表现更自然地应对这些挑战。在这项研究中，我们提出将图形转换为图像以准确保留其高阶结构特征，从而彻底改变用于解决图结构组合任务的表示。这种方法允许机器模拟人类处理复杂的组合挑战。通过将由多模态大型语言模型 (MLLM) 驱动的创新范式与简单的搜索技术相结合，我们旨在开发一种新颖而有效的框架来解决此类问题。我们对 MLLM 的研究涵盖了各种基于图的任务，从影响力最大化等组合问题到网络拆除中的顺序决策，以及解决六个与图相关的基本问题。我们的研究结果表明，MLLM 表现出卓越的空间智能和处理这些问题的独特能力，大大提高了机器理解和分析图形结构数据的潜力，其深度和直觉与人类认知相似。这些结果还意味着，将 MLLM 与简单的优化策略相结合可以形成一种新颖而有效的方法，用于应对图形结构组合挑战，而无需复杂的推导、计算要求高的训练和微调。]]></description>
      <guid>https://arxiv.org/abs/2501.11968</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UI-TARS：开创性的与本机代理的自动化 GUI 交互</title>
      <link>https://arxiv.org/abs/2501.12326</link>
      <description><![CDATA[arXiv:2501.12326v1 公告类型：新
摘要：本文介绍了 UI-TARS，这是一种原生 GUI 代理模型，它仅将屏幕截图视为输入并执行类似人类的交互（例如键盘和鼠标操作）。与依赖于具有专家制作的提示和工作流程的大量包装的商业模型（例如 GPT-4o）的现行代理框架不同，UI-TARS 是一个端到端模型，其性能优于这些复杂的框架。实验证明了其卓越的性能：UI-TARS 在评估感知、接地和 GUI 任务执行的 10 多个 GUI 代理基准测试中实现了 SOTA 性能。值得注意的是，在 OSWorld 基准测试中，UI-TARS 在 50 步中获得了 24.6 分，在 15 步中获得了 22.7 分，优于 Claude（分别为 22.0 分和 14.9 分）。在AndroidWorld中，UI-TARS得分达到46.6，超越GPT-4o（34.5）。UI-TARS包含几个关键创新：（1）增强感知：利用大规模GUI截图数据集，实现对UI元素的情境感知理解和精准字幕；（2）统一动作建模，将动作标准化到跨平台的统一空间中，并通过大规模动作轨迹实现精准落地和交互；（3）System-2推理，将深思熟虑的推理融入多步决策中，涉及任务分解、反思思维、里程碑识别等多种推理模式。（4）具有反射在线轨迹的迭代训练，通过在数百台虚拟机上自动收集、过滤和反射性地细化新的交互轨迹来解决数据瓶颈问题。通过迭代训练和反射调优，UI-TARS不断从错误中学习，以最少的人为干预适应不可预见的情况。我们还分析了 GUI 代理的演进路径，以指导该领域的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2501.12326</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>