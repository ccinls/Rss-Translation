<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>自动提取空间语义图以识别认知障碍</title>
      <link>https://arxiv.org/abs/2502.01685</link>
      <description><![CDATA[arXiv:2502.01685v1 公告类型：新
摘要：现有的从图片描述中分析语言内容以评估认知语言障碍的方法经常忽略参与者的视觉叙事路径，而这通常需要眼动追踪来评估。空间语义图是一种有用的工具，仅从记录中分析这种叙事路径，但它们受到需要手动标记内容信息单元 (CIU) 的限制。在本文中，我们提出了一种自动估计空间语义图的方法（通过自动提取 CIU），该方法通常用于认知语言分析中的 Cookie Theft 图片。该方法能够在图片描述过程中自动表征视觉语义路径。实验表明，自动空间语义图可以有效区分认知障碍和未障碍的说话者。统计分析表明，自动化方法得出的特征产生的结果与手动方法相当，感兴趣的临床组之间的组差异甚至更大。这些结果强调了自动提取空间语义特征的方法在开发用于认知障碍评估的临床语音模型中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.01685</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思路链推理的亚稳态动力学：搜索、强化学习和提炼的可证明优势</title>
      <link>https://arxiv.org/abs/2502.01694</link>
      <description><![CDATA[arXiv:2502.01694v1 公告类型：新
摘要：提高大型语言模型 (LLM) 推理能力的一个关键范例是分配更多的推理时间计算来搜索验证器或奖励模型。然后可以利用此过程来改进预训练模型或将其推理模式提炼为更高效的模型。在本文中，我们通过将思路链 (CoT) 生成视为亚稳态马尔可夫过程来研究推理时间计算：简单的推理步骤（例如代数运算）形成密集连接的集群，而困难的推理步骤（例如应用相关定理）在集群之间创建稀疏、低概率的边缘，从而导致更长的时间尺度上的相变。在这个框架下，我们证明实施奖励稀疏边缘的搜索协议可以通过减少到达不同集群的预期步骤数来改善 CoT。相反，当模型被限制在预训练图的局部信息时，我们对推理能力设定了一个限制。我们还表明，可以利用搜索获得的信息来获得更好的推理模型：（1）可以通过策略梯度方法直接微调预训练模型以支持稀疏边，此外（2）可以将推理动态的压缩亚稳态表示提炼为更小、更高效的模型。]]></description>
      <guid>https://arxiv.org/abs/2502.01694</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于检测现实世界数据中的认知问题的代理 AI 工作流程</title>
      <link>https://arxiv.org/abs/2502.01789</link>
      <description><![CDATA[arXiv:2502.01789v1 公告类型：新
摘要：早期识别认知问题至关重要，但通常会受到细微症状表现的阻碍。本研究使用 LLaMA 3 8B 开发并验证了一种全自动多智能体 AI 工作流程，以识别来自麻省总医院布莱根分院的 3,338 份临床记录中的认知问题。代理工作流程利用动态协作的任务特定代理从临床记录中提取有意义的见解，并与专家驱动的基准进行了比较。两种工作流程都实现了高分类性能，F1 分数分别为 0.90 和 0.91。代理工作流程显示出更高的特异性（1.00）并在更少的迭代中实现了快速细化。虽然两种工作流程在验证数据上的性能都降低了，但代理工作流程保持了完美的特异性。这些发现凸显了全自动多智能体 AI 工作流程以更高的效率实现专家级准确性的潜力，为在临床环境中检测认知问题提供了一种可扩展且经济高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.01789</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分布式认知系统和进化策略构建认知双胞胎</title>
      <link>https://arxiv.org/abs/2502.01834</link>
      <description><![CDATA[arXiv:2502.01834v1 公告类型：新
摘要：这项工作提出了一种基于交互的认知双胞胎（外部代理的计算版本）的技术，该技术使用输入输出训练和进化策略在分布式认知架构框架之上构建。在这里，我们展示了可以协调许多简单的物理和虚拟设备，通过以端到端的方式训练系统并呈现性能指标来实现对人机交互行为的良好近似。生成的认知双胞胎以后可用于自动执行任务、生成更逼真的类人人工智能体或进一步研究其行为。]]></description>
      <guid>https://arxiv.org/abs/2502.01834</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CH-MARL：面向可持续海上物流的约束分层多智能体强化学习</title>
      <link>https://arxiv.org/abs/2502.02060</link>
      <description><![CDATA[arXiv:2502.02060v1 公告类型：新
摘要：应对温室气体排放和资源不平等等全球挑战需要在自主代理之间进行先进的人工智能驱动协调。我们提出了 CH-MARL（约束分层多智能体强化学习），这是一个新颖的框架，它将分层决策与动态约束执行和公平意识奖励塑造相结合。CH-MARL 采用实时约束执行层来确保遵守全球排放上限，同时结合公平指标来促进代理之间的公平资源分配。在模拟海上物流环境中进行的实验表明，排放量显着减少，同时公平性和运营效率得到提高。除了这一领域特定的成功之外，CH-MARL 还为受限、动态环境中的多智能体协调挑战提供了可扩展、可推广的解决方案，从而推动了强化学习的最新进展。]]></description>
      <guid>https://arxiv.org/abs/2502.02060</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仅靠标准神经计算不足以实现逻辑智能</title>
      <link>https://arxiv.org/abs/2502.02135</link>
      <description><![CDATA[arXiv:2502.02135v1 公告类型：新
摘要：目前设计的神经网络无法实现真正​​的逻辑智能。现代人工智能模型依赖于标准神经计算（基于内积的转换和非线性激活）来从数据中近似模式。虽然这种架构对于归纳学习有效，但它缺乏演绎推理和逻辑一致性所必需的结构保证。因此，深度网络在没有大量事后修改的情况下难以进行基于规则的推理、结构化泛化和可解释性。本立场文件认为，必须从根本上重新考虑标准神经层以整合逻辑推理。我们提倡逻辑神经单元 (LNU) - 模块化组件，将逻辑运算（例如 AND、OR、NOT）的可微分近似直接嵌入神经架构中。我们批评现有的神经符号方法，强调标准神经计算在逻辑推理方面的局限性，并将 LNU 视为人工智能的必要范式转变。最后，我们概述了实施路线图，讨论了理论基础、架构集成以及未来研究的主要挑战。]]></description>
      <guid>https://arxiv.org/abs/2502.02135</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行风险感知驾驶场景分析</title>
      <link>https://arxiv.org/abs/2502.02145</link>
      <description><![CDATA[arXiv:2502.02145v1 公告类型：新
摘要：大型语言模型 (LLM) 可以捕捉细微的上下文关系、推理和复杂的问题解决。通过利用其处理和解释大规模信息的能力，LLM 已显示出解决特定领域挑战的潜力，包括自动驾驶系统中的挑战。本文提出了一个利用 LLM 对生成的驾驶场景进行风险感知分析的新框架。我们假设 LLM 可以有效评估自动驾驶测试模拟器生成的驾驶场景是否对安全至关重要。为了验证这一假设，我们进行了实证评估，以评估 LLM 在执行此任务方面的有效性。该框架还将提供反馈，通过使用对抗方法修改现有的非关键场景并测试其在验证运动规划算法中的有效性来生成新的安全关键场景。代码和场景可在以下位置获得：https://github.com/yuangao-tum/Riskaware-Scenario-analyse]]></description>
      <guid>https://arxiv.org/abs/2502.02145</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过去偏技术缓解安全一致语言模型的漏洞</title>
      <link>https://arxiv.org/abs/2502.02153</link>
      <description><![CDATA[arXiv:2502.02153v1 公告类型：新
摘要：安全对齐是现实世界人工智能应用的一个重要研究课题。尽管人工智能的安全性和可信度具有多面性，但当前的安全对齐方法通常侧重于全面的安全概念。通过仔细评估现有安全对齐方法的模型，我们发现，虽然它们通常会提高整体安全性能，但无法确保特定类别的安全性。我们的研究首先确定了在不牺牲模型有用性的情况下消除此类漏洞的难度。我们观察到，虽然较小的 KL 惩罚参数、增加训练迭代和数据集清理可以增强安全性，但它们不一定能改善安全性和有用性之间的权衡。我们发现，安全对齐甚至可能引起不良影响，并导致模型倾向于生成导致拒绝响应的负面标记，而不管输入上下文如何。为了解决这个问题，我们引入了一种无需学习的方法，即 Token 级安全去偏推理 (TSDI)，使用随机构造的提示在生成过程中估计和纠正这种偏差。我们的实验表明，我们的方法可以在保持安全性的同时增强模型的帮助性，从而改善权衡帕累托前沿。]]></description>
      <guid>https://arxiv.org/abs/2502.02153</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引出游戏：评估能力引出技术</title>
      <link>https://arxiv.org/abs/2502.02180</link>
      <description><![CDATA[arXiv:2502.02180v1 公告类型：新
摘要：能力评估是理解和规范可能部署或进一步开发的人工智能系统所必需的。因此，评估必须提供对人工智能系统能力的准确评估。然而，在许多情况下，以前潜在的能力已经从模型中引出，有时是在首次发布之后很久。因此，人们做出了巨大的努力来开发从模型中引出潜在能力的方法。在本文中，我们通过有意训练模型生物（具有通过密码显示的隐藏能力的语言模型）来评估能力引出技术的有效性。我们介绍了一种基于断路训练模型生物的新方法，它比标准的密码锁定模型对引出技术的鲁棒性更强。我们专注于基于提示和激活引导的引出技术，并将它们与微调方法进行比较。提示技术可以在 MCQA 设置中引出密码锁定和断路模型生物的实际能力，而引导则无法做到这一点。对于代码生成任务，只有微调才能引出我们新模型生物的隐藏能力。此外，我们的结果表明，结合多种技术可以提高引出率。不过，如果可能的话，微调应该是提高能力评估可信度的首选方法。]]></description>
      <guid>https://arxiv.org/abs/2502.02180</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对临时团队合作的极小化极大化方法</title>
      <link>https://arxiv.org/abs/2502.02377</link>
      <description><![CDATA[arXiv:2502.02377v1 公告类型：新
摘要：我们提出了一种用于临时团队合作 (AHT) 的极小最大贝叶斯方法，该方法针对合作伙伴的对抗性先验优化策略，明确考虑到部署时对合作伙伴的不确定性。与假设合作伙伴有特定分布的现有方法不同，我们的方法提高了最坏情况下的性能保证。大量实验（包括对 Melting Pot 套件中的协调烹饪任务的评估）表明，与自我游戏、虚拟游戏和最佳反应学习相比，我们的方法具有出色的稳健性。我们的工作强调了选择适当的队友训练分布以实现 AHT 稳健性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.02377</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向可证明解决凸优化问题的图神经网络</title>
      <link>https://arxiv.org/abs/2502.02446</link>
      <description><![CDATA[arXiv:2502.02446v1 公告类型：新
摘要：最近，消息传递图神经网络 (MPNN) 因其能够捕获变量约束交互而显示出解决组合和连续优化问题的潜力。虽然现有方法利用 MPNN 来近似解或热启动传统求解器，但它们通常缺乏可行性保证，特别是在凸优化设置中。在这里，我们提出了一个迭代 MPNN 框架来解决凸优化问题，并提供可证明的可行性保证。首先，我们证明 MPNN 可以可证明地模拟标准内点法来解决具有线性约束的二次问题，涵盖 SVM 等相关问题。其次，为了确保可行性，我们引入了一个从可行点开始并迭代地将搜索限制在可行区域内的变体。实验结果表明，我们的方法在解决方案质量和可行性方面优于现有的神经基线，可以很好地推广到未知的问题规模，并且在某些情况下，比 Gurobi 等最先进的求解器实现更快的解决时间。]]></description>
      <guid>https://arxiv.org/abs/2502.02446</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续空间中的任意时间增量式 $\rho$POMDP 规划</title>
      <link>https://arxiv.org/abs/2502.02549</link>
      <description><![CDATA[arXiv:2502.02549v1 公告类型：新
摘要：部分可观察马尔可夫决策过程 (POMDP) 为自动驾驶和机器人探索等应用中的不确定性决策提供了一个强大的框架。它们的扩展 $\rho$POMDP 引入了信念依赖奖励，从而能够明确推理不确定性。现有的连续空间在线 $\rho$POMDP 求解器依赖于固定信念表示，限制了适应性和细化 - 对于信息收集等任务至关重要。我们提出了 $\rho$POMCPOW，这是一种随时求解器，可动态细化信念表示，并正式保证随着时间的推移不断改进。为了减轻更新信念依赖奖励的高计算成本，我们提出了一种新颖的增量计算方法。我们证明了它对常见熵估计器的有效性，将计算成本降低了几个数量级。实验结果表明，$\rho$POMCPOW 在效率和解决方案质量方面均优于最先进的求解器。]]></description>
      <guid>https://arxiv.org/abs/2502.02549</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型多模态模型生成个性化图像</title>
      <link>https://arxiv.org/abs/2410.14170</link>
      <description><![CDATA[arXiv:2410.14170v2 公告类型：交叉 
摘要：个性化内容过滤，例如推荐系统，已成为缓解信息过载的关键基础设施。然而，这些系统仅仅过滤现有的内容，并且受到其有限的多样性的限制，难以满足用户多样化的内容需求。为了解决这一限制，个性化内容生成已成为一个具有广泛应用前景的方向。然而，大多数现有研究都集中在个性化文本生成上，而对个性化图像生成的关注相对较少。个性化图像生成中有限的工作面临着从嘈杂的用户交互图像和复杂的多模态指令中准确捕捉用户的视觉偏好和需求的挑战。更糟糕的是，缺乏用于训练个性化图像生成模型的监督数据。
为了克服这些挑战，我们提出了一个名为 Pigeon 的个性化图像生成框架，它采用了具有三个专用模块的卓越大型多模态模型，可以从嘈杂的用户历史和多模态指令中捕捉用户​​的视觉偏好和需求。为了缓解数据稀缺的问题，我们引入了一个两阶段偏好对齐方案，包括掩蔽偏好重构和成对偏好对齐，以使 Pigeon 与个性化图像生成任务保持一致。我们将 Pigeon 应用于个性化贴纸和电影海报生成，其中大量定量结果和人工评估凸显了它优于各种生成基线。]]></description>
      <guid>https://arxiv.org/abs/2410.14170</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如何构建量子超级计算机：从数百个量子比特扩展到数百万个量子比特</title>
      <link>https://arxiv.org/abs/2411.10406</link>
      <description><![CDATA[arXiv:2411.10406v2 公告类型：交叉
摘要：在四十年的时间里，量子计算已经从一种智力上的好奇心发展成为一种可能实现的技术。今天，在数百个物理量子比特上进行量子算法原语的小规模演示和在单个逻辑量子比特上进行原理验证错误校正已经成为可能。尽管取得了重大进展和令人兴奋，但通往全栈可扩展技术的道路在很大程度上仍是未知的。存在大量未解决或被忽视的量子硬件、制造、软件架构和算法挑战。这些问题可能会在可预见的未来严重破坏实用级量子计算机的到来。在这里，我们对这些扩展挑战进行了全面的回顾。我们展示了如何通过采用现有的半导体技术来构建更高质量的量子比特、采用系统工程方法以及在异构高性能计算基础设施中执行分布式量子计算来铺平扩展之路。这些研究和开发机会可以解锁某些有前景的应用，特别是对自然或工程量子系统生成的量子数据进行有效的量子模拟/学习。为了估计这些承诺的真实成本，我们提供了基于超导量子位的当前、目标和期望硬件规格的表面码纠错量子计算机上经典硬量子化学计算的详细资源和敏感性分析，并考虑了实际的错误分布。此外，我们认为，为了以经济高效的方式解决行业规模的经典优化和机器学习问题，应将具有定制设计的加速器的异构量子概率计算视为实现可扩展性的补充途径。]]></description>
      <guid>https://arxiv.org/abs/2411.10406</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从公共广场到回音室：网络话语的碎片化</title>
      <link>https://arxiv.org/abs/2501.18441</link>
      <description><![CDATA[arXiv:2501.18441v1 公告类型：交叉 
摘要：本文探讨了社交媒体算法和过滤气泡如何导致在线话语的分裂，加剧意识形态分歧并破坏共同理解。该研究借鉴了迈克尔·桑德尔对社区和共同价值观的哲学强调，探讨了数字平台如何在社会紧张加剧时期放大歧视话语，包括性别歧视、种族主义、仇外心理、残疾歧视、同性恋恐惧症和宗教不容忍。通过分析数字社区的动态，该研究强调了推动话语碎片出现和演变以应对现实世界事件的机制。研究结果揭示了社交媒体结构如何加剧两极分化，限制跨群体对话，并削弱公正社会所必需的集体推理。本研究将哲学观点置于社交媒体互动的计算分析中，为数字时代碎片化话语带来的挑战提供了细致入微的理解。]]></description>
      <guid>https://arxiv.org/abs/2501.18441</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于室内导航辅助的自适应物体检测：实时算法的性能评估</title>
      <link>https://arxiv.org/abs/2501.18444</link>
      <description><![CDATA[arXiv:2501.18444v1 公告类型：交叉 
摘要：本研究解决了视障人士辅助技术中对准确、高效物体检测的需求。我们在室内导航辅助环境中评估了四种实时物体检测算法 YOLO、SSD、Faster R-CNN 和 Mask R-CNN。使用室内物体检测数据集，我们分析了检测精度、处理速度和对室内环境的适应性。我们的研究结果强调了精度和效率之间的权衡，为选择实时辅助导航的最佳算法提供了见解。这项研究推动了自适应机器学习应用的发展，增强了视障人士的室内导航解决方案并促进了无障碍性。]]></description>
      <guid>https://arxiv.org/abs/2501.18444</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIND：面向多模态临床预测任务的模态知情知识提炼框架</title>
      <link>https://arxiv.org/abs/2502.01158</link>
      <description><![CDATA[arXiv:2502.01158v1 公告类型：交叉 
摘要：多模态融合利用跨模态的信息来学习更好的特征表示，目的是提高基于融合的任务的性能。然而，多模态数据集（尤其是在医疗环境中）通常比单模态数据集小，这可能会阻碍多模态模型的性能。此外，模态数量的增加通常与多模态网络规模的整体增加有关，这在医疗用例中可能是不可取的。使用较小的单模态编码器可能会导致性能不佳，尤其是在处理高维临床数据时。在本文中，我们提出了模态信息知识蒸馏 (MIND) 框架，这是一种基于知识蒸馏的多模态模型压缩方法，它将知识从不同大小的预训练深度神经网络集合转移到较小的多模态学生中。教师模型由单模态网络组成，允许学生从不同的表示中学习。 MIND 采用多头联合融合模型，而非单头模型，因此在单峰样本的情况下可以使用单峰编码器，而无需填补或掩盖缺失的模态。因此，MIND 生成了一个优化的多峰模型，增强了多峰和单峰表征。它还可用于在训练期间平衡多峰学习。我们使用时间序列数据和胸部 X 光图像对 MIND 在二元和多标签临床预测任务上的表现进行评估。此外，我们还在三个非医学多峰多类数据集上评估了 MIND 框架的通用性。实验结果表明，与最先进的基线相比，MIND 增强了小型多峰网络在所有五个任务以及各种融合方法和多峰架构上的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.01158</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>微调 LLaMA 2 干扰：针对最佳效率的语言实现的比较研究</title>
      <link>https://arxiv.org/abs/2502.01651</link>
      <description><![CDATA[arXiv:2502.01651v1 公告类型：交叉 
摘要：本文介绍了一项旨在优化 Llama2 推理的比较研究，这是机器学习和自然语言处理 (NLP) 的一个关键方面。我们评估了各种编程语言和框架，包括 TensorFlow、PyTorch、Python、Mojo、C++ 和 Java，通过广泛的基准测试分析了它们在速度、内存消耗和易实现性方面的性能。强调了每种方法的优势和局限性，并提出了并行处理和硬件利用率的优化策略。此外，我们研究了 Mojo SDK，这是一种专为 Apple Silicon 上的大型语言模型 (LLM) 推理而设计的新框架，将其性能与 C、C++、Rust、Zig、Go 和 Julia 中的实现进行了基准测试。我们在 Apple M1 Max 上进行的实验展示了 Mojo SDK 的竞争性能、易用性和无缝的 Python 兼容性，使其成为 Apple Silicon 上 LLM 推理的强大替代方案。我们还讨论了在资源受限的硬件上部署 LLM 的更广泛的影响，并确定了未来研究的潜在方向。]]></description>
      <guid>https://arxiv.org/abs/2502.01651</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合组相对策略优化：一种增强策略优化的多样本方法</title>
      <link>https://arxiv.org/abs/2502.01652</link>
      <description><![CDATA[arXiv:2502.01652v1 公告类型：交叉 
摘要：混合组相对策略优化 (Hybrid GRPO) 是一种强化学习框架，它通过结合经验多样本动作评估来扩展近端策略优化 (PPO) 和组相对策略优化 (GRPO)，同时保持基于价值函数的学习的稳定性。与 DeepSeek GRPO 不同，后者消除了价值函数，转而采用纯经验奖励估计，而混合 GRPO 引入了一种结构化优势计算方法，平衡了经验动作采样和自举价值估计。这种方法提高了样本效率，提高了学习稳定性，并减轻了纯经验方法中观察到的方差放大。对 PPO、DeepSeek GRPO 和混合 GRPO 进行了详细的数学比较，重点介绍了优势估计和策略更新方面的主要差异。在受控强化学习环境中进行的实验验证表明，与现有方法相比，混合 GRPO 实现了更快的收敛速度、更稳定的策略更新和更高的样本效率。本文探索了混合 GRPO 的几种扩展，包括熵正则化采样、分层多步骤子采样、自适应奖励规范化和基于价值的行动选择。除了模拟环境中的强化学习之外，混合 GRPO 还提供了一个可扩展的框架，用于弥合大型语言模型 (LLM) 与现实世界基于代理的决策之间的差距。通过将结构化经验采样与强化学习稳定机制相结合，混合 GRPO 在自主机器人、金融建模和人工智能驱动的控制系统中具有潜在的应用。这些发现表明，混合 GRPO 是一种强大且适应性强的强化学习方法，为进一步推进政策优化铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.01652</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于二元 PSO 的集成欠采样模型，用于重新平衡不平衡训练数据</title>
      <link>https://arxiv.org/abs/2502.01655</link>
      <description><![CDATA[arXiv:2502.01655v1 公告类型：交叉 
摘要：集成技术和欠采样技术都是解决不平衡数据集分类问题的有效工具。本文提出了一种新的集成方法，结合了集成学习对偏置分类器的优势和一种新的欠采样方法。欠采样方法称为二元 PSO 实例选择；它与集成分类器一起寻找最合适的长度和多数类样本组合，以构建具有少数类样本的新数据集。所提出的方法采用多目标策略，该方法的贡献是显着提高了不平衡分类的性能，同时保证了原始数据集的最佳完整性。我们对所提出的方法进行了实验，并将其处理不平衡数据集的性能与其他几种传统的基本集成方法进行了比较。还对这些不平衡数据集进行了实验，使用改进的版本，其中集成分类器被包装在二元 PSO 实例选择中。根据实验结果，我们提出的方法优于单一集成方法、最先进的欠采样方法以及这些方法与传统 PSO 实例选择算法的组合。]]></description>
      <guid>https://arxiv.org/abs/2502.01655</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>