<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 29 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>本科学习革命：CourseGPT 及其生成式 AI 进步</title>
      <link>https://arxiv.org/abs/2407.18310</link>
      <description><![CDATA[arXiv:2407.18310v1 公告类型：交叉 
摘要：将生成式人工智能 (GenAI) 融入教育环境为增强学习体验提供了变革潜力。本文介绍了 CourseGPT，这是一种生成式人工智能工具，旨在支持教师并增强本科生的教育体验。CourseGPT 基于 Mistral AI 的开源大型语言模型 (LLM) 构建，提供持续的教师支持和课程材料的定期更新，丰富了学习环境。通过利用课程特定的内容，例如幻灯片和补充阅读和参考资料，CourseGPT 为学生的询问提供精确、动态生成的响应。与通用人工智能模型不同，CourseGPT 允许教师管理和控制响应，从而扩展课程范围而不会产生过多的细节。本文使用 CPR E 431 - 信息系统安全基础课程作为试点，展示了 CourseGPT 的应用。这门课程招生人数众多，课程内容多样，是 CourseGPT 的理想试验台。该工具旨在增强学习体验、加速反馈流程和简化管理任务。该研究评估了 CourseGPT 对学生成绩的影响，重点关注正确性得分、上下文回忆和回答的忠实性。结果表明，具有更多参数的 Mixtral-8x7b 模型优于较小的模型，正确性得分为 88.0%，忠实性得分为 66.6%。此外，还收集了前学生和助教对 CourseGPT 的准确性、有用性和整体表现的反馈。结果显示，绝大多数人认为 CourseGPT 在解决他们的疑问方面非常准确和有益，许多人称赞它能够及时提供相关信息。]]></description>
      <guid>https://arxiv.org/abs/2407.18310</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:25 GMT</pubDate>
    </item>
    <item>
      <title>用于无监督社交事件检测的自适应差分隐私结构熵最小化</title>
      <link>https://arxiv.org/abs/2407.18274</link>
      <description><![CDATA[arXiv:2407.18274v1 公告类型：交叉 
摘要：社交事件检测是指从社交媒体数据流中提取相关的消息簇来表示现实世界中的特定事件。社交事件检测在观点分析、社会安全和决策等许多领域都很重要。目前大多数方法都是监督的，需要访问大量数据。这些方法需要事先了解事件，并且存在泄露消息中敏感信息的高风险，使得它们在开放世界环境中的适用性较差。因此，在充分利用消息中丰富的信息并保护数据隐私的同时进行无监督检测仍然是一个重大挑战。为此，我们提出了一种新颖的社交事件检测框架ADP-SEMEvent，这是一种优先考虑隐私的无监督社交事件检测方法。具体而言，ADP-SEMEvent分为两个阶段，即隐私消息图的构建阶段和隐私消息图的聚类阶段。在第一阶段，使用自适应差分隐私方法构建隐私消息图。在此过程中，我们的方法可以根据开放环境中每天发生的事件自适应地应用差分隐私，以最大限度地利用隐私预算。在第二阶段，为了解决噪声导致的数据效用降低的问题，使用一种基于最优子图的新型二维结构熵最小化算法来检测消息图中的事件。这个过程的亮点是无监督的，并且不会损害差分隐私。在两个公共数据集上进行的大量实验表明，ADP-SEMEvent 可以在保持合理的隐私预算参数的同时实现与最先进方法相当的检测性能。]]></description>
      <guid>https://arxiv.org/abs/2407.18274</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:24 GMT</pubDate>
    </item>
    <item>
      <title>罗马不是一步建成的：芯片设计法学硕士的分级指导</title>
      <link>https://arxiv.org/abs/2407.18276</link>
      <description><![CDATA[arXiv:2407.18276v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 通过硬件描述语言 (HDL) 生成有效地进行计算机硬件综合。然而，LLM 辅助的 HDL 生成方法在处理复杂任务时会遇到困难。我们引入了一套分层提示技术，这些技术有助于实现高效的逐步设计方法，并为该过程开发了一个可推广的自动化流程。为了评估这些技术，我们提出了一组基准硬件设计，这些设计具有或不具有架构层次结构的解决方案。使用这些基准，我们比较了各种开源和专有 LLM，包括我们自己微调的 Code Llama-Verilog 模型。我们的分层方法会自动为标准平面提示方法无法实现的复杂硬件模块生成成功的设计，从而使较小的开源 LLM 能够与大型专有模型竞争。分层提示减少了 HDL 生成时间并节省了 LLM 成本。我们的实验详细说明了哪些 LLM 能够用于哪些应用程序，以及如何在各种模式下应用分层方法。我们探索使用自动脚本分层提示生成复杂核心的案例研究，包括第一个没有人工反馈的 LLM 设计的处理器。]]></description>
      <guid>https://arxiv.org/abs/2407.18276</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:24 GMT</pubDate>
    </item>
    <item>
      <title>具有黄金代码反馈的 Verilog 生成大型语言模型</title>
      <link>https://arxiv.org/abs/2407.18271</link>
      <description><![CDATA[arXiv:2407.18271v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展引发了人们对从自然语言指令自动生成寄存器传输级 (RTL) 代码（尤其是 Verilog）的极大兴趣。虽然像 ChatGPT 这样的商业 LLM 已经主导了这个领域，但开源替代品在性能上却落后了不少，限制了这种新兴技术的灵活性和数据隐私。本研究介绍了一种利用强化学习和黄金代码反馈来提高预训练模型性能的新方法。利用开源数据和基础模型，我们以相当大的优势取得了最先进的 (SOTA) 结果。值得注意的是，我们的 6.7B 参数模型 \ours{} 与目前同类最佳的 13B 和 16B 模型相比表现出卓越的性能。此外，通过全面分析直接微调的局限性和强化学习的训练动态，我们认为开发与 Verilog 代码固有并行语义相一致的全面监督信号对于有效生成至关重要。与本研究相关的代码和数据可在 \url{https://github.com/CatIIIIIIIII/veriseek} 上公开获取。模型权重可在 \url{https://huggingface.co/WANGNingroci/VeriSeek} 上访问。]]></description>
      <guid>https://arxiv.org/abs/2407.18271</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:23 GMT</pubDate>
    </item>
    <item>
      <title>AICircuit：人工智能驱动的模拟集成电路设计的多级数据集和基准</title>
      <link>https://arxiv.org/abs/2407.18272</link>
      <description><![CDATA[arXiv:2407.18272v1 公告类型：交叉 
摘要：模拟和射频电路设计需要广泛探索电路拓扑和参数，以满足特定的设计标准，如功耗和带宽。设计人员必须查看文献中最先进的拓扑配置，并扫描每个配置中的各种电路参数。这个设计过程高度专业化且耗时，特别是当电路参数数量增加且电路变得更加复杂时。先前的研究已经探索了机器学习在增强电路设计程序方面的潜力。然而，这些研究主要集中在简单的电路上，而忽略了更实用和更复杂的模拟和射频系统。在电路设计中发挥机器学习能力的一个主要障碍是通用和多样化数据集的可用性，以及稳健的指标，这些对于彻底评估和改进模拟和射频电路领域的机器学习算法至关重要。我们提出了 AICircuit，这是一个全面的多级数据集和基准，用于开发和评估模拟和射频电路设计中的 ML 算法。 AICircuit 包含七种常用的基本电路和两种由多个电路块组成的复杂无线收发器系统，涵盖了实际应用中遇到的各种设计场景。我们在数据集上广泛评估了各种 ML 算法，揭示了 ML 算法在学习从设计规范到所需电路参数的映射方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.18272</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:23 GMT</pubDate>
    </item>
    <item>
      <title>MCU-MixQ：针对 MCU 的硬件/软件协同优化混合精度神经网络设计框架</title>
      <link>https://arxiv.org/abs/2407.18267</link>
      <description><![CDATA[arXiv:2407.18267v1 公告类型：交叉 
摘要：混合精度神经网络 (MPNN) 利用刚好足够的数据宽度进行神经网络处理，是满足 MCU 内存和计算等严格资源限制的有效方法。然而，MCU 级 ISA 中仍然缺乏亚字节和混合精度 SIMD 操作，并且 MCU 有限的计算能力仍未得到充分利用，这进一步加剧了神经网络处理中遇到的计算限制。因此，MPNN 的优势无法充分发挥。在这项工作中，我们建议在典型 MCU 中的单指令多数据 (SIMD) 指令中打包多个低位宽算术运算，然后通过探索卷积中的数据并行性和计算并行性以及提出的 SIMD 打包来开发高效的卷积运算符。最后，我们进一步利用神经架构搜索 (NAS) 构建了一个 HW/SW 共同设计的 MPNN 设计框架，即 MCU-MixQ。该框架可以同时优化 MPNN 量化和 MPNN 实现效率，在神经网络性能和准确率之间取得最佳平衡。根据我们的实验结果，在相同的资源约束下，MCU-MixQ 分别比 CMix-NN 和 MCUNet 实现了 2.1$\times$ 和 1.4$\times$ 的加速比。]]></description>
      <guid>https://arxiv.org/abs/2407.18267</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:22 GMT</pubDate>
    </item>
    <item>
      <title>LaMAGIC：基于语言模型的模拟集成电路拓扑生成</title>
      <link>https://arxiv.org/abs/2407.18269</link>
      <description><![CDATA[arXiv:2407.18269v1 公告类型：交叉 
摘要：在电子和电气工程领域，鉴于现代应用的复杂性和定制要求，模拟电路的自动化越来越重要。然而，现有的方法只开发基于搜索的算法，需要多次模拟迭代来设计自定义电路拓扑，这通常是一个耗时的过程。为此，我们引入了 LaMAGIC，这是一种基于语言模型的开创性拓扑生成模型，它利用监督微调进行自动化模拟电路设计。LaMAGIC 可以在一次传递中从自定义规范中高效地生成优化的电路设计。我们的方法涉及对电路的各种输入和输出公式的细致开发和分析。这些公式可以确保电路的规范表示，并与 LM 的自回归性质相一致，从而有效地解决将模拟电路表示为图形的挑战。实验结果表明，LaMAGIC 在 0.01 的严格公差下成功率高达 96%。我们还研究了 LaMAGIC 的可扩展性和适应性，特别是测试了它在更复杂电路上的性能。我们的研究结果表明，基于邻接矩阵的电路公式在浮点输入下效果更佳，表明它适合处理复杂的电路设计。这项研究不仅展示了语言模型在图形生成方面的潜力，还为未来自动化模拟电路设计的探索建立了基础框架。]]></description>
      <guid>https://arxiv.org/abs/2407.18269</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:22 GMT</pubDate>
    </item>
    <item>
      <title>使用弱化和完成修复 $\mathcal{EL_\perp}$ 本体网络——扩展版本</title>
      <link>https://arxiv.org/abs/2407.18848</link>
      <description><![CDATA[arXiv:2407.18848v1 公告类型：新
摘要：本体及其对齐的质量对于开发高质量的基于语义的应用程序至关重要。传统的调试技术通过删除不需要的公理和映射来修复本体网络，但可能会因此删除本体网络领域中正确的后果。在本文中，我们提出了一个修复本体网络的框架来处理这个问题。它定义了调试、弱化和完成等基本操作。此外，它还定义了组合运算符，这些运算符反映了如何以及何时使用基本运算符的选择，以及关于本体网络中本体和对齐的自主性级别的选择。我们展示了组合运算符对修复网络质量的影响，并提出了一个实现的工具。通过将我们的框架与现有的调试、弱化和完成算法结合使用，我们基本上为扩展以前的工作和系统提供了蓝图。]]></description>
      <guid>https://arxiv.org/abs/2407.18848</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:21 GMT</pubDate>
    </item>
    <item>
      <title>CORN：基于接触的一般看不见物体的非抓握操作对象表示</title>
      <link>https://arxiv.org/abs/2403.10760</link>
      <description><![CDATA[arXiv:2403.10760v1 公告类型：交叉
摘要：非抓握操作对于操纵太薄、太大或在野外无法抓取的物体至关重要。为了避开传统基于建模的方法中接触建模的困难，强化学习 (RL) 最近成为一种有前途的替代方案。然而，以前的 RL 方法要么缺乏对不同物体形状进行概括的能力，要么使用简单的动作原语来限制机器人运动的多样性。此外，由于训练采用高维感官输入的策略的成本很高，因此在不同的物体几何形状上使用 RL 具有挑战性。我们提出了一种新颖的基于接触的对象表示和预训练管道来解决这个问题。为了实现大规模并行训练，我们利用轻量级的基于补丁的变压器架构作为处理点云的编码器，从而将我们的训练扩展到数千个环境中。与从头开始学习或其他形状表示基线相比，我们的表示促进了时间和数据效率高的学习。我们通过将训练好的策略零样本迁移到新的现实世界对象来验证整个系统的有效性。代码和视频可在 https://sites.google.com/view/contact-non-prehensile 上找到。]]></description>
      <guid>https://arxiv.org/abs/2403.10760</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:21 GMT</pubDate>
    </item>
    <item>
      <title>延迟优化的深度神经网络 (DNN)：使用片上多处理器系统 (MPSoC) 的边缘人工智能方法</title>
      <link>https://arxiv.org/abs/2407.18264</link>
      <description><![CDATA[arXiv:2407.18264v1 公告类型：交叉 
摘要：几乎在每一个严重依赖计算的应用程序中，从 6G 通信系统到自动驾驶平台，很大一部分计算都应该靠近客户端。移动设备中的边缘计算 (AI at Edge) 是满足这一要求的优化方法之一。因此，在这项工作中，研究了实现低延迟和功率优化的智能移动系统的可能性和挑战。在边缘利用基于现场可编程门阵列 (FPGA) 的解决方案将导致带宽优化的设计，从而可以在系统级期限内提高计算效率。此外，本研究讨论了嵌入式 FPGA 边缘设备（使用 Xilinx 多处理器片上系统 (MPSoC)）和云上神经网络 (NN) 的各种性能方面和实现可行性。这项工作的主要目标是展示一个混合系统，该系统使用 Xilinx Inc. 开发的深度学习可编程引擎作为硬件加速器的主要组件。然后基于此设计，利用嵌入式解决方案来呈现高效的移动边缘计算系统。]]></description>
      <guid>https://arxiv.org/abs/2407.18264</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:21 GMT</pubDate>
    </item>
    <item>
      <title>任何四个实数都是四边形，类似地</title>
      <link>https://arxiv.org/abs/2407.18770</link>
      <description><![CDATA[arXiv:2407.18770v1 公告类型：新
摘要：这项工作提出了一种依赖于广义均值的数字类比形式化。它受到人工智能和机器学习应用的最新进展的推动，其中类比的概念用于推断结果、创建数据，甚至作为对象表示或嵌入的评估工具，这些表示或嵌入基本上是数字的集合（向量、矩阵、张量）。这种扩展的类比使用需要数学基础和对数字之间类比概念的清晰理解。我们提出了一种依赖于以幂参数定义的广义均值的类比统一观点。特别是，我们表明任何四个增加的正实数都是具有唯一合适幂的类比。此外，我们表明任何这样的类比都可以简化为等效的算术类比，并且任何类比方程都有一个增加数字的解，这可以推广到复数而不受限制。这些基础性成果有助于更好地理解以数字表示的领域的类比。]]></description>
      <guid>https://arxiv.org/abs/2407.18770</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:20 GMT</pubDate>
    </item>
    <item>
      <title>从哲学家的视角理解XAI：历史视角</title>
      <link>https://arxiv.org/abs/2407.18782</link>
      <description><![CDATA[arXiv:2407.18782v1 公告类型：新
摘要：尽管可解释人工智能（XAI）最近成为一个热门话题，并且已经开发了几种不同的方法，但人们仍然普遍认为它缺乏令人信服的统一基础。另一方面，在过去的几个世纪里，解释的概念本身一直是广泛哲学分析的主题，试图在科学规律的背景下解决“为什么”的基本问题。然而，这种讨论很少与XAI联系在一起。本文试图填补这一空白，旨在通过认识论的视角探索人工智能中的解释概念。通过比较科学哲学和人工智能的历史发展，一幅有趣的画面浮现出来。具体来说，我们表明，这两个领域都独立地从逻辑演绎到统计解释模型逐渐发展，从而在两种情况下都经历了从确定性到非确定性和概率因果关系的范式转变。有趣的是，我们还注意到，类似的概念在两个领域都独立出现，例如解释与理解之间的关系以及实用因素的重要性。我们的研究旨在成为理解人工智能解释概念的哲学基础的第一步，我们希望我们的研究结果能够为 XAI 的难以捉摸的本质提供一些新的启示。]]></description>
      <guid>https://arxiv.org/abs/2407.18782</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:20 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能可增强生成人工智能的可指导性</title>
      <link>https://arxiv.org/abs/2407.18722</link>
      <description><![CDATA[arXiv:2407.18722v1 公告类型：新
摘要：生成式人工智能，尤其是通过大型语言模型 (LLM)，已经改变了文本、图像和音乐的内容创作，展示了通过提示遵循指令的能力，这在很大程度上得益于指令调整。指令调整是一种监督式微调方法，其中 LLM 在使用特定任务和相应指令格式化的数据集上进行训练。该方法系统地增强了模型理解和执行所提供指令的能力。尽管取得了这些进步，但 LLM 仍然面临着一致解释复杂、多步骤指令并将其推广到新任务的挑战，这对于在现实世界场景中更广泛地应用至关重要。本文探讨了为什么神经符号人工智能提供了一条更好的途径来增强 LLM 的可指导性。我们探索使用符号任务规划器将高级指令分解为结构化任务，使用神经语义解析器将这些任务转化为可执行操作，以及使用神经符号执行器执行这些操作，同时动态维护状态的明确表示。我们还试图表明，神经符号方法可以增强任务执行的可靠性和情境感知能力，使 LLM 能够以更高的精度和灵活性动态解释和响应更广泛的教学情境。]]></description>
      <guid>https://arxiv.org/abs/2407.18722</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:19 GMT</pubDate>
    </item>
    <item>
      <title>SysML 和 BPMN 中的多机器人系统架构设计</title>
      <link>https://arxiv.org/abs/2407.18749</link>
      <description><![CDATA[arXiv:2407.18749v1 公告类型：新
摘要：多机器人系统 (MRS) 是一个包含许多不同软件和硬件组件的复杂系统。本文主要解决的问题是 MRS 设计的复杂性。所提出的解决方案提供了一种基于形式化系统工程方法的模块化建模和仿真技术，因此 MRS 设计的复杂性被分解和降低。通过两种正式的架构描述语言 (ADL)（即系统建模语言 (SysML) 和业务流程模型和符号 (BPMN)）对 MRS 进行建模，以设计系统蓝图。通过使用这些抽象设计 ADL，项目的实施变得与技术无关。这允许将设计概念从一种编程语言转移到另一种编程语言。在模拟阶段，使用多代理环境来模拟 MRS 蓝图。模拟已在 Java 代理开发 (JADE) 中间件中实现。因此，其结果可用于以性能评估矩阵的形式分析和验证所提出的 MRS 模型。]]></description>
      <guid>https://arxiv.org/abs/2407.18749</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:19 GMT</pubDate>
    </item>
    <item>
      <title>以数据为中心的自动化开发协同演进策略</title>
      <link>https://arxiv.org/abs/2407.18690</link>
      <description><![CDATA[arXiv:2407.18690v1 公告类型：新
摘要：人工智能（AI）对许多领域产生了重大影响，这在很大程度上要归功于机器学习模型所需的大量高质量数据。现在的重点是数据中心 AI 策略，优先考虑数据开发而不是模型设计进度。自动化此过程至关重要。在本文中，我们是第一篇介绍自动数据中心开发（AD^2）任务并概述其核心挑战的工作，这些挑战需要领域专家般的任务调度和实施能力，而这在以前的工作中基本上没有得到探索。
通过利用大型语言模型（LLM）强大的复杂问题解决能力，我们提出了一种基于 LLM 的自主代理，配备了一种名为协作知识学习增强检索进化（Co-STEER）的策略，以同时应对所有挑战。具体而言，我们提出的 Co-STEER 代理通过我们提出的进化策略丰富了其领域知识，并通过积累和检索特定领域的实践经验来发展其调度和实施技能。随着计划的改进，实施能力也会加速。同时，随着实施反馈变得更加彻底，调度准确性也会提高。这两种能力通过实践反馈共同发展，从而实现协作进化过程。
大量实验结果表明，我们的 Co-STEER 代理在 AD^2 研究中开辟了新天地，具有强大的可进化计划和实施能力，并展示了其组件的显著有效性。我们的 Co-STEER 为 AD^2 的发展铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2407.18690</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:18 GMT</pubDate>
    </item>
    <item>
      <title>无监督知识探索的聚类规范</title>
      <link>https://arxiv.org/abs/2407.18712</link>
      <description><![CDATA[arXiv:2407.18712v1 公告类型：新
摘要：语言模型的部署为生成可靠信息带来了挑战，尤其是当这些模型使用人类偏好进行微调时。为了提取没有（可能）有偏见的人类标签的编码知识，已经开发了对比一致搜索 (CCS) 等无监督探测技术 (Burns 等人，2022 年)。然而，给定数据集中显着但不相关的特征可能会误导这些探测 (Farquhar 等人，2023 年)。针对这一问题，我们提出了一种聚类规范化方法，通过在应用无监督探测技术之前对对比对的激活进行聚类和规范化来最大限度地减少此类特征的影响。虽然这种方法没有解决区分一般知识和模拟知识的问题（这是潜在知识引出文献中的一个主要问题（Christiano 等人，2021 年）），但它显着提高了无监督探测在干扰中识别预期知识的能力。]]></description>
      <guid>https://arxiv.org/abs/2407.18712</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:18 GMT</pubDate>
    </item>
    <item>
      <title>结合认知 AI 和生成 AI，实现交互式 AI 代理的自我解释</title>
      <link>https://arxiv.org/abs/2407.18335</link>
      <description><![CDATA[arXiv:2407.18335v1 公告类型：新
摘要：虚拟实验研究助理 (VERA) 是一个基于探究的学习环境，它使学习者能够构建复杂生态系统的概念模型，并尝试基于代理的模型模拟。本研究探讨了认知人工智能和生成人工智能在 VERA 等交互式人工智能代理中的自我解释融合。从认知人工智能的角度来看，我们赋予 VERA 一个以任务-方法-知识 (TMK) 语言表示的自身设计、知识和推理的功能模型。从生成人工智能的角度来看，我们使用 ChatGPT、LangChain 和 Chain-of-Thought 基于 VERA TMK 模型回答用户问题。因此，我们结合认知和生成人工智能来生成关于 VERA 如何工作并产生答案的解释。对 VERA 在 66 个来自早期工作的问题库中生成解释的初步评估似乎很有希望。]]></description>
      <guid>https://arxiv.org/abs/2407.18335</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫决策过程中的非理性黑天鹅假说</title>
      <link>https://arxiv.org/abs/2407.18422</link>
      <description><![CDATA[arXiv:2407.18422v1 Announce Type: new 
摘要：黑天鹅事件是统计上罕见的事件，具有极高的风险。定义黑天鹅事件的典型观点被广泛认为源自不可预测的时变环境；然而，社区缺乏对黑天鹅事件的全面定义。为此，本文挑战了标准观点的不完整性，并声称由于人类对其价值和可能性的误解，高风险、统计上罕见的事件也可能发生在不变的环境中，我们称之为空间黑天鹅事件。我们首先仔细对黑天鹅事件进行分类，重点关注空间黑天鹅事件，并从数学上形式化黑天鹅事件的定义。我们希望这些定义可以为开发通过合理纠正人类感知来防止此类事件的算法铺平道路]]></description>
      <guid>https://arxiv.org/abs/2407.18422</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 指导因果机器学习</title>
      <link>https://arxiv.org/abs/2407.18607</link>
      <description><![CDATA[arXiv:2407.18607v1 公告类型：新
摘要：自从 ChatGPT 向公众推出以来，它产生了前所未有的影响。虽然一些专家称赞了人工智能的进步并强调了它们的潜在风险，但另一些人对大型语言模型 (LLM) 的准确性和实用性持批评态度。在本文中，我们对 LLM 识别因果关系的能力感兴趣。我们专注于成熟的 GPT-4 (Turbo)，并在最严格的条件下评估其性能，通过隔离其在没有任何上下文的情况下仅基于变量标签推断因果关系的能力，展示了当仅提供标签信息时可以预期的最低有效性水平。我们表明，问卷参与者认为 GPT-4 图在评估类别中最准确，其次是领域专家构建的知识图，而因果机器学习 (ML) 远远落后。我们利用这些结果来强调因果机器学习的重要局限性，它经常生成违反常识的因果图，从而影响对因果图的信任。然而，我们表明，将 GPT-4 与因果机器学习配对可以克服这一限制，与仅通过因果机器学习学习的结构相比，从真实数据中学习的图形结构与领域专家识别的结构更接近。总的来说，我们的研究结果表明，尽管 GPT-4 并非专门为因果推理而设计的，但它仍然可以成为因果表示的宝贵工具，因为它改进了因果机器学习算法的因果发现过程，而因果机器学习算法正是为此而设计的。]]></description>
      <guid>https://arxiv.org/abs/2407.18607</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>情感框架：迈向类人情感代理</title>
      <link>https://arxiv.org/abs/2407.18316</link>
      <description><![CDATA[arXiv:2407.18316v1 公告类型：新
摘要：游戏环境因其交互性而为训练虚拟代理提供了独特的机会，它提供了多样化的游戏轨迹和情感标签。尽管它们具有潜力，但没有一个强化学习框架将人类情感模型作为其观察空间或奖励机制的一部分。为了解决这个问题，我们提出了 \emph{Affectively Framework}，这是一组将情感作为观察空间的一部分的 Open-AI Gym 环境。本文介绍了该框架及其三个游戏环境，并提供了基线实验来验证其有效性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.18316</guid>
      <pubDate>Mon, 29 Jul 2024 06:29:16 GMT</pubDate>
    </item>
    </channel>
</rss>