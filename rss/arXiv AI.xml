<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 07 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>特朗普会在 2024 年获胜吗？通过大型语言模型进行多步推理预测美国总统大选</title>
      <link>https://arxiv.org/abs/2411.03321</link>
      <description><![CDATA[arXiv:2411.03321v1 公告类型：新
摘要：大型语言模型 (LLM) 能否准确预测选举结果？虽然 LLM 在医疗保健、法律分析和创造性任务等各个领域都表现出色，但它们预测选举的能力仍然未知。选举预测带来了独特的挑战，例如选民层面的数据有限、政治格局瞬息万变以及需要对复杂的人类行为进行建模。为了应对这些挑战，我们引入了一个专为政治分析而设计的多步骤推理框架。我们的方法已通过 2016 年和 2020 年美国全国选举研究 (ANES) 的真实数据以及领先的机器学习框架生成的合成角色得到验证，为选民行为建模提供了可扩展的数据集。为了捕捉时间动态，我们结合了候选人的政策立场和传记细节，确保模型适应不断变化的政治背景。我们的多步推理流程借鉴了思维链提示，系统地整合了人口、意识形态和时间相关因素，增强了模型的预测能力。此外，我们还应用我们的框架提前预测了 2024 年美国总统大选的结果，证明了 LLM 对未知政治数据的适应性。]]></description>
      <guid>https://arxiv.org/abs/2411.03321</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RuAG：大型语言模型的学习规则增强生成</title>
      <link>https://arxiv.org/abs/2411.03349</link>
      <description><![CDATA[arXiv:2411.03349v1 公告类型：新
摘要：上下文学习 (ICL) 和检索增强生成 (RAG) 因其通过整合外部知识来增强 LLM 推理能力的能力而受到关注，但由于上下文窗口大小有限，导致信息注入不足。为此，我们提出了一个新颖的框架 RuAG，用于自动将大量离线数据提炼为可解释的一阶逻辑规则，这些规则被注入到 LLM 中以增强其推理能力。我们的方法首先制定依赖于 LLM 常识的搜索过程，其中 LLM 自动定义头部和主体谓词。然后，RuAG 应用蒙特卡洛树搜索 (MCTS) 来处理组合搜索空间并有效地从数据中发现逻辑规则。生成的逻辑规则被翻译成自然语言，允许有针对性的知识注入并无缝集成到 LLM 提示中，以供 LLM 的下游任务推理。我们对公共和私人工业任务（包括自然语言处理、时间序列、决策和工业任务）上的框架进行了评估，证明了其在增强 LLM 执行各种任务的能力方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.03349</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Watson：基于基础模型的代理推理的认知可观察性框架</title>
      <link>https://arxiv.org/abs/2411.03455</link>
      <description><![CDATA[arXiv:2411.03455v1 公告类型：新
摘要：随着基础模型 (FM) 在复杂软件系统（例如基于 FM 的代理软件（即 Agentware））中发挥越来越重要的作用，它们为开发人员带来了可观察性方面的重大挑战。与传统软件不同，代理使用大量数据和不透明的隐式推理自主运行，因此很难在运行时观察和理解它们的行为，尤其是当它们采取意外操作或遇到错误时。在本文中，我们强调了传统操作可观察性在基于 FM 的软件环境中的局限性，并介绍了认知可观察性作为此类创新系统出现的一种新型必需可观察性。然后，我们提出了一个新颖的框架，为代理的隐式推理过程提供认知可观察性（又称推理可观察性），并通过对 AutoCodeRover（一种用于自主程序改进的尖端 Agentware）的案例研究，证明了我们的框架在提高 Agentware 的可调试性以及 Agentware 的能力方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.03455</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 生成的基于分布的美国选举结果预测，第一部分</title>
      <link>https://arxiv.org/abs/2411.03486</link>
      <description><![CDATA[arXiv:2411.03486v1 公告类型：新
摘要：本文介绍了基于分布的预测，这是一种使用大型语言模型 (LLM) 作为预测工具的新方法，它将输出标记概率解释为表示模型学习到的世界表示的分布。这种基于分布的性质为分析算法保真度提供了另一种视角，补充了硅片采样中使用的方法。我们在最近的美国总统大选背景下展示了基于分布的预测的使用，表明该方法可用于确定任务特定的偏见、提示噪音和算法保真度。这种方法对于评估各个领域基于 LLM 的预测的可靠性和提高透明度具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2411.03486</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱嵌入的全双曲旋转</title>
      <link>https://arxiv.org/abs/2411.03622</link>
      <description><![CDATA[arXiv:2411.03622v2 公告类型：新
摘要：双曲旋转通常用于有效地对知识图谱及其固有层次结构进行建模。然而，现有的双曲旋转模型依赖于对数和指数映射进行特征转换。这些模型仅将数据特征投影到双曲空间中进行旋转，限制了它们充分利用双曲空间的能力。为了解决这个问题，我们提出了一种专为知识图谱嵌入而设计的新型全双曲模型。我们使用 Lorentz 模型直接在双曲空间中定义模型，而不是特征映射。我们的模型将知识图谱中的每个关系视为从头实体到尾实体的 Lorentz 旋转。我们采用 Lorentzian 版本距离作为衡量三元组可信度的评分函数。标准知识图谱完成基准测试的大量结果表明，我们的模型以更少的参数实现了具有竞争力的结果。此外，我们的模型在 CoDEx-s 和 CoDEx-m 数据集上获得了最佳性能，这些数据集比以前更加多样化和具有挑战性。我们的代码可在 https://github.com/llqy123/FHRE 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.03622</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RTify：将深度神经网络与人类行为决策相结合</title>
      <link>https://arxiv.org/abs/2411.03630</link>
      <description><![CDATA[arXiv:2411.03630v1 公告类型：新
摘要：当前灵长类视觉的神经网络模型专注于复制行为准确性的总体水平，往往忽略了感知决策的丰富动态性质。在这里，我们引入了一个新颖的计算框架，通过学习将循环神经网络 (RNN) 的时间动态与人类反应时间 (RT) 对齐，来模拟人类行为选择的动态。我们描述了一种近似值，它允许我们限制 RNN 解决具有人类 RT 的任务所需的时间步数。该方法针对各种心理物理学实验进行了广泛的评估。我们还表明，该近似值可用于优化“理想观察者”RNN 模型，以在没有人类数据的情况下实现速度和准确性之间的最佳权衡。结果发现，所得模型可以很好地解释人类 RT 数据。最后，我们使用近似值来训练流行的 Wong-Wang 决策模型的深度学习实现。该模型与卷积神经网络 (CNN) 视觉处理模型集成，并使用人工和自然图像刺激进行评估。总体而言，我们提出了一个新颖的框架，有助于将当前的视觉模型与人类行为相结合，使我们更接近人类视觉的集成模型。]]></description>
      <guid>https://arxiv.org/abs/2411.03630</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>策略聚合</title>
      <link>https://arxiv.org/abs/2411.03651</link>
      <description><![CDATA[arXiv:2411.03651v1 公告类型：新
摘要：我们考虑了 AI 价值对齐的挑战，其中多个个体在底层马尔可夫决策过程中具有不同的奖励函数和最佳策略。我们将这个问题形式化为策略聚合问题，其目标是确定理想的集体策略。我们认为，以社会选择理论为基础的方法特别合适。我们的主要见解是，可以通过用状态-动作占用多胞形的子集体积来识别序数偏好来重新解释社会选择方法。基于这一见解，我们证明了各种方法（包括赞成投票、Borda 计数、比例否决核心和分位数公平性）可以实际应用于策略聚合。]]></description>
      <guid>https://arxiv.org/abs/2411.03651</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语言模型实现探索性蛋白质组学研究的自动化</title>
      <link>https://arxiv.org/abs/2411.03743</link>
      <description><![CDATA[arXiv:2411.03743v1 公告类型：新
摘要：随着人工智能的发展，它对科学的贡献正在从模拟复杂问题发展到自动化整个研究过程并产生新发现。实现这一进步需要基于现实世界科学数据的专门通用模型和反映人类科学方法的迭代探索性框架。在本文中，我们介绍了 PROTEUS，这是一个从原始蛋白质组学数据中进行科学发现的全自动系统。PROTEUS 使用大型语言模型 (LLM) 执行分层规划、执行专门的生物信息学工具并迭代细化分析工作流程以生成高质量的科学假设。该系统以蛋白质组学数据集为输入，无需人工干预即可生成一套全面的研究目标、分析结果和新颖的生物学假设。我们对 PROTEUS 进行了评估，评估了从各种生物样本（例如免疫细胞、肿瘤）和不同样本类型（单细胞和块）收集的 12 个蛋白质组学数据集，产生了 191 个科学假设。我们使用基于 5 个指标的自动 LLM 评分和人类专家的详细评论来评估这些假设。结果表明，PROTEUS 始终如一地产生可靠、逻辑连贯的结果，这些结果与现有文献非常吻合，同时还提出了新颖的可评估假设。该系统灵活的架构有助于无缝集成各种分析工具并适应不同的蛋白质组学数据类型。通过自动化复杂的蛋白质组学分析工作流程和假设生成，PROTEUS 有可能大大加快蛋白质组学研究中的科学发现速度，使研究人员能够有效地探索大规模数据集并发现生物学见解。]]></description>
      <guid>https://arxiv.org/abs/2411.03743</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索医学领域多模态人工智能的发展前景：技术挑战和临床应用范围审查</title>
      <link>https://arxiv.org/abs/2411.03782</link>
      <description><![CDATA[arXiv:2411.03782v1 公告类型：新
摘要：医疗保健领域的最新技术进步导致患者数据数量和多样性空前增长。虽然人工智能 (AI) 模型在分析单个数据模式方面显示出有希望的结果，但人们越来越认识到，集成多个互补数据源的模型，即所谓的多模态 AI，可以增强临床决策。本范围审查考察了基于深度学习的多模态 AI 在医学领域的应用前景，分析了 2018 年至 2024 年期间发表的 432 篇论文。我们对不同医学学科的多模态 AI 开发进行了广泛的概述，研究了各种架构方法、融合策略和常见应用领域。我们的分析表明，多模态 AI 模型的表现始终优于单模态 AI 模型，AUC 平均提高了 6.2 个百分点。然而，仍然存在一些挑战，包括跨部门协调、异构数据特征和不完整的数据集。我们批判性地评估了开发多模态 AI 系统的技术和实践挑战，并讨论了其临床实施的潜在策略，包括简要概述了可用于临床决策的商用多模态 AI 模型。此外，我们还确定了推动多模态 AI 发展的关键因素，并提出了加速该领域成熟的建议。本综述让研究人员和临床医生全面了解医学多模态 AI 的现状、挑战和未来方向。]]></description>
      <guid>https://arxiv.org/abs/2411.03782</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MRJ-Agent：一种高效的多轮对话越狱代理</title>
      <link>https://arxiv.org/abs/2411.03814</link>
      <description><![CDATA[arXiv:2411.03814v1 公告类型：新
摘要：大型语言模型（LLM）在知识库和理解能力方面表现出色，但也被证明在受到越狱攻击时容易产生非法或不道德的反应。为了确保在关键应用中负责任地部署它们，了解LLM的安全能力和漏洞至关重要。以前的研究主要关注单轮对话中的越狱，忽视了多轮对话中的潜在越狱风险，而多轮对话是人类与LLM交互并从中提取信息的重要方式。一些研究越来越多地集中在多轮对话中与越狱相关的风险上。这些努力通常涉及使用手工制作的模板或提示工程技术。然而，由于多轮对话固有的复杂性，它们的越狱性能有限。为了解决这个问题，我们提出了一种新颖的多轮对话越狱代理，强调隐身性在识别和减轻LLM对人类价值观的潜在威胁方面的重要性。我们提出了一种风险分解策略，将风险分散到多轮查询中，并利用心理策略来增强攻击强度。大量实验表明，我们提出的方法超越了其他攻击方法，并实现了最先进的攻击成功率。我们将提供相应的代码和数据集以供将来研究。代码将很快发布。]]></description>
      <guid>https://arxiv.org/abs/2411.03814</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从新手到专家：通过逐步强化学习实现 LLM 代理策略优化</title>
      <link>https://arxiv.org/abs/2411.03817</link>
      <description><![CDATA[arXiv:2411.03817v1 公告类型：新
摘要：大型语言模型 (LLM) 的出色功能使其成为各种自主代理系统中的关键组件。虽然传统方法依赖于 LLM 的固有知识而没有微调，但最近的方法已经转向强化学习策略，以进一步增强代理使用环境和工具解决复杂交互任务的能力。然而，以前的方法受到稀疏奖励问题的限制，现有数据集仅为每个多步骤推理链提供最终标量奖励，可能导致策略学习无效和低效。在本文中，我们介绍了 StepAgent，它利用分步奖励来优化代理的强化学习过程。继承新手到专家理论的精神，我们首先比较专家和代理的行为，以自动生成中间奖励以进行细粒度优化。此外，我们提出了隐式奖励和逆强化学习技术，以促进代理反思和策略调整。进一步的理论分析表明，代理的动作分布可以在多个训练周期内收敛到专家动作分布。跨各种数据集的实验结果表明，StepAgent 的表现优于现有的基线方法。]]></description>
      <guid>https://arxiv.org/abs/2411.03817</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越彩虹：台式电脑上的高性能深度强化学习</title>
      <link>https://arxiv.org/abs/2411.03820</link>
      <description><![CDATA[arXiv:2411.03820v1 公告类型：新
摘要：Rainbow Deep Q-Network (DQN) 证明，结合多种独立增强功能可以显著提高强化学习 (RL) 代理的性能。在本文中，我们介绍了“超越彩虹”(BTR)，这是一种新算法，它将 RL 文献中的六项改进集成到 Rainbow DQN，为使用台式电脑的 RL 建立了新的最先进水平，在 atari-60 上的人类标准化四分位均值 (IQM) 为 7.4。除了 Atari，我们还展示了 BTR 处理复杂 3D 游戏的能力，成功地训练代理玩超级马里奥银河、马里奥赛车和真人快打，只需进行最少的算法更改。在设计 BTR 时考虑到计算效率，代理可以在 12 小时内使用台式电脑在 2 亿个 Atari 帧上进行训练。此外，我们对每个组件进行了详细的消融研究，使用多种措施分析了性能和影响。]]></description>
      <guid>https://arxiv.org/abs/2411.03820</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OML：开放、可货币化、忠诚的人工智能</title>
      <link>https://arxiv.org/abs/2411.03887</link>
      <description><![CDATA[arXiv:2411.03887v1 公告类型：新
摘要：人工智能 (AI) 在广泛的任务范围内稳步提升。然而，人工智能的开发和部署几乎完全由少数强大的组织控制，这些组织正在竞相创建通用人工智能 (AGI)。中心化实体在几乎没有公众监督的情况下做出决策，塑造人类的未来，往往带来无法预见的后果。在本文中，我们提出了 OML，它代表开放、可货币化和忠诚的人工智能，这是一种旨在使人工智能开发民主化的方法。OML 是通过一个涵盖人工智能、区块链和密码学的跨学科框架实现的。我们提出了几种使用可信执行环境 (TEE)、传统加密原语（如完全同态加密和功能加密）、混淆和植根于人工智能任务的样本复杂性和内在难度的人工智能原生解决方案等技术构建 OML 的想法。我们工作的一项关键创新是引入了一个新的科学领域：人工智能原生密码学。与专注于离散数据和二进制安全保证的传统密码学不同，人工智能原生密码学利用人工智能数据表示的连续性及其低维流形，专注于提高近似性能。一个核心思想是将人工智能攻击方法（如数据中毒）转变为安全工具。这种新颖的方法为 OML 1.0 奠定了基础，它使用模型指纹来保护人工智能模型的完整性和所有权。OML 的精神是建立一个去中心化、开放和透明的人工智能开发平台，使社区能够贡献、货币化和拥有人工智能模型。通过区块链技术分散控制并确保透明度，OML 可以防止权力集中，并提供以前不可能实现的人工智能开发问责制。]]></description>
      <guid>https://arxiv.org/abs/2411.03887</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您所需要的只是词汇化：检查词汇知识在组合 QALD 系统中的影响</title>
      <link>https://arxiv.org/abs/2411.03906</link>
      <description><![CDATA[arXiv:2411.03906v1 公告类型：新
摘要：在本文中，我们研究了词汇化对基于链接数据 (QALD) 的问答系统的影响。众所周知，在解释 SPARQL 的自然语言问题时，关键挑战之一在于弥合词汇鸿沟，即将查询中的单词映射到正确的词汇元素。我们在本文中认为，词汇化，即关于给定词汇的单词潜在解释的明确知识，可以大大简化任务并提高 QA 系统的性能。为了实现这一目标，我们提出了一个组合 QA 系统，该系统可以利用组合方式的明确词汇知识来推断 SPARQL 查询中问题的含义。我们表明，在给定词汇知识的情况下，此类系统的性能远远超出当前的 QA 系统，与 QALD-9 上的最佳 QA 系统相比，微观 $F_1$ 分数可提高高达 $35.8\%$。这表明包含明确词汇知识的重要性和潜力。相比之下，我们表明 LLM 利用词汇知识的能力有限，与没有词汇知识的版本相比，只有微小的改进。这表明 LLM 无法根据问题各部分的含义对问题进行组合解释，这是组合方法的一个关键特征。总之，我们的工作为 QALD 研究开辟了新途径，强调了词汇化和组合性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2411.03906</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于无监督对象发现的掩蔽多查询槽注意力</title>
      <link>https://arxiv.org/abs/2404.19654</link>
      <description><![CDATA[arXiv:2404.19654v1 公告类型：交叉 
摘要：无监督对象发现正在成为解决需要将图像分解为实体的识别问题（例如语义分割和对象检测）的重要研究方向。最近，利用自监督的对象中心方法因其简单性和对不同设置和条件的适应性而受到欢迎。然而，这些方法并没有利用现代自监督方法中已经采用的有效技术。在这项工作中，我们考虑了一种以对象为中心的方法，其中通过一组称为槽的查询表示来重建 DINO ViT 特征。基于此，我们提出了一种对输入特征的掩蔽方案，该方案有选择地忽略背景区域，从而诱导我们的模型在重建阶段更多地关注显着对象。此外，我们将槽注意力扩展到多查询方法，允许模型学习多组槽，从而产生更稳定的掩码。在训练期间，这些多组槽位是独立学习的，而在测试时，这些组通过匈牙利匹配合并以获得最终槽位。我们在 PASCAL-VOC 2012 数据集上的实验结果和消融显示了每个组件的重要性，并强调了它们的组合如何持续改善对象定位。我们的源代码可在以下位置获得：https://github.com/rishavpramanik/maskedmultiqueryslot]]></description>
      <guid>https://arxiv.org/abs/2404.19654</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>log-RRIM：通过局部到全局反应表征学习和交互建模进行产量预测</title>
      <link>https://arxiv.org/abs/2411.03320</link>
      <description><![CDATA[arXiv:2411.03320v1 公告类型：交叉 
摘要：准确预测化学反应产量对于优化有机合成至关重要，可以减少实验所花费的时间和资源。随着人工智能 (AI) 的兴起，人们越来越有兴趣利用基于 AI 的方法来加速产量预测，而无需进行体外实验。我们提出了 log-RRIM，这是一种基于图形转换器的创新框架，旨在预测化学反应产量。我们的方法实现了一种独特的从局部到全局的反应表示学习策略。该方法首先捕获详细的分子级信息，然后对分子间相互作用进行建模和聚合，确保准确考虑不同大小的分子碎片对产量的影响。log-RRIM 的另一个关键特征是它集成了一种交叉注意机制，该机制专注于试剂和反应中心之间的相互作用。这种设计反映了化学反应中的一个基本原理：试剂在影响键断裂和形成过程中起着至关重要的作用，而这最终会影响反应产量。在我们的实验中，log-RRIM 的表现优于现有方法，尤其是对于中高产率反应，证明了其作为预测器的可靠性。其先进的反应物-试剂相互作用建模和对小分子碎片的敏感性使其成为化学合成中反应规划和优化的宝贵工具。log-RRIM 的数据和代码可通过 https://github.com/ninglab/Yield_log_RRIM 访问。]]></description>
      <guid>https://arxiv.org/abs/2411.03320</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有域自适应和不确定性量化的强透镜系统的神经网络预测</title>
      <link>https://arxiv.org/abs/2411.03334</link>
      <description><![CDATA[arXiv:2411.03334v1 公告类型：交叉 
摘要：对于来自现代和下一代宇宙调查的复杂数据，对强引力透镜进行建模在计算上是昂贵的。深度学习已成为一种有前途的方法来寻找透镜并预测透镜参数，例如爱因斯坦半径。均值方差估计器 (MVE) 是一种从神经网络预测中获取任意 (数据) 不确定性的常用方法。然而，神经网络尚未被证明能够成功地在域外目标数据上表现良好 - 例如，当在模拟数据上进行训练并应用于真实的观测数据时。在这项工作中，我们首次研究了 MVE 与无监督域自适应 (UDA) 结合对强透镜数据的有效性。源域数据无噪声，目标域数据具有模仿现代宇宙学调查的噪声。我们发现，将 UDA 添加到 MVE 中可以使目标数据的准确性比没有 UDA 的 MVE 模型提高约两倍。包括 UDA 还允许进行更精确的随机不确定性预测。这种方法的进步可能使 MVE 模型未来能够应用于实际观测数据。]]></description>
      <guid>https://arxiv.org/abs/2411.03334</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于评估的人工智能规划安全案例</title>
      <link>https://arxiv.org/abs/2411.03336</link>
      <description><![CDATA[arXiv:2411.03336v2 公告类型：交叉 
摘要：我们概述了前沿人工智能系统的开发人员如何构建一个结构化的理由——一个“安全案例”——即人工智能系统不太可能通过策划造成灾难性的后果。策划是一种潜在的威胁模型，人工智能系统可以秘密地追求不一致的目标，隐藏其真正的能力和目标。在本报告中，我们提出了安全案例可以用于策划的三个论点。对于每个论点，我们概述了如何从实证评估中收集证据，以及需要满足哪些假设才能提供强有力的保证。首先，前沿人工智能系统的开发人员可以争辩说人工智能系统没有策划的能力（策划无能）。其次，有人可能会说人工智能系统不能通过策划造成伤害（伤害无能）。第三，有人可能会说，即使人工智能系统故意试图颠覆不可接受的结果（伤害控制），围绕人工智能系统的控制措施也会阻止不可接受的结果。此外，我们还讨论了安全案例如何通过人工智能系统与其开发人员合理一致的证据得到支持（一致性）。最后，我们指出，迄今为止，提出这些安全论据所需的许多假设尚未得到充分满足，需要在多个未解决的研究问题上取得进展。]]></description>
      <guid>https://arxiv.org/abs/2411.03336</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>哪些功能有助于越狱法学硕士？调查攻击背后的机制</title>
      <link>https://arxiv.org/abs/2411.03343</link>
      <description><![CDATA[arXiv:2411.03343v1 公告类型：交叉 
摘要：虽然“越狱”一直是研究 LLM（大型语言模型）安全性和可靠性的核心，但这些攻击背后的潜在机制尚不清楚。一些先前的研究使用线性方法来分析越狱提示或模型拒绝。然而，在这里，我们比较了线性和非线性方法来研究提示中有助于成功越狱的特征。我们通过仅基于与提示标记相对应的潜在表示部分来探测越狱成功来做到这一点。首先，我们引入了一个包含 35 种攻击方法的 10,800 次越狱尝试的数据集。然后我们展示了不同的越狱方法通过提示中的不同非线性特征起作用。具体而言，我们发现虽然探测器可以高度准确地区分成功和不成功的越狱提示，但它们通常很难转移到保留的攻击方法。我们还表明，非线性探测可用于通过指导对抗性潜在扰动的设计来机械地越狱 LLM。这些机械越狱能够比训练的 35 种技术中的 34 种更可靠地越狱 Gemma-7B-IT。最终，我们的结果表明，仅凭通用或线性提示特征无法彻底理解越狱。]]></description>
      <guid>https://arxiv.org/abs/2411.03343</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用对抗性攻击破坏图像和文本分类算法</title>
      <link>https://arxiv.org/abs/2411.03348</link>
      <description><![CDATA[arXiv:2411.03348v2 公告类型：交叉 
摘要：机器学习模型容易受到对抗性攻击，其中可以操纵输入以导致错误分类。虽然以前的研究主要集中在生成对抗网络 (GAN) 等技术上，但在文本和图像分类模型中对 GAN 和合成少数过采样技术 (SMOTE) 进行对抗性攻击的探索有限。我们的研究通过训练各种机器学习模型并使用 GAN 和 SMOTE 生成旨在攻击文本分类模型的额外数据点来解决这一差距。此外，我们将研究扩展到人脸识别模型，训练卷积神经网络 (CNN) 并使其受到对抗性攻击，使用 GradCAM 识别的关键特征进行快速梯度符号扰动，GradCAM 是一种用于突出显示 CNN 在分类中使用的关键图像特征的技术。我们的实验揭示了分类模型中存在一个重大漏洞。具体来说，我们观察到，攻击后表现最好的文本分类模型的准确率下降了 20%，而面部识别准确率则下降了 30%。这凸显了这些模型容易受到输入数据操纵的影响。对抗性攻击不仅会危及安全性，还会破坏机器学习系统的可靠性。通过展示对抗性攻击对文本分类和面部识别模型的影响，我们的研究强调了开发针对此类漏洞的强大防御措施的迫切需要。]]></description>
      <guid>https://arxiv.org/abs/2411.03348</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>