<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>集成推理系统以实现值得信赖的人工智能，第四届逻辑与编程实践研讨会 (LPOP) 论文集</title>
      <link>https://arxiv.org/abs/2410.19738</link>
      <description><![CDATA[arXiv:2410.19738v1 公告类型：新
摘要：本论文集包含将在第四届编程逻辑与实践 (LPOP) 研讨会上展示的工作的摘要和立场文件。该研讨会将于 2024 年 10 月 13 日在美国德克萨斯州达拉斯举行，作为一项混合活动，与第 40 届国际逻辑编程会议 (ICLP) 同期举行。本次研讨会的重点是集成推理系统以实现值得信赖的人工智能，特别是包括集成具有规则和约束的各种编程模型。]]></description>
      <guid>https://arxiv.org/abs/2410.19738</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ScreenWriter：自动剧本生成和电影摘要</title>
      <link>https://arxiv.org/abs/2410.19809</link>
      <description><![CDATA[arXiv:2410.19809v1 公告类型：新
摘要：创意视频内容的激增推动了对文本描述或摘要的需求，这些描述或摘要允许用户回忆关键情节点或无需观看即可获得概述。电影内容的数量和周转速度推动了自动摘要，但这仍然具有挑战性，需要识别角色意图和非常长期的时间依赖性。现有的少数尝试此任务的方法严重依赖文本剧本作为输入，极大地限制了它们的适用性。在这项工作中，我们提出了自动剧本生成任务，以及一种仅对视频进行操作并产生包括对话、演讲者姓名、场景中断和视觉描述在内的输出的方法 ScreenWriter。ScreenWriter 引入了一种基于视觉向量序列将视频分割成场景的新算法，以及一种基于演员面部数据库确定角色名称的具有挑战性的问题的新方法。我们进一步展示了如何使用这些自动剧本通过基于场景分隔的分层摘要方法生成情节概要。我们在最近的 MovieSum 数据集上测试了最终摘要的质量，并使用视频对其进行了扩充，并表明它们优于许多假设可以访问黄金标准剧本的比较模型。]]></description>
      <guid>https://arxiv.org/abs/2410.19809</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>步骤引导推理：使用引导生成和步骤推理提高数学推理能力</title>
      <link>https://arxiv.org/abs/2410.19817</link>
      <description><![CDATA[arXiv:2410.19817v1 公告类型：新
摘要：数学推理一直是大型语言模型 (LLM) 的一个挑战性方面。然而，逐步的思路链 (CoT) 推理的引入显著提高了 LLM 的数学能力。尽管取得了这些进展，但当前的方法要么需要大量推理数据集作为训练数据集，要么依赖于通常会牺牲准确性的少量方法。为了解决数学推理中的这个瓶颈，我们提出了一种称为分步指导推理的新方法，而无需进一步进行模型微调。在这种方法中，LLM 会反思小的推理步骤——类似于人类如何深思熟虑并关注下一步要做什么。通过将这种反思过程纳入推理阶段，LLM 可以有效地引导其推理从一个步骤到下一个步骤。我们的方法显著提高了数学性能，在AMC23数据集上的准确率从30%提高到57.5%，相对提升了91.7%；在MATH数据集的采样5级问题上，我们实现了55.8%的相对准确率提升，从43%提升到67%。]]></description>
      <guid>https://arxiv.org/abs/2410.19817</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言代理与因果关系相遇——连接法学硕士和因果世界模型</title>
      <link>https://arxiv.org/abs/2410.19923</link>
      <description><![CDATA[arXiv:2410.19923v1 公告类型：新
摘要：大型语言模型 (LLM) 最近在规划和推理应用中显示出巨大的前景。这些任务需要强大的系统，这可以说需要对环境有因果理解。虽然 LLM 可以从其预训练数据中获取并反映常识性因果知识，但这些信息通常不完整、不正确或不适用于特定环境。相比之下，因果表示学习 (CRL) 侧重于识别给定环境中的底层因果结构。我们提出了一个将 CRL 与 LLM 集成的框架，以实现因果感知推理和规划。该框架学习因果世界模型，其中因果变量与自然语言表达相关联。这种映射为 LLM 提供了一个灵活的接口来处理和生成文本形式的动作和状态描述。实际上，因果世界模型充当了 LLM 可以查询和交互的模拟器。我们评估了该框架在时间尺度和环境复杂性上的因果推理和规划任务。我们的实验证明了该方法的有效性，因果感知方法优于基于 LLM 的推理器，尤其是在较长的规划范围内。]]></description>
      <guid>https://arxiv.org/abs/2410.19923</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>合作战略规划增强大型语言模型的推理能力</title>
      <link>https://arxiv.org/abs/2410.20007</link>
      <description><![CDATA[arXiv:2410.20007v1 公告类型：新
摘要：增强大型语言模型 (LLM) 的推理能力对于使其能够解决复杂的多步骤问题至关重要。多智能体框架在增强 LLM 的推理能力方面表现出巨大潜力。然而，LLM 智能体之间缺乏有效的合作阻碍了它们的性能，尤其是在多步骤推理任务中。本文提出了一种新颖的合作多智能体推理框架 (CoPlanner)，通过分离推理步骤并将不同的职责分配给不同的智能体。CoPlanner 由两个 LLM 智能体组成：一个规划智能体和一个推理智能体。规划智能体提供高级战略提示，而推理智能体遵循这些提示并推断答案。通过近端策略优化 (PPO) 的交互式推理过程训练规划代理的策略，基于 LLaMA-3-8B 的 CoPlanner 在 LogiQA 上的表现比之前的最佳方法高出 9.94\%，在 BBH 上的表现比之前的最佳方法高出 3.09\%。我们的结果表明，规划代理的指导和代理之间的有效合作有助于 CoPlanner 在解决多步骤推理问题方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2410.20007</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAD-Sherlock：用于检测脱离上下文的错误信息的多智能体辩论</title>
      <link>https://arxiv.org/abs/2410.20140</link>
      <description><![CDATA[arXiv:2410.20140v1 公告类型：新
摘要：最具挑战性的错误信息形式之一是将图像与误导性文本配对使用，从而产生虚假叙述。现有的人工智能驱动的检测系统缺乏可解释性，需要昂贵的微调。我们通过 MAD-Sherlock 解决了这些问题：一种用于 OOC 错误信息检测的多智能体辩论系统。MAD-Sherlock 引入了一种新颖的多智能体辩论框架，其中多模态智能体协作以评估上下文一致性并请求外部信息以增强跨上下文推理和决策。即使没有特定领域的微调，我们的框架也能以最先进的精度实现可解释的检测。广泛的消融研究证实，外部检索显着提高了检测准确性，用户研究表明 MAD-Sherlock 提高了专家和非专家的性能。这些结果将 MAD-Sherlock 定位为自主和公民情报应用的强大工具。]]></description>
      <guid>https://arxiv.org/abs/2410.20140</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 可以不断在 X-Modal 推理的模态性上发展</title>
      <link>https://arxiv.org/abs/2410.20178</link>
      <description><![CDATA[arXiv:2410.20178v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 因其在多模态理解方面的出色能力而备受关注。然而，现有方法严重依赖于广泛的模态特定预训练和联合模态调整，导致扩展到新模态时计算负担过重。在本文中，我们提出了 PathWeave，这是一个灵活且可扩展的框架，具有模态路径切换和扩展能力，使 MLLM 能够不断地在模态上进化以进行 $\mathbb{X}$ 模态推理。我们利用持续学习的概念，在预训练的 MLLM 之上开发增量训练策略，使其能够使用单模态数据扩展到新模态，而无需执行联合模态预训练。具体来说，我们引入了一种新颖的适配器中适配器 (AnA) 框架，其中单模态和跨模态适配器无缝集成，以促进有效的模态对齐和协作。此外，在两种类型的适配器之间应用了基于 MoE 的门控模块，以进一步增强多模态交互。为了研究所提出的方法，我们建立了一个具有挑战性的基准，称为模态持续学习 (MCL)，它由来自五种不同模态的高质量 QA 数据组成：图像、视频、音频、深度和点云。大量实验证明了所提出的 AnA 框架在持续学习过程中对学习可塑性和记忆稳定性的有效性。此外，PathWeave 的表现与最先进的 MLLM 相当，同时将参数训练负担减少了 98.73%。我们的代码位于 https://github.com/JiazuoYu/PathWeave]]></description>
      <guid>https://arxiv.org/abs/2410.20178</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考不确定性：大型语言模型时代的批判性评论与分析</title>
      <link>https://arxiv.org/abs/2410.20199</link>
      <description><![CDATA[arXiv:2410.20199v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 已成为广泛人工智能应用的基础。随着 LLM 的使用范围不断扩大，准确估计其预测中的不确定性变得至关重要。当前的方法通常难以准确识别、测量和解决真正的不确定性，其中许多方法主要侧重于估计模型置信度。这种差异主要是由于对将不确定性注入模型的位置、时间和方式的理解不完整。本文介绍了一个专门设计用于识别和理解不确定性类型和来源的综合框架，与 LLM 的独特特征相一致。我们的框架通过系统地对每种类型进行分类和定义，增强了对各种不确定性格局的理解，为开发能够精确量化这些不确定性的有针对性的方法奠定了坚实的基础。我们还详细介绍了关键的相关概念，并研究了当前方法在任务关键型和安全敏感型应用中的局限性。本文最后对未来发展方向进行了展望，旨在提高这些方法在现实场景中的可靠性和实际应用。]]></description>
      <guid>https://arxiv.org/abs/2410.20199</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SWE-Search：使用蒙特卡洛树搜索和迭代细化增强软件代理</title>
      <link>https://arxiv.org/abs/2410.20285</link>
      <description><![CDATA[arXiv:2410.20285v1 公告类型：新
摘要：在复杂和动态环境中工作的软件工程师必须不断适应不断变化的需求，从经验中不断学习，并根据新见解重新考虑他们的方法。然而，当前基于大型语言模型 (LLM) 的软件代理通常依赖于僵化的流程，并且倾向于重复无效的操作，而没有能力评估其性能或随着时间的推移调整其策略。为了应对这些挑战，我们提出了 SWE-Search，这是一个多代理框架，它将蒙特卡洛树搜索 (MCTS) 与自我改进机制相结合，以增强软件代理在存储库级软件任务上的性能。SWE-Search 通过结合混合值函数扩展了传统的 MCTS，该函数利用 LLM 进行数值估计和定性评估。这使得自反馈循环成为可能，代理可以根据定量数值评估和对追求轨迹的定性自然语言评估迭代地改进其策略。该框架包括用于自适应探索的 SWE-Agent、用于迭代反馈的价值代理和促进多代理辩论以进行协作决策的鉴别器代理。将我们的方法应用于 SWE-bench 基准测试，与没有 MCTS 的标准开源代理相比，我们的方法在五个模型中表现出 23% 的相对性能提升。我们的分析揭示了性能如何随着搜索深度的增加而扩展，并确定了促进软件代理有效自我评估的关键因素。这项工作突出了自我评估驱动的搜索技术在复杂、动态的软件工程环境中增强代理推理和规划的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.20285</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱上复杂逻辑查询回答的有效指令解析插件</title>
      <link>https://arxiv.org/abs/2410.20321</link>
      <description><![CDATA[arXiv:2410.20321v1 公告类型：新 
摘要：知识图谱查询嵌入 (KGQE) 旨在将一阶逻辑 (FOL) 查询嵌入低维 KG 空间，以对不完整 KG 进行复杂推理。为了增强 KGQE 模型的泛化，最近的研究整合了各种外部信息（例如实体类型和关系上下文），以更好地捕获 FOL 查询的逻辑语义。整个过程通常称为查询模式学习 (QPL)。然而，当前的 QPL 方法通常受到模式实体对齐偏差问题的影响，导致学习到的有缺陷的查询模式限制了 KGQE 模型的性能。为了解决这个问题，我们提出了一个有效的查询指令解析插件 (QIPP)，它利用预训练语言模型 (PLM) 的上下文感知来从类似代码的查询指令中捕获潜在查询模式。与以前的 QPL 方法引入的外部信息不同，我们首先提出类似代码的指令，以另一种格式表达 FOL 查询。此格式利用文本变量和嵌套元组来传达 FOL 查询中的逻辑语义，作为基于 PLM 的指令编码器获取完整查询模式的原材料。在此基础上，我们设计了一个查询引导指令解码器，以使查询模式适应 KGQE 模型。为了进一步增强 QIPP 在各种 KGQE 模型中的有效性，我们提出了一种基于压缩优化边界和自适应规范化组件的查询模式注入机制，使 KGQE 模型能够更有效地利用查询模式。大量实验表明，我们的即插即用方法提高了八种基本 KGQE 模型的性能，并且优于两种最先进的 QPL 方法。]]></description>
      <guid>https://arxiv.org/abs/2410.20321</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoKaggle：用于自主数据科学竞赛的多智能体框架</title>
      <link>https://arxiv.org/abs/2410.20424</link>
      <description><![CDATA[arXiv:2410.20424v1 公告类型：新
摘要：涉及表格数据的数据科学任务带来了复杂的挑战，需要复杂的问题解决方法。我们提出了 AutoKaggle，这是一个功能强大且以用户为中心的框架，可通过协作多代理系统帮助数据科学家完成日常数据管道。AutoKaggle 实现了一个迭代开发过程，结合了代码执行、调试和全面的单元测试，以确保代码的正确性和逻辑一致性。该框架提供高度可定制的工作流程，允许用户在每个阶段进行干预，从而将自动化智能与人类专业知识相结合。我们的通用数据科学工具包包括经过验证的数据清理、特征工程和建模功能，构成了该解决方案的基础，通过简化常见任务来提高生产力。我们选择了 8 个 Kaggle 竞赛来模拟真实应用场景中的数据处理工作流程。评测结果表明，AutoKaggle 在典型的数据科学流程中获得了 0.85 的验证提交率和 0.82 的综合得分，充分证明了其在处理复杂数据科学任务方面的有效性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2410.20424</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与法学硕士互动的可理解性协议的实施和应用</title>
      <link>https://arxiv.org/abs/2410.20600</link>
      <description><![CDATA[arXiv:2410.20600v1 公告类型：新
摘要：我们的兴趣在于构建交互式系统，让人类专家与机器学习引擎在数据分析任务上进行交互。这在解决科学、环境、医学等领域出现的复杂问题时具有重要意义，这些问题无法立即通过通常的统计或数学建模方法解决。在这种情况下，将人类的专业知识和创造力与现代机器学习能力结合起来，通过构建数据的新内部表示来识别模式，可能会为可能的解决方案提供一些见解。在本文中，我们研究了一种抽象协议的实现，该协议是为代理之间的交互而开发的，每个代理都能够构建预测和解释。[12] 中描述的 \PXP 协议受到“双向可理解性”概念的启发，并使用一对通信有限状态机来指定。虽然形式化允许作者证明有关协议的几个属性，但没有提出任何实现。在这里，我们针对这种情况解决了这一缺陷：其中一个代理使用大型语言模型 (LLM) 充当“生成器”，另一个代理使用人类专家或人类专家的代理（例如，使用人类专业知识编译的数据库）充当“测试器”。我们相信这些用例将成为上述问题的一种广泛适用的交互形式。我们提出了通用实现的算法描述，并在两个不同领域（放射学和药物发现）对其使用进行了初步实验。实验结果提供了早期证据，支持该协议能够以 [12] 中提出的方式捕获人类 LLM 中的单向和双向可理解性。]]></description>
      <guid>https://arxiv.org/abs/2410.20600</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能应用中的可解释性：比较不同技术的框架</title>
      <link>https://arxiv.org/abs/2410.20873</link>
      <description><![CDATA[arXiv:2410.20873v1 公告类型：新
摘要：人工智能与业务流程的整合显著增强了金融、医疗保健和零售等各个行业的决策能力。然而，由于最近的深度学习模型不透明，通常充当黑匣子，因此解释这些人工智能系统做出的决策是一项重大挑战。为了解决这种不透明性，出现了多种可解释性技术。然而，在实际的业务应用中，挑战在于选择一种合适的可解释性方法来平衡可理解性和准确性。本文提出了一种评估不同可解释性技术一致性的新方法，解决了理解可解释性技术输出差异的实际需求。基于我们提出的方法，我们对六种领先的可解释性技术进行了全面的比较分析，以帮助指导在实践中选择此类技术。我们提出的通用方法是在最流行的深度学习架构之一 Vision Transformer 模型的基础上进行评估的，该模型经常用于商业应用。值得注意的是，我们提出了一种新颖的指标来衡量可直观解释的可解释性技术的一致性。通过提供一个实用的框架来理解各种可解释性技术的一致性，我们的研究旨在促进可解释的人工智能系统在商业应用中的更广泛集成。]]></description>
      <guid>https://arxiv.org/abs/2410.20873</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有潜在变量的主动因果结构学习：面向自主机器人绕行学习</title>
      <link>https://arxiv.org/abs/2410.20894</link>
      <description><![CDATA[arXiv:2410.20894v1 公告类型：新
摘要：通用人工智能 (AGI) 代理和机器人必须能够应对不断变化的环境和任务。当环境中发生新的结构变化时，它们必须能够主动构建与环境交互的新内部因果模型。因此，我们声称具有潜在变量的主动因果结构学习 (ACSLWL) 是构建 AGI 代理和机器人的必要组成部分。本文描述了当模拟机器人在通往目标的路径上意外地第一次遇到某种透明障碍时，ACSLWL 如何学习复杂的规划和基于期望的绕行行为。 ACSWL 包括在环境中采取行动、发现新的因果关系、构建新的因果模型、利用因果模型最大化其预期效用、在出现意外观察时检测可能的潜在变量以及构建新的结构 - 内部因果模型和相关参数的最佳估计，以便能够有效应对新遇到的情况。也就是说，代理必须能够构建新的因果内部模型，将之前意外和低效（次优）的情况转变为具有最佳操作计划的可预测情况。]]></description>
      <guid>https://arxiv.org/abs/2410.20894</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FACTS：用于世界建模的分解状态空间框架</title>
      <link>https://arxiv.org/abs/2410.20922</link>
      <description><![CDATA[arXiv:2410.20922v1 公告类型：新
摘要：世界建模对于通过学习空间和时间依赖性来理解和预测复杂系统的动态至关重要。然而，当前的框架，如 Transformers 和 Mambas 等选择性状态空间模型，在有效编码空间和时间结构方面表现出局限性，特别是在需要长期高维序列建模的场景中。为了解决这些问题，我们提出了一种新颖的循环框架，即 \textbf{FACT}ored \textbf{S}tate-space (\textbf{FACTS}) 模型，用于时空世界建模。FACTS 框架构建了一个图形结构内存，具有学习可置换内存表示的路由机制，确保对输入排列的不变性，同时通过选择性状态空间传播进行调整。此外，FACTS 支持高维序列的并行计算。我们通过多种任务对 FACTS 进行了实证评估，包括多元时间序列预测和以对象为中心的世界建模，结果表明，尽管它采用通用的世界建模设计，但其表现始终优于或匹敌专门的最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.20922</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体强化学习中的主动可读性</title>
      <link>https://arxiv.org/abs/2410.20954</link>
      <description><![CDATA[arXiv:2410.20954v1 公告类型：新
摘要：多智能体顺序决策问题已出现在许多关键应用中，包括城市交通、自动驾驶汽车、军事行动等。其广为人知的解决方案，即多智能体强化学习，近年来得到了巨大的发展。其中，建模其他智能体的解决方案范式引起了我们的兴趣，它不同于传统的价值分解或通信机制。它使智能体能够理解和预测他人的行为并促进他们的协作。受最近关于可读性的研究的启发，该研究允许智能体通过其行为揭示其意图，我们提出了一个多智能体主动可读性框架来提高其性能。以可读性为导向的框架允许智能体进行可读性操作，从而帮助他人优化其行为。此外，我们设计了一系列模拟常见场景的问题域，并最好地描述了多智能体强化学习中的可读性。实验结果表明，与几种多智能体强化学习算法相比，新框架效率更高，训练时间更短。]]></description>
      <guid>https://arxiv.org/abs/2410.20954</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号学习产生逻辑约束</title>
      <link>https://arxiv.org/abs/2410.20957</link>
      <description><![CDATA[arXiv:2410.20957v1 公告类型：新
摘要：神经符号系统结合了神经感知和逻辑推理的能力。然而，神经符号系统的端到端学习仍然是一个尚未解决的挑战。本文提出了一个自然框架，将神经网络训练、符号基础和逻辑约束合成融合成一个连贯而高效的端到端学习过程。该框架的能力来自于在训练和推理阶段系统中神经部分和符号部分之间改进的交互。从技术上讲，为了弥合连续神经网络和离散逻辑约束之间的差距，我们引入了一种凸差规划技术来放宽逻辑约束，同时保持其精度。我们还采用基数约束作为逻辑约束学习的语言，并结合信任区域方法以避免学习中逻辑约束的退化。理论分析和实证评估都证实了所提框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.20957</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习处理车辆路径问题的复杂约束</title>
      <link>https://arxiv.org/abs/2410.21066</link>
      <description><![CDATA[arXiv:2410.21066v1 公告类型：新
摘要：车辆路径问题 (VRP) 可以模拟许多现实世界场景，并且通常涉及复杂的约束。虽然最近的神经方法擅长基于可行性掩蔽构建解决方案，但它们在处理复杂约束方面却举步维艰，尤其是在获取掩蔽本身是 NP 难的情况下。在本文中，我们提出了一种新颖的主动不可行性预防 (PIP) 框架，以提升神经方法对更复杂的 VRP 的能力。我们的 PIP 集成了拉格朗日乘数作为增强约束意识的基础，并引入了预防性不可行性掩蔽来主动引导解决方案构建过程。此外，我们提出了 PIP-D，它采用辅助解码器和两种自适应策略来学习和预测这些定制的掩蔽，从而有可能提高性能，同时显着降低训练期间的计算成本。为了验证我们的 PIP 设计，我们在不同的约束难度水平下对极具挑战性的带时间窗口的旅行商问题 (TSPTW) 和带草稿限制的 TSP (TSPDL) 变体进行了广泛的实验。值得注意的是，我们的 PIP 可以通用地增强许多神经方法，并且既显著降低了不可行率，又显著提高了解决方案的质量。]]></description>
      <guid>https://arxiv.org/abs/2410.21066</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现反事实解释的统一评估：利用大型语言模型进行以人为本的评估</title>
      <link>https://arxiv.org/abs/2410.21131</link>
      <description><![CDATA[arXiv:2410.21131v1 公告类型：新
摘要：随着机器学习模型的发展，保持透明度需要更多以人为本的可解释人工智能技术。反事实解释源于人类推理，确定获得给定输出所需的最小输入变化，因此对于支持决策至关重要。尽管这些解释很重要，但对其的评估往往缺乏用户研究的基础，而且仍然支离破碎，现有指标未能完全捕捉人类的观点。为了应对这一挑战，我们开发了一组不同的 30 个反事实场景，并从 206 名受访者那里收集了 8 个评估指标的评分。随后，我们对不同的大型语言模型 (LLM) 进行了微调，以预测这些指标的平均或个人人类判断。我们的方法使 LLM 在零样本评估中达到高达 63% 的准确率，并在所有指标上进行微调后达到 85%（超过 3 类预测）。预测人工评分的微调模型在评估不同的反事实解释框架时具有更好的可比性和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2410.21131</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于可扩展电子商务的图像分层知识图谱构建</title>
      <link>https://arxiv.org/abs/2410.21237</link>
      <description><![CDATA[arXiv:2410.21237v1 公告类型：新
摘要：知识图谱 (KG) 在各种 AI 系统中发挥着越来越重要的作用。对于电子商务而言，高效且低成本的自动化知识图谱构建方法是实现各种成功的下游应用的基础。在本文中，我们提出了一种从原始产品图像构建结构化产品知识图谱的新方法。该方法协同利用视觉语言模型 (VLM) 和大型语言模型 (LLM) 的最新进展，完全自动化流程并允许及时更新图形。我们还提供了一个人工注释的电子商务产品数据集，用于对知识图谱构建中的产品属性提取进行基准测试。我们的方法在所有指标和评估属性方面都优于我们的基线，证明了其有效性和巨大的使用潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.21237</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>