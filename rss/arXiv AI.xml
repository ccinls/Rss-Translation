<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>乐高点：多步空间推理的MLLM的好处有多好？</title>
      <link>https://arxiv.org/abs/2503.19990</link>
      <description><![CDATA[ARXIV：2503.19990V1公告类型：新 
摘要：多步空间推理需要对多个顺序步骤进行空间关系的理解和推理，这对于解决复杂的现实世界应用至关重要，例如机器人操纵，自主导航和自动组装。为了评估当前的多模式大语言模型（MLLM）如何获得了这种基本能力，我们介绍了\ textbf {lego-puzzles}，这是一个可扩展的基准测试，旨在通过基于Lego的任务在MLLM中评估\ textbf {spatial Gealptial}和\ textbf {spatial Gearlity}和\ textbf {sequential推理}。乐高点由1,100个经过精心策划的视觉询问（VQA）样品组成，这些样本涵盖11个不同的任务，从基本的空间理解到复杂的多步推理。基于乐高点式群体，我们对最先进的MLLM进行了全面评估，并发现其空间推理能力的重大限制：即使是最强大的MLLM也只能回答大约一半的测试案例，而人类参与者的精度超过90％。除了VQA任务外，我们还评估了MLLM的能力在汇编插图之后生成乐高图像。我们的实验表明，只有GEMINI-2.0-FLASH和GPT-4O具有遵循这些说明的能力有限，而其他MLLM可以复制输入图像或产生完全无关紧要的输出。总体而言，Lego-Puzzles在现有MLLM的空间理解和顺序推理能力中暴露了关键缺陷，并强调了多模式空间推理的进一步进步。]]></description>
      <guid>https://arxiv.org/abs/2503.19990</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>二次分配的无监督学习</title>
      <link>https://arxiv.org/abs/2503.20001</link>
      <description><![CDATA[ARXIV：2503.20001V1公告类型：新 
摘要：我们介绍了Plume Search，这是一个数据驱动的框架，可通过无监督学习来提高组合优化的搜索效率。与受到监督或强化学习不同，羽流搜索使用基于排列的损失直接从问题实例中学习，并采用非自动进取方法。我们评估了其在二次分配问题上的性能，这是一个基本的NP硬性问题，涵盖了各种组合优化问题。实验结果表明，羽流搜索始终提高溶液质量。此外，我们研究了概括行为，并表明学到的模型会跨不同的密度和大小概括。]]></description>
      <guid>https://arxiv.org/abs/2503.20001</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Omninova：一般的多模式框架</title>
      <link>https://arxiv.org/abs/2503.20028</link>
      <description><![CDATA[ARXIV：2503.20028V1公告类型：新 
摘要：大型语言模型（LLM）与专业工具的集成为智能自动化系统提供了新的机会。但是，由于协调困难，效率低下的资源利用和信息流不一致，策划多个LLM驱动的代理来处理复杂的任务仍然具有挑战性。我们提出了Omninova，这是一种模块化的多代理自动化框架，将语言模型与专用工具（例如Web搜索，爬网和代码执行功能）相结合。 Omninova介绍了三个关键创新：（1）层次多代理架构，具有独特的协调员，计划者，主管和专家代理商； （2）一种动态任务路由机制，可根据任务复杂性优化代理部署； （3）多层LLM集成系统，该系统将适当的模型分配给不同的认知要求。我们在研究，数据分析和Web交互域中的50个复杂任务中进行的评估表明，Omninova在任务完成率（87 \％与基线62 \％），效率（41 \％\％降低令牌用法）和结果质量评估和4.2/5 vs.基础3.1/5）的现有框架（87 \％\％\％\％）。我们既可以为多代理系统设计贡献一个理论框架，也为基于LLM的自动化系统中最新的开源实现提供了开源实现。]]></description>
      <guid>https://arxiv.org/abs/2503.20028</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用训练前示范中隐式反馈的多代理运动生成模型的直接训练后偏好对齐方式</title>
      <link>https://arxiv.org/abs/2503.20105</link>
      <description><![CDATA[ARXIV：2503.20105V1公告类型：新 
摘要：LLM的最新进展已彻底改变了体现应用中的运动产生模型。尽管LLM型自动回归运动生成模型受到训练可伸缩性的受益，但其令牌预测目标与人类偏好之间仍然存在差异。结果，仅通过令牌预测目标进行预训练的模型通常会产生偏离人类希望的行为，从而使训练后的偏好偏好对齐对产生人类脱颖而出的动作至关重要。不幸的是，训练后的对齐需要由预训练的模型产生的动作的广泛优先排名，这些动作的含量为昂贵的注释，尤其是在多代理设置中。最近，人们对利用前训练示范的兴趣越来越多，以可稳定地生成训练后一致性的偏好数据。但是，这些方法通常采用对抗性假设，将所有预训练的模型生成的样本视为不受欢迎的例子。这种对抗性方法忽略了该模型自身的偏好排名提供的有价值的信号，最终降低了一致性的有效性，并可能导致行为不一致。在这项工作中，我们没有将所有生成的样本视为同样不好的样本，而是利用了在训练前演示中编码的隐性偏好，以在预先训练的模型的几代人之间构建偏好排名，从而提供了更细微的偏好一致性指导，而人类成本为零。我们将我们的方法应用于大规模的交通模拟，并在改善预训练模型生成的行为的现实主义方面证明了其有效性，从而使轻巧的1M运动生成模型可与SOTA大型基于基于sotation的模型相媲美，而仅依靠预培训的示范中的隐式反馈，而无需额外的培训后培训后的人类偏好批准或高计算成本。]]></description>
      <guid>https://arxiv.org/abs/2503.20105</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>综合世界模型用于双层计划</title>
      <link>https://arxiv.org/abs/2503.20124</link>
      <description><![CDATA[ARXIV：2503.20124V1公告类型：新 
摘要：现代强化学习（RL）系统在复杂的环境（例如视频游戏）中表现出了显着的功能。但是，在学习新领域时，它们仍然无法实现类似人类的样本效率和适应性。基于理论的增强学习（TBRL）是一种专门旨在解决这一差距的算法框架。以认知理论为基础，TBRL利用结构化的，因果世界模型 - “理论”  - 作为用于计划，概括和探索的前向模拟器。尽管当前的TBRL系统提供了令人信服的解释，解释了人类如何学习视频游戏，但它们面临着几个技术局限性：他们的理论语言是限制性的，并且他们的计划算法是不可扩展的。为了应对这些挑战，我们介绍了Theorycoder，这是TBRL的实例化，该实例化利用了理论的层次结构表示和有效的程序合成方法，以实现更强大的学习和计划。 TheopithCoder为代理提供了通用抽象（例如，“移动到”），然后通过学习低级过渡模型（通过大语言模型从观察结果中综合的Python程序）将其扎根于特定环境中。一种二线计划算法可以利用这种层次结构来解决大域。我们证明，这种方法可以成功应用于多样化且具有挑战性的网格世界游戏，在这种游戏中，基于直接综合政策的方法的方法很差。消融研究证明了使用层次抽象的好处。]]></description>
      <guid>https://arxiv.org/abs/2503.20124</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>透视偏移的神经符号世界模型：社会意识的机器人导航框架</title>
      <link>https://arxiv.org/abs/2503.20425</link>
      <description><![CDATA[ARXIV：2503.20425V1公告类型：新 
摘要：与人类一起在环境中导航要求代理在不确定性下推理并解释周围人们的信念和意图。在连续的决策框架下，自然可以将以自然的导航表示为马尔可夫决策过程（MDP）。但是，社会导航还需要对他人的隐藏信念进行推理，这本质上会导致马尔可夫决策过程（POMDP），在该过程中，代理人无法直接访问他人的心理状态。受到思想和认知计划理论的启发，我们提出（1）基于神经符号模型的社会导航的增强型学习体系结构，以应对部分可观察到的信念跟踪的挑战； （2）一个透视转移操作员进行信念估计，利用结构化多代理设置中的基于影响力的抽象（IBA）的最新工作。]]></description>
      <guid>https://arxiv.org/abs/2503.20425</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>程序知识本体论（PKO）</title>
      <link>https://arxiv.org/abs/2503.20634</link>
      <description><![CDATA[ARXIV：2503.20634V1公告类型：新 
摘要：流程，工作流和准则是确保工业公司正确运作的核心：对于工厂线路，机械或服务的成功运营，行业运营商通常依靠他们过去的经验和专业知识。效果是，这种程序知识（PK）仍然默认，因此很难有效地利用。本文介绍了PKO，即程序知识本体论，通过重复和扩展现有本体论，可以明确的程序及其执行。 PKO建立在从三个异构工业用例中收集的要求基础上，并且可以由任何AI和数据驱动的工具利用，这些工​​具依靠共享且可互操作的表示以支持PK在其整个生命周期中的治理。我们通过讨论利用PKO进行PK启发和开发的应用来描述其结构和设计方法，并概述了其相关性，质量和影响。]]></description>
      <guid>https://arxiv.org/abs/2503.20634</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语义超图推理对n- ary关系事实的归纳链接预测</title>
      <link>https://arxiv.org/abs/2503.20676</link>
      <description><![CDATA[ARXIV：2503.20676V1公告类型：新 
摘要：n- ary关系事实代表两个以上实体之间的语义相关性。尽管最近的研究开发了链接预测（LP）方法，以推断包含n- ary关系事实的知识图（kgs）的缺失关系，但它们通常仅限于跨性环境。完全归纳的环境对以前看不见的实体进行了预测，仍然是一个重大挑战。由于现有方法主要是基于实体嵌入的，因此它们难以捕获独立于实体的逻辑规则。为了填补这一空白，我们提出了一个关于N- ARY关系事实的完全归纳链路预测（ILP）的N- ARY子图推理框架。该框架是局部子图的原因，并且具有捕获N- ARY模式的强大推理能力。具体而言，我们介绍了一种新型的图形结构，即N-Ary语义超图，以促进子图提取。此外，我们开发了一个子图汇总网络NS-HART，以有效地挖掘子图中的复杂语义相关性。从理论上讲，我们从分数函数优化的角度提供了详尽的分析，以阐明NS-HART对N-ARY ILP任务的有效性。从经验上讲，我们对一系列电感基准进行了广泛的实验，包括转移推理（具有和没有实体特征）和成对子图推理。结果突出了N- ARY子图推理框架的优越性和NS-HART的特殊电感能力。本文的源代码已在https://github.com/yin-gz/nary-antuctive-subgraph上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2503.20676</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无图形的无模型增强学习剂，用于有效的电网拓扑控制</title>
      <link>https://arxiv.org/abs/2503.20688</link>
      <description><![CDATA[ARXIV：2503.20688V1公告类型：新 
摘要：由生产商的出现和对清洁能源解决方案的需求驱动的电网管理的复杂性日益增加，需要创新的方法来确保稳定性和效率。本文在无模型学习的无模型框架内提出了一种新颖的方法，旨在在没有事先专家知识的情况下优化电力网络操作。我们引入了蒙面的拓扑操作空间，使代理商能够探索降低成本的各种策略，同时使用国家逻辑作为选择适当行动的指南来维持可靠的服务。通过在模拟的5个近端环境中对20种不同场景进行广泛的实验，我们证明了我们的方法可以持续减少功率损耗，同时确保对潜在停电的电网稳定性。结果强调了将动态观察形式化与基于对手的培训相结合的有效性，这为现代能源系统中自主管理解决方案的可行方式，甚至用于为该领域建立基础模型。]]></description>
      <guid>https://arxiv.org/abs/2503.20688</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI创新，清洁能源和数字经济在美国净零排放量的作用：ARDL方法</title>
      <link>https://arxiv.org/abs/2503.19933</link>
      <description><![CDATA[ARXIV：2503.19933V1公告类型：交叉 
摘要：目前的论文研究了AI创新，GDP增长，可再生能源利用，数字经济和工业化对1990年至2022年美国CO2排放的影响，并结合了ARDL方法。结果表明，AI创新，可再生能源使用和数字经济减少了CO2排放，而GDP扩展和工业化加剧了生态系统的损害。单位根测试（ADF，PP和DF-GLS）揭示了组件之间的异质整合水平，从而确保了ARDL分析中的鲁棒性。互补方法（FMOL，DOL和CCR）验证了结果，从而提高了其可靠性。成对的Granger因果关系评估确定了二氧化碳排放和AI创新以及数字经济中的牢固的单向连接，强调了它们在生态可持续性中的重要作用。这项研究强调了战略行动以培养公平增长的要求，包括AI技术的进步，绿色能源采用和对环境意识的工业发展，以改善美国的环境质量。]]></description>
      <guid>https://arxiv.org/abs/2503.19933</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反向提示：在文本到图像中破解食谱</title>
      <link>https://arxiv.org/abs/2503.19937</link>
      <description><![CDATA[ARXIV：2503.19937V1公告类型：交叉 
摘要：文本到图像的生成越来越流行，但是实现所需图像通常需要广泛的及时工程。在本文中，我们探讨了如何从参考图像中解码文本提示，这是我们称为图像反向提示工程的过程。这项技术使我们能够从参考图像中获得见解，了解伟大艺术家的创作过程，并产生令人印象深刻的新图像。为了应对这一挑战，我们提出了一种称为自动反向提示优化（ARPO）的方法。具体而言，我们的方法通过迭代模拟梯度提示优化过程将初始提示完善到高质量的提示中：1）从当前提示中生成重新创建的图像以实例化其指导能力； 2）产生文本梯度，这些梯度是候选的提示，旨在减少已重新创建的图像和参考图像之间的差异； 3）使用贪婪的搜索方法更新当前提示符，以最大程度地提高提示图和参考图像之间的剪辑相似性。我们将ARPO与几种基线方法进行比较，包括手工制作的技术，基于梯度的提示方法，图像字幕和数据驱动的选择方法。定量和定性结果都表明，我们的ARPO迅速收敛以产生高质量的反向提示。更重要的是，我们可以通过直接编辑这些反向提示来轻松创建具有不同样式和内容的新颖图像。代码将公开可用。]]></description>
      <guid>https://arxiv.org/abs/2503.19937</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FUXI-RTM：具有辐射转移建模的物理指导的预测框架</title>
      <link>https://arxiv.org/abs/2503.19940</link>
      <description><![CDATA[ARXIV：2503.19940V1公告类型：交叉 
摘要：与传统的视频生成类似，当前基于深度学习的天气预测框架通常缺乏明确的物理限制，从而导致非物理输出限制其对操作预测的可靠性。在需要适当代表的各种物理过程中，辐射在驱动地球的天气和气候系统时起着基本作用。但是，由于其固有的复杂性和高计算成本，对传统数值天气预测（NWP）模型的辐射转移过程的准确模拟仍然具有挑战性。在这里，我们提出了Fuxi-RTM，这是一种混合物理学引导的深度学习框架，旨在提高天气预测的精度，同时实现身体一致性。 FUXI-RTM与固定的基于深度学习的辐射转移模型（DLRTM）替代的固定的预测模型（FUXI）集成了一级预测模型（FUXI），从而有效地替代了常规的辐射参数化方案。这代表了第一个基于深度学习的天气预报框架，以明确结合物理过程建模。 Fuxi-RTM在全面的5年数据集中进行了评估，在3320变量和交货时间组合中的88.51％中，其不受约束的速度优于其不受约束的对应物，辐射通量预测的改善。通过合并其他物理过程，Fuxi-RTM为下一代天气预报系统铺平了道路，这些系统既准确又一致。]]></description>
      <guid>https://arxiv.org/abs/2503.19940</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>体现AI的身体发现</title>
      <link>https://arxiv.org/abs/2503.19941</link>
      <description><![CDATA[ARXIV：2503.19941V1公告类型：交叉 
摘要：在追求人工通用智能（AGI）时，体现人工智能（AI）的重要性变得越来越明显。遵循这一趋势，将机器人与AGI相结合的研究变得突出。由于已经设计了各种实施方案，因此对不同实施方案的适应性对AGI很重要。我们引入了一个新的挑战，称为“体现AI的身体发现”，重点是识别实施方案并汇总神经信号功能的任务。挑战涵盖了人工智能的确切定义以及在动态环境中识别实施例的复杂任务，而传统方法通常证明是不足的。为了应对这些挑战，我们采用因果推理方法，并通过开发用于使用虚拟环境测试算法的模拟器来评估它。最后，我们通过经验测试来验证算法的功效，以根据虚拟环境在各种情况下证明它们的稳健性能。]]></description>
      <guid>https://arxiv.org/abs/2503.19941</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>水位预测和洪水预测的基于时空的雷达降水模型</title>
      <link>https://arxiv.org/abs/2503.19943</link>
      <description><![CDATA[ARXIV：2503.19943V1公告类型：交叉 
摘要：研究区域：Goslar和G \“ Ottingen，下萨克森州，德国。研究重点：2017年7月，Goslar和G \ g \ g \ g \&#39;的城市经历了严重的洪水事件，其特征是短短20分钟的短期警告时间，导致广泛的区域洪水和重大损害。这突出了对更可靠和及时的洪水预测系统的迫切需求。本文介绍了一项关于基于雷达的降水数据对戈斯拉尔河水水平的预测的全面研究。此外，该研究还研究了降水如何影响g \“ ottingen中的水位预测。该分析将雷达衍生的时空降水模式与从地面站获得的水文传感器数据整合在一起，以评估这种方法在改善洪水预测能力方面的有效性。该区域的促进性促进与该材料的新水平洞察力：基于密钥的模型，是一个基于密钥的模型，是键入的图像，是键入的图像，这是一个基于限制性的模型。与传统的水文模型不同，导致具有残差的时空降水模型。 LSTM预测时间。结果证明了STRPMR捕获极端事件和更准确的洪水预测的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.19943</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在乳房X线照片中优化乳腺癌检测：一项关于转移学习，减少分辨率和多视图分类的全面研究</title>
      <link>https://arxiv.org/abs/2503.19945</link>
      <description><![CDATA[ARXIV：2503.19945V1公告类型：交叉 
摘要：本研究探讨了在乳房X线照片中使用机器学习在应用机器学习中的开放问题。当前的方法通常采用两阶段的转移学习过程：首先，调整经过自然图像训练的骨干模型以开发补丁分类器，然后将其用于创建单视图的全图分类器。此外，许多研究都利用两种乳房X线摄影视图来增强模型性能。在这项工作中，我们系统地研究了五个关键问题：（1）中间补丁分类器是最佳性能必不可少的吗？ （2）在自然图像分类中表现出色的骨干模型在乳房X线照片上始终优于其他模型吗？ （3）减少用于GPU处理的乳房X线照片分辨率时，学习到衡量技术的大小是否优于常规方法？ （4）在两视图分类器中将两种乳腺X线摄影视图纳入显着提高了检测准确性？ （5）在分析低质量和高质量乳房X线照片时，这些发现如何有所不同？通过解决这些问题，我们开发了模型，以优于单视图和两视图分类器的先前结果。我们的发现提供了对模型架构和转移学习策略的见解，这些策略有助于更准确，有效的乳房X线照片分析。]]></description>
      <guid>https://arxiv.org/abs/2503.19945</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>消失深度：一个深度适配器，具有代码编码的位置深度编码的位置深度</title>
      <link>https://arxiv.org/abs/2503.19947</link>
      <description><![CDATA[ARXIV：2503.19947V1公告类型：交叉 
摘要：通用度量深度理解对于精确的视觉指导机器人技术至关重要，当前最新的（SOTA）视力编码器不支持这一点。为了解决这个问题，我们提出了消失的深度，这是一种自制的训练方法，该方法扩展了预验证的RGB编码器，以将指标深度纳入其特征嵌入。基于我们新颖的位置深度编码，我们启用稳定的深度密度和深度分布不变特征提取。我们在相关的下游任务中实现了绩效的改进和SOTA结果 - 无需对编码器进行填充。最值得注意的是，我们在Sun-RGBD细分时达到了56.05 MIOU，在Void的深度完成下达到88.3 RMSE，在NYUV2场景分类上达到了83.8顶级1的精度。在6D对象的姿势估计中，我们在几个相关的RGBD下游任务中，我们的前身DINOV2，EVA-02和OMNIVORE的前身均优于Dinov2，EVA-02和Omnivore的前身，并获得了非传输编码器的SOTA结果。]]></description>
      <guid>https://arxiv.org/abs/2503.19947</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过VLM和软奖励通过视觉人类偏好进行测试时间推理</title>
      <link>https://arxiv.org/abs/2503.19948</link>
      <description><![CDATA[ARXIV：2503.19948V1公告类型：交叉 
摘要：视觉语言模型（VLM）可以有效地捕获人类的视觉偏好吗？这项工作通过培训VLM来解决这个问题，以在测试时考虑偏好，采用受DeepSeek R1和OpenAI O1启发的强化学习方法。使用ImageRward和人类偏好得分V2（HPSV2）之类的数据集，我们的模型在Imagerward测试集（通过ImageRand官方分配中训练）的精度为64.9％，在HPSV2上获得了65.4％的精度（对大约25％的数据进行了培训）。这些结果与传统的基于编码器的模型相匹配，同时提供透明的推理和增强的概括。这种方法不仅可以使用丰富的VLM世界知识，而且可以使用其思考的潜力，从而产生可解释的结果，从而有助于决策过程。通过证明当前VLM合理的人类视觉偏好，我们为图像排名提供了有效的软奖励策略，超越了简单的选择或评分方法。这种推理能力使VLM可以对纵横比或复杂性的无任意图像进行排名 - 可能会扩大视觉偏好优化的有效性。通过减少对广泛的标记的需求，同时提高奖励的概括和解释性，我们的发现可能是一个强大的英里石，可以进一步增强文本到视觉模型。]]></description>
      <guid>https://arxiv.org/abs/2503.19948</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>logQuant：较高精度保存的对数分布的KV缓存的2位量化</title>
      <link>https://arxiv.org/abs/2503.19950</link>
      <description><![CDATA[ARXIV：2503.19950V1公告类型：交叉 
摘要：我们介绍了logquant，这是一种针对大型语言模型（LLM）推断的KV缓存的开创性的2位量化技术，在保留出色的性能的同时，可节省大量内存。先前的方法要么假设以后的令牌更重要，要么试图根据早期的注意模式预测重要的令牌。但是，两种方法都可以导致性能瓶颈或频繁的错误预测。
  logquant采用了不同的方法。通过应用基于日志的过滤机制，它可以在整个上下文中有选择地压缩KV缓存，与现有方法相比，通过相同甚至减少的内存足迹实现更好的性能。在基准测试中，它可将吞吐量提高25％，并使批次大小增加60％，而不会增加记忆消耗。对于诸如数学和代码完成之类的具有挑战性的任务，LogQuant在相同的压缩率下将准确性提高了40％至200％，表现优于可比较的技术。Logquant毫不费力地与Python的Transformers库库（如Python&#39;s Transformers库）毫不费力地集成。实施可以在https://github.com/concyclics/logquantkv中提供。]]></description>
      <guid>https://arxiv.org/abs/2503.19950</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Acvubench：以音频为中心的视频理解基准测试</title>
      <link>https://arxiv.org/abs/2503.19951</link>
      <description><![CDATA[ARXIV：2503.19951V1公告类型：交叉 
摘要：音频通常是视频理解音频视频模型（LLMS）的任务的辅助方式，只是有助于理解视觉信息。但是，对视频的透彻理解在很大程度上取决于听觉信息，因为音频提供了关键的上下文，情感提示和语义，这意味着仅视觉数据通常就缺乏。本文提出了一个以音频为中心的视频理解基准（ACVubench），以评估多模式LLM的视频理解能力，特别关注听觉信息。具体而言，Acvubench结合了2,662个视频，涵盖了18个不同的域以及丰富的听觉信息，以及超过13k的高质量人类注释或经过验证的问题解答对。此外，Acvubench推出了一套精心设计的以音频为中心的任务，从整体上测试了视频中对音频内容和视听互动的理解。对各种开源和专有的多模式LLM进行了彻底的评估，然后进行了视听LLMS缺陷的分析。演示可从https://github.com/lark-png/acvubench获得。]]></description>
      <guid>https://arxiv.org/abs/2503.19951</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Excot：使用执行反馈优化文本到SQL的推理</title>
      <link>https://arxiv.org/abs/2503.19988</link>
      <description><![CDATA[ARXIV：2503.19988V1公告类型：交叉 
摘要：文本到SQL需要精确的推理将自然语言问题转换为结构化查询。尽管大型语言模型（LLMS）在许多推理任务中都表现出色，但它们利用文本到SQL的思想链（COT）推理的能力仍未得到充实。我们确定临界局限性：零射cot提供最小的收益，而直接偏好优化（DPO）不带COT产生边缘改善。我们提出了Excot，这是一个新颖的框架，它通过将COT推理与外部和政策的DPO相结合，从而迭代地优化开源LLM，仅依赖于执行精度作为反馈。这种方法消除了对奖励模型或人类宣传的偏好的需求。
  我们的实验结果表明了绩效的显着增长：Excot将鸟类开发的执行精度从57.37％提高到68.51％，蜘蛛测试集从78.81％到Llama-3 70B的78.81％到86.59％，QWEN-2.5-ECODER证明了相似的改进。我们的最佳模型在鸟类和蜘蛛数据集的单模设置中实现了最先进的性能，在鸟类测试集中尤其达到68.53％。]]></description>
      <guid>https://arxiv.org/abs/2503.19988</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>