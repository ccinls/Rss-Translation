<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>ElecBench：大型语言模型的电力调度评估基准</title>
      <link>https://arxiv.org/abs/2407.05365</link>
      <description><![CDATA[arXiv:2407.05365v1 公告类型：新
摘要：为应对电网稳定性的迫切需求以及可再生能源整合和电力市场动态带来的复杂挑战，电力行业越来越多地寻求创新的技术解决方案。在此背景下，大型语言模型（LLM）以其出色的自然语言处理、逻辑推理和泛化能力成为提高电力行业效率和促进智能化进程的关键技术。尽管其潜力巨大，但由于电力行业缺乏针对LLM的绩效评估基准，限制了这些技术的有效应用。针对这一空白，我们的研究引入了电力行业LLM的评估基准“ElecBench”。ElecBench旨在通过提供对行业特定场景的全面覆盖、深化专业知识测试和提高决策精度来克服现有评估基准的不足。该框架将场景分为通用知识和专业业务，进一步细分为事实性、逻辑性、稳定性、安全性、公平性和表达性六个核心性能指标，并细分为 24 个子指标，深刻洞察了电力行业 LLM 应用的能力和局限性。为了确保透明度，我们将完整的测试集公开，评估了 8 个 LLM 在各种场景和指标下的性能。ElecBench 致力于成为电力行业 LLM 应用的标准基准，支持场景、指标和模型的持续更新，以推动技术进步和应用。]]></description>
      <guid>https://arxiv.org/abs/2407.05365</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型群体的集体创新</title>
      <link>https://arxiv.org/abs/2407.05377</link>
      <description><![CDATA[arXiv:2407.05377v1 公告类型：新
摘要：人类文化依赖于集体创新：我们不断探索如何将环境中的现有元素组合起来以创造新元素的能力。语言被认为在人类文化中发挥着关键作用，推动个人认知能力并塑造沟通。然而，大多数集体创新模型都没有为代理分配认知能力或语言能力。在这里，我们贡献了一项集体创新的计算研究，其中代理是大型语言模型 (LLM)，它们玩 Little Alchemy 2，这是一款最初为人类开发的创意视频游戏，正如我们所论证的那样，它捕捉到了以前测试平台中不存在的创新格局的有用方面。我们首先单独研究 LLM，发现它既表现出有用的技能，也表现出关键的局限性。然后，我们研究分享与其行为相关的信息的 LLM 群体，并关注社交连接对集体表现的影响。与之前的人类和计算研究一致，我们观察到具有动态连接的群体胜过完全连接的群体。我们的工作揭示了未来集体创新研究的机遇和挑战，随着生成人工智能算法和人类共同创新，这些机遇和挑战变得越来越重要。]]></description>
      <guid>https://arxiv.org/abs/2407.05377</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:20 GMT</pubDate>
    </item>
    <item>
      <title>KAE：一种基于属性的知识图谱对齐与扩展方法</title>
      <link>https://arxiv.org/abs/2407.05320</link>
      <description><![CDATA[arXiv:2407.05320v1 公告类型：新 
摘要：解决语义异构性问题的一个常见方法是利用一个或多个候选 KG 中编码的信息来执行知识图谱 (KG) 扩展，其中参考 KG 和候选 KG 之间的对齐被视为关键过程。然而，现有的 KG 对齐方法主要依赖实体类型 (etype) 标签匹配作为先决条件，这在实践中表现不佳或在某些情况下不适用。在本文中，我们设计了一个基于机器学习的 KG 扩展框架，包括一种替代的基于属性的对齐方法，该方法允许根据用于定义 etype 的属性来对齐 etype。主要的直觉是，属性有意定义 etype，并且该定义独立于用于命名 etype 的特定标签以及 KG 的特定层次结构模式。与最新成果相比，实验结果从数量和质量上证明了 KG 对齐方法的有效性以及所提出的 KG 扩展框架的优越性。]]></description>
      <guid>https://arxiv.org/abs/2407.05320</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>人工智能、合理化和公共部门控制的限度：税收政策优化案例</title>
      <link>https://arxiv.org/abs/2407.05336</link>
      <description><![CDATA[arXiv:2407.05336v1 公告类型：新
摘要：人工智能 (AI) 在公共部门的使用最好被理解为长期合理化和官僚化进程的延续和强化。借鉴韦伯的观点，我们认为这些过程的核心是用工具理性取代传统，即实现任何给定政策目标的最可计算和最有效的方式。在本文中，我们展示了公众和学术界对人工智能系统的批评有多少源于众所周知的韦伯合理化核心的紧张关系。为了说明这一点，我们引入了一个思想实验，其中人工智能系统用于优化税收政策以推进特定的规范目标，减少经济不平等。我们的分析表明，建立一个促进社会和经济平等的机器式税收制度是可能的。然而，它也强调了人工智能驱动的政策优化 (i) 排除了其他竞争性政治价值观，(ii) 凌驾于公民对彼此的非工具性义务的意识之上，以及 (iii) 破坏了人类作为自我决定生物的概念。当代学术研究和倡导旨在确保人工智能系统合法、合乎道德和安全，这些研究建立并强化了支撑合理化过程的核心假设，包括现代观念，即科学可以扫除压迫性制度，用理性规则取而代之，从而将人类从道德不公正中拯救出来。这过于乐观了。科学只能提供手段，不能决定目的。尽管如此，人工智能在公共部门的使用也可以使自由民主国家的机构和进程受益。最重要的是，人工智能驱动的政策优化要求规范性目标明确化和形式化，从而接受公众的审查和辩论。]]></description>
      <guid>https://arxiv.org/abs/2407.05336</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:19 GMT</pubDate>
    </item>
    <item>
      <title>预测伦理模型中的一些问题：一组注释版的“道德故事”对比集</title>
      <link>https://arxiv.org/abs/2407.05244</link>
      <description><![CDATA[arXiv:2407.05244v1 公告类型：新
摘要：像 Delphi 这样的模型已经能够以惊人的准确度将道德困境标记为道德或不道德。本文通过确定将道德困境转化为基于文本的输入的问题，挑战了准确性作为道德建模的整体指标。它通过对比集展示了这些问题，这些对比集大大降低了在数据集 Moral Stories 上训练的分类器的性能。最终，我们获得了具体估计，即特定形式的数据错误陈述对分类器准确性的损害程度。具体而言，对情况描述内容进行标签更改调整（小至 3-5 个字）可以将分类器准确度降低到 51%，几乎是初始准确度 99.8% 的一半。将情况与误导性的社会规范联系起来会将准确度降低到 98.8%，而添加文本偏见（即暗示情况已经符合某个标签）会将准确度降低到 77%。
这些结果不仅表明许多道德模型存在严重过度拟合，而且需要采取一些预防措施来确保输入准确捕捉道德困境。本文建议重新审视社会规范的结构，训练模型以使用可废止推理来询问背景，并过滤输入以消除文本偏见。这样做不仅为我们提供了首次具体估计歪曲道德数据对准确性的平均成本，还为研究人员提供了在研究中考虑这些估计的实用技巧。]]></description>
      <guid>https://arxiv.org/abs/2407.05244</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>WorkArena++：面向基于组合规划和推理的共同知识工作任务</title>
      <link>https://arxiv.org/abs/2407.05291</link>
      <description><![CDATA[arXiv:2407.05291v1 公告类型：新
摘要：大型语言模型 (LLM) 模仿人类智能的能力导致基于 LLM 的自主代理激增。尽管最近的 LLM 似乎能够根据用户指令进行规划和推理，但它们在将这些功能应用于自主任务解决方面的有效性仍未得到充分探索。在企业环境中尤其如此，其中自动化代理有望发挥巨大作用。为了填补这一空白，我们提出了 WorkArena++，这是一个新颖的基准，由 682 个任务组成，这些任务对应于知识工作者日常执行的实际工作流程。WorkArena++ 旨在评估 Web 代理的规划、解决问题、逻辑/算术推理、检索和上下文理解能力。我们对最先进的 LLM 和视觉语言模型 (VLM) 以及人类工作者的实证研究表明，这些模型作为工作场所的有用助手面临着若干挑战。除了基准之外，我们还提供了一种机制，可以轻松生成数千条真实观察/动作轨迹，可用于微调现有模型。总的来说，我们希望这项工作能够成为一种有用的资源，帮助社区朝着有能力的自主代理的方向发展。基准可以在 https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus 找到。]]></description>
      <guid>https://arxiv.org/abs/2407.05291</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>MINDECHO：为关键意见领袖提供角色扮演语言代理</title>
      <link>https://arxiv.org/abs/2407.05305</link>
      <description><![CDATA[arXiv:2407.05305v1 公告类型：新 
摘要：大型语言模型（LLM）在各种应用中都表现出色，其中角色扮演语言代理（RPLA）吸引了广泛的用户群。现在，对代表关键意见领袖（KOL）的 RPLA 的需求日益增长，即塑造其领域趋势和观点的互联网名人。然而，这方面的研究仍未得到充分探索。因此，在本文中，我们介绍了 MINDECHO，一个用于开发和评估 KOL RPLA 的综合框架。MINDECHO 从各个专业领域的互联网视频记录中收集 KOL 数据，并利用 GPT-4 合成他们的对话。然后，对话和记录分别用于个性化模型训练和推理时间检索。我们的评估涵盖了 KOL 的一般维度（即知识和语气）和以粉丝为中心的维度。大量实验验证了 MINDECHO 在开发和评估 KOL RPLA 方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.05305</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:18 GMT</pubDate>
    </item>
    <item>
      <title>解决 X 及其他问题：大型语言模型能否解决具有两个以上未知数的复杂数学问题？</title>
      <link>https://arxiv.org/abs/2407.05134</link>
      <description><![CDATA[arXiv:2407.05134v1 公告类型：新 
摘要：大型语言模型 (LLM) 在解决数学问题方面表现出色，这是人类智能的标志。尽管在当前基准测试中成功率很高；然而，这些通常只涉及一两个未知数的简单问题，不足以挑战它们的推理能力。本文介绍了一种新颖的基准 BeyondX，旨在通过结合具有多个未知数的问题来解决这些限制。认识到从头开始提出多个未知数问题的挑战，我们使用创新的自动化管道开发了 BeyondX，该管道通过扩大简单问题中的未知数数量来逐步增加复杂性。对 BeyondX 的实证研究表明，现有 LLM 的性能，即使是专门针对数学任务进行微调的 LLM，也会随着未知数数量的增加而显着下降 - 在 GPT-4 中观察到的性能下降高达 70\%。为了应对这些挑战，我们提出了“公式化并求解”策略，这是一种通用的提示方法，可以有效处理具有任意数量未知数的问题。我们的研究结果表明，该策略不仅可以提高 LLM 在 BeyondX 基准上的表现，还可以更深入地了解 LLM 在面对更复杂的数学挑战时的计算极限。]]></description>
      <guid>https://arxiv.org/abs/2407.05134</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>Lucy：思考和推理解决文本转 SQL</title>
      <link>https://arxiv.org/abs/2407.05153</link>
      <description><![CDATA[arXiv:2407.05153v1 公告类型：新
摘要：大型语言模型 (LLM) 在帮助用户以自然语言查询数据库方面取得了重大进展。虽然基于 LLM 的技术在许多标准基准测试中提供了最先进的结果，但当应用于大型企业数据库时，它们的性能会显著下降。原因是这些数据库有大量具有复杂关系的表，这对于 LLM 的推理来说具有挑战性。我们分析了 LLM 在这些设置中面临的挑战，并提出了一种新的解决方案，该解决方案将 LLM 理解问题的能力与自动推理技术结合起来，以处理复杂的数据库约束。基于这些想法，我们开发了一个新框架，该框架在复杂基准测试中的零样本文本到 SQL 中的表现优于最先进的技术]]></description>
      <guid>https://arxiv.org/abs/2407.05153</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>5G RAN 中基于通用 Transformer 的无线链路故障预测框架</title>
      <link>https://arxiv.org/abs/2407.05197</link>
      <description><![CDATA[arXiv:2407.05197v1 公告类型：新 
摘要：无线接入网络 (RAN) 中的无线链路故障 (RLF) 预测系统对于确保无缝通信和满足 5G 网络的高数据速率、低延迟和提高可靠性的严格要求至关重要。然而，降水、湿度、温度和风等天气条件会影响这些通信链路。通常，历史无线链路关键绩效指标 (KPI) 及其周围气象站观测值用于构建基于学习的 RLF 预测模型。然而，这样的模型必须能够学习动态 RAN 中的空间天气环境，并有效地使用天气观测数据对时间序列 KPI 进行编码。现有的研究未能将预测模型的这两个基本设计方面结合起来。本文通过提出 GenTrap 来填补这一空白，GenTrap 是一种新颖的 RLF 预测框架，它引入了基于图神经网络 (GNN) 的可学习天气效应聚合模块，并采用最先进的时间序列变换器作为无线链路故障预测的时间特征提取器。 GenTrap 提出的聚合方法可以集成到任何现有的预测模型中，以实现更好的性能和通用性。我们在两个真实数据集（农村和城市）上对 GenTrap 进行了评估，其中包含 260 万个 KPI 数据点，结果表明 GenTrap 的 F1 分数（农村为 0.93，城市为 0.79）明显高于同类产品，同时还具有通用性。]]></description>
      <guid>https://arxiv.org/abs/2407.05197</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:17 GMT</pubDate>
    </item>
    <item>
      <title>使用低资源数据进行垃圾邮件检测的条件半监督数据增强</title>
      <link>https://arxiv.org/abs/2407.04990</link>
      <description><![CDATA[arXiv:2407.04990v1 公告类型：新
摘要：已经尝试了几种机器学习方案来检测垃圾邮件。但是，这些方案大多需要大量标记数据。解决数据可用性不足的现有技术存在有效性和鲁棒性问题。因此，本文针对缺乏数据可用性的垃圾邮件检测模型提出了一种条件半监督数据增强（CSSDA）。CSSDA 的主要架构包括特征提取和增强生成网络。在这里，我们利用未标记的数据进行数据增强以扩展训练数据。我们提出的方案中的增强生成通过条件方案从未标记的数据中生成潜在变量作为假样本。潜在变量可以来自标记和未标记的数据，作为我们垃圾邮件检测模型中最终分类器的输入。实验结果表明，与几种利用和不利用未标记数据的相关方法相比，我们提出的 CSSDA 取得了优异的效果。在对不同数量的未标记数据进行实验时，CSSDA 是唯一一个在标记数据量较大的情况下获得约 85% 平衡准确率的稳健模型。我们还进行了几项消融研究，以详细调查我们提出的方案。结果还表明，几项消融研究加强了我们提出的创新。这些实验表明，未标记数据对使用条件半监督垃圾邮件检测方案进行数据增强具有重大贡献。]]></description>
      <guid>https://arxiv.org/abs/2407.04990</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>MFE-ETP：体现任务规划的多模态基础模型综合评估基准</title>
      <link>https://arxiv.org/abs/2407.05047</link>
      <description><![CDATA[arXiv:2407.05047v1 公告类型：新
摘要：近年来，多模态基础模型（MFM）与具身人工智能（EAI）以前所未有的速度齐头并进。两者的融合引起了人工智能研究界的极大关注。在这项工作中，我们试图对MFM在具身任务规划方面的表现进行深入而全面的评估，旨在阐明其在该领域的能力和局限性。为此，我们首先根据具身任务规划的特点开发了一个系统的评估框架，该框架涵盖了MFM的四个关键能力：对象理解、时空感知、任务理解和具身推理。随后，我们提出了一个新的基准MFE-ETP，描述了其复杂多变的任务场景、典型而多样的任务类型、不同难度的任务实例以及从多个具身问答到具身任务推理的丰富测试用例类型。最后，我们提供了一个简单易用的自动评估平台，该平台能够在建议的基准上自动测试多个 MFM。使用基准和评估平台，我们评估了几种最先进的 MFM，发现它们的性能明显落后于人类水平。MFE-ETP 是一个高质量、大规模且具有挑战性的基准，与现实世界的任务相关。]]></description>
      <guid>https://arxiv.org/abs/2407.05047</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>星座方法下概率论证的先进算法方法</title>
      <link>https://arxiv.org/abs/2407.05058</link>
      <description><![CDATA[arXiv:2407.05058v1 公告类型：新
摘要：以论证形式进行可废止和冲突知识推理是计算论证的一个关键研究领域。在各种不确定性下进行推理既是自动论证推理的关键特征，也是具有挑战性的障碍。结果表明，使用概率的论证推理通常面临较高的计算复杂度，尤其是对于所谓的星座方法。在本文中，我们开发了一种算法方法来克服这一障碍。我们改进了现有的复杂性结果，并表明两个主要推理任务（计算给定集合作为扩展的概率和论证可接受的概率）在复杂性上有所不同：前者是#P-完全的，而后者在考虑其底层计数问题时是#-dot-NP-完全的。我们提出了一种算法，用于计算论证集作为完整扩展的概率这一复杂任务，方法是使用对树分解进行动态规划。实验评估表明我们的方法很有前景。]]></description>
      <guid>https://arxiv.org/abs/2407.05058</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:16 GMT</pubDate>
    </item>
    <item>
      <title>具有神经编译库的算法语言模型</title>
      <link>https://arxiv.org/abs/2407.04899</link>
      <description><![CDATA[arXiv:2407.04899v1 公告类型：新
摘要：推理和规划等重要任务从根本上来说都是算法性的，这意味着要稳健地解决它们需要获得真正的推理或规划算法，而不是捷径。大型语言模型缺乏真正的算法能力，主要是因为神经网络优化算法、其优化数据和优化目标的局限性，也是因为架构缺乏表达力。为了解决这个问题，我们的论文提出用一个基本操作库和复杂的可微分程序来增强 LLM，这样就不需要从头开始学习常用算法了。我们在基于 LLaMA3 构建的变压器架构中添加了内存、寄存器、基本操作和自适应递归。然后，我们定义了一种将算法直接编译成可微分起始库的方法，该库在本地使用并传播梯度进行优化。在这项初步研究中，我们探索了使用可微分计算机增强 LLaMA3 的可行性，例如通过在具有可变计算深度的简单算法任务上微调小型变压器。]]></description>
      <guid>https://arxiv.org/abs/2407.04899</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:15 GMT</pubDate>
    </item>
    <item>
      <title>ZOBNN：具有刻意量化参数的二元神经网络的零开销可靠设计</title>
      <link>https://arxiv.org/abs/2407.04964</link>
      <description><![CDATA[arXiv:2407.04964v1 公告类型：新
摘要：深度神经网络 (DNN) 中的低精度权重和激活在硬件效率方面优于全精度权重和激活。当使用低精度操作实现时，特别是在网络参数二值化的极端情况下（即 BNN），量化最常提到的两个好处是减少内存消耗和加快推理过程。在本文中，我们介绍了极低精度神经网络的第三个优点：改进的容错属性。我们通过全面分析研究了内存故障对最先进的二元神经网络 (BNN) 的影响。尽管在 BNN 架构中包含了浮点参数以提高准确性，但我们的研究结果表明，BNN 对由内存故障引起的这些参数的偏差非常敏感。鉴于这一关键发现，我们提出了一种通过新颖的刻意均匀量化来限制浮点参数范围的技术，以提高 BNN 的可靠性。引入的量化技术减少了 BNN 中使用的浮点参数的比例，而不会在推理阶段产生任何额外的计算开销。对所提出的 BNN 架构（即 ZOBNN）进行的大量实验故障模拟表明，与传统浮点 DNN 相比，其鲁棒性提高了 5 倍。值得注意的是，这种改进是在不产生任何计算开销的情况下实现的。至关重要的是，这种增强没有计算开销。 \ToolName~ 在计算资源有限的关键边缘应用中表现出色，优先考虑可靠性和实时性能。]]></description>
      <guid>https://arxiv.org/abs/2407.04964</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:15 GMT</pubDate>
    </item>
    <item>
      <title>LogicVista：视觉环境中的多模态法学硕士逻辑推理基准</title>
      <link>https://arxiv.org/abs/2407.04973</link>
      <description><![CDATA[arXiv:2407.04973v1 公告类型：新
摘要：我们提出了 LogicVista，这是一个评估基准，用于评估多模态大型语言模型 (MLLM) 在视觉环境中的综合逻辑推理能力。MLLM 的最新进展展示了各种令人着迷的能力，从基于图像创作诗歌到进行数学推理。然而，仍然缺乏对 MLLM 在逻辑推理任务中能力的系统评估，这对于导航和解谜等活动至关重要。因此，我们使用 448 个多项选择题样本，评估了 5 个逻辑推理任务中涵盖 9 种不同能力的一般逻辑认知能力。每个问题都标注了正确答案和选择背后的人工推理，从而可以进行开放式和多项选择式评估。使用 LogicVista 对总共 8 个 MLLM 进行了全面评估。代码和数据可在 https://github.com/Yijia-Xiao/LogicVista 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.04973</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:15 GMT</pubDate>
    </item>
    <item>
      <title>探究黑盒代码语言模型</title>
      <link>https://arxiv.org/abs/2407.04868</link>
      <description><![CDATA[arXiv:2407.04868v1 公告类型：新
摘要：语言模型 (LM) 已显示出其在与代码相关的任务中的应用，并且最近提出了几种代码~LM。该方向的大多数研究仅关注 LM 在不同基准上的性能改进，而 LM 被视为黑匣子。除此之外，少数研究试图了解注意层在代码~LM 中的作用。尽管如此，前馈层仍未得到充分探索，它占典型转换器模型参数的三分之二。
在这项工作中，我们试图通过检查前馈层来深入了解代码语言模型的内部工作原理。为了进行调查，我们使用了两个最先进的代码~LM，Codegen-Mono 和 Ploycoder，以及三种广泛使用的编程语言，Java、Go 和 Python。我们专注于研究存储概念的组织、这些概念的可编辑性以及不同层的作用和输入上下文大小变化对输出生成的影响。我们的实证结果表明，较低层捕获句法模式，而较高层编码抽象概念和语义。我们表明，感兴趣的概念可以在前馈层内编辑，而不会影响代码语言模型的性能。此外，我们观察到初始层充当“思考”层，而后续层对于预测后续代码标记至关重要。此外，我们发现早期层可以准确预测较小的上下文，但较大的上下文需要关键的后续层的贡献。我们预计这些发现将有助于更好地理解、调试和测试代码语言模型。]]></description>
      <guid>https://arxiv.org/abs/2407.04868</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:14 GMT</pubDate>
    </item>
    <item>
      <title>用于解决规范冲突的可废止道义演算</title>
      <link>https://arxiv.org/abs/2407.04869</link>
      <description><![CDATA[arXiv:2407.04869v1 公告类型：新
摘要：在决定如何行动时，我们必须考虑其他代理的规范和价值观。然而，我们的规范在不断发展。我们经常添加例外或改变主意，因此规范可能会随着时间的推移而发生冲突。因此，为了保持对他人规范的准确心理模型，从而避免社会摩擦，必须迅速发现和解决此类冲突。形式化这一过程一直是各种道义逻辑和规范多代理系统的重点。我们旨在弥合这两个领域之间的差距。我们贡献了一个具有继承性的可废止道义演算，并证明它可以解决规范冲突。通过这种分析，我们还揭示了一种常见的解决策略作为转移注意力的手段。因此，本文为规范冲突检测和解决提供了理论上合理的公理化。]]></description>
      <guid>https://arxiv.org/abs/2407.04869</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:14 GMT</pubDate>
    </item>
    <item>
      <title>评估用于生成和判断编程反馈的语言模型</title>
      <link>https://arxiv.org/abs/2407.04873</link>
      <description><![CDATA[arXiv:2407.04873v1 公告类型：新 
摘要：大型语言模型 (LLM) 的出现改变了广泛领域的研究和实践。在计算教育研究 (CER) 领域，LLM 受到了广泛关注，尤其是在学习编程的背景下。然而，CER 中关于 LLM 的大部分工作都集中在应用和评估专有模型上。在本文中，我们评估了开源 LLM 在为编程作业生成高质量反馈以及判断编程反馈质量方面的效率，并将结果与​​专有模型进行对比。我们对学生提交的 Python 入门编程练习数据集的评估表明，最先进的开源 LLM（Meta 的 Llama3）在编程反馈的生成和评估方面几乎与专有模型（GPT-4o）相当。我们进一步证明了小型 LLM 在任务中的效率，并强调有各种各样的 LLM 可供教育工作者和从业者免费获得。]]></description>
      <guid>https://arxiv.org/abs/2407.04873</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:14 GMT</pubDate>
    </item>
    <item>
      <title>代码幻觉</title>
      <link>https://arxiv.org/abs/2407.04831</link>
      <description><![CDATA[arXiv:2407.04831v1 公告类型：新
摘要：生成模型（例如大型语言模型）被广泛用作代码副驾驶和整个程序生成。然而，它们生成的程序在集成方面的正确性、真实性和可靠性往往值得怀疑，因为它们可能不符合用户要求、提供不正确和/或无意义的输出，甚至包含语义/语法错误 - 统称为 LLM 幻觉。在这项工作中，我们介绍了几种类型的代码幻觉。我们使用大型语言模型手动生成了这种幻觉代码。我们还提出了一种技术 - HallTrigger，以展示生成任意代码幻觉的有效方法。我们的方法利用 LLM 的 3 种不同动态属性来制作提示，这些提示可以成功地从模型中触发幻觉，而无需访问模型架构或参数。流行的黑盒模型的结果表明 HallTrigger 确实有效，并且普遍存在的 LLM 幻觉对软件开发产生了巨大的影响。]]></description>
      <guid>https://arxiv.org/abs/2407.04831</guid>
      <pubDate>Wed, 10 Jul 2024 03:23:13 GMT</pubDate>
    </item>
    </channel>
</rss>