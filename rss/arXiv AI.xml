<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 21 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>研究大型语言模型中相似性判断的上下文效应</title>
      <link>https://arxiv.org/abs/2408.10711</link>
      <description><![CDATA[arXiv:2408.10711v1 公告类型：新
摘要：大型语言模型 (LLM) 彻底改变了 AI 模型理解和生成自然语言文本的能力。它们越来越多地被用于在现实世界场景中授权和部署代理，这些代理根据对上下文的理解做出决策并采取行动。因此，研究人员、政策制定者和企业都在努力确保这些代理做出的决策符合人类价值观和用户期望。话虽如此，人类价值观和决策并不总是容易衡量的，而且会受到不同认知偏见的影响。行为科学中有大量文献研究人类判断中的偏见。在这项工作中，我们报告了一项正在进行的研究，研究 LLM 与受顺序偏见影响的人类判断的一致性。具体来说，我们关注一项著名的人类研究，该研究显示了相似性判断中顺序效应的证据，并将其复制到各种流行的 LLM 中。我们报告了 LLM 表现出类似人类的顺序效应偏差的不同设置，并讨论了这些发现的含义，以便为基于 LLM 的应用程序的设计和开发提供信息。]]></description>
      <guid>https://arxiv.org/abs/2408.10711</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:49 GMT</pubDate>
    </item>
    <item>
      <title>对本地 LLaMA-3 大型语言模型进行微调，以实现放射肿瘤学中保护隐私的自动医生信件生成</title>
      <link>https://arxiv.org/abs/2408.10715</link>
      <description><![CDATA[arXiv:2408.10715v1 公告类型：新
摘要：在日常临床实践中，生成医生信件是一项耗时的任务。本研究调查了大型语言模型 (LLM)（特别是 LLaMA 模型）的局部微调，以便在放射肿瘤学领域以隐私保护的方式生成医生信件。我们的研究结果表明，未经微调的基础 LLaMA 模型不足以有效地生成医生信件。QLoRA 算法提供了一种有效的方法，用于在有限的计算资源（即医院内单个 48 GB GPU 工作站）下对 LLM 进行局部机构内微调。经过微调的 LLM 成功学习了放射肿瘤学特定信息并以机构特定风格生成医生信件。生成的摘要报告的 ROUGE 分数突出了 8B LLaMA-3 模型优于 13B LLaMA-2 模型。医生对 10 例病例进行多维度评估后发现，尽管经过微调的 LLaMA-3 模型在生成除提供的输入数据之外的内容方面的能力有限，但它成功地生成了问候语、诊断和治疗历史、进一步治疗的建议以及计划的时间表。总体而言，临床专家对临床效益的评价很高（4 分制中平均得分为 3.44）。通过医生的仔细检查和纠正，基于 LLM 的自动医生信件生成具有重大的实用价值。]]></description>
      <guid>https://arxiv.org/abs/2408.10715</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:49 GMT</pubDate>
    </item>
    <item>
      <title>抽象论证中的拒绝：比接受更难？</title>
      <link>https://arxiv.org/abs/2408.10683</link>
      <description><![CDATA[arXiv:2408.10683v1 公告类型：新
摘要：抽象论证是一种流行的工具包，用于建模、评估和比较论证。论证框架 (AF) 中指定了论证之间的关系，并将条件置于论证集 (扩展) 上，以允许对 AF 进行评估。为了更具表现力，AF 增加了直接交互论证的 \emph{接受条件} 或可接受论证集的约束，从而产生了辩证框架或受约束的论证框架。在本文中，我们考虑了从扩展中 \emph{拒绝} 论证的灵活条件，我们称之为拒绝条件 (RC)。在技术层面上，我们将每个论证与特定的逻辑程序相关联。我们分析了由此产生的复杂性，包括结构参数树宽。拒绝 AF 具有很强的表现力，在多项式层次的更高层次上自然会产生问题。]]></description>
      <guid>https://arxiv.org/abs/2408.10683</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>创世纪：迈向系统生物学研究的自动化</title>
      <link>https://arxiv.org/abs/2408.10689</link>
      <description><![CDATA[arXiv:2408.10689v1 公告类型：新
摘要：将人工智能应用于科学的前沿是科学研究的闭环自动化：机器人科学家。我们之前已经开发了两个机器人科学家：“亚当”（用于酵母功能生物学）和“夏娃”（用于早期药物设计）。我们现在正在开发下一代机器人科学家 Genesis。通过 Genesis，我们旨在证明使用机器人科学家可以比人类科学家更快地、以更低的成本研究某个科学领域。我们在此报告 Genesis 项目的进展情况。Genesis 旨在自动改进具有数千个相互作用的因果成分的系统生物学模型。完成后，Genesis 将能够每天并行启动和执行一千个假设主导的闭环实验循环。这里我们描述了核心 Genesis 硬件：一千个计算机控制的 $\mu$ 生物反应器。对于集成质谱平台，我们开发了 AutonoMS，这是一个自动运行、处理和分析高通量实验的系统。我们还开发了 Genesis-DB，这是一个旨在使软件代理能够访问大量结构化域信息的数据库系统。我们开发了 RIMBO（生物本体模型改进修订版）来描述计划对模型进行的数十万次更改。我们通过开发两个关系学习生物信息学项目证明了这一基础设施的实用性。最后，我们描述了 LGEM+，这是一个用于自动溯因改进基因组规模代谢模型的关系学习系统。]]></description>
      <guid>https://arxiv.org/abs/2408.10689</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>在边缘上微调和部署大型语言模型：问题与方法</title>
      <link>https://arxiv.org/abs/2408.10691</link>
      <description><![CDATA[arXiv:2408.10691v1 公告类型：新 
摘要：自 2019 年 GPT2-1.5B 发明以来，大型语言模型 (LLM) 已从专用模型转变为多功能基础模型。LLM 表现出令人印象深刻的零样本能力，然而，需要在本地数据集上进行微调，并需要大量资源才能部署。传统的一阶优化器微调技术需要大量的 GPU 内存，这超出了主流硬件的能力。因此，我们有必要研究内存效率高的方法。模型压缩技术可以降低能耗、运营成本和环境影响，从而支持可持续的人工智能进步。此外，大规模基础模型已经扩展到创建图像、音频、视频和多模态内容，进一步强调了高效部署的必要性。因此，我们有必要全面概述网络边缘上流行的内存效率高微调方法。我们还回顾了有关模型压缩的最新文献，以提供在网络边缘部署 LLM 的愿景。]]></description>
      <guid>https://arxiv.org/abs/2408.10691</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>战略家：通过双层树搜索法学习法学硕士的战略技能</title>
      <link>https://arxiv.org/abs/2408.10635</link>
      <description><![CDATA[arXiv:2408.10635v1 公告类型：新
摘要：在本文中，我们提出了一种新方法策略师，该方法利用 LLM 通过自我改进过程获得玩多智能体游戏的新技能。我们的方法通过使用蒙特卡洛树搜索和基于 LLM 的反射进行自我游戏模拟来收集质量反馈，然后可用于学习高级战略技能，例如如何评估指导低级执行的状态。我们展示了我们的方法如何在游戏环境中用于行动规划和对话生成，并在这两项任务上取得良好的表现。具体来说，我们证明我们的方法可以帮助训练智能体，其性能优于传统的基于强化学习的方法和其他基于 LLM 的技能学习方法，包括纯策略游戏 (GOPS) 和抵抗军：阿瓦隆。]]></description>
      <guid>https://arxiv.org/abs/2408.10635</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:47 GMT</pubDate>
    </item>
    <item>
      <title>对 LLM 进行微调以提高性能并减少模型偏差的较小 SFT 损失</title>
      <link>https://arxiv.org/abs/2408.10642</link>
      <description><![CDATA[arXiv:2408.10642v1 公告类型：新
摘要：Instruct LLM 提供了一种用于大规模语言模型的范式，以使 LLM 与人类偏好保持一致。该范式包含监督微调和从人类反馈中强化学习。该范式还用于下游场景，以使 LLM 适应特定的语料库和应用程序。与 SFT 相比，许多工作都集中在 RLHF 上，并提出了几种算法，例如 PPO、DPO、IPO、KTO、MinorDPO 等。同时，SFT 的大部分工作都集中在如何收集、过滤和混合高质量数据上。在本文中，我们借鉴 DPO 和 MinorDPO 的见解，提出了一种 SFT 的训练指标来衡量优化模型与原始模型之间的差异，并提出了一个损失函数 MinorSFT，可以提高训练效果，并减少优化后的 LLM 与原始 LLM 之间的差异。]]></description>
      <guid>https://arxiv.org/abs/2408.10642</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:47 GMT</pubDate>
    </item>
    <item>
      <title>Hokoff：《王者荣耀》真实游戏数据集及其离线强化学习基准</title>
      <link>https://arxiv.org/abs/2408.10556</link>
      <description><![CDATA[arXiv:2408.10556v1 公告类型：新
摘要：离线强化学习 (RL) 和离线多智能体强化学习 (MARL) 的进步关键取决于高质量、预先收集的离线数据集的可用性，这些数据集代表了现实世界的复杂性和实际应用。然而，现有的数据集往往在简单性和缺乏真实性方面存在不足。为了解决这一差距，我们提出了 Hokoff，这是一套全面的预先收集的数据集，涵盖离线 RL 和离线 MARL，并附带一个强大的框架，以促进进一步的研究。这些数据来自《王者荣耀》，这是一款公认的多人在线战斗竞技场 (MOBA) 游戏，以其错综复杂的性质而闻名，与现实生活中的情况非常相似。利用这个框架，我们对各种离线 RL 和离线 MARL 算法进行了基准测试。我们还介绍了一种针对游戏固有的分层动作空间量身定制的新型基线算法。我们揭示了当前离线 RL 方法在处理任务复杂性、泛化和多任务学习方面的不足。]]></description>
      <guid>https://arxiv.org/abs/2408.10556</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:46 GMT</pubDate>
    </item>
    <item>
      <title>利用几何图解代数问题的全息推理</title>
      <link>https://arxiv.org/abs/2408.10592</link>
      <description><![CDATA[arXiv:2408.10592v1 公告类型：新
摘要：用几何图 (APGD) 解决代数问题仍然是一个具有挑战性的问题，因为图处理的研究并不像语言处理那样深入。为了应对这一挑战，本文提出了一种全息图推理方案，并利用该方案开发了一种高性能的 APGD 解决方法。为了实现这一目标，它首先定义了一种全息图，即一种图形，并提出了一个全息图生成器将给定的 APGD 转换为全息图，该全息图代表了 APGD 的全部信息，可以通过统一的方式从中获取解决问题的关系。然后，全息图推理方法 HGR 使用一组准备好的图形模型来推导代数方程，这与几何定理一致。可以通过将新的图形模型添加到池中来更新该方法。最后，它采用深度强化学习来提高从池中选择模型的效率。整个 HGR 不仅保证了较高的求解精度和较少的推理步骤，而且通过提供所有推理步骤的描述，大大提高了求解过程的可解释性。实验结果表明 HGR 在提高 APGD 求解的精度和可解释性方面是有效的。]]></description>
      <guid>https://arxiv.org/abs/2408.10592</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:46 GMT</pubDate>
    </item>
    <item>
      <title>QPO：通过多循环离线强化学习实现查询相关的提示优化</title>
      <link>https://arxiv.org/abs/2408.10504</link>
      <description><![CDATA[arXiv:2408.10504v1 公告类型：新
摘要：提示工程在提升大型语言模型 (LLM) 在不同任务上的性能方面取得了显著成功。然而，大多数现有的提示优化方法仅关注任务级性能，忽略了查询优先提示的重要性，导致性能不佳。此外，这些方法严重依赖与 LLM 的频繁交互来获得反馈以指导优化过程，从而产生大量冗余交互成本。在本文中，我们引入了查询相关提示优化 (QPO)，它利用多循环离线强化学习迭代微调小型预训练语言模型以生成针对输入查询定制的最佳提示，从而显着提高对大型目标 LLM 的提示效果。我们从离线提示演示数据中获得见解，这些数据已经大量存在，是对开源任务上的各种提示进行基准测试的副产品，从而避免了在线交互的费用。此外，我们在每个循环中不断用生成的提示扩充离线数据集，因为经过微调的模型中的提示应该比原始数据集中的源提示表现更好。这些迭代循环引导模型生成最佳提示。在各种 LLM 规模和各种 NLP 和数学任务上进行的实验证明了我们的方法在零样本和少样本场景中的有效性和成本效益。]]></description>
      <guid>https://arxiv.org/abs/2408.10504</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:45 GMT</pubDate>
    </item>
    <item>
      <title>连续域中动态智能体高维执行能力的近似估计</title>
      <link>https://arxiv.org/abs/2408.10512</link>
      <description><![CDATA[arXiv:2408.10512v1 公告类型：新
摘要：在许多现实世界的连续动作领域中，人类代理必须决定尝试哪些动作，然后尽其所能执行这些动作。然而，人类无法毫无错误地执行动作。人类在这些领域的表现可以通过使用人工智能来辅助决策而得到潜在改善。人工智能正确推理人类代理应该尝试什么动作的一个要求是该人类执行错误或技能的正确模型。最近的工作已经展示了使用不同领域的各种类型的代理来估计这种执行错误的成功技术。然而，这项先前的工作做出了几个假设，限制了这些想法在现实世界中的应用。首先，先前的工作假设误差分布是对称正态的，这意味着只需要估计一个参数。实际上，代理误差分布可能表现出任意形状，应该更灵活地建模。其次，假设代理的执行误差在所有观察中保持不变。尤其是对于人类代理来说，执行错误会随时间而变化，必须考虑到这一点才能获得有效的估计。为了克服这两个缺点，我们提出了一种基于粒子滤波器的新型估计器来解决这个问题。在描述了这个近似估计器的细节之后，我们通过实验探索了各种设计决策，并在各种设置下将其性能与以前的技能估计器进行比较，以展示改进之处。结果是一个能够生成更现实、随时间变化的代理执行技能估计的估计器，然后可以用来帮助代理做出更好的决策并提高他们的整体表现。]]></description>
      <guid>https://arxiv.org/abs/2408.10512</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:45 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的 IVR</title>
      <link>https://arxiv.org/abs/2408.10549</link>
      <description><![CDATA[arXiv:2408.10549v1 公告类型：新
摘要：使用传统的 IVR（交互式语音应答）方法通常不足以满足客户需求。本文研究了人工智能 (AI) 技术在提高呼叫中心 IVR 系统效率方面的应用。所提出的方法基于语音到文本转换解决方案的集成、使用大型语言模型 (LLM) 的文本查询分类和语音合成。特别注意使这些技术适用于哈萨克语，包括在专门的数据集上微调模型。描述了在实际呼叫中心实施开发的系统进行查询分类的实际方面。研究结果表明，人工智能技术在呼叫中心 IVR 系统中的应用减少了操作员的工作量，提高了客户服务质量，并提高了查询处理的效率。所提出的方法可以适用于使用各种语言的呼叫中心。]]></description>
      <guid>https://arxiv.org/abs/2408.10549</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:45 GMT</pubDate>
    </item>
    <item>
      <title>IDEA：通过归纳、推理和溯因增强语言代理的规则学习能力</title>
      <link>https://arxiv.org/abs/2408.10455</link>
      <description><![CDATA[arXiv:2408.10455v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 已经针对演绎和归纳推理进行了彻底评估，但它们在交互式环境中的溯因推理和整体规则学习能力仍未得到充分探索。这项工作引入了 RULEARN，这是一种专门设计用于评估 LLM 在交互式环境中的规则学习能力的新基准。在 RULEARN 中，代理与环境交互以收集观察结果并辨别模式，并利用这些见解来解决问题。为了进一步增强此基准中 LLM 代理的规则学习能力，我们提出了 IDEA 代理，它集成了归纳、演绎和溯因过程。IDEA 代理通过利用结构化的推理序列来改进这种方法：通过溯因生成假设，通过演绎测试它们，并根据归纳反馈对其进行改进。此序列使代理能够动态地建立和应用规则，模仿类似人类的推理过程。我们对五个代表性 LLM 的评估表明，虽然这些模型可以生成合理的初始假设，但它们往往难以在环境中进行战略互动、有效地整合反馈以及自适应地改进假设。IDEA 代理在 RULEARN 基准上表现出显著的改进性能，为开发能够在现实世界场景中进行类似人类规则学习的代理提供了宝贵的见解。我们将发布我们的代码和数据。]]></description>
      <guid>https://arxiv.org/abs/2408.10455</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:44 GMT</pubDate>
    </item>
    <item>
      <title>讲座是否有利于学习？知识图谱支持的智能授课助理 (ILA) 系统的讲座语音情感分析</title>
      <link>https://arxiv.org/abs/2408.10492</link>
      <description><![CDATA[arXiv:2408.10492v1 公告类型：新
摘要：本文介绍了一种智能讲课助理 (ILA) 系统，该系统利用知识图谱来表示课程内容和最佳教学策略。该系统旨在通过实时分析语音、内容和教学方法来支持教师提高学生的学习能力。作为初步调查，我们提出了一个关于讲座语音情绪分析的案例研究，其中我们开发了一个包含 3,000 多个一分钟讲座语音片段的训练集。每个片段都被手动标记为引人入胜或不引人入胜。利用这个数据集，我们根据从语音片段中提取的各种特征构建和评估了几个分类模型。结果显示出良好的性能，在超过 800 个测试语音片段的独立集合中，无聊的讲座的 F1 分数达到 90%。这个案例研究为开发一个更复杂的模型奠定了基础，该模型将内容分析和教学实践相结合。我们的最终目标是利用现代人工智能技术帮助教师更具吸引力、更有效地教学。]]></description>
      <guid>https://arxiv.org/abs/2408.10492</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:44 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型关键主题检测开发人工智能反欺凌系统</title>
      <link>https://arxiv.org/abs/2408.10417</link>
      <description><![CDATA[arXiv:2408.10417v1 公告类型：新
摘要：本文介绍并评估了人工智能 (AI) 反欺凌系统的开发工作。该系统旨在通过社交媒体和其他机制识别协同欺凌攻击，对其进行描述并提出补救和响应活动。具体来说，大型语言模型 (LLM) 用于填充增强的基于专家系统的欺凌攻击网络模型。这有助于分析和补救活动（例如向社交媒体公司生成报告消息）的确定。本文描述了该系统，并分析了 LLM 用于填充模型的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.10417</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:43 GMT</pubDate>
    </item>
    <item>
      <title>通过分布式摄像机网络和隐私保护边缘计算评估认知障碍的可行性</title>
      <link>https://arxiv.org/abs/2408.10442</link>
      <description><![CDATA[arXiv:2408.10442v1 公告类型：新
摘要：介绍：轻度认知障碍 (MCI) 的特征是认知功能下降超出了典型的年龄和教育相关预期。由于 MCI 与社交互动减少和无目的运动增加有关，我们旨在自动捕捉这些行为以加强纵向监测。
方法：使用隐私保护分布式摄像机网络，我们从 1700$m^2$ 空间内接受治疗的 MCI 患者群体中收集运动和社交互动数据。我们开发了运动和社交互动特征，然后将其用于训练一系列机器学习算法，以区分认知功能较高和较低的 MCI 组。
结果：Wilcoxon 秩和检验显示，高功能和低功能队列在线性路径长度、步行速度、步行时方向变化、速度和方向变化的熵以及室内空间中的群体形成数量等特征方面存在统计学上的显着差异。尽管缺乏与特定 MCI 级别相关联的个人标识符，但使用最重要特征的机器学习方法提供了 71% 的准确率。
讨论：我们提供证据表明，使用边缘计算框架的隐私保护低成本摄像头网络有可能从群体活动期间捕捉到的动作和社交互动中区分不同程度的认知障碍。]]></description>
      <guid>https://arxiv.org/abs/2408.10442</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的查询语言</title>
      <link>https://arxiv.org/abs/2408.10362</link>
      <description><![CDATA[arXiv:2408.10362v1 公告类型：新
摘要：我们通过使用声明性语言查询神经网络模型，为解释和理解神经网络模型的数据库启发式方法奠定了基础。为此，我们研究了基于一阶逻辑的不同查询语言，这些语言主要在对神经网络模型的访问方式上有所不同。实数上的一阶逻辑自然会产生一种将网络视为黑盒的语言；只能查询网络定义的输入输出函数。这本质上是约束查询语言的方法。另一方面，可以通过将网络视为加权图并使用权重项求和扩展一阶逻辑来获得白盒语言。后一种方法本质上是 SQL 的抽象。一般来说，这两种方法在表达能力上是无法比拟的，我们将展示这一点。然而，在自然情况下，白盒方法可以包含黑盒方法；这是我们的主要结果。我们具体证明了对于由具有固定数量的隐藏层和分段线性激活函数的前馈神经网络定义的实函数上的线性约束查询的结果。]]></description>
      <guid>https://arxiv.org/abs/2408.10362</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能驱动的评审系统：在可扩展且具有偏见的学术评审中评估法学硕士</title>
      <link>https://arxiv.org/abs/2408.10365</link>
      <description><![CDATA[arXiv:2408.10365v1 公告类型：新
摘要：自动审阅有助于处理大量论文，提供早期反馈和质量控制，减少偏见，并允许分析趋势。我们通过成对比较，使用人类偏好竞技场来评估自动论文评论与人工评论的一致性。收集人类偏好可能很耗时；因此，我们还使用 LLM 自动评估评论，以提高样本效率，同时减少偏见。除了评估 LLM 评论中的人类和 LLM 偏好之外，我们还对 LLM 进行微调以预测人类偏好，预测在 LLM 之间的正面交锋中人类会更喜欢哪些评论。我们人为地在论文中引入错误并分析 LLM 的回应以确定局限性，使用自适应审查问题、元提示、角色扮演、整合视觉和文本分析、使用特定场地的审查材料并预测人类偏好，从而改进传统审查流程的局限性。我们将公开的 arXiv 和开放获取的 Nature 期刊论文的评论放在网上，同时提供免费服务，帮助作者审阅和修改他们的研究论文并提高论文质量。这项工作开发了概念验证型 LLM 审阅系统，可快速提供一致、高质量的评论并评估其质量。我们通过为 LLM 增添多份文档（包括审阅表、审阅者指南、道德和行为准则、领域主席指南和往年统计数据），找出自动审阅可能检测到的论文错误和缺点，并评估成对审阅者的偏好，从而降低滥用、评论分数虚高、评级过度自信和分数分布不均的风险。这项工作确定并解决了使用 LLM 作为审阅者和评估者的局限性，并提高了审阅过程的质量。]]></description>
      <guid>https://arxiv.org/abs/2408.10365</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:42 GMT</pubDate>
    </item>
    <item>
      <title>伪装的狼比没牙的老虎更有害：利用用户行为作为触发因素的自适应恶意代码注入后门攻击</title>
      <link>https://arxiv.org/abs/2408.10334</link>
      <description><![CDATA[arXiv:2408.10334v1 Announce Type: new 
摘要：近年来，大型语言模型（LLM）在代码生成领域取得了重大进展。然而，随着越来越多的用户依赖这些模型进行软件开发，与代码生成模型相关的安全风险也变得越来越显著。研究​​表明，传统的深度学习鲁棒性问题也对代码生成领域产生了负面影响。在本文中，我们首先提出了专注于代码生成场景中安全问题的博弈论模型。该框架概述了攻击者可能传播恶意代码模型以制造安全威胁的场景和模式。我们还首次指出攻击者可以使用后门攻击来动态调整恶意代码注入的时机，从而根据用户的技能水平释放不同程度的恶意代码。通过在领先的代码生成模型上进行大量实验，我们验证了我们提出的博弈论模型，并强调了这些新的攻击场景对代码模型的安全使用构成的重大威胁。]]></description>
      <guid>https://arxiv.org/abs/2408.10334</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:41 GMT</pubDate>
    </item>
    <item>
      <title>LegalBench-RAG：法律领域检索增强生成的基准</title>
      <link>https://arxiv.org/abs/2408.10343</link>
      <description><![CDATA[arXiv:2408.10343v1 公告类型：新
摘要：检索增强生成 (RAG) 系统显示出巨大的潜力，并且在 AI 驱动的法律应用中变得越来越重要。现有的基准测试（例如 LegalBench）评估了大型语言模型 (LLM) 在法律领域的生成能力，但在评估 RAG 系统的检索组件方面存在一个关键的差距。为了解决这个问题，我们推出了 LegalBench-RAG，这是第一个专门用于评估法律领域内 RAG 管道检索步骤的基准测试。LegalBench-RAG 强调精确检索，重点是从法律文件中提取最小、高度相关的文本段。这些高度相关的片段比检索文档 ID 或大量不精确的块序列更受欢迎，这两者都可能超出上下文窗口限制。长上下文窗口的处理成本更高，导致更高的延迟，并导致 LLM 忘记或产生幻觉信息。此外，精确的结果使 LLM 能够为最终用户生成引文。LegalBench-RAG 基准是通过将 LegalBench 查询中使用的上下文追溯到法律语料库中的原始位置而构建的，从而产生了一个包含 6,858 个查询-答案对的数据集，该数据集包含超过 7900 万个字符的语料库，完全由法律专家人工注释。我们还推出了 LegalBench-RAG-mini，这是一个轻量级版本，可用于快速迭代和实验。通过提供专用的法律检索基准，LegalBench-RAG 成为公司和研究人员的重要工具，专注于提高法律领域 RAG 系统的准确性和性能。LegalBench-RAG 数据集可在 https://github.com/zeroentropy-cc/legalbenchrag 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2408.10343</guid>
      <pubDate>Wed, 21 Aug 2024 06:28:41 GMT</pubDate>
    </item>
    </channel>
</rss>