<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 18 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于自动脑电图背景分析和报告生成的混合人工智能系统</title>
      <link>https://arxiv.org/abs/2411.09874</link>
      <description><![CDATA[arXiv:2411.09874v1 公告类型：新
摘要：脑电图 (EEG) 在各种神经系统疾病的诊断中起着至关重要的作用。然而，小型医院和诊所通常缺乏先进的 EEG 信号分析系统，在手动 EEG 读取中容易出现误解。本研究提出了一种创新的混合人工智能 (AI) 系统，用于自动解释 EEG 背景活动并生成报告。该系统结合了用于后部优势节律 (PDR) 预测的深度学习模型、无监督伪影去除和用于异常检测的专家设计的算法。对于 PDR 预测，使用了 1530 个标记的 EEG，最佳集成模型实现了 0.237 的平均绝对误差 (MAE)、0.359 的均方根误差 (RMSE)、0.6Hz 误差内的 91.8% 的准确率以及 1.2Hz 误差内的 99% 的准确率。 AI 系统在检测普遍性背景减慢方面的表现明显优于神经科医生（p = 0.02；F1：AI 0.93，神经科医生 0.82），并且表现出局部异常检测的改善，尽管统计上并不显着（p = 0.79；F1：AI 0.71，神经科医生 0.55）。在内部数据集和天普大学异常脑电图语料库上的验证均显示出一致的性能（F1：分别为 0.884 和 0.835；p = 0.66），证明了其普遍性。使用大型语言模型 (LLM) 生成报告的准确率达到 100%，这已由另外三个独立的 LLM 验证。这种混合 AI 系统为资源有限的环境中的脑电图解释提供了一种易于扩展且准确的解决方案，可帮助神经科医生提高诊断准确性并降低误诊率。]]></description>
      <guid>https://arxiv.org/abs/2411.09874</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AMXFP4：使用非对称微尺度浮点来驯服激活异常值，以实现 4 位 LLM 推理</title>
      <link>https://arxiv.org/abs/2411.09909</link>
      <description><![CDATA[arXiv:2411.09909v1 公告类型：新
摘要：扩展具有扩展上下文长度的大型语言模型 (LLM) 增加了对高效低位量化的需求，以管理其大量的计算需求。但是，由于激活异常值，将精度降低到 4 位通常会降低性能。为了解决这个问题，我们提出了非对称微缩放 4 位浮点 (AMXFP4) 以实现高效的 LLM 推理。这种新颖的数据格式利用非对称共享尺度来缓解异常值，同时自然地捕获分组量化引入的不对称性。与依赖数据旋转和昂贵校准的传统 4 位量化方法不同，AMXFP4 使用非对称共享尺度进行直接 4 位转换，在各种 LLM 任务中实现近乎理想的量化精度，包括多轮对话、长上下文推理和视觉问答。我们的 AMXFP4 格式明显优于 MXFP4 和其他领先的量化技术，可实现稳健、无校准的 4 位推理。]]></description>
      <guid>https://arxiv.org/abs/2411.09909</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图的因果关系复杂性实证插件</title>
      <link>https://arxiv.org/abs/2411.10008</link>
      <description><![CDATA[arXiv:2411.10008v1 公告类型：新
摘要：本文重点研究了计算因果关系查询的经验插件估计的计算复杂性。给定因果图和观测数据，任何可识别的因果查询都可以根据观察到的变量的表达式来估计，称为估计量。然后可以通过插入从数据中经验计算出的概率来评估估计量。与传统观点相反，传统观点认为高维概率函数将导致估计量的评估时间呈指数增长。我们表明，计算可以高效完成，可能在数据大小的线性时间内完成，具体取决于估计量的超图。
具体而言，我们表明，估计量结构的树宽和超树宽度都限制了插件估计量的评估复杂性，类似于它们在图模型中概率推理的复杂性中的作用。通常，超树宽度提供更有效的界限，因为经验分布是稀疏的。]]></description>
      <guid>https://arxiv.org/abs/2411.10008</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>芯片已启航：对芯片设计人工智能毫无根据的怀疑论的批判</title>
      <link>https://arxiv.org/abs/2411.10053</link>
      <description><![CDATA[arXiv:2411.10053v1 公告类型：新
摘要：2020 年，我们推出了一种能够生成超人芯片布局的深度强化学习方法，随后我们在《自然》杂志上发表了该方法并在 GitHub 上开源。AlphaChip 激发了芯片设计 AI 方面的大量工作，并已在 Alphabet 最先进的芯片中部署，并由外部芯片制造商扩展。即便如此，ISPD 2023 上的一篇未经同行评审的受邀论文质疑了它的性能声明，尽管它未能按照《自然》杂志中描述的方式运行我们的方法。例如，它没有预先训练 RL 方法（消除了从先前经验中学习的能力），使用的计算资源大大减少（RL 经验收集器减少了 20 倍，GPU 数量减少了一半），没有训练到收敛（机器学习的标准做法），并且对不代表现代芯片的测试用例进行了评估。最近，Igor Markov 发表了对三篇论文的荟萃分析：我们经过同行评审的《自然》论文、未经同行评审的 ISPD 论文以及 Markov 自己未发表的论文（尽管他没有透露他是该论文的合著者）。尽管 AlphaChip 已经获得广泛采用和影响，但我们还是发表了此回应，以确保没有人会因为错误而放弃在这个影响深远的领域进行创新。]]></description>
      <guid>https://arxiv.org/abs/2411.10053</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过即时学习和聚合实现联邦域泛化</title>
      <link>https://arxiv.org/abs/2411.10063</link>
      <description><![CDATA[arXiv:2411.10063v1 公告类型：新
摘要：联邦域泛化 (FedDG) 旨在通过解决隐私保护约束下的数据异质性来改进看不见的域中的全局模型泛化。现有 FedDG 研究中的一种常见策略涉及在客户端之间共享特定领域的知识，例如频谱信息、类原型和数据样式。但是，这些知识是直接从本地客户端样本中提取的，共享此类敏感信息会带来数据泄露的潜在风险，这可能无法完全满足 FedDG 的要求。在本文中，我们引入了提示学习以适应 FedDG 场景中的预训练视觉语言模型 (VLM)，并利用本地学习的提示作为更安全的桥梁来促进客户端之间的知识转移。具体而言，我们通过提示学习和聚合 (PLAN) 提出了一种新颖的 FedDG 框架，它包括两个训练阶段，以在每个联邦回合中协作生成本地提示和全局提示。首先，每个客户端使用自己的数据执行文本和视觉提示学习，并将全局提示视为共同参考，从而间接同步本地提示。其次，所有特定领域的本地提示在客户端之间交换，并使用基于注意力机制的轻量级聚合器选择性地聚合到全局提示中。最终应用全局提示来使 VLM 适应未知目标域。由于我们的 PLAN 框架只需要训练有限数量的提示和轻量级聚合器，因此它在 FedDG 的计算和通信效率方面具有显著优势。大量实验证明了 PLAN 在四个基准数据集上的卓越泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2411.10063</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将生物 SSVEP 反应适应于人工神经网络</title>
      <link>https://arxiv.org/abs/2411.10084</link>
      <description><![CDATA[arXiv:2411.10084v1 公告类型：新
摘要：神经元重要性评估对于理解人工神经网络 (ANN) 的内部工作原理以及提高其可解释性和效率至关重要。本文介绍了一种受神经科学技术频率标记启发的神经元重要性评估新方法。通过对图像输入应用正弦对比度调制并分析由此产生的神经元激活，该方法能够对网络的决策过程进行细粒度分析。使用卷积神经网络进行图像分类的实验表明，在基于部分的频率标记下，神经元特定响应中存在显着的谐波和互调。这些发现表明，ANN 在调整闪烁频率时表现出类似于生物大脑的行为，从而为通过频率标记进行神经元/过滤器重要性评估开辟了途径。所提出的方法有望应用于网络修剪和模型可解释性，有助于可解释人工智能的发展并解决神经网络缺乏透明度的问题。未来的研究方向包括开发新的损失函数，以鼓励 ANN 中生物学上合理的行为。]]></description>
      <guid>https://arxiv.org/abs/2411.10084</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>1000 人的生成代理模拟</title>
      <link>https://arxiv.org/abs/2411.10109</link>
      <description><![CDATA[arXiv:2411.10109v1 公告类型：新
摘要：人类行为模拟的前景——跨领域复制人类行为的通用计算代理——可以广泛应用于政策制定和社会科学。我们提出了一种新颖的代理架构，可以模拟 1,052 个真实个体的态度和行为——将大型语言模型应用于有关他们生活的定性访谈，然后测量这些代理如何很好地复制他们所代表的个体的态度和行为。生成代理复制参与者在综合社会调查中的回答的准确率是参与者两周后复制自己答案的 85%，并且在预测实验复制中的性格特征和结果方面表现相当。与给定人口统计描述的代理相比，我们的架构减少了跨种族和意识形态群体的准确性偏差。这项工作为有助于调查个人和集体行为的新工具奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.10109</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仅注意的 Transformer 中的记忆</title>
      <link>https://arxiv.org/abs/2411.10115</link>
      <description><![CDATA[arXiv:2411.10115v1 公告类型：新
摘要：最近的研究探索了多头注意力的记忆能力，但这些发现受到上下文大小不切实际的限制。我们提出了一种基于语言的 Transformers 的新证明，将当前假设扩展到任何上下文大小。我们的方法通过使用注意力层实现更有效的精确记忆，同时引入了分布近似记忆的概念，从而改进了最先进的方法。通过实验验证，我们证明我们提出的界限更准确地反映了语言模型的真实记忆能力，并与以前的工作进行了精确的比较。]]></description>
      <guid>https://arxiv.org/abs/2411.10115</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻仅解码器 Transformer 架构中的谄媚行为：合成数据干预</title>
      <link>https://arxiv.org/abs/2411.10156</link>
      <description><![CDATA[arXiv:2411.10156v1 Announce Type: new 
摘要：针对大型语言模型中强化学习从人类反馈中得出的谄媚现象问题，本研究将合成数据干预技术应用于仅解码器的Transformer架构。基于现有文献中的研究空白，研究者设计了通过生成多样化数据来降低模型迎合倾向的实验流程，并使用GPT4o作为实验工具进行验证。实验使用了100道真假题，对比了合成数据干预训练的模型与原始未训练模型在多个指标上的表现。结果表明，SDI训练模型在准确率和谄媚率方面支持该技术，在减少谄媚现象方面具有显著的效果。值得注意的是，数据集、实验流程、代码和数据结果已上传至Github，链接为https://github.com/brucewang123456789/GeniusTrail.git。]]></description>
      <guid>https://arxiv.org/abs/2411.10156</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估“宪法”在从人工智能反馈中学习中的作用</title>
      <link>https://arxiv.org/abs/2411.10168</link>
      <description><![CDATA[arXiv:2411.10168v1 公告类型：新
摘要：大型语言模型 (LLM) 的功能不断增强，已导致它们被用作人类反馈的替代品，用于训练和评估其他 LLM。这些方法通常依赖于“宪法”，即批评模型用来提供反馈和改进生成的书面指南。我们通过使用四种不同的宪法来改善以患者为中心的医疗访谈沟通，研究宪法的选择如何影响反馈质量。在 215 名人类评分员进行的成对比较中，我们发现详细的宪法在情感品质方面取得了更好的结果。然而，在学习与信息收集和提供相关的更注重实践的技能方面，没有一种宪法比基线表现更好。我们的研究结果表明，虽然应该优先考虑详细的宪法，但在某些领域，人工智能反馈作为奖励信号的有效性可能受到限制。]]></description>
      <guid>https://arxiv.org/abs/2411.10168</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>新兴传播的语义与空间性</title>
      <link>https://arxiv.org/abs/2411.10173</link>
      <description><![CDATA[arXiv:2411.10173v1 公告类型：新
摘要：当人工智能体通过通信渠道联合训练执行协作任务时，它们会开发出不透明的面向目标的通信协议。良好的任务表现通常被认为是有意义的交流正在进行的充分证据，但现有的实证结果表明，共同目标引发的沟通策略在几乎完美地解决任务的同时，可能违反直觉。在这项工作中，我们确定了有意义的交流的目标无关先决条件，我们称之为语义一致性，基于消息在不同实例之间应该具有相似含义的想法。我们为这个想法提供了一个正式的定义，并用它来比较新兴通信领域最常见的两个目标：歧视和重建。我们在温和的假设下证明，语义不一致的通信协议可以是歧视任务的最佳解决方案，但不是重建的最佳解决方案。我们进一步表明，重建目标鼓励更严格的属性，即空间意义，这也考虑了消息之间的距离。新兴通信游戏的实验验证了我们的理论结果。这些发现证明了基于距离的沟通目标的固有优势，并将先前的经验发现具体化。]]></description>
      <guid>https://arxiv.org/abs/2411.10173</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让人们失败！探索可解释的虚拟和机器人代理在边做边学任务中的影响</title>
      <link>https://arxiv.org/abs/2411.10176</link>
      <description><![CDATA[arXiv:2411.10176v1 公告类型：新
摘要：与人工智能 (AI) 代理进行协作决策带来了机遇和挑战。虽然人类与人工智能的表现往往超过个人，但这种技术对人类行为的影响仍未得到充分理解，主要是当人工智能代理能够为其建议提供合理的解释时。本研究比较了经典解释与伙伴感知解释对人类在边学边做任务中的行为和表现的影响。参与者分为三组：一组与计算机交互，另一组与人形机器人交互，第三组没有协助。结果表明，伙伴感知解释对参与者的影响因所涉及的人工智能代理类型而异。有了计算机，参与者缩短了任务完成时间。同时，与人形机器人互动的人更倾向于遵循其建议，尽管他们并没有减少时间。有趣的是，自主执行边学边做任务的参与者表现出比可解释人工智能 (XAI) 协助的参与者更出色的知识获取能力。这些发现提出了深刻的问题，对自动辅导和人机协作具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2411.10176</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>供应链中的代理法学硕士：面向自主多代理共识寻求</title>
      <link>https://arxiv.org/abs/2411.10184</link>
      <description><![CDATA[arXiv:2411.10184v1 公告类型：新
摘要：本文探讨了大型语言模型 (LLM) 如何自动寻求供应链管理 (SCM) 中的共识，在供应链管理中，库存水平和交货时间等问题的频繁决策需要公司之间的协调。传统的 SCM 依靠人类的共识来决策，以避免出现牛鞭效应等突发问题。一些常规的共识流程，特别是那些耗时且成本高昂的流程，可以实现自动化。现有的自动协调解决方案面临挑战，因为高进入门槛将中小企业拒之门外，能力有限，在复杂情况下的适应性有限。然而，生成式人工智能的最新进展，尤其是 LLM，显示出克服这些障碍的希望。在大量数据集上训练的 LLM 可以协商、推理和计划，以最小的进入门槛促进大规模接近人类水平的共识。在这项工作中，我们确定了现有方法的主要局限性，并提出了自主的 LLM 代理来解决这些差距。我们引入了一系列专为 LLM 代理量身定制的、针对供应链的新型共识寻求框架，并通过库存管理案例研究验证了我们方法的有效性。为了加速 SCM 社区的进步，我们开放了我们的代码，为 LLM 驱动的自主供应链解决方案的进一步发展奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.10184</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不一致知识推理的逻辑——使用当今术语的表述 (2024)</title>
      <link>https://arxiv.org/abs/2411.10197</link>
      <description><![CDATA[arXiv:2411.10197v1 公告类型：新
摘要：在许多情况下，人类必须用不一致的知识进行推理。这些不一致可能是由于信息来源不完全可靠而发生的。为了用不一致的知识进行推理，不可能像在谓词逻辑中那样将一组前提视为绝对真理。然而，将前提集视为一组假设，就可以从一组不一致的前提中推导出有用的结论。本文描述了一种用不一致知识进行推理的逻辑。这种逻辑是 N. Rescher [15] 工作的概括。在逻辑中，可靠性关系用于在不相容的假设之间进行选择。只有在得出矛盾时才会做出这些选择。只要没有得出矛盾，知识就被认为是一致的。这使得为逻辑定义基于论证的推理过程成为可能。对于该逻辑，基于 Y. Shoham [22, 23] 的思想定义了一种语义。事实证明，根据 S. Kraus、D. Lehmann 和 M. Magidor [12] 的定义，该逻辑的语义是一种优先语义。因此，该逻辑是系统 P 的逻辑，具有理想非单调逻辑的所有属性。]]></description>
      <guid>https://arxiv.org/abs/2411.10197</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>儿科超声心动图的人工智能：利用可解释人工智能和联邦学习探索挑战、机遇和临床应用</title>
      <link>https://arxiv.org/abs/2411.10255</link>
      <description><![CDATA[arXiv:2411.10255v1 公告类型：新
摘要：儿童心脏病包括广泛的先天性和后天性疾病。更复杂的先天性畸形需要差异化和多模式决策过程，通常包括超声心动图作为中心成像方法。人工智能 (AI) 通过促进儿科超声心动图数据的自动解释，为临床医生带来了巨大的希望。然而，将 AI 技术应用于儿科超声心动图分析面临着公共数据可用性有限、数据隐私和 AI 模型透明度等挑战。最近，研究人员专注于颠覆性技术，例如联邦学习 (FL) 和可解释 AI (XAI)，以改进自动诊断和决策支持工作流程。本研究全面概述了 AI 在儿科超声心动图方面的局限性和机遇，强调了 XAI 和 FL 的协同工作流程和作用，确定了研究空白，并探索了未来的潜在发展。此外，三个相关的临床用例展示了 XAI 和 FL 的功能，重点是 (i) 视图识别、(ii) 疾病分类、(iii) 心脏结构分割和 (iv) 心脏功能的定量评估。]]></description>
      <guid>https://arxiv.org/abs/2411.10255</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模型剪枝后训练后的缩放法则</title>
      <link>https://arxiv.org/abs/2411.10272</link>
      <description><![CDATA[arXiv:2411.10272v1 公告类型：新 
摘要：基于 Transformer 架构的大型语言模型 (LLM) 广泛应用于各个领域和任务。然而，它们不断增加的规模对硬件提出了很高的要求，限制了实际部署。为了缓解这种情况，已经开发了模型修剪技术来创建更高效​​的模型，同时保持高性能。尽管如此，修剪后的后训练对于性能恢复至关重要，并且可能耗费大量资源。本文研究了修剪后的 LLM 的后训练要求，并引入了一种缩放定律来确定最佳的后训练数据量。使用深度修剪、宽度修剪和 2:4 半结构化修剪对 Llama-3 和 Qwen-2.5 系列模型进行训练后实验，结果表明，更高的修剪率需要更多的后训练数据来恢复性能，而更大的 LLM 则需要更少的数据。所提出的缩放定律根据模型在修剪前后的参数数量以及训练后的标记数量来预测模型的损失。此外，我们发现从较小的 LLM 建立的缩放定律可以可靠地推广到较大的 LLM。这项工作为修剪后的 LLM 的训练后提供了宝贵的见解，并提供了一种实用的缩放定律来优化训练后的数据使用。]]></description>
      <guid>https://arxiv.org/abs/2411.10272</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GUI 代理的曙光：使用 Claude 3.5 进行初步案例研究 计算机使用</title>
      <link>https://arxiv.org/abs/2411.10323</link>
      <description><![CDATA[arXiv:2411.10323v1 公告类型：新
摘要：最近发布的模型 Claude 3.5 Computer Use 是第一个在公共测试版中提供计算机使用作为图形用户界面 (GUI) 代理的前沿 AI 模型。作为早期测试版，它在现实世界复杂环境中的能力仍然未知。在这个探索 Claude 3.5 Computer Use 的案例研究中，我们策划和组织了一系列精心设计的任务，涵盖各种领域和软件。从这些案例中观察到，Claude 3.5 Computer Use 在端到端语言到桌面操作方面具有前所未有的能力。除了这项研究之外，我们还提供了一个开箱即用的代理框架，用于轻松部署基于 API 的 GUI 自动化模型。我们的案例研究旨在通过详细的分析展示 Claude 3.5 Computer Use 的能力和局限性的基础，并提出有关规划、行动和批评的问题，这些问题必须考虑在未来的改进中。我们希望这一初步探索能够启发 GUI 代理社区未来的研究。本文中的所有测试用例都可以通过该项目进行尝试：https://github.com/showlab/computer_use_ootb。]]></description>
      <guid>https://arxiv.org/abs/2411.10323</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>形成辅助高置信度实例级损失以促进从标签比例进行学习</title>
      <link>https://arxiv.org/abs/2411.10364</link>
      <description><![CDATA[arXiv:2411.10364v1 公告类型：新
摘要：从标签比例学习 (LLP) 是一项具有挑战性的弱监督学习任务，旨在通过使用实例袋和袋内类别的比例来训练分类器，而不是每个实例的注释标签。除了传统的袋级损失之外，LLP 的主流方法是将辅助实例级损失与由预测形成的伪标签结合起来。不幸的是，我们通过经验观察到伪标签通常由于过度平滑而不准确，尤其是在袋子尺寸较大的场景中，这会损害分类器感应。为了缓解这个问题，我们提出了一种新颖的 LLP 方法，即从标签比例学习辅助高置信度实例级损失 (L^2P-AHIL)。具体来说，我们提出了一种基于对偶熵的权重 (DEW) 方法来自适应地测量伪标签的置信度。它同时强调在包级上的准确预测，并避免过度平滑的预测。然后，我们用 DEW 形成高置信度的实例级损失，并以自训练的方式将其与包级损失联合优化。基准数据集上的实验结果表明，L^2P-AHIL 可以超越现有的基线方法，并且随着包大小的增加，性能增益会更加显著。]]></description>
      <guid>https://arxiv.org/abs/2411.10364</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用联合条件扩散模型缓解电力系统 WECC 复合负荷模型的参数退化</title>
      <link>https://arxiv.org/abs/2411.10431</link>
      <description><![CDATA[arXiv:2411.10431v1 公告类型：新
摘要：近年来，数据驱动的动态系统建模受到了广泛关注。它的逆公式，参数估计，旨在从观测中推断固有的模型参数。然而，参数退化，即不同的参数组合产生相同的可观测输出，对准确和唯一地识别模型参数构成了关键障碍。在电力系统 WECC 复合负荷模型 (CLM) 的背景下，公用事业从业者已经观察到，为一个故障事件精心选择的 CLM 参数在另一个故障中可能无法令人满意地发挥作用。在这里，我们创新了一种基于联合条件扩散模型的逆问题求解器 (JCDI)，它结合了联合条件架构和多事件观测的同时输入，以提高参数的通用性。对 WECC CLM 的模拟研究表明，提出的 JCDI 有效地降低了退化参数的不确定性，因此与单事件学习方案相比，参数估计误差降低了 42.1%。这使得该模型能够以高精度预测不同故障事件（包括电子负载跳闸和电机停转）下的功率轨迹，优于标准深度强化学习和监督学习方法。我们预计这项工作将有助于缓解系统动力学中的参数退化，为各个科学领域提供通用的参数估计框架。]]></description>
      <guid>https://arxiv.org/abs/2411.10431</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过网络取证审查人类足迹和步态进行个人身份识别</title>
      <link>https://arxiv.org/abs/2204.09344</link>
      <description><![CDATA[arXiv:2204.09344v1 公告类型：交叉 
摘要：人类足迹具有一组独特的脊线，是其他人类无法比拟的，因此可用于不同的身份证件，例如出生证明、印度生物识别系统 AADHAR 卡、驾驶执照、PAN 卡和护照。在犯罪现场，被告必须走动并留下鞋印和赤脚印，因此，恢复足迹对于识别罪犯至关重要。基于足迹的生物识别是一种相当新的个人识别技术。指纹、视网膜、虹膜和人脸识别是记录个人出勤情况最有用的方法。这一次，世界正面临全球恐怖主义问题。识别恐怖分子是一项挑战，因为他们的生活与公民一样正常。他们的软目标包括国防、硅和纳米技术芯片制造单位、制药业等特殊利益行业。他们假装自己是宗教人士，因此寺庙和其他圣地，甚至市场都是他们的目标。这些地方可以快速获得他们的足迹。步态本身足以预测嫌疑人的行为。本研究旨在确定足迹和步态作为个人识别的替代方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2204.09344</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>