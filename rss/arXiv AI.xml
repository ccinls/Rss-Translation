<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>KnowWhereGraph 本体</title>
      <link>https://arxiv.org/abs/2410.13948</link>
      <description><![CDATA[arXiv:2410.13948v1 公告类型：新
摘要：KnowWhereGraph 是最大的完全公开可用的地理空间知识图谱之一。它包括 30 个层级的数据，涉及自然灾害（例如飓风、野火）、气候变量（例如气温、降水）、土壤特性、作物和土地覆盖类型、人口统计和人类健康、各种地点和地区标识符等主题。各种应用程序通过图表利用这些数据来应对粮食安全和农业供应链中的挑战；与土壤保护实践和农场劳动力相关的可持续性；以及灾难发生后提供紧急人道主义援助。在本文中，我们介绍了作为 KnowWhereGraph 模式的本体。这个广泛的概述提供了对图表及其模式的要求和设计规范的深入了解，包括开发方法（模块化本体建模）和用于实现、实现和部署 KnowWhereGraph 及其最终用户界面和公共查询 SPARQL 端点的资源。]]></description>
      <guid>https://arxiv.org/abs/2410.13948</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从开放式对话中推断目标</title>
      <link>https://arxiv.org/abs/2410.13957</link>
      <description><![CDATA[arXiv:2410.13957v1 公告类型：新
摘要：我们提出了一种在线方法，让具身代理学习并实现不同的用户目标。虽然像 RLHF 这样的离线方法可以表示各种目标，但需要大量数据集，但我们的方法实现了类似的灵活性和在线效率。我们从与大型语言模型 (LLM) 的对话中提取自然语言目标表示。我们提示 LLM 扮演具有不同目标的人类，并使用相应的可能性对潜在目标进行贝叶斯推理。因此，我们的方法可以根据不受限制的对话来表示复杂目标的不确定性。我们分别使用基于文本的界面和 AI2Thor 模拟在杂货店购物和家用机器人辅助领域评估我们的方法。结果表明，我们的方法优于缺乏明确目标表示或概率推理的消融基线。]]></description>
      <guid>https://arxiv.org/abs/2410.13957</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CausalChat：使用大型语言模型进行交互式因果模型开发和改进</title>
      <link>https://arxiv.org/abs/2410.14146</link>
      <description><![CDATA[arXiv:2410.14146v1 公告类型：新
摘要：因果网络在许多领域被广泛用于建模变量之间的复杂关系。最近的一种方法试图通过人类的集体参与，利用群体智慧来构建因果网络。虽然这可以产生能够很好地模拟潜在现象的详细因果网络，但它需要大量具有领域理解能力的个体。我们采用了一种不同的方法：利用大型语言模型（例如 OpenAI 的 GPT-4）通过吸收大量文献学到的因果知识。在一个名为 CausalChat 的专用可视化分析界面中，用户可以递归地探索单个变量或变量对以识别因果关系、潜在变量、混杂因素和中介因素，通过对话构建详细的因果网络。每个探测交互都被转换成定制的 GPT-4 提示，并通过与生成的文本链接的视觉表示来传达响应以进行解释。我们展示了 CausalChat 在不同数据环境中的功能，并开展了涉及领域专家和外行人员的用户研究。]]></description>
      <guid>https://arxiv.org/abs/2410.14146</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行事件解构，以增强基于多模态方面的情绪分析</title>
      <link>https://arxiv.org/abs/2410.14150</link>
      <description><![CDATA[arXiv:2410.14150v1 Announce Type: new 
摘要：随着互联网的快速发展，用户生成内容的丰富度不断提升，多模态方面情感分析（MABSA）成为研究热点。现有研究在MABSA方面取得了一定的成果，但并未有效解决多实体和多情感共存场景下的分析挑战。本文创新性地引入大型语言模型（LLM）进行事件分解，提出了一种基于强化学习的多模态方面情感分析（MABSA-RL）框架。该框架利用LLM将原文分解为事件集，降低分析复杂度，引入强化学习优化模型参数。实验结果表明，MABSA-RL在两个基准数据集上优于现有的先进方法。本文为多模态方面情感分析提供了一种新的研究视角和方法。]]></description>
      <guid>https://arxiv.org/abs/2410.14150</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能的正式解释</title>
      <link>https://arxiv.org/abs/2410.14219</link>
      <description><![CDATA[arXiv:2410.14219v1 公告类型：新
摘要：尽管人工智能 (AI) 在实践中取得了成功，但当前的神经 AI 算法面临两个重大问题。首先，神经架构做出的决策往往容易产生偏见和脆弱性。其次，当需要一系列推理时，神经系统通常表现不佳。神经符号人工智能是一种很有前途的方法，它通过结合神经感知和符号推理的力量来解决这些（和其他）弱点。同时，人工智能的成功使得理解其行为变得至关重要，从而导致了可解释人工智能 (XAI) 的发展。虽然神经符号 AI 系统比纯神经 AI 具有重要优势，但我们仍然需要解释它们的行为，而这些行为被神经和符号成分的相互作用所掩盖。为了解决这个问题，本文提出了一种解释神经符号系统决策的形式化方法。该方法取决于使用正式的溯因解释和分层解决神经符号可解释性问题。也就是说，它首先计算系统的符号组件的形式解释，用于识别需要解释的神经信息各个部分的子集。然后，仅解释那些彼此独立的单个神经输入，这有助于简化分层形式解释，并有助于提高该方法的整体性能。一些复杂推理任务的实验结果表明，与纯神经系统相比，从解释大小、解释时间、训练时间、模型大小和报告的解释质量来看，所提出的方法具有实际效率。]]></description>
      <guid>https://arxiv.org/abs/2410.14219</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多智能体模拟合成法学硕士 (LLM) 的训练后数据</title>
      <link>https://arxiv.org/abs/2410.14251</link>
      <description><![CDATA[arXiv:2410.14251v1 公告类型：新
摘要：后期训练对于使大型语言模型 (LLM) 遵循人类指令至关重要。受到最近使用 LLM 模拟人类社会的成功启发，我们利用多智能体模拟自动生成各种基于文本的场景，捕捉广泛的现实世界人类需求。我们提出了 MATRIX，这是一个可以创建逼真且可扩展场景的多智能体模拟器。利用这些输出，我们引入了一种新颖的场景驱动指令生成器 MATRIX-Gen，用于可控且高度逼真的数据合成。大量实验表明，我们的框架可以有效地生成通用数据和特定领域的数据。值得注意的是，在 AlpacaEval 2 和 Arena-Hard 基准测试中，使用 MATRIX-Gen 合成的数据集（仅 20K 个指令-响应对）进行后训练的 Llama-3-8B-Base 表现优于使用超过 1000 万个指令-响应对进行训练的 Meta 的 Llama-3-8B-Instruct 模型；请参阅我们的项目 https://github.com/ShuoTang123/MATRIX-Gen。]]></description>
      <guid>https://arxiv.org/abs/2410.14251</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Nova：一种迭代规划和搜索方法，用于增强 LLM 生成想法的新颖性和多样性</title>
      <link>https://arxiv.org/abs/2410.14255</link>
      <description><![CDATA[arXiv:2410.14255v1 公告类型：新
摘要：科学创新对人类至关重要，利用大型语言模型 (LLM) 来产生研究想法可以改变发现。然而，现有的 LLM 通常会产生过于简单和重复的建议，因为它们在获取创新外部知识方面的能力有限。为了解决这个问题，我们引入了一种增强的规划和搜索方法，旨在提高基于 LLM 的系统的创造潜力。我们的方法涉及一个迭代过程，有目的地规划外部知识的检索，逐步丰富想法的生成，提供更广泛和更深入的见解。通过自动和人工评估的验证表明，我们的框架大大提高了生成想法的质量，特别是在新颖性和多样性方面。我们的框架产生的独特新颖想法的数量是没有它的 3.4 倍。此外，我们的方法优于目前最先进的方法，在瑞士锦标赛评估中，基于 170 篇种子论​​文产生的顶级想法至少多 2.5 倍。]]></description>
      <guid>https://arxiv.org/abs/2410.14255</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoMAL：用于混合自主交通的协作多智能体大型语言模型</title>
      <link>https://arxiv.org/abs/2410.14368</link>
      <description><![CDATA[arXiv:2410.14368v1 公告类型：新
摘要：自动驾驶汽车融入城市交通，通过减少拥堵和系统地优化交通流量，具有提高效率的巨大潜力。在本文中，我们介绍了 CoMAL（协作多智能体 LLM），这是一个旨在通过自动驾驶汽车之间的协作来优化交通流量，解决混合自动驾驶交通问题的框架。CoMAL 建立在大型语言模型之上，在交互式交通模拟环境中运行。它利用感知模块来观察周围的智能体，利用记忆模块来存储每个智能体的策略。整体工作流程包括一个协作模块，鼓励自动驾驶汽车讨论有效策略并分配角色，一个推理引擎，根据分配的角色确定最佳行为，以及一个执行模块，使用结合基于规则的模型的混合方法控制车辆动作。实验结果表明，CoMAL 在 Flow 基准上取得了优异的表现。此外，我们评估了不同语言模型的影响，并将我们的框架与强化学习方法进行了比较。它突出了 LLM 代理的强大协作能力，并提出了一种有希望的混合自治交通挑战解决方案。代码可在 https://github.com/Hyan-Yao/CoMAL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.14368</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的端到端神经符号强化学习代理</title>
      <link>https://arxiv.org/abs/2410.14371</link>
      <description><![CDATA[arXiv:2410.14371v1 公告类型：新
摘要：深度强化学习 (RL) 代理依赖于捷径学习，这阻止了它们推广到略有不同的环境。为了解决这个问题，已经开发了使用以对象为中心的状态的符号方法。但是，将这些方法与深度代理进行比较并不公平，因为后者是从原始像素状态开始操作的。在这项工作中，我们实例化了符号 SCoBots 框架。SCoBots 将 RL 任务分解为中间的、可解释的表示，最终基于一组可理解的以对象为中心的关系概念做出行动决策。这种架构有助于揭开代理决策的神秘面纱。通过明确学习从原始状态、以对象为中心的 RL 和通过规则提取的策略提炼中提取以对象为中心的表示，这项工作将自己置于神经符号 AI 范式中，将神经网络的优势与符号 AI 相结合。我们展示了端到端训练的 SCoBot 的第一个实现，并在不同的 Atari 游戏中分别评估其组件。结果证明了该框架创建可解释和执行的 RL 系统的潜力，并为未来获得端到端可解释的 RL 代理的研究方向铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14371</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当 LLM 遵循指示时，他们内心是否“知道”？</title>
      <link>https://arxiv.org/abs/2410.14516</link>
      <description><![CDATA[arXiv:2410.14516v1 公告类型：新
摘要：指令遵循对于使用大型语言模型 (LLM) 构建 AI 代理至关重要，因为这些模型必须严格遵守用户提供的约束和指南。然而，LLM 往往无法遵循简单而明确的指令。为了改善指令遵循行为并防止不良输出，需要更深入地了解 LLM 的内部状态与这些结果的关系。我们对 LLM 内部状态的分析揭示了输入嵌入空间中与成功遵循指令相关的维度。我们证明，与随机更改相比，沿此维度修改表示可以提高指令遵循的成功率，而不会影响响应质量。进一步的调查显示，这个维度与提示的措辞更密切相关，而不是任务或指令的固有难度。这一发现还解释了为什么 LLM 有时无法遵循明确的指令，以及为什么即使内容基本保持不变，提示工程也往往有效。这项工作深入了解了法学硕士 (LLM) 遵循指令的内部运作，为可靠的法学硕士 (LLM) 代理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14516</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LTLf 中责任归因和预期的计算基础</title>
      <link>https://arxiv.org/abs/2410.14544</link>
      <description><![CDATA[arXiv:2410.14544v1 公告类型：新
摘要：责任是机器伦理和自主系统领域的关键概念之一。它是一个多方面的概念，涉及对行动和策略的反事实推理。在本文中，我们基于 LTLf 研究战略环境中的不同责任变体。我们展示了与反应合成中的概念的联系，包括获胜、主导和尽力而为策略的综合。这种联系为责任的计算基础提供了基础，包括复杂性特征以及用于归因和预测责任的合理、完整和最佳算法。]]></description>
      <guid>https://arxiv.org/abs/2410.14544</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransBox: EL++封闭的本体嵌入</title>
      <link>https://arxiv.org/abs/2410.14571</link>
      <description><![CDATA[arXiv:2410.14571v1 公告类型：新
摘要：OWL（Web 本体语言）本体能够将关系和类型事实表示为标准知识图谱，将复杂领域知识表示为描述逻辑（DL）公理，广泛应用于医疗保健和生物信息学等领域。受知识图谱嵌入成功的启发，嵌入 OWL 本体近年来引起了广泛关注。当前的方法主要侧重于学习原子概念和角色的嵌入，通过专门设计的评分函数实现基于规范化公理的评估。然而，它们往往忽略了复杂概念的嵌入，使得用更复杂的公理进行推断变得困难。这种限制降低了它们在高级推理任务（如本体学习和本体介导的查询回答）中的有效性。在本文中，我们提出了 EL++ 封闭本体嵌入，它能够通过组合在 DL 中表示任何逻辑表达式。此外，我们开发了 TransBox，这是一种有效的 EL++ 封闭本体嵌入方法，可以处理多对一、一对多和多对多关系。我们大量的实验表明，TransBox 通常在各种现实世界数据集中实现最佳性能，用于预测复杂的公理。]]></description>
      <guid>https://arxiv.org/abs/2410.14571</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能很好地估计指令遵循中的不确定性吗？</title>
      <link>https://arxiv.org/abs/2410.14582</link>
      <description><![CDATA[arXiv:2410.14582v1 公告类型：新
摘要：大型语言模型 (LLM) 可以成为各个领域的有价值的个人 AI 代理，前提是它们能够精确地遵循用户指令。然而，最近的研究表明 LLM 的指令遵循能力存在很大局限性，这引发了人们对其在高风险应用中的可靠性的担忧。准确评估 LLM 在遵守指令方面的不确定性对于降低部署风险至关重要。据我们所知，我们首次系统地评估了 LLM 在指令遵循方面的不确定性估计能力。我们的研究确定了现有指令遵循基准的主要挑战，其中多种因素与来自指令遵循的不确定性纠缠在一起，使方法和模型之间的隔离和比较变得复杂。为了解决这些问题，我们引入了一个受控评估设置，其中包含两个基准版本的数据，从而能够全面比较各种条件下的不确定性估计方法。我们的研究结果表明，现有的不确定性方法很难，尤其是当模型在指令遵循中出现细微错误时。虽然内部模型状态提供了一些改进，但它们在更复杂的场景中仍然不足。我们从受控评估设置中获得的见解为理解 LLM 的局限性和在指令跟随任务中不确定性估计的潜力提供了关键的理解，为更值得信赖的 AI 代理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14582</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MCSFF：用于实体对齐的多模态一致性和特异性融合框架</title>
      <link>https://arxiv.org/abs/2410.14584</link>
      <description><![CDATA[arXiv:2410.14584v1 公告类型：新
摘要：多模态实体对齐 (MMEA) 对于增强知识图谱和改进信息检索和问答系统至关重要。现有方法通常侧重于通过模态的互补性来整合模态，但忽略了每种模态的特殊性，这可能会掩盖关键特征并降低对齐准确性。为了解决这个问题，我们提出了多模态一致性和特异性融合框架 (MCSFF)，它创新地整合了模态的互补性和特异性方面。我们利用 Scale Computing 的超融合基础设施来优化大规模数据处理中的 IT 管理和资源分配。我们的框架首先使用模态嵌入计算每种模态的相似度矩阵以保留其独特特征。然后，迭代更新方法对模态特征进行去噪和增强，以充分表达关键信息。最后，我们整合来自所有模态的更新信息，以创建丰富而精确的实体表示。实验表明，我们的方法在 MMKG 数据集上的表现优于当前最先进的 MMEA 基线，证明了其有效性和实用潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.14584</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联想记忆和死亡神经元</title>
      <link>https://arxiv.org/abs/2410.13866</link>
      <description><![CDATA[arXiv:2410.13866v1 公告类型：交叉 
摘要：在“神经生物学和机器学习中的大型联想记忆问题”中，Dmitry Krotov 和 John Hopfield 介绍了一种系统构建具有非增加能量或 Lyapunov 函数的神经常微分方程的通用技术。我们研究了这种能量函数，并发现它容易受到神经元死亡问题的影响。神经元死亡的状态空间中的每个点都包含在具有恒定能量的非紧凑区域中。在这些平坦区域中，能量函数本身并不能完全确定所有自由度，因此不能用于分析稳定性或找到稳定状态或吸引盆地。我们对动态系统进行直接分析，并展示如何解决由对应于死神经元的平坦方向引起的问题：（i）可以从能量和 Hessian 矩阵（拉格朗日函数）中提取有关固定点处状态向量的所有信息，（ii）在 Hessian 矩阵范围内分析稳定性就足够了，（iii）如果接触平坦区域的稳定状态是稳定的，则整个平坦区域就是吸引盆。对于实际架构，Hessian 矩阵的分析可能很复杂，因此我们表明，对于略微改变的动态系统（具有相同的稳定状态结构），可以推导出没有对应于死神经元的平坦区域的多样化 Lyapunov 函数系列。此外，这些能量函数允许将拉格朗日函数与不一定是正定的 Hessian 矩阵一起使用，甚至可以考虑具有非对称前馈和反馈连接的架构。]]></description>
      <guid>https://arxiv.org/abs/2410.13866</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>星条旗和硅谷：揭秘 ChatGPT 的全美式、单色、顺性别偏见</title>
      <link>https://arxiv.org/abs/2410.13868</link>
      <description><![CDATA[arXiv:2410.13868v1 公告类型：交叉 
摘要：本文研究了 ChatGPT 等大型语言模型 (LLM) 中与偏见、毒性、不可靠性和缺乏稳健性相关的挑战。它强调这些问题主要源于训练 LLM 的数据的质量和多样性，而不是模型架构本身。随着 LLM 越来越多地融入各种现实世界的应用程序中，它们通过放大现有偏见和产生有害内容对社会产生负面影响的可能性成为一个紧迫的问题。本文呼吁跨学科努力应对这些挑战。此外，它强调研究人员、从业者和利益相关者之间需要合作，以建立治理框架、监督和问责机制，以减轻有偏见的 LLM 带来的有害后果。通过积极应对这些挑战，人工智能社区可以利用 LLM 的巨大潜力来改善社会，而不会延续有害偏见或加剧现有的不平等。]]></description>
      <guid>https://arxiv.org/abs/2410.13868</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用受不确定性影响的生成模型来解释图像分类器</title>
      <link>https://arxiv.org/abs/2410.13871</link>
      <description><![CDATA[arXiv:2410.13871v1 公告类型：交叉 
摘要：我们建议通过给定的图像分类器不确定性来调节生成模型，以分析和解释其行为。对合成数据和损坏版本的 MNIST 数据集进行的初步实验说明了这个想法。]]></description>
      <guid>https://arxiv.org/abs/2410.13871</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度知识追踪助力传统黑人学院和大学的个性化自适应学习</title>
      <link>https://arxiv.org/abs/2410.13876</link>
      <description><![CDATA[arXiv:2410.13876v1 公告类型：交叉 
摘要：个性化自适应学习 (PAL) 通过密切监控个别学生的进步并根据他们独特的知识和需求定制学习路径而脱颖而出。有效实施 PAL 的关键技术是知识追踪，它模拟学生不断发展的知识以预测他们未来的表现。深度学习的最新进展通过深度知识追踪 (DKT) 显着增强了知识追踪。然而，在传统的黑人学院和大学 (HBCU) 中，对科学、技术、工程和数学 (STEM) 教育的 DKT 研究有限。本研究建立了一个全面的数据集来调查 DKT 在 HBCU 的 STEM 教育中实施 PAL，利用多个最先进的 (SOTA) DKT 模型来检查知识追踪性能。该数据集包括 Prairie View A&amp;M 大学 (PVAMU) 八所学院 17,181 名本科生的 352,148 条学习记录。所采用的 SOTA DKT 模型包括 DKT、DKT+、DKVMN、SAKT 和 KQN。实验结果表明 DKT 模型能够准确预测学生的学业成绩。具体而言，SAKT 和 KQN 模型在准确性和 AUC 方面优于其他模型。这些发现对教职员工和学术顾问具有重要意义，为在学期结束前识别出有学业表现不佳风险的学生提供了宝贵的见解。此外，这允许采取主动干预措施来支持学生的学业进步，从而有可能提高学生的留校率和毕业率。]]></description>
      <guid>https://arxiv.org/abs/2410.13876</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变压器在图表理解中的应用：最新进展与未来趋势回顾</title>
      <link>https://arxiv.org/abs/2410.13883</link>
      <description><![CDATA[arXiv:2410.13883v1 公告类型：交叉 
摘要：近年来，人们对视觉语言任务的兴趣日益浓厚，尤其是那些涉及图表交互的任务。这些任务本质上是多模态的，需要模型来处理图表图像、附带文本、底层数据表以及用户查询。传统上，图表理解 (CU) 依赖于启发式和基于规则的系统。然而，最近集成了变压器架构的进展显着提高了性能。本文回顾了 CU 中的著名研究，重点关注在端到端 (E2E) 解决方案中使用变压器的最先进的 (SoTA) 框架。分析了相关的基准数据集和评估技术。此外，本文还确定了关键挑战并概述了推进 CU 解决方案的有希望的未来方向。按照 PRISMA 指南，在 Google Scholar 上进行了全面的文献检索，重点关注 20 年 1 月至 24 年 6 月的出版物。经过严格的筛选和质量评估，选择了 32 项研究进行深入分析。根据所需的认知任务，CU 任务分为三层范式。还回顾了解决各种 CU 任务的框架的最新进展。根据 E2E 解决方案可解决的任务数量，框架分为单任务或多任务。在多任务框架中，探索了预训练和基于提示工程的技术。本综述概述了领先的架构、数据集和预训练任务。尽管取得了重大进展，但在 OCR 依赖性、处理低分辨率图像和增强视觉推理方面仍然存在挑战。未来的方向包括应对这些挑战、开发强大的基准和优化模型效率。此外，集成可解释的 AI 技术并探索真实数据和合成数据之间的平衡对于推进 CU 研究至关重要。]]></description>
      <guid>https://arxiv.org/abs/2410.13883</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S$^4$ST：一种强效、自转移、快速且简单的可转移针对性攻击的尺度转换</title>
      <link>https://arxiv.org/abs/2410.13891</link>
      <description><![CDATA[arXiv:2410.13891v1 公告类型：交叉 
摘要：针对深度神经网络的可转移定向对抗攻击 (TTA) 已被证明比非定向攻击更具挑战性，但它们仍然相对未被充分探索。本文为利用简单的基于梯度的基线执行高效但可转移的定向攻击提供了新的见解。我们的研究强调了图像变换在梯度计算中的关键重要性，标志着从普遍强调损失函数转向解决梯度消失问题。此外，我们开发了两个有效的盲估计器，有助于设计转换策略以增强黑盒条件下的定向可转移性。对抗性示例对几何变换的自转移性已被确定为与其黑盒可转移性密切相关，这些基本操作是促进定向可转移性的强大但重叠的代理。替代自对齐评估进一步突出了简单缩放变换的卓越功效，可与大多数先进方法相媲美。基于这些见解，我们引入了一种以扩展为中心的转换策略，称为强、自可迁移、快速和简单扩展转换 (S4ST)，以增强可迁移的针对性攻击。在 ImageNet 兼容基准数据集上进行的实验中，我们提出的 S4ST 在各种具有挑战性的黑盒模型中实现了 SOTA 平均目标传输成功率，比之前的领先方法高出 14% 以上，而执行时间仅为 25%。此外，我们的方法大大降低了 SOTA 攻击，并表现出对现实世界 API 的显著效果。这项工作标志着 TTA 的重大飞跃，揭示了它们构成的现实威胁，并为未来的研究提供了一种实用的生成方法。]]></description>
      <guid>https://arxiv.org/abs/2410.13891</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>