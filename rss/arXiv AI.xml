<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 06 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>没有万能的方法：利用法学硕士的风险和陷阱因公司规模而异</title>
      <link>https://arxiv.org/abs/2408.01444</link>
      <description><![CDATA[arXiv:2408.01444v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在从大型泛大陆公司到新兴创业公司等一系列组织中部署战略用例方面发挥着关键作用。成功利用 LLM 所涉及的问题和挑战可能因组织规模而异。重要的是研究和讨论这些与 LLM 适应相关的问题，重点关注工业关注的规模，并集思广益寻找可能的解决方案和未来方向。这样的研究在当前的研究文献中并没有得到突出的体现。在本研究中，我们采用了三重策略：首先，我们与行业从业者进行案例研究，以制定关键研究问题；其次，我们研究现有的工业出版物来解决这些问题；最后，我们为行业更有效地利用 LLM 提供了实用指南。]]></description>
      <guid>https://arxiv.org/abs/2408.01444</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:25 GMT</pubDate>
    </item>
    <item>
      <title>构建符合伦理道德且值得信赖的生物医学人工智能生态系统，助力基础模型的转化和临床整合</title>
      <link>https://arxiv.org/abs/2408.01431</link>
      <description><![CDATA[arXiv:2408.01431v1 公告类型：交叉 
摘要：基础模型 (FM) 因其能够表示和情境化多模态生物医学数据而成为生物医学 AI 生态系统的基石。这些功能使 FM 能够适应各种任务，包括生物医学推理、假设生成和临床决策。这篇评论文章探讨了以 FM 为中心的道德和值得信赖的 AI (ETAI) 生物医学生态系统的基础组成部分，强调了关键挑战和解决方案。ETAI 生物医学生态系统由七个关键组成部分定义，它们共同将 FM 整合到临床环境中：数据生命周期管理、数据处理、模型开发、模型评估、临床转化、AI 治理和监管以及利益相关者参与。虽然生物医学 AI 的潜力巨大，但它需要提高道德警惕性和责任感。例如，偏见可能来自数据、算法和用户交互，因此需要在模型开发之前、期间和之后评估和减轻偏见的技术。此外，可解释性、可说明性和可问责性是确保 AI 系统可信度的关键，而训练、测试和评估中的工作流程透明度对于可重复性至关重要。保护患者隐私和安全涉及解决数据访问、云数据隐私、患者重新识别、会员推理攻击和数据记忆方面的挑战。此外，以全球标准为指导，AI 治理和监管对于生物医学中合乎道德的 AI 使用至关重要。此外，利益相关者的参与对于临床转化的 AI 流程和生命周期的每个阶段都至关重要。通过遵守这些原则，我们可以利用 AI 的变革潜力并开发 ETAI 生态系统。]]></description>
      <guid>https://arxiv.org/abs/2408.01431</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:24 GMT</pubDate>
    </item>
    <item>
      <title>人工智能惠及所有人：识别与多样性和包容性相关的人工智能事件</title>
      <link>https://arxiv.org/abs/2408.01438</link>
      <description><![CDATA[arXiv:2408.01438v1 公告类型：交叉 
摘要：人工智能 (AI) 技术的快速发展带来了重大进步和挑战，多样性和包容性 (D&amp;I) 成为一个关键问题。解决人工智能中的 D&amp;I 对于减少偏见和歧视、增强公平性和防止不利的社会影响至关重要。尽管 D&amp;I 很重要，但它往往被忽视，导致事件带有内在偏见和道德困境。通过 D&amp;I 视角分析人工智能事件对于识别偏见原因和制定缓解策略至关重要，从而确保更公平、更公正的人工智能技术。然而，对 D&amp;I 相关的人工智能事件的系统调查很少。本研究通过手动分析人工智能事件数据库 (AIID 和 AIAAIC) 来识别和理解人工智能系统中的 D&amp;I 问题，从而应对这些挑战。该研究开发了一个决策树，用于调查与 AI 事件相关的 D&amp;I 问题，并填充与 D&amp;I 相关的 AI 事件的公共存储库。决策树通过卡片分类练习和焦点小组讨论进行了验证。研究表明，所分析的 AI 事件中几乎有一半与 D&amp;I 有关，其中种族、性别和年龄歧视尤为突出。决策树和由此产生的公共存储库旨在促进进一步的研究和负责任的 AI 实践，促进包容和公平的 AI 系统的发展。]]></description>
      <guid>https://arxiv.org/abs/2408.01438</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:24 GMT</pubDate>
    </item>
    <item>
      <title>可转移的对抗性面部图像用于隐私保护</title>
      <link>https://arxiv.org/abs/2408.01428</link>
      <description><![CDATA[arXiv:2408.01428v1 公告类型：交叉 
摘要：深度人脸识别 (FR) 系统的成功引发了严重的隐私问题，因为它们能够在数字世界中对用户进行未经授权的跟踪。先前的研究提出在人脸图像中引入不可察觉的对抗性噪声来欺骗那些人脸识别模型，从而实现增强人脸隐私保护的目的。然而，它们严重依赖用户选择的参考来指导对抗性噪声的生成，并且无法在黑盒场景中同时构建自然且高度可迁移的对抗性人脸图像。鉴于此，我们提出了一种新颖的人脸隐私保护方案，该方案在保持高视觉质量的同时提高了可迁移性。我们建议直接塑造整个面部空间，而不是利用一种面部特征（如化妆信息）来整合对抗性噪声。为了实现这一目标，我们首先利用全局对抗性潜在搜索来遍历生成模型的潜在空间，从而创建具有高可迁移性的自然对抗性人脸图像。然后，我们引入了一个关键的地标正则化模块来保留视觉身份信息。最后，我们研究了各种潜在空间的影响，发现 $\mathcal{F}$ 潜在空间有利于视觉自然性和对抗性可迁移性之间的权衡。在两个数据集上进行的大量实验表明，我们的方法在保持高视觉质量的同时显著提高了攻击可迁移性，在深度 FR 模型中的表现比最先进的方法平均提高了 25%，在商业 FR API（包括 Face++、阿里云和腾讯）中的表现比最先进的方法提高了 10%。]]></description>
      <guid>https://arxiv.org/abs/2408.01428</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:23 GMT</pubDate>
    </item>
    <item>
      <title>一种多模车载通信网络敏捷适配方法</title>
      <link>https://arxiv.org/abs/2408.01429</link>
      <description><![CDATA[arXiv:2408.01429v1 Announce Type: cross 
摘要：本文重点研究车载通信网络中通信模式分配对通信效率的影响。具体来说，利用马尔可夫决策过程和强化学习，根据驾驶场景和业务需求，建立多模通信设备的敏捷适配机制。然后，利用Q学习训练敏捷适配强化学习模型并输出训练好的模型。通过学习在不同状态下采取的最佳动作来最大化累积奖励，避免在不稳定的通信场景下由于时延测量不准确导致的适配效果不佳的问题。实验表明，所提方案能够快速适应动态车联网环境，同时实现较高的并发性和通信效率。]]></description>
      <guid>https://arxiv.org/abs/2408.01429</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:23 GMT</pubDate>
    </item>
    <item>
      <title>SUSTechGAN：自动驾驶恶劣条件下的物体识别图像生成</title>
      <link>https://arxiv.org/abs/2408.01430</link>
      <description><![CDATA[arXiv:2408.01430v1 公告类型：交叉 
摘要：自动驾驶显著受益于数据驱动的深度神经网络。然而，自动驾驶中的数据通常符合长尾分布，其中恶劣条件下的关键驾驶数据很难收集。虽然生成对抗网络（GAN）已被用于增强自动驾驶的数据，但在恶劣条件下生成驾驶图像仍然具有挑战性。在这项工作中，我们提出了一种具有双注意模块和多尺度生成器的新型 SUSTechGAN 来生成驾驶图像，以提高恶劣条件下自动驾驶的物体识别能力。我们测试了 SUSTechGAN 和现有的知名 GAN，以在雨天和夜晚的恶劣条件下生成驾驶图像，并将生成的图像应用于重新训练物体识别网络。具体而言，我们将生成的图像添加到训练数据集中以重新训练众所周知的 YOLOv5，并评估重新训练的 YOLOv5 在恶劣条件下物体识别的改进。实验结果表明，我们的 SUSTechGAN 生成的驾驶图像显著提高了重新训练的 YOLOv5 在雨天和夜间条件下的性能，优于众所周知的 GAN。开源代码、视频说明和数据集可在第 1 页找到，以促进恶劣条件下自动驾驶图像生成的开发。]]></description>
      <guid>https://arxiv.org/abs/2408.01430</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:23 GMT</pubDate>
    </item>
    <item>
      <title>用于小样本图像分类的 Siamese Transformer 网络</title>
      <link>https://arxiv.org/abs/2408.01427</link>
      <description><![CDATA[arXiv:2408.01427v1 公告类型：交叉 
摘要：人类在视觉分类任务中表现出非凡的能力，能够用最少的例子准确识别和分类新图像。这种能力归因于他们专注于细节并识别以前看到的图像和新图像之间的共同特征的能力。相比之下，现有的少样本图像分类方法通常强调全局特征或局部特征，很少有研究考虑两者的结合。为了解决这一限制，我们提出了一种基于 Siamese Transformer 网络 (STN) 的新方法。我们的方法采用两个并行分支网络，利用预先训练的 Vision Transformer (ViT) 架构分别提取全局和局部特征。具体而言，我们实现了 ViT-Small 网络架构，并使用通过自监督学习获得的预训练模型参数初始化分支网络。我们将欧几里得距离测量应用于全局特征，将 Kullback-Leibler (KL) 散度测量应用于局部特征。为了整合这两个指标，我们首先采用 L2 归一化，然后对归一化结果进行加权以获得最终的相似度得分。该策略充分利用了全局和局部特征的优势，同时确保了它们的互补性。在训练阶段，我们采用元学习方法来微调整个网络。我们的策略有效地利用了全局和局部特征在小样本图像分类中的潜力，避免了对复杂特征自适应模块的需求并增强了模型的泛化能力。大量实验表明，我们的框架简单而有效，在 5 次和 1 次场景中的四个流行的小样本分类基准上实现了比最先进的基线更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.01427</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:22 GMT</pubDate>
    </item>
    <item>
      <title>具有延迟推理的完美信息蒙特卡罗</title>
      <link>https://arxiv.org/abs/2408.02380</link>
      <description><![CDATA[arXiv:2408.02380v1 公告类型：新
摘要：不完美信息游戏，例如 Bridge 和 Skat，由于状态空间爆炸和隐藏信息而带来挑战，给搜索算法带来了巨大的障碍。基于确定性的算法通过采样隐藏信息并在完美信息设置中解决游戏来提供解决方案，从而促进快速有效的行动估计。然而，过渡到完美信息带来了挑战，尤其是一种称为策略融合的挑战。这项研究引入了“扩展完美信息蒙特卡罗”（EPIMC），这是一种在线算法，灵感来自最先进的基于确定性的方法完美信息蒙特卡罗（PIMC）。EPIMC 通过推迟完美信息解析来增强 PIMC 的能力，从而减少与策略融合相关的缓解问题。然而，推迟叶子评估器的决定引入了新的考虑因素，例如先前的推理水平与新推迟的解析之间的相互作用。在我们的实证分析中，我们研究了 EPIMC 在一系列游戏中的表现，特别关注那些具有不同程度策略融合的游戏。我们的结果表明，性能显著提高，特别是在策略融合对游戏玩法产生重大影响的游戏中。此外，我们的研究为解决与策略融合相关的挑战的确定性算法奠定了理论基础。从而增强了我们在非完美信息游戏场景中对这些算法的理解。]]></description>
      <guid>https://arxiv.org/abs/2408.02380</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:21 GMT</pubDate>
    </item>
    <item>
      <title>用于解释强化学习的反事实 Shapley 值</title>
      <link>https://arxiv.org/abs/2408.02529</link>
      <description><![CDATA[arXiv:2408.02529v1 公告类型：新
摘要：本文介绍了一种新方法反事实 Shapley 值 (CSV)，该方法通过将反事实分析与 Shapley 值相结合来增强强化学习 (RL) 中的可解释性。该方法旨在量化和比较不同状态维度对各种行动选择的贡献。为了更准确地分析这些影响，我们引入了新的特征值函数，即“反事实差异特征值”和“平均反事实差异特征值”。这些函数有助于计算 Shapley 值以评估最佳和非最佳动作之间的贡献差异。在 GridWorld、FrozenLake 和 Taxi 等多个 RL 领域的实验证明了 CSV 方法的有效性。结果表明，该方法不仅提高了复杂 RL 系统的透明度，而且还量化了各种决策之间的差异。]]></description>
      <guid>https://arxiv.org/abs/2408.02529</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:21 GMT</pubDate>
    </item>
    <item>
      <title>通过重新定义谓词来进行反向解释</title>
      <link>https://arxiv.org/abs/2408.02606</link>
      <description><![CDATA[arXiv:2408.02606v1 公告类型：新
摘要：基于谓词的历史解释 (HXP) 通过任意谓词的棱镜研究强化学习 (RL) 代理在代理与环境 (历史) 交互序列中的行为。为此，为历史中的每个动作计算一个动作重要性分数。解释在于向用户显示最重要的操作。由于计算动作的重要性是 #W[1] 困难的，因此有必要让长历史近似分数，但要以牺牲其质量为代价。因此，我们提出了一种新的 HXP 方法，称为 Backward-HXP，以提供这些历史的解释，而无需近似分数。实验表明 B-HXP 能够总结长历史。]]></description>
      <guid>https://arxiv.org/abs/2408.02606</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:21 GMT</pubDate>
    </item>
    <item>
      <title>在注重隐私的助手中实现情境完整性</title>
      <link>https://arxiv.org/abs/2408.02373</link>
      <description><![CDATA[arXiv:2408.02373v1 公告类型：新
摘要：高级人工智能助手结合前沿 LLM 和工具访问，代表用户自主执行复杂任务。虽然此类助手的帮助可以随着对电子邮件和文档等用户信息的访问而大大增加，但这引发了对助手在没有用户监督的情况下与第三方共享不当信息的隐私担忧。为了引导信息共享助手按照隐私期望行事，我们建议实施 $\textit{contextual integrity}$ (CI)，这是一个将隐私等同于给定上下文中适当信息流的框架。具体来说，我们设计和评估了许多策略来引导助手的信息共享行为符合 CI。我们的评估基于由合成数据和人工注释组成的新型表格填写基准，它表明促使前沿 LLM 执行基于 CI 的推理会产生很好的结果。]]></description>
      <guid>https://arxiv.org/abs/2408.02373</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:20 GMT</pubDate>
    </item>
    <item>
      <title>开发波兰语的 PUGG：KBQA、MRC 和 IR 数据集构建的现代方法</title>
      <link>https://arxiv.org/abs/2408.02337</link>
      <description><![CDATA[arXiv:2408.02337v1 公告类型：新
摘要：人工智能和自然语言处理的进步彻底改变了机器与人之间的语言交互，其中问答 (QA) 系统发挥着关键作用。知识库问答 (KBQA) 任务利用结构化知识图谱 (KG)，可以处理大量知识密集型问题。然而，KBQA 数据集存在显著差距，尤其是对于低资源语言。这些数据集的许多现有构建流程已经过时，人力效率低下，并且没有使用大型语言模型 (LLM) 等现代辅助工具来减少工作量。为了解决这个问题，我们设计并实施了一种现代的半自动化数据集创建方法，涵盖了 KBQA、机器阅读理解 (MRC) 和信息检索 (IR) 等任务，专门针对低资源环境量身定制。我们执行了此流程并引入了 PUGG 数据集、第一个波兰 KBQA 数据集以及用于 MRC 和 IR 的新数据集。此外，我们还提供了全面的实施、深刻的发现、详细的统计数据和基线模型的评估。]]></description>
      <guid>https://arxiv.org/abs/2408.02337</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:19 GMT</pubDate>
    </item>
    <item>
      <title>论智能的一致性推理悖论与对人工智能的最佳信任：“我不知道”的力量</title>
      <link>https://arxiv.org/abs/2408.02357</link>
      <description><![CDATA[arXiv:2408.02357v1 公告类型：新
摘要：我们引入了一致性推理悖论 (CRP)。一致性推理是人类智能的核心，它能够处理等效但由不同句子描述的任务（“告诉我时间！”和“现在几点了？”）。CRP 断言一致性推理意味着易错性——特别是，人工智能中的类人智能必然伴随着类人易错性。具体来说，它指出存在一些问题，例如在基本算术中，任何始终回答并努力通过一致推理模仿人类智能的人工智能都会无限次地产生幻觉（产生错误但合理的答案）。悖论是存在一种非一致性推理的人工智能（因此不可能达到人类智能的水平），它会在同一组问题上正确回答。 CRP 还表明，即使从概率意义上检测这些幻觉，也比解决原始问题更难，而且有些问题人工智能可能会正确回答，但它无法提供正确的逻辑解释来解释它是如何得出答案的。因此，CRP 意味着任何值得信赖的人工智能（即从不错误回答的人工智能）都必须能够说“我不知道”。此外，这只能通过隐式计算我们引入的一个新概念来实现，称为“我不知道”功能——这是现代人工智能目前所缺乏的。鉴于这些见解，CRP 还提供了对通用人工智能 (AGI) 行为的一瞥。AGI 不能“几乎肯定”，也不能总是解释自己，因此要值得信赖，它必须能够说“我不知道”。]]></description>
      <guid>https://arxiv.org/abs/2408.02357</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:19 GMT</pubDate>
    </item>
    <item>
      <title>MAO：具有多代理编排的流程模型生成框架</title>
      <link>https://arxiv.org/abs/2408.01916</link>
      <description><![CDATA[arXiv:2408.01916v1 公告类型：新
摘要：流程模型在软件工程中经常用于描述业务需求、指导软件测试和控制系统改进。然而，传统的流程​​建模方法往往需要众多专家的参与，这既昂贵又耗时。因此，探索一种更高效、更经济的自动化建模方法已成为当前研究的重点。本文探讨了一种利用多智能体编排（MAO）自动生成流程模型的框架，旨在提高流程建模的效率并为领域专家提供有价值的见解。我们的框架MAO利用大型语言模型作为多智能体的基石，采用创新的提示策略来确保多智能体之间的高效协作。具体来说，1）生成。MAO的第一阶段是从文本描述中生成一个略微粗糙的过程模型；2）细化。智能体将通过多轮对话不断细化初始过程模型；3）审查。大型语言模型在多轮对话中容易出现幻听现象，因此智能体需要检查和修复过程模型中的语义幻听；4）测试。过程模型的表示形式多种多样。因此，智能体利用外部工具测试生成的过程模型是否包含格式错误，即格式幻听，然后调整过程模型以符合输出范式。实验表明，我们框架生成的过程模型在四个不同的数据集上分别优于现有方法和手动建模 89%、61%、52% 和 75%。]]></description>
      <guid>https://arxiv.org/abs/2408.01916</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:18 GMT</pubDate>
    </item>
    <item>
      <title>强化学习中对象级泛化的视觉基础</title>
      <link>https://arxiv.org/abs/2408.01942</link>
      <description><![CDATA[arXiv:2408.01942v1 公告类型：新
摘要：泛化是遵循自然语言指令的代理面临的关键挑战。为了实现这一目标，我们利用视觉语言模型 (VLM) 进行视觉基础，并将其视觉语言知识转移到以对象为中心的任务的强化学习 (RL) 中，这使得代理能够对看不见的对象和指令进行零样本泛化。通过视觉基础，我们获得了指令中指示的目标对象的基于对象的置信度图。基于此图，我们介绍了两种将 VLM 知识转移到 RL 的途径。首先，我们提出了一种基于对象的内在奖励函数，该函数源自置信度图，以更有效地引导代理朝向目标对象。其次，与语言嵌入相比，置信度图为代理的策略提供了更统一、更易于访问的任务表示。这使代理能够通过可理解的视觉置信度图处理看不见的对象和指令，从而促进零样本对象级泛化。单任务实验证明，我们的内在奖励显著提高了具有挑战性的技能学习的表现。在多任务实验中，通过对训练集以外的任务进行测试，我们表明，当为代理提供置信度图作为任务表示时，其泛化能力比基于语言的条件反射更好。代码可在 https://github.com/PKU-RL/COPL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.01942</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:18 GMT</pubDate>
    </item>
    <item>
      <title>SR-CIS：具有解耦记忆和推理的自反思增量系统</title>
      <link>https://arxiv.org/abs/2408.01970</link>
      <description><![CDATA[arXiv:2408.01970v1 公告类型：新
摘要：人类快速学习新知识同时保留旧记忆的能力对当前的深度学习模型提出了重大挑战。为了应对这一挑战，我们从人类记忆和学习机制中汲取灵感，提出了自反思互补增量系统 (SR-CIS)。SR-CIS 由解构的互补推理模块 (CIM) 和互补记忆模块 (CMM) 组成，在 CIM 中具有用于快速推理的小模型和用于慢速审议的大模型，并通过置信度感知在线异常检测 (CA-OAD) 机制实现高效协作。CMM 由特定于任务的短期记忆 (STM) 区域和通用的长期记忆 (LTM) 区域组成。通过设置特定于任务的低秩自适应 (LoRA) 和相应的原型权重和偏差，它实例化参数和表示记忆的外部存储，从而将记忆模块与推理模块解构。通过在训练期间存储图像的文本描述，并在训练后将其与场景重放模块 (SRM) 相结合以进行记忆组合，以及定期进行短期到长期记忆重构，SR-CIS 可以在有限的存储要求下实现稳定的增量记忆。在有限的存储和低数据资源的限制下，SR-CIS 平衡了模型可塑性和记忆稳定性，在多个标准和少量增量学习基准上超越了现有的竞争基线。]]></description>
      <guid>https://arxiv.org/abs/2408.01970</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:18 GMT</pubDate>
    </item>
    <item>
      <title>面向智能制造的云服务组合综述</title>
      <link>https://arxiv.org/abs/2408.01795</link>
      <description><![CDATA[arXiv:2408.01795v1 Announce Type: new 
摘要：智能制造是利用物联网、大数据、人工智能等先进技术提高制造业生产效率和质量的一种新模式。作为推动制造业转型升级的重要支撑，云服务优化受到研究者的关注，近年来该领域的研究成果令人瞩目。为了智能制造平台的可持续发展，本文总结了面向智能制造的云服务优化的流程。进一步针对现有研究中优化指标分散、定义不统一/不规范的问题，从智能制造平台可持续发展的迫切要求出发，定义了11个兼顾三方参与主体的优化指标。接下来，将服务优化算法分为启发式和强化学习两大类，在对两大类进行比较后，针对性地提出了当前服务优化的关键技术。最后，总结了服务优化的研究热点和未来的研究趋势。]]></description>
      <guid>https://arxiv.org/abs/2408.01795</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:17 GMT</pubDate>
    </item>
    <item>
      <title>在图上明智行走：通过有效的引导-探索实现双代理的知识图谱推理</title>
      <link>https://arxiv.org/abs/2408.01880</link>
      <description><![CDATA[arXiv:2408.01880v1 公告类型：新
摘要：近年来，多跳推理因其有效性和可解释性而被广泛应用于知识图谱 (KG) 推理。然而，以前的多跳推理方法存在两个主要缺点。首先，由于奖励稀疏，代理在早期阶段难以学习有效且稳健的策略。其次，这些方法通常在稀疏知识图等特定数据集上失败，在这些数据集中，代理需要遍历漫长的推理路径。为了解决这些问题，我们提出了一种基于分层强化学习 (HRL) 的双代理多跳推理模型，称为 FULORA。FULORA 通过双代理之间的有效引导探索来解决上述推理挑战。高级代理在简化的知识图上行走，为在原始知识图上行走的低级代理提供分阶段的提示。在这个框架中，低级代理优化了一个价值函数，以平衡两个目标：（1）最大化回报，（2）整合高级代理的有效指导。在三个真实世界知识图谱数据集上进行的实验表明，FULORA 的表现优于基于 RL 的基线，尤其是在长距离推理的情况下。]]></description>
      <guid>https://arxiv.org/abs/2408.01880</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:17 GMT</pubDate>
    </item>
    <item>
      <title>GPUDrive：100 万 FPS 数据驱动的多智能体驾驶模拟</title>
      <link>https://arxiv.org/abs/2408.01584</link>
      <description><![CDATA[arXiv:2408.01584v1 公告类型：新
摘要：多智能体学习算法已成功在各种游戏中生成超人规划，但对部署的多智能体规划器的设计影响不大。将这些技术应用于多智能体规划的一个关键瓶颈是它们需要数十亿步的经验。为了能够以这种规模研究多智能体规划，我们提出了 GPUDrive，这是一个基于 Madrona 游戏引擎构建的 GPU 加速多智能体模拟器，每秒可生成超过一百万步的经验。观察、奖励和动态函数直接用 C++ 编写，允许用户定义复杂的异构智能体行为，并将其降低到高性能 CUDA。我们表明，使用 GPUDrive，我们能够在 Waymo Motion 数据集中的许多场景中有效地训练强化学习智能体，在几分钟内为单个场景生成高效的目标实现智能体，并在几个小时内生成一般有能力的智能体。我们将这些训练有素的代理作为代码库的一部分发布于 https://github.com/Emerge-Lab/gpudrive。]]></description>
      <guid>https://arxiv.org/abs/2408.01584</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:16 GMT</pubDate>
    </item>
    <item>
      <title>集成大型语言模型和知识图谱来提取和验证文本测试数据</title>
      <link>https://arxiv.org/abs/2408.01700</link>
      <description><![CDATA[arXiv:2408.01700v1 公告类型：新
摘要：航空航天制造公司（例如泰雷兹阿莱尼亚航天公司）设计、开发、集成、验证和确认具有高复杂性和低容量特征的产品。他们仔细记录每个产品的所有阶段，但由于文档中数据的异构性和非结构化性质，跨产品的分析具有挑战性。在本文中，我们提出了一种混合方法，该方法利用知识图谱 (KG) 结合大型语言模型 (LLM) 来提取和验证这些文档中包含的数据。我们考虑一个案例研究，重点关注与卫星电子板相关的测试数据。为此，我们扩展了语义传感器网络本体。我们将报告的元数据存储在 KG 中，而实际测试结果存储在可通过虚拟知识图谱访问的 parquet 中。验证过程使用基于 LLM 的方法进行管理。我们还进行了基准研究，以评估最先进的 LLM 在执行此任务时的性能。最后，我们分析了自动化现有的手动数据提取和验证流程以便进行后续跨报告分析的成本和收益。]]></description>
      <guid>https://arxiv.org/abs/2408.01700</guid>
      <pubDate>Tue, 06 Aug 2024 06:30:16 GMT</pubDate>
    </item>
    </channel>
</rss>