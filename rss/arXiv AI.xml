<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 25 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>知识图：数据集成和有见地的发现的未来</title>
      <link>https://arxiv.org/abs/2502.15689</link>
      <description><![CDATA[ARXIV：2502.15689V1公告类型：新 
摘要：知识图是一种有效的方法，用于代表和连接各种概念的信息，可用于推理，问题答案和知识基础完成任务。他们通过链接点来组织数据，使研究人员能够将各种信息源相结合到一个数据库中。这种跨学科的方法有助于发现新的研究问题和思想。知识图创建了一个数据点（节点）及其连接（边缘）的网络，从而增强了用于多种目的数据的导航，理解和利用。他们捕获了非结构化数据源固有的复杂关系，为不同实体及其属性提供了语义框架。开发知识图的策略包括使用种子数据，命名实体识别和关系提取。这些图提高了聊天机器人的准确性，并包括多媒体数据以获取更丰富的信息。创建高质量的知识图涉及自动化方法和人类的监督，对于准确而全面的数据表示至关重要。]]></description>
      <guid>https://arxiv.org/abs/2502.15689</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在合成神经认知中概念起源的核心的分类剪辑过程</title>
      <link>https://arxiv.org/abs/2502.15710</link>
      <description><![CDATA[ARXIV：2502.15710V1公告类型：新 
摘要：本文在人工智能神经心理学领域进行了调查，这是语言模型进行的分类分割过程。此过程涉及在不同的神经层上创建新功能分类维度，以分析输入文本数据并执行所需的任务。多层感知器（MLP）网络中的每个神经元都与特定类别相关联，该类别由神经聚集函数携带的三个因素产生：分类启动，分类注意力和分类阶段。在每个新层，这些因素决定了从前体神经元类别得出的新类别的形成。通过分类剪辑的过程，这些新类别是通过选择性地从前一个类别中提取特定细分的特定细分而创建的，从而构建了形式和类别背景之间的区别。我们以探索性方式探索了这种合成剪辑的几个认知特征：分类降低，分类选择性，初始嵌入维度的分离以及分类区域的分割。]]></description>
      <guid>https://arxiv.org/abs/2502.15710</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>logic.py：桥接LLM和约束求解器之间的差距</title>
      <link>https://arxiv.org/abs/2502.15776</link>
      <description><![CDATA[ARXIV：2502.15776V1公告类型：新 
摘要：我们提出了一种使用大型语言模型正式和解决基于搜索的问题的新方法，这在先前的最新结果上大大改善了。我们证明了这种方法对逻辑难题基准斑马凝胶台的功效。我们的方法没有让LLM尝试直接解决难题，而是促使模型以称为Logic.py的逻辑域特异性语言（DSL）形式化问题。然后，使用约束求解器来解决这种形式化的表示形式，从而利用语言模型和求解器的优势。我们的方法比Zebralogicbench在Llama 3.1 70B的基线性能中实现了65％的绝对改善，这为新的最新技术创造了超过90％以上的新最先进。这一重大进步证明了将语言模型与特定于领域的语言和辅助工具相结合的潜力，这些工具在传统上具有挑战性的LLMS任务。]]></description>
      <guid>https://arxiv.org/abs/2502.15776</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>所有人：基于LLMS的多标准决策制定人类专家级别的一般框架</title>
      <link>https://arxiv.org/abs/2502.15778</link>
      <description><![CDATA[ARXIV：2502.15778V1公告类型：新 
摘要：使用多个级别和属性的定量和定性分析在各个领域中广泛应用多标准决策〜（MCDM），以支持决策者在复杂的情况下做出科学和理性的决策。但是，传统的MCDM方法在高维问题中面临瓶颈。鉴于大型语言模型〜（LLM）在各种复杂任务中实现了令人印象深刻的表现，但是有限的工作在人类领域专家的帮助下评估了特定MCDM问题的LLM，我们通过提出基于LLM的评估来进一步探索LLM的能力自动处理一般复杂MCDM问题的框架。在框架内，我们评估了各种典型的开源模型的性能以及Claude和Chatgpt等商业模型，在3个重要应用程序上，与评估地面真相相比，这些模型只能达到60 \％的准确率。在掺入经过思考链或很少的发动机提示后，准确率上升到70 \％左右，并且高度依赖于模型。为了进一步提高性能，采用了基于洛拉的微调技术。实验结果表明，不同应用的精度率显着提高到95 \％左右，并且在不同模型之间的性能差异很微不足道，表明基于洛拉的微型LLMS在解决MCDM任务时具有显着稳定的优势，并且可以提供MCDM任务，并且可以提供。针对各种MCDM挑战的人类专家级解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.15778</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优质质量：高质量数据在自动化中的多种多语言数据击败多种多样的数据</title>
      <link>https://arxiv.org/abs/2502.15795</link>
      <description><![CDATA[ARXIV：2502.15795V1公告类型：新 
摘要：自动化，将非正式数学语言转换为形式规格和证明的过程仍然是最先进（大型）语言模型的艰巨任务。现有作品指出了竞争性能差距的竞争解释。为此，我们介绍了一种新颖的方法，该方法利用手工策划的提示来利用背面翻译来增强语言模型的数学能力，尤其是解决了标记数据的稀缺性所带来的挑战。具体而言，我们评估了此策略的三个主要变体：（1）即时（在线）倒流，（2）蒸馏（2）蒸馏（离线）倒流几乎没有放大，以及（3）逐线证明分析使用证明状态信息。每个变体旨在优化数据质量而不是数量，重点是生成的证明的高保真度，而不是纯粹的数据量表。我们的发现提供了证据表明，采用我们提出的方法生成合成数据（优先考虑质量而不是数量），可改善LLMS的自动化性能，如标准基准（例如ProfiveNet）所测量的。至关重要的是，我们的方法使用最少数量的令牌来优于预测模型。我们还通过战略提示和反向翻译表明，我们的方法超过了通过广泛的多语言数据集（例如MMA在验证网络上，只有1/150个令牌）的性能。综上所述，我们的方法显示了一种有希望的新方法，可以显着减少正式化证明所需的资源，从而加速AI数学。]]></description>
      <guid>https://arxiv.org/abs/2502.15795</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通用AI最大化变异的授权</title>
      <link>https://arxiv.org/abs/2502.15820</link>
      <description><![CDATA[ARXIV：2502.15820V1公告类型：新 
摘要：本文提出了一个统一AIXI的理论框架 - 一种通用AI的模型 - 具有变异性授权作为探索的内在驱动力。我们建立在自我AIXI的现有框架的基础上，即一种普遍的学习推动者，可以通过展示其既定术语之一可以解释为变异赋权目标，从而预测其自身行动。我们进一步证明，通用AI的计划过程可以最大程度地减少预期的变异能量（主动推理的核心原理），从而揭示了通用AI代理的固有平衡目标指导行为并降低了好奇心）。此外，我们认为，通用AI代理商的寻求权力倾向不仅可以作为确保未来奖励的工具策略来解释，而且还可以作为授权最大化的直接结果 - 即，\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \在不确定环境中的可控性。我们的主要贡献是展示这些内在动机（授权，好奇心）如何系统地导致通用AI代理人寻求和维持高级选度状态。我们证明，在适当的条件下，自动渐近渐近地收敛于与AIXI相同的性能，并强调其寻求力量的行为自然而然地从奖励最大化和好奇心驱动的探索中出现。由于AIXI可以视为人工通用智能（AGI）的贝叶斯最佳数学公式，因此我们的结果对于有关AI安全性和AGI的可控性的进一步讨论很有用。]]></description>
      <guid>https://arxiv.org/abs/2502.15820</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于对数学，技术和因果方法的全面检查，一种数据特征之间关系的新方法</title>
      <link>https://arxiv.org/abs/2502.15838</link>
      <description><![CDATA[ARXIV：2502.15838V1公告类型：新 
摘要：人工智能（AI）的扩展引起了人们对透明度，问责制和解释性的关注，反事实推理作为解决这些问题的关键方法。但是，当前的数学，技术和因果方法依赖于外部化技术，这些技术使单个坐标空间内特征关系正常化，通常会扭曲内在相互作用。这项研究提出了收敛融合范式（CFP）理论，该理论是整合数学，技术和因果观点的框架，以提供对特征关系的更精确，更全面的分析。 CFP理论介绍了希尔伯特空间和向后的因果关系，以重新解释特征关系作为新兴的结构，从而为共同原因问题提供了潜在的解决方案，这是因果建模中的基本挑战。从数学的角度来看，它利用了基于Riemannian的歧管框架，从而改善了高维数据相互作用的结构表示。从因果推论的角度来看，CFP理论采用绑架作为方法论基础，采用希尔伯特空间进行动态因果推理方法，在这种方法中，在缘故中推断出因果关系，并且特征关系随着新兴的特性而发展。最终，CFP理论介绍了一种新颖的AI建模方法，该方法可以整合希尔伯特空间，后退因果关系和里曼尼亚的几何形状，从而增强了反事实推理的AI治理和透明度。]]></description>
      <guid>https://arxiv.org/abs/2502.15838</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动板台：自主代理长期连贯性的基准</title>
      <link>https://arxiv.org/abs/2502.15840</link>
      <description><![CDATA[ARXIV：2502.15840V1公告类型：新 
摘要：尽管大型语言模型（LLM）可以在孤立的短期任务中表现出令人印象深刻的熟练程度，但它们通常无法在更长的时间范围内保持连贯的性能。在本文中，我们提出了自动售台，这是一个模拟环境，旨在专门测试基于LLM的代理商管理直接，长期运行的业务场景的能力：操作自动售货机。代理商必须平衡库存，下订单，设定价格和处理每日费用 - 每个任务都是简单但共同统计的，长期（每次运行&gt; 20m代币）都强调LLM进行持续，连贯的决策能力。我们的实验表明，多个LLM的性能差异很大：Claude 3.5十四行诗和O3-Mini在大多数运行中都很好地管理机器并盈利，但是所有模型都可以通过误解的交付时间表，忘记订单，或者降至降级，或者降低切向“熔化”循环，它们很少从中恢复。我们发现失败与模型上下文窗口完整的点之间没有明确的相关性，这表明这些崩溃并非源于内存限制。除了突出长期范围内绩效的较高差异外，Verdend Bench还测试了模型获得资本的能力，这是许多假设的危险AI场景的必要性。我们希望基准可以帮助准备更强的AI系统的出现。]]></description>
      <guid>https://arxiv.org/abs/2502.15840</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>C3AI：制定和评估宪法AI的宪法</title>
      <link>https://arxiv.org/abs/2502.15861</link>
      <description><![CDATA[ARXIV：2502.15861V1公告类型：新 
摘要：宪法AI（CAI）使用宪法指导LLM行为，但是确定哪些原则对模型对准最有效仍然是一个悬而未决的挑战。我们介绍了C3AI框架（\ textIt {CAI模型的制定宪法}），该框架提供了两个关键功能：（1）选择和结构化原则以在微调之前形成有效的宪法； （2）评估微调的CAI模型是否遵循这些原则。通过分析AI和心理学的原则，我们发现，基于行为的原则与人类的偏好相比，基于行为的原则比基于人类的偏好更加吻合。在安全对齐用例中，我们应用了一种基于图的原理选择方法来完善现有的CAI构成，改善了安全措施，同时保持了强大的一般推理能力。有趣的是，与我们的人类一致性结果相比，微调的CAI模型在负面的原则上表现良好，但在积极的框架上挣扎。这突出了原理设计和模型依从性之间的潜在差距。总体而言，C3AI提供了一种结构化且可扩展的方法来制作和评估CAI宪法。]]></description>
      <guid>https://arxiv.org/abs/2502.15861</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI成本和计算会计的实用原则</title>
      <link>https://arxiv.org/abs/2502.15873</link>
      <description><![CDATA[ARXIV：2502.15873V1公告类型：新 
摘要：政策制定者越来越多地使用开发成本和计算作为AI模型功能和风险的代理。最近的法律提出了根据特定阈值取决于的监管要求。但是，如何执行此次会计的技术歧义可能会产生破坏监管有效性的漏洞。本文提出了设计实用AI成本和计算会计标准的七个原则，这些原则（1）（1）减少战略游戏的机会，（2）避免阻止负责任的风险减轻，以及（3）在公司和司法管辖区之间实施一致的实施。]]></description>
      <guid>https://arxiv.org/abs/2502.15873</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在流域系统中的地下水充电和地表径流管理的水资源分配的多目标优化</title>
      <link>https://arxiv.org/abs/2502.15953</link>
      <description><![CDATA[ARXIV：2502.15953V1公告类型：新 
摘要：土地降解和空气污染主要是由于盐度湖泊干燥以及由于其干燥的底部而释放到大气中的土壤和荒漠化引起的。湖泊的完整干燥造成了社区环境灾难。在这项研究中，我们提出了一个优化问题，以确定总表面径流，以维持盐度湖水（Urmia Lake）。所提出的过程有两个关键阶段：使用敏感性分析方法基于历史数据来确定湖水水平的影响因素，并优化有效变量，以在不断变化的设计变量下稳定湖水水平。基于Sobol&#39;-Jansen和Morris技术，地下水位和总表面径流流非常有效，在湖水水平的非线性和相互作用的影响下。由于灵敏度分析，我们发现可以通过调整总表面径流有效地管理湖泊水平。我们使用遗传算法，非线性优化和模式搜索技术来解决优化问题。此外，湖泊水平的约束是根据图案作为每月恒定数字建立的。为了保持一致的湖泊水平，有必要在填充季节将表面径流增加约8.7倍。在排水季节，有必要将该数量增加33.5倍。将来，结果可能是湖泊康复的指南。]]></description>
      <guid>https://arxiv.org/abs/2502.15953</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种基于知识蒸馏的方法来增强分类器模型的透明度</title>
      <link>https://arxiv.org/abs/2502.15959</link>
      <description><![CDATA[ARXIV：2502.15959V1公告类型：新 
摘要：随着人工智能（AI）的快速发展，尤其是在医学领域，其解释性的需求已增长。在医学图像分析中，高度的透明度和模型可解释性可以帮助临床医生更好地理解和信任AI模型的决策过程。在这项研究中，我们提出了一种基于知识蒸馏（KD）的方法，旨在提高医学图像分析中AI模型的透明度。最初的步骤是使用传统的CNN获取教师模型，然后使用KD来简化CNN体系结构，保留数据集的大多数功能，并减少网络层的数量。它还使用学生模型的功能图来执行层次分析，以识别关键特征和决策过程。这导致直观的视觉解释。我们选择了三个公共医疗数据集（脑瘤，眼病和阿尔茨海默氏病）来测试我们的方法。它表明，即使减少了层的数量，我们的模型在测试集中也提供了显着的结果，并减少了可解释性分析所需的时间。]]></description>
      <guid>https://arxiv.org/abs/2502.15959</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测拥抱面孔的开放量AI模型增长</title>
      <link>https://arxiv.org/abs/2502.15987</link>
      <description><![CDATA[ARXIV：2502.15987V1公告类型：新 
摘要：随着开放权重的AI景观继续扩大模型开发，大量投资和用户的兴趣 - 预测哪些模型最终将推动创新并塑造AI生态系统变得越来越重要。在科学文献中与引文动态的相似之处的基础上，我们提出了一个框架，以量化开放权重模型的影响如何发展。具体而言，我们适应了Wang等人引入的模型。对于科学引用，使用三个关键参数 -  iMmediacy，寿命和相对适应性，跟踪开放重量模型的微调模型的累积数量。我们的发现表明，这种引用风格的方法可以有效地捕获开放型模型采用的各种轨迹，大多数模型都很好地拟合，并且异常值表明使用了独特的模式或使用中突然跳跃。]]></description>
      <guid>https://arxiv.org/abs/2502.15987</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式不一致推理（MMIR）：多模式推理模型的新基准</title>
      <link>https://arxiv.org/abs/2502.16033</link>
      <description><![CDATA[arxiv：2502.16033v1公告类型：新 
摘要：现有的多模式大型语言模型（MLLMS）主要是对一致的视觉文本输入进行训练和测试的，因此打开了一个问题，即它们是否可以处理现实世界中的不一致之处。为了弥合这一差距，我们提出了多模式不一致推理（MMIR）基准测试，以评估MLLM检测和推理有关网页，演示幻灯片和海报等文物中语义不匹配的能力。 MMIR包括534个具有挑战性的样本，每个样本都包含五个重度推理类别的合成错误：事实矛盾，身份错误贡献，上下文不匹配，定量差异和时间/空间不相互关系。我们评估了六个最先进的MLLM，表明具有专用多模式推理功能的模型（例如O1）大大优于其同行，而开源模型仍然特别容易受到不一致错误的影响。详细的错误分析进一步表明，模型在检测限制在单一模态的情况下，尤其是在文本中，但在跨模式冲突和复杂布局中挣扎中表现出色。探测实验表明，单模式的提示，包括经营链（COT）和标记（SOM）方法，可产生边缘增长，揭示了交叉模式推理中的关键瓶颈。我们的发现强调了对高级多模式推理的需求，并指出了对多模式不一致的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2502.16033</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>居里：对AI代理进行严格和自动化的科学实验</title>
      <link>https://arxiv.org/abs/2502.16069</link>
      <description><![CDATA[ARXIV：2502.16069V1公告类型：新 
摘要：科学实验，是人类进步的基石，要求对可靠性，有条不紊的控制和解释性严格，以产生有意义的结果。尽管大语言模型（LLM）在自动化科学过程的不同方面的功能增长，但自动化严格的实验仍然是一个重大挑战。为了解决这一差距，我们提出了Curie，这是一个AI代理框架，旨在通过三个关键组件将严格嵌入实验过程中：一个可增强可靠性的代理内部严格模块，以维持有条不紊的控制模块，以维持有条理的控制和一个实验知识模块可增强可解释性。为了评估Curie，我们设计了一个新型的实验基准，该基准由四个计算机科学领域的46个问题组成，这些问题来自有影响力的研究论文，并广泛采用了开源项目。与测试最强的基线相比，我们在正确回答实验问题方面取得了3.4 $ \ times $的改进。Curie在https://github.com/just-curieous/curie上开源。]]></description>
      <guid>https://arxiv.org/abs/2502.16069</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>比零射门更糟？一个事实检查数据集，用于评估抹布的鲁棒性侵害检索的鲁棒性</title>
      <link>https://arxiv.org/abs/2502.16101</link>
      <description><![CDATA[Arxiv：2502.16101V1公告类型：新 
摘要：检索增强的一代（RAG）在减轻大语言模型（LLMS）的幻觉方面表现出了令人印象深刻的能力。但是，LLM努力处理误导性检索，并且在暴露于冲突或有选择性的证据时通常无法保持自己的推理，从而使它们容易受到现实世界中的误解。在这种现实的检索情况下，误导性和相互矛盾的信息猖ramp，尤其是在政治领域，在政治领域中，证据通常被选择性地构架，不完整或两极分化。但是，现有的抹布基准在很大程度上假设了一个干净的检索设置，在该设置中，模型通过准确检索金标准文档的答案而成功。此假设无法与现实世界的条件保持一致，从而导致了抹布系统性能的高估。为了弥合这一差距，我们介绍了Raguard，这是一个事实检查数据集，旨在评估抹布系统的鲁棒性，以免误导检索。与依靠合成噪声的先前基准分析不同，我们的数据集从Reddit讨论中构建了其检索语料库，从而捕获了自然发生的错误信息。它将检索到的证据分为三种类型：支持，误导性和无关紧要，为评估抹布系统如何导航不同的检索信息提供了一个现实且具有挑战性的测试床。我们的基准实验表明，当暴露于误导性检索中时，所有经过测试的LLM驱动的抹布系统的表现都比其零射击基线（即根本没有检索）差，突显了它们对嘈杂环境的敏感性。据我们所知，Raguard是系统地评估RAG鲁棒性稳健性的第一个基准。我们预计，这种基准将推动未来的研究，以改善理想化数据集之外的破布系统，从而使其对现实世界应用程序更可靠。]]></description>
      <guid>https://arxiv.org/abs/2502.16101</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Plangen：用于生成计划和推理轨迹的多代理框架，用于解决复杂问题</title>
      <link>https://arxiv.org/abs/2502.16111</link>
      <description><![CDATA[ARXIV：2502.16111V1公告类型：新 
摘要：最近的代理框架和推理时间算法通常由于验证生成的计划或推理或单个任务中实例的复杂性而在复杂的计划问题上遇到困难。这些任务的许多现有方法要么执行任务级验证，而无需考虑约束，要么应用推论时间算法而不适应实例级别的复杂性。为了解决这些局限性，我们提出了Plangen，这是一种模型不合时宜且易于扩展的代理框架，具有三个关键组件：约束，验证和选择剂。具体而言，我们的方法提出了约束引导的迭代验证，以增强推理时间算法的性能 - 最佳的N，思想树和重生。在Plangen框架中，选择代理根据实例复杂性优化算法选择，从而确保更好地适应复杂的计划问题。实验结果表明，在多个基准测试中的最强基线取得了显着改善，从而实现了自然计划的最先进结果（$ \ sim $ 8％$ \ uparrow $），OlympiadBench（$ \ sim $ 4％$ \ uparrow $）， docfinqa（$ \ sim $ 7％$ \ uparrow $）和gpqa（$ \ sim $ 1％$ \ uparrow $）。我们的关键发现强调了限制迭代验证的限制，改善了推理时间算法，自适应选择进一步提高了复杂的计划和推理问题的绩效。]]></description>
      <guid>https://arxiv.org/abs/2502.16111</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>原则上的模式：LLMS在嘈杂观测下的归纳推理的脆弱性</title>
      <link>https://arxiv.org/abs/2502.16169</link>
      <description><![CDATA[arxiv：2502.16169v1公告类型：新 
摘要：归纳推理是人类认知的基石，可以从有限的数据中概括，但尚未通过大语言模型（LLM）完全实现。尽管现代LLM在推理任务上表现出色，但在不完美的观察结果下，它们保持稳定，一致的规则抽象的能力仍然没有得到充实。为了填补这一空白，在这项工作中，我们引入了强大的规则诱导，该任务评估了LLMS从与嘈杂示例融合的数据中推断规则的能力。为了解决此任务，我们进一步提出了样品调节的细化（SRR），这是一种通过观察多元化和执行引导的反馈来增强推理稳定性的方法。跨算术，加密和列表功能的实验揭示了：（1）SRR在噪声下的实验优于其他方法，其性能降低最小； （2）尽管精度有轻微的差异，但LLM在噪声下表现出不稳定的不稳定（例如，0％的精度变化，仅一致的得分为70％）； （3）反事实任务差距突出了LLMS对记忆模式而不是真实抽象的依赖。我们的发现挑战了LLMS的推理鲁棒性，揭示了对假设漂移和模式过度拟合的敏感性，同时提供了对发展类似人类的归纳系统至关重要的经验证据。代码和数据可在\ href {https://github.com/lcy2723/robust-rule-intuction} {https://github.com/lcy.2723/robust-rule-induction} {]]></description>
      <guid>https://arxiv.org/abs/2502.16169</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>欧盟人工智能法中的鲁棒性和网络安全</title>
      <link>https://arxiv.org/abs/2502.16184</link>
      <description><![CDATA[ARXIV：2502.16184V1公告类型：新 
摘要：《欧盟人工智能法》（AIA）为不同类型的AI系统建立了不同的法律原则。尽管先前的工作试图阐明其中一些原则，但很少关注鲁棒性和网络安全。本文旨在填补这一空白。我们确定了与高风险AI系统（ART。15AIA）和通用AI模型（Art。55AIA）相关的规定中的法律挑战和缺点。我们表明，鲁棒性和网络安全需求对性能中断的弹性。此外，我们根据机器学习（ML）文献的最新进步来评估实施这些规定的潜在挑战。我们的分析为制定统一标准，欧洲委员会的指南以及基准和测量方法的努力提供了帮助。 15（2）AIA。因此，我们试图弥合法律术语和ML研究之间的差距，从而在研究和实施工作之间取得更好的一致性。]]></description>
      <guid>https://arxiv.org/abs/2502.16184</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RTL的早期功率，性能和区域估计的机器学习框架</title>
      <link>https://arxiv.org/abs/2502.16203</link>
      <description><![CDATA[ARXIV：2502.16203V1公告类型：新 
摘要：VLSI设计不断发展的景观中的关键阶段是设计阶段，该阶段被转换为寄存器转移级别（RTL），该阶段通过硬件说明语言（如Verilog）指定系统功能。通常，评估RTL设计的质量要求通过电子设计自动化（EDA）工具完全合成，这是耗时的过程，不适合快速设计迭代和优化。尽管机器学习最近的突破（ML）带来了早期的预测模型，但这些方法通常无法提供有关广泛的RTL设计的强大和可推广的解决方案。本文提出了一个前合成框架，该框架可以直接从硬件说明语言（HDL）代码直接使用库文件而不是切换文件来对功率，性能和区域（PPA）指标进行早期估算。所提出的框架引入了一个比特级表示，称为简单操作员图（SOG），该图形使用单位操作员生成了广义且灵活的结构，该结构紧密反映了综合设计后的特征。提出的模型桥接了RTL和后合成设计，这将有助于精确预测关键指标。提出的基于树的ML框架显示出优异的预测性能PPA估计。对147种不同的RTL设计进行了验证。提出的具有147种不同设计的模型显示，WNS，TNS和功率的精度分别为98％，98％和90％，表明相对于最先进的方法而言，精确的准确性提高了。]]></description>
      <guid>https://arxiv.org/abs/2502.16203</guid>
      <pubDate>Tue, 25 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>