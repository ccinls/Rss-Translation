<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>概率人工智能</title>
      <link>https://arxiv.org/abs/2502.05244</link>
      <description><![CDATA[arXiv:2502.05244v1 公告类型：新
摘要：人工智能通常是指人工系统的科学和工程，它可以执行通常与需要人类智能的方面相关的任务，例如玩游戏、翻译语言和驾驶汽车。近年来，基于学习、数据驱动的人工智能方法取得了令人兴奋的进展，机器学习和深度学习使计算机系统能够以前所未有的方式感知世界。强化学习使围棋等复杂游戏和四足运动等具有挑战性的机器人任务取得了突破。
智能的一个关键方面是不仅要做出预测，还要推理这些预测中的不确定性，并在做出决策时考虑这种不确定性。这就是这篇关于“概率人工智能”的手稿的内容。第一部分介绍了机器学习的概率方法。我们讨论了由于缺乏数据而导致的“认知”不确定性与“随机”不确定性之间的区别，后者是不可约化的，例如，源于嘈杂的观察和结果。我们讨论了概率推理的具体方法和高效近似推理的现代方法。
手稿的第二部分是关于在顺序决策任务中考虑不确定性。我们考虑主动学习和贝叶斯优化——通过提出有助于减少认知不确定性的实验来收集数据的方法。然后，我们考虑强化学习和使用神经网络函数逼近的现代深度强化学习方法。最后，我们讨论了基于模型的强化学习中的现代方法，这些方法利用认知和随机不确定性来指导探索，同时还推理安全性。]]></description>
      <guid>https://arxiv.org/abs/2502.05244</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ITBench：评估 AI 代理在各种现实世界 IT 自动化任务中的表现</title>
      <link>https://arxiv.org/abs/2502.05352</link>
      <description><![CDATA[arXiv:2502.05352v1 公告类型：新
摘要：实现使用 AI 代理自动化关键 IT 任务的愿景取决于衡量和理解所提解决方案有效性的能力。我们引入了 ITBench，这是一个框架，它提供了一种系统的方法来对 AI 代理进行基准测试，以解决现实世界的 IT 自动化任务。我们的初始版本针对三个关键领域：站点可靠性工程 (SRE)、合规性和安全运营 (CISO) 和财务运营 (FinOps)。该设计使 AI 研究人员能够通过按钮式工作流和可解释的指标了解 AI 代理在 IT 自动化方面面临的挑战和机遇。ITBench 包括一组初始的 94 个真实场景，可以通过社区贡献轻松扩展。我们的结果表明，由最先进模型驱动的代理仅解决了 13.8% 的 SRE 场景、25.2% 的 CISO 场景和 0% 的 FinOps 场景。我们希望 ITBench 成为正确、安全和快速的 AI 驱动 IT 自动化的关键推动者。]]></description>
      <guid>https://arxiv.org/abs/2502.05352</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过混合人工智能实现元认知的概率基础</title>
      <link>https://arxiv.org/abs/2502.05398</link>
      <description><![CDATA[arXiv:2502.05398v2 公告类型：新
摘要：元认知是关于代理自身内部过程的推理概念，最近它重新引起了人工智能 (AI) 和机器学习系统的关注。本文回顾了一种称为“错误检测和纠正规则”(EDCR) 的混合人工智能方法，该方法允许学习规则来纠正感知（例如神经）模型。此外，我们引入了一个概率框架，为先前的实证研究增加了严谨性，我们使用该框架来证明元认知改进的必要和充分条件的结果，以及该方法的局限性。一组未来的]]></description>
      <guid>https://arxiv.org/abs/2502.05398</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Agentic AI Systems 应用于金融服务中的任务：建模和模型风险管理团队</title>
      <link>https://arxiv.org/abs/2502.05439</link>
      <description><![CDATA[arXiv:2502.05439v1 公告类型：新
摘要：大型语言模型的出现开启了代理系统的新时代，人工智能程序在不同领域表现出卓越的自主决策能力。本文探讨了金融服务行业的代理系统工作流程。特别是，我们建立了能够有效协作执行复杂建模和模型风险管理 (MRM) 任务的代理团队。建模团队由一名经理和多名代理组成，他们执行特定任务，例如探索性数据分析、特征工程、模型选择、超参数调整、模型训练、模型评估和编写文档。MRM 团队由一名经理和专门的代理组成，他们执行的任务包括检查建模文档的合规性、模型复制、概念健全性、结果分析和编写文档。我们通过展示一系列应用于信用卡欺诈检测、信用卡审批和投资组合信用风险建模数据集的数值示例，证明了建模和 MRM 团队的有效性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2502.05439</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适者生存：特工能否生存下来并且依然优秀？</title>
      <link>https://arxiv.org/abs/2502.05442</link>
      <description><![CDATA[arXiv:2502.05442v1 公告类型：新
摘要：随着人工智能模型的强大和通用性不断增强，了解代理如何在复杂环境中学习和做出决策对于促进道德行为至关重要。本文探讨了将生物驱动力（特别是自我保护）应用于三个不同代理的伦理影响。使用 NEAT 优化的贝叶斯代理、使用随机变分推理优化的贝叶斯代理和 GPT 4o 代理玩模拟的、LLM 生成的基于文本的冒险游戏。代理在每种情况下选择行动以求生存，适应日益具有挑战性的场景。模拟后分析评估了代理决策的道德分数，揭示了他们为生存而做出的权衡。具体而言，分析发现，当危险增加时，代理会忽略道德考虑并选择不道德的行为。代理的集体行为，即用道德换取生存，表明优先考虑生存会增加不道德行为的风险。在 AGI 的背景下，设计代理以优先考虑生存可能会增加不道德决策和意外突发行为的可能性，从而引发有关人工智能安全研究中目标设计的基本问题。]]></description>
      <guid>https://arxiv.org/abs/2502.05442</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的去中心化生成代理，具有自适应分层知识图谱，可用于合作规划</title>
      <link>https://arxiv.org/abs/2502.05453</link>
      <description><![CDATA[arXiv:2502.05453v1 公告类型：新
摘要：在动态开放世界场景中开发用于长期合作的智能代理是多智能体系统中的一项重大挑战。传统的多智能体强化学习 (MARL) 框架（如集中训练分散执行 (CTDE)）在可扩​​展性和灵活性方面存在困难。它们需要集中的长期规划，如果没有自定义奖励函数，这很难实现，并且在处理多模态数据时面临挑战。CTDE 方法还假设固定的合作策略，这使得它们在智能体需要独立适应和规划的动态环境中不切实际。为了解决分散的多智能体合作问题，我们在一种新颖的多智能体 Crafter 环境中提出了分散自适应知识图谱记忆和结构化通信系统 (DAMCS)。我们的生成代理由大型语言模型 (LLM) 提供支持，通过利用外部知识和语言进行长期规划和推理，比传统的 MARL 代理更具可扩展性。 DAMCS 并非完全共享所有过去经验的信息，而是引入了多模态记忆系统，该系统以分层知识图谱和结构化通信协议的形式组织，以优化代理协作。这使代理能够从过去的交互中推理并有效地共享相关信息。在新型多代理开放世界任务上的实验表明，DAMCS 在任务效率和协作方面均优于 MARL 和 LLM 基线。与单代理场景相比，双代理场景以少 63% 的步骤实现了相同的目标，而六代理场景以少 74% 的步骤实现了相同的目标，这凸显了自适应记忆和结构化通信在实现长期目标方面的重要性。我们在 https://happyeureka.github.io/damcs 公开发布了我们的项目。]]></description>
      <guid>https://arxiv.org/abs/2502.05453</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分层强化学习的顺序随机组合优化</title>
      <link>https://arxiv.org/abs/2502.05537</link>
      <description><![CDATA[arXiv:2502.05537v1 公告类型：新
摘要：强化学习 (RL) 已成为组合优化 (CO) 问题的有前途的工具，因为它能够学习快速、有效和可推广的解决方案。尽管如此，现有的研究大多集中在一次性确定性 CO，而顺序随机 CO (SSCO) 尽管有广泛的应用，如自适应影响最大化 (IM) 和传染病干预，却很少被研究。在本文中，我们研究了 SSCO 问题，其中我们首先确定所有时间步骤的预算（例如，自适应 IM 中的种子节点数）分配，然后为每个时间步骤选择一组节点。现有的少数关于 SSCO 的研究通过假设时间范围内的预算分配均匀分布来简化问题，从而产生次优解决方案。我们提出了一种通用的分层强化学习 (HRL) 框架，称为唤醒-睡眠选项 (WS-option)，这是一个基于选项的两层框架，可同时决定较高层的自适应预算分配和较低层的节点选择。WS-option 从两层马尔可夫决策过程 (MDP) 的连贯公式开始，捕捉两层决策之间的相互依赖关系。在此基础上，WS-option 采用了几种创新设计来平衡模型的训练稳定性和计算效率，防止两层之间的恶性循环干扰问题。实证结果表明，与传统方法相比，WS-option 表现出显著提高的有效性和通用性。此外，学习到的模型可以推广到更大的图，从而显著降低了计算资源的开销。]]></description>
      <guid>https://arxiv.org/abs/2502.05537</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识就是力量：利用大型语言模型增强认知诊断</title>
      <link>https://arxiv.org/abs/2502.05556</link>
      <description><![CDATA[arXiv:2502.05556v1 公告类型：新
摘要：认知诊断模型 (CDM) 旨在通过分析学生在一系列练习中的表现来评估学生的认知状态。然而，现有的 CDM 通常由于缺乏丰富的先验知识而难以诊断不经常练习的学生和练习。随着拥有广泛领域知识的大型语言模型 (LLM) 的进步，它们融入认知诊断中带来了一个有希望的机会。尽管有这种潜力，但将 LLM 与 CDM 集成仍面临重大挑战。LLM 不太适合捕捉学生和练习之间的细粒度协作交互，而且 LLM 的语义空间与 CDM 的行为空间之间的差异阻碍了有效的集成。为了解决这些问题，我们提出了一种新颖的知识增强认知诊断 (KCD) 框架，这是一个与模型无关的框架，利用 LLM 来增强 CDM 并与各种 CDM 架构兼容。 KCD 框架分为两个阶段：LLM 诊断和认知水平对齐。在 LLM 诊断阶段，对学生和练习进行诊断，以实现全面而详细的建模。在认知水平对齐阶段，我们使用对比学习和掩码重建方法弥合 CDM 的行为空间和 LLM 的语义空间之间的差距。在多个真实世界数据集上的实验证明了我们提出的框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.05556</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缩小基于人工智能的网络管理中的责任差距：智能审计系统方法</title>
      <link>https://arxiv.org/abs/2502.05608</link>
      <description><![CDATA[arXiv:2502.05608v1 公告类型：新
摘要：现有的网络范例通过使用基于人工智能 (AI) 的网络管理工具，实现了更低的停机时间和更高的体验质量 (QoE)。这些人工智能管理系统可以自动响应网络条件的变化，降低运营商的运营成本，并提高整体性能。虽然采用基于人工智能的管理工具可以提高整体网络性能，但它也带来了一些挑战，例如消除人工监督、侵犯隐私、算法偏差和模型不准确。此外，未能解决这些挑战的基于人工智能的代理应该自己承担责任，而不是整个网络。为了解决这一问责差距，提出了一个由深度强化学习 (DRL) 模型和机器学习 (ML) 模型组成的框架，以识别和分配责任数值给参与任何与网络条件有关的决策的基于人工智能的管理代理，最终影响最终用户。创建了一个模拟环境，以便使用模拟网络操作参数对框架进行训练。在测试中，DRL 模型识别基于 AI 的管理代理的准确率为 96%，而使用梯度下降的 ML 模型学习网络状况的准确率为 83%。]]></description>
      <guid>https://arxiv.org/abs/2502.05608</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无定形堡垒在线：协作设计开放式多智能体 AI 和游戏环境</title>
      <link>https://arxiv.org/abs/2502.05632</link>
      <description><![CDATA[arXiv:2502.05632v1 公告类型：新
摘要：本研究介绍了 Amorphous Fortress Online——一个基于网络的平台，用户可以在该平台上设计由多智能体 AI 角色组成的培养皿式环境和游戏。用户可以玩、创建和分享由微观但透明的有限状态机代理组成的人工生命和游戏环境，这些代理彼此交互。该网站具有多个交互式编辑器和可访问的设置，可直接从浏览器查看多智能体交互。该系统用于提供使用简单 AI 代理的突发行为的主题多样的 AI 和游戏环境的数据库。]]></description>
      <guid>https://arxiv.org/abs/2502.05632</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>管理关键矿产供应链中的地质不确定性：POMDP 方法及其在美国锂资源中的应用</title>
      <link>https://arxiv.org/abs/2502.05690</link>
      <description><![CDATA[arXiv:2502.05690v1 公告类型：新 
摘要：受全球向可再生能源技术和电动汽车转型的推动，世界正进入一个前所未有的关键矿产需求时期。这种转变给矿产资源开发带来了独特的挑战，特别是由于地质不确定性——这是传统供应链优化方法无法充分解决的一个关键特征。为了应对这一挑战，我们提出了一种部分可观测马尔可夫决策过程 (POMDP) 的新应用，该过程可优化关键矿产采购决策，同时明确考虑地质不确定性的动态性质。通过对美国锂供应链的案例研究，我们证明基于 POMDP 的政策与传统方法相比取得了更好的结果，尤其是在初始储量估计不完善的情况下。我们的框架为平衡国内资源开发与国际供应多样化提供了定量见解，为政策制定者提供了一种系统的方法来进行关键矿产供应链中的战略决策。]]></description>
      <guid>https://arxiv.org/abs/2502.05690</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人机协同的障碍与途径：博弈论方法</title>
      <link>https://arxiv.org/abs/2502.05934</link>
      <description><![CDATA[arXiv:2502.05934v1 公告类型：新
摘要：在什么条件下，有能力的人工智能代理可以有效地将其行为与人类偏好保持一致？更具体地说，当它们足够熟练地与我们合作时，协调需要多长时间，什么时候在计算上是可行的？这些人工智能对齐的基本问题有助于定义什么使人工智能代理“足够安全”并对人类有价值。由于这种一般能力的系统尚不存在，因此需要进行理论分析以确定保证何时成立——以及它们甚至是什么。
我们引入了一个博弈论框架，该框架以更少的假设概括了先前的对齐方法，使我们能够分析跨 $M$ 个目标和 $N$ 个代理的对齐的计算复杂性，并提供上限和下限。与以前的工作不同，以前的工作通常假设共同的先验、理想化的通信或隐式可处理性，我们的框架在最小假设下正式描述了对齐的难度。
我们的主要结果表明，即使代理完全理性且计算不受限制，对齐也可以在任务空间大小的时间上以高概率实现线性。因此，在现实世界中，任务空间的输入长度通常是指数级的，这仍然是不切实际的。更引人注目的是，我们的下限表明，当扩展到指数级的许多任务或代理时，对齐是不可能加速的，这突出了可扩展对齐的基本计算障碍。
放宽这些理想化的假设，我们研究了具有噪声消息（表示混淆意图）的计算受限的代理，结果表明，虽然对齐仍然可以以高概率成功，但它会导致任务空间大小、代理数量和任务数量的额外指数级减速。
我们最后确定了使对齐更可行的条件。]]></description>
      <guid>https://arxiv.org/abs/2502.05934</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MetaChain：LLM 代理的全自动零代码框架</title>
      <link>https://arxiv.org/abs/2502.05957</link>
      <description><![CDATA[arXiv:2502.05957v1 公告类型：新 
摘要：大型语言模型 (LLM) 代理在任务自动化和智能决策方面表现出了卓越的能力，推动了 LangChain 和 AutoGen 等代理开发框架的广泛采用。然而，这些框架主要服务于具有丰富技术专业知识的开发人员——考虑到全球只有 0.03% 的人口具备必要的编程技能，这是一个很大的限制。这种明显的可访问性差距提出了一个基本问题：我们能否让每个人，无论技术背景如何，仅使用自然语言就能构建自己的 LLM 代理？为了应对这一挑战，我们引入了 MetaChain——一个全自动、高度自我开发的框架，使用户能够仅通过自然语言创建和部署 LLM 代理。作为一个自主的代理操作系统，MetaChain 包含四个关键组件：i) 代理系统实用程序、ii) LLM 驱动的可操作引擎、iii) 自我管理文件系统和 iv) 自玩代理定制模块。这个轻量级但功能强大的系统能够高效、动态地创建和修改工具、代理和工作流程，无需编码或人工干预。除了无代码代理开发功能外，MetaChain 还可用作通用 AI 助手的多功能多代理系统。对 GAIA 基准的全面评估表明，MetaChain 在通用多代理任务中的有效性超越了现有的最先进方法。此外，与许多基于 LLM 的替代解决方案相比，MetaChain 的检索增强生成 (RAG) 相关功能始终表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.05957</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多智能体强化学习训练社交推理语言模型</title>
      <link>https://arxiv.org/abs/2502.06060</link>
      <description><![CDATA[arXiv:2502.06060v1 公告类型：新
摘要：在多智能体环境中，使用自然语言进行交流是一种强大的工具，因为它使独立智能体能够在部分可观察的环境中共享信息，并允许与人类进行零样本协调。然而，大多数先前的研究都受到限制，因为它们要么依赖于大量人类演示的训练，要么缺乏生成自然和有用的沟通策略的能力。在这项工作中，我们训练语言模型，使其能够使用自然语言就其环境进行富有成效的讨论，而无需任何人类演示。我们将沟通问题分解为倾听和说话。我们的主要思想是利用智能体的目标来预测有关世界的有用信息，作为指导交流的密集奖励信号。具体来说，我们通过训练模型根据讨论预测有关环境的信息来提高模型的倾听技能，同时通过多智能体强化学习通过根据消息对其他智能体的影响来奖励消息来提高模型的说话技能。为了研究沟通在复杂社交环境中的作用和必要性，我们研究了一款基于《我们之中》的具身社交推理游戏，其中需要回答的关键问题是对抗冒名顶替者的身份。我们分析了由于我们的技术而出现的行为，例如指控嫌疑人和提供证据，并发现它可以促进激烈的讨论，与标准 RL 相比，胜率提高了一倍。我们在 https://socialdeductionllm.github.io/ 上发布了我们的代码和模型]]></description>
      <guid>https://arxiv.org/abs/2502.06060</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息在人机决策中的价值</title>
      <link>https://arxiv.org/abs/2502.06152</link>
      <description><![CDATA[arXiv:2502.06152v1 公告类型：新
摘要：人类和人工智能经常配对执行决策任务，期望实现互补性能，其中人类和人工智能的结合优于其中任何一种单独执行。然而，如果不了解每个代理使用的特定信息和策略，如何提高人机团队的性能通常并不清楚。我们提供了一个决策理论框架，用于描述信息的价值——从而为代理提供在人工智能辅助决策工作流程中更好地利用可用信息的机会。我们展示了该框架在模型选择、人机性能的实证评估和解释设计中的应用。我们提出了一种新颖的基于信息的实例级解释技术，该技术采用传统的基于显着性的解释来解释决策中的信息价值。]]></description>
      <guid>https://arxiv.org/abs/2502.06152</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>期望-冷漠框架中的条件作用和 AGM 类信念变化</title>
      <link>https://arxiv.org/abs/2502.06235</link>
      <description><![CDATA[arXiv:2502.06235v1 公告类型：新
摘要：我们展示了如何扩展 AGM 信念变化框架（扩展、修订、收缩），以处理所谓的可取性-无差异框架中的条件，该框架基于接受和拒绝选项的抽象概念以及事件的抽象概念。这种抽象级别使我们能够同时处理经典和量子概率论。]]></description>
      <guid>https://arxiv.org/abs/2502.06235</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AppVLM：用于在线应用程序控制的轻量级视觉语言模型</title>
      <link>https://arxiv.org/abs/2502.06395</link>
      <description><![CDATA[arXiv:2502.06395v1 公告类型：新
摘要：将基础模型用作智能手机助手（称为应用代理）是一项关键的研究挑战。这些代理旨在通过解释文本指令并通过设备界面执行操作来在智能手机上执行人类指令。虽然前景看好，但当前的方法面临着重大限制。使用大型专有模型（例如 GPT-4o）的方法计算成本高昂，而使用较小的微调模型的方法通常缺乏对分布外任务的适应性。在这项工作中，我们引入了轻量级视觉语言模型 (VLM) AppVLM。首先，我们在 AndroidControl 数据集上对其进行离线微调。然后，我们通过从 AndroidWorld 环境收集数据并执行进一步的训练迭代来完善其策略。我们的结果表明，与所有评估基线相比，AppVLM 在 AndroidControl 数据集的离线评估中实现了最高的动作预测准确率，并且在 AndroidWorld 环境中的在线任务完成成功率与 GPT-4o 相匹配，同时速度提高了十倍。这使得 AppVLM 成为实际部署的实用且高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.06395</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>POMDP 的更严格的值函数近似</title>
      <link>https://arxiv.org/abs/2502.06523</link>
      <description><![CDATA[arXiv:2502.06523v1 公告类型：新
摘要：解决部分可观察马尔可夫决策过程 (POMDP) 通常需要推理指数级多状态信念的值。为了实现实际性能，最先进的求解器使用值界限来指导这种推理。然而，合理的上限值边界通常在计算上很昂贵，并且这种边界的紧密度与其计算成本之间存在权衡。本文介绍了一种新的、可证明比常用的快速知情边界更严格的上限值边界。我们的实证评估表明，尽管新的上限值边界增加了计算开销，但它可以在广泛的基准测试中加速最先进的 POMDP 求解器。]]></description>
      <guid>https://arxiv.org/abs/2502.06523</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们能相信人工智能基准吗？人工智能评估当前问题的跨学科回顾</title>
      <link>https://arxiv.org/abs/2502.06559</link>
      <description><![CDATA[arXiv:2502.06559v1 公告类型：新
摘要：定量人工智能 (AI) 基准已成为评估 AI 模型和系统的性能、能力和安全性的基本工具。目前，它们决定了 AI 发展的方向，并在监管框架中发挥着越来越重要的作用。然而，随着它们的影响力不断扩大，人们对它们如何以及以何种影响来评估高度敏感的话题（例如能力，包括高影响能力、安全性和系统性风险）的担忧也在不断增加。本文对过去 10 年发表的约 100 项研究进行了跨学科的元评论，讨论了定量基准测试实践中的缺点。它将基准测试设计和应用中的许多细粒度问题（例如数据集创建中的偏差、文档不足、数据污染以及无法区分信号和噪声）与更广泛的社会技术问题（例如过于注重根据一次性测试逻辑评估基于文本的 AI 模型，而这种逻辑未能解释 AI 模型如何日益多模式化并与人类和其他技术系统交互）结合在一起。我们的审查还强调了当前基准测试实践中的一系列系统性缺陷，例如激励机制不一致、构建有效性问题、未知的未知数以及基准测试结果游戏问题。此外，它强调了基准测试实践如何从根本上受到文化、商业和竞争动态的影响，这些动态往往优先考虑最先进的性能而忽略了更广泛的社会关注。通过概述与现有基准测试程序相关的风险，我们解决了对基准测试的过度信任问题，并为持续努力提高定量 AI 基准在现实场景复杂性中的可问责性和相关性做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2502.06559</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论效用在半值数据估值中的影响</title>
      <link>https://arxiv.org/abs/2502.06574</link>
      <description><![CDATA[arXiv:2502.06574v1 公告类型：新
摘要：机器学习 (ML) 中的基于半值的数据评估通过利用合作博弈论和效用概念的原理来量化单个数据点对下游 ML 任务的贡献。虽然该框架已在实践中用于评估数据质量，但我们的实验表明，不同效用之间的评估结果不一致，尽管所有这些都与 ML 性能有关。除了引起对数据评估可靠性的担忧之外，这种不一致性很难解释，因为它源于效用与数据点和半值权重的复杂相互作用，这在先前的工作中几乎没有研究过。在本文中，我们迈出了阐明效用对基于半值的数据评估的影响的第一步。具体而言，我们为广泛的分类效用系列提供了这种影响的几何解释，其中包括准确性和算术平均值。我们引入了空间特征的概念：给定一个半值，数据点可以嵌入到二维空间中，效用函数映射到该空间的对偶。这种几何视角将数据集和半值的影响与效用的影响分开，为实验观察到的估值结果对效用选择的敏感性提供了理论解释。]]></description>
      <guid>https://arxiv.org/abs/2502.06574</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>