<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 30 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>多模态基准调查：大型 AI 模型时代</title>
      <link>https://arxiv.org/abs/2409.18142</link>
      <description><![CDATA[arXiv:2409.18142v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 的快速发展为人工智能带来了重大进步，显著增强了理解和生成多模态内容的能力。虽然先前的研究主要集中在模型架构和训练方法上，但对用于评估这些模型的基准的彻底分析仍未得到充分探索。本调查通过系统地回顾 211 个评估 MLLM 的基准来解决这一差距，这些基准涵盖四个核心领域：理解、推理、生成和应用。我们对不同模态的任务设计、评估指标和数据集构造进行了详细的分析。我们希望这项调查能够通过提供基准测试实践的全面概述并确定未来工作的有希望的方向，为 MLLM 研究的持续发展做出贡献。一个相关的 GitHub 存储库收集了最新的论文。]]></description>
      <guid>https://arxiv.org/abs/2409.18142</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Data-Prep-Kit：为 LLM 应用程序开发准备好数据</title>
      <link>https://arxiv.org/abs/2409.18164</link>
      <description><![CDATA[arXiv:2409.18164v1 公告类型：新
摘要：数据准备是任何大型语言模型 (LLM) 开发的第一步，也是非常重要的一步。本文介绍了一种易于使用、可扩展且可扩展的开源数据准备工具包，称为 Data Prep Kit (DPK)。DPK 的架构和设计旨在使用户能够根据需要扩展数据准备。使用 DPK，他们可以在本地机器上准备数据，也可以毫不费力地扩展到在具有数千个 CPU 核心的集群上运行。DPK 附带一组高度可扩展且可扩展的模块，可转换自然语言和代码数据。如果用户需要额外的转换，可以使用广泛的 DPK 支持轻松开发它们以进行转换创建。这些模块可以独立使用，也可以通过流水线执行一系列操作。在本文中，我们描述了 DPK 架构，并展示了其从小规模到大量 CPU 的性能。DPK 的模块已用于准备 Granite 模型 [1] [2]。我们相信 DPK 对 AI 社区做出了宝贵贡献，可以轻松准备数据以增强其 LLM 模型的性能或使用检索增强生成 (RAG) 来微调模型。]]></description>
      <guid>https://arxiv.org/abs/2409.18164</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用强化学习实现自主网络防御</title>
      <link>https://arxiv.org/abs/2409.18197</link>
      <description><![CDATA[arXiv:2409.18197v1 公告类型：新
摘要：在网络安全军备竞赛中，防御者处于明显劣势，因为他们需要成功检测并反击每一次恶意攻击。相比之下，攻击者只需成功一次即可。为了公平竞争，我们研究了自主代理在现实网络防御场景中的有效性。我们首先概述了问题，提供了强化学习的背景并详细介绍了我们提出的代理设计。使用网络环境模拟，其中有 13 个主机跨越 3 个子网，我们训练了一个新颖的强化学习代理，并表明它可以可靠地防御两个高级持续威胁 (APT) 红色代理的持续攻击：一个完全了解网络布局，另一个必须通过探索发现资源但更为通用。]]></description>
      <guid>https://arxiv.org/abs/2409.18197</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMMT-IF：具有挑战性的多模式多转弯指令跟随基准</title>
      <link>https://arxiv.org/abs/2409.18216</link>
      <description><![CDATA[arXiv:2409.18216v1 公告类型：新
摘要：评估多模式、多轮对话的指令遵循能力具有挑战性。由于输入模型上下文中可能存在多条指令，因此这项任务对于人类评分者来说非常耗时，而且我们表明基于 LLM 的评委偏向于来自同一模型的答案。我们提出了 MMMT-IF，这是一种基于图像的多轮问答评估集，在问题之间添加了全局指令，以限制答案格式。这要求模型检索分散在长对话中的指令并在指令约束下进行推理。所有指令都可以通过代码执行进行客观验证。我们引入了程序指令遵循 ($\operatorname{PIF}$) 指标来衡量在执行推理任务时正确遵循的指令的比例。 $\operatorname{PIF-N-K}$ 指标集通过测量语料库中样本的比例来进一步评估稳健性，其中对于每个样本，N 个生成的模型响应中至少有 K 个获得 $\operatorname{PIF}$ 分数为 1。$\operatorname{PIF}$ 指标与评级后的人类指令一致，显示出 60% 的相关性。实验表明，Gemini 1.5 Pro、GPT-4o 和 Claude 3.5 Sonnet 的 $\operatorname{PIF}$ 指标从模型中第 1 轮的平均 0.81 下降到第 20 轮的 0.64。在所有轮次中，当每个响应重复 4 次（$\operatorname{PIF-4-4}$）时，GPT-4o 和 Gemini 只有 $11\%$ 的时间成功遵循所有指令。当所有指令也附加到模型输入上下文的末尾时，$\operatorname{PIF}$ 指标平均提高了 22.3 分，这表明该任务的挑战不仅在于遵循指令，还在于检索分散在模型上下文中的指令。我们计划开源 MMMT-IF 数据集和指标计算代码。]]></description>
      <guid>https://arxiv.org/abs/2409.18216</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>值得信赖的人工智能：保护大型语言模型中的敏感数据</title>
      <link>https://arxiv.org/abs/2409.18222</link>
      <description><![CDATA[arXiv:2409.18222v1 公告类型：新
摘要：大型语言模型 (LLM) 通过实现强大的文本生成和理解，改变了自然语言处理 (NLP)。然而，它们在医疗保健、金融和法律服务等敏感领域的部署引发了人们对隐私和数据安全的严重担忧。本文提出了一个全面的框架，将信任机制嵌入 LLM，以动态控制敏感信息的披露。该框架集成了三个核心组件：用户信任分析、信息敏感性检测和自适应输出控制。通过利用基于角色的访问控制 (RBAC)、基于属性的访问控制 (ABAC)、命名实体识别 (NER)、上下文分析和差异隐私等隐私保护方法等技术，系统可确保根据用户的信任级别适当地披露敏感信息。通过专注于平衡数据效用和隐私，所提出的解决方案提供了一种在高风险环境中安全部署 LLM 的新方法。未来的工作将集中在各个领域测试该框架，以评估其在保持系统效率的同时管理敏感数据的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.18222</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>前列腺癌收件箱消息的回顾性比较分析：封闭域法学硕士与临床团队的回应</title>
      <link>https://arxiv.org/abs/2409.18290</link>
      <description><![CDATA[arXiv:2409.18290v1 公告类型：新
摘要：收件箱消息交互在医患沟通中起着至关重要的作用，发生在患者护理过程的所有阶段（前、中、后）。然而，回复这些患者的询问已经成为医疗保健工作流程的沉重负担，耗费了临床护理团队大量的时间。为了解决这个问题，我们推出了 RadOnc-GPT，这是一种由 GPT-4 提供支持的专门的大型语言模型 (LLM)，其设计重点是前列腺癌的放射治疗，具有先进的提示工程，专门用于协助生成响应。我们将 RadOnc-GPT 与来自全院 EHR 数据库和内部放射肿瘤学专用数据库的患者电子健康记录 (EHR) 集成在一起。RadOnc-GPT 在 158 个之前记录的收件箱消息交互上进行了评估。定量自然语言处理 (NLP) 分析和两项针对临床医生和护士的评分研究用于评估 RadOnc-GPT 的响应。我们的研究结果表明，RadOnc-GPT 在“清晰度”和“同理心”方面略胜于临床护理团队，而在“完整性”和“正确性”方面取得了相当的分数。据估计，从阅读询问到发送回复，RadOnc-GPT 可为护士节省每条消息 5.2 分钟，为临床医生节省 2.4 分钟。使用 RadOnc-GPT 生成收件箱消息草稿有可能减轻临床护理团队的工作量，并通过生成高质量、及时的响应来降低医疗保健成本。]]></description>
      <guid>https://arxiv.org/abs/2409.18290</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用动态模板约束大型语言模型进行肺癌筛查的跨机构结构化放射学报告</title>
      <link>https://arxiv.org/abs/2409.18319</link>
      <description><![CDATA[arXiv:2409.18319v1 公告类型：新
摘要：结构化放射学报告有利于优化临床工作流程和患者结果。当前 LLM 在创建结构化报告时面临着格式错误、内容幻觉和上传到外部服务器时隐私泄露问题的挑战。我们的目标是开发一个增强的开源 LLM，用于从自由文本描述创建结构化和标准化的 LCS 报告。在机构 IRB 批准后，回顾性分析了来自两家机构的 5,442 份去识别的 LCS 报告。从两个机构中平均随机选择 500 份报告，然后手动标记以进行评估。来自两家机构的两名放射科医生开发了一个标准化模板，其中包括 29 个肺结节报告特征。我们提出了模板约束解码来增强最先进的开源 LLM，包括 LLAMA、Qwen 和 Mistral。从 F1 分数、置信区间、McNemar 检验和 z 检验等方面对 LLM 性能进行了广泛评估。基于从大规模数据集创建的结构化报告，我们制作了一个结节级检索系统的原型，并进行了自动统计分析。我们的软件 vLLM-structure 可公开用于本地部署，并具有增强的 LLM。我们的模板约束解码方法持续提高了多机构数据集上的 LLM 性能，既没有格式错误，也没有内容幻觉。我们的方法将最佳开源 LLAMA-3.1 405B 提高了 10.42%，比 GPT-4o 高出 17.19%。我们利用增强的 LLM 技术成功制作了一个新型结节检索系统的原型，并在大型多模态数据库上进行了演示。自动得出的统计分布在结节类型、位置、大小、状态和 Lung-RADS 方面与之前的发现非常一致。]]></description>
      <guid>https://arxiv.org/abs/2409.18319</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GPU 中与输入相关的功耗</title>
      <link>https://arxiv.org/abs/2409.18324</link>
      <description><![CDATA[arXiv:2409.18324v1 公告类型：新
摘要：众所周知，GPU 耗电量大，由于人工智能的蓬勃发展，它们目前是未来数据中心高功耗需求的主要贡献者。在这些流行的工作负载中，大多数 GPU 使用都由大型通用矩阵-矩阵乘法 (GEMM) 组成，因此这些乘法已经过优化，可以实现硬件资源的高利用率。在这项工作中，我们表明，修改 GEMM 的输入数据，同时保持矩阵形状和大小，可以显著改变这些内核的功耗。我们尝试了四种输入变化：值分布、位相似性、位置和稀疏性，涉及不同的数据类型。我们的研究结果表明，这些变化可以使 GEMM 期间的 GPU 功耗改变近 40%。我们假设，由于 GPU 中位翻转次数的变化，会发生与输入相关的功耗变化。我们建议通过编译器和调度程序优化来利用此属性来管理电源并降低能耗。]]></description>
      <guid>https://arxiv.org/abs/2409.18324</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种以公平为导向的学习人类兼容谈判策略的方法</title>
      <link>https://arxiv.org/abs/2409.18335</link>
      <description><![CDATA[arXiv:2409.18335v1 公告类型：新
摘要：尽管人工智能和自然语言处理最近取得了进展，但谈判仍然是人工智能代理面临的一个难题。传统的博弈论方法在双人零和博弈中效果很好，但由于无法学习与人类兼容的策略，它们在谈判中举步维艰。另一方面，仅使用人类数据的方法往往是特定领域的，缺乏博弈论策略所提供的理论保证。受公平性作为一般和博弈中最优性标准的启发，我们提出了一个名为 FDHC 的谈判框架，该框架将公平性纳入奖励设计和搜索中，以学习与人类兼容的谈判策略。我们的方法包括一种新颖的 RL+搜索技术 LGM-Zero，它利用预先训练的语言模型从大型动作空间中检索与人类兼容的提议。我们的结果表明，我们的方法能够实现更平等的谈判结果并提高谈判质量。]]></description>
      <guid>https://arxiv.org/abs/2409.18335</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 RL 微调改善自动驾驶的代理行为</title>
      <link>https://arxiv.org/abs/2409.18343</link>
      <description><![CDATA[arXiv:2409.18343v1 公告类型：新
摘要：自动驾驶汽车研究中的一个主要挑战是建模代理行为，它具有关键的应用，包括为车外评估构建逼真可靠的模拟，以及为车内规划预测交通代理运动。虽然监督学习已在各个领域的代理建模中取得成功，但这些模型在测试时部署时可能会受到分布变化的影响。在这项工作中，我们通过使用强化学习对行为模型进行闭环微调来提高代理行为的可靠性。我们的方法在 Waymo Open Sim Agents 挑战赛中展示了改进的整体性能，以及改进的目标指标，例如碰撞率。此外，我们提出了一种新颖的策略评估基准，以直接评估模拟代理衡量自动驾驶汽车规划器质量的能力，并证明我们的方法在这个新基准上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.18343</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度卷积网络进行非结构化道路上自动驾驶的多模态轨迹预测</title>
      <link>https://arxiv.org/abs/2409.18399</link>
      <description><![CDATA[arXiv:2409.18399v1 公告类型：新 
摘要：近年来，自动驾驶在露天采矿中的应用越来越受到关注，以实现安全高效的矿物运输。与城市结构化道路相比，矿区非结构化道路边界不均匀，缺乏明确界定的车道标记。这导致缺乏足够的约束信息来预测其他人为驾驶车辆的轨迹，从而导致轨迹预测问题的不确定性更高。提出了一种预测目标车辆的多种可能轨迹及其概率的方法。目标车辆的周围环境和历史轨迹被编码为光栅化图像，用作深度卷积网络的输入，以预测目标车辆的多种可能轨迹。该方法在专门为露天采矿自动驾驶场景设计的数据集上进行了离线测试，并与基于物理的方法进行了比较和评估。开源代码和数据可在 https://github.com/LLsxyc/mine_motion_prediction.git 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.18399</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自闭症严重程度检测的物理增强元组变换器</title>
      <link>https://arxiv.org/abs/2409.18438</link>
      <description><![CDATA[arXiv:2409.18438v1 公告类型：新
摘要：自闭症谱系障碍 (ASD) 的早期诊断是改善自闭症儿童健康和福祉的有效且有利的一步。手动 ASD 诊断测试劳动密集、复杂，并且由于多种因素影响结果，容易出现人为错误。本文提出了一种利用物理定律识别 ASD 严重程度的新框架。所提出的基于物理的神经网络架构对通过在更高维潜在空间中观察基于骨架的运动轨迹的一部分来提取的主体行为进行编码。两个解码器，即基于物理和非基于物理的解码器，使用这种潜在嵌入并预测未来的运动模式。物理分支利用适用于预测过程中的骨架序列的物理定律，而非基于物理的分支则经过优化，以最小化主体的预测运动和实际运动之间的差异。分类器还利用相同的潜在空间嵌入来识别 ASD 严重程度。这种双重生成目标明确地迫使网络将受试者的实际行为与受物理定律支配的儿童的一般正常行为进行比较，从而帮助完成 ASD 识别任务。所提出的方法在多个 ASD 诊断基准上获得了最先进的性能。为了说明所提出的框架在 ASD 诊断任务之外的实用性，我们使用公开可用的跌倒预测任务基准进行了第三次实验，并展示了我们模型的优越性。]]></description>
      <guid>https://arxiv.org/abs/2409.18438</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用自注意力和进化强化学习进行成本感知动态云工作流调度</title>
      <link>https://arxiv.org/abs/2409.18444</link>
      <description><![CDATA[arXiv:2409.18444v1 公告类型：新
摘要：云端成本感知动态多工作流调度 (CDMWS) 是一种云工作流管理问题，旨在分配虚拟机 (VM) 实例来执行工作流中的任务，以最小化总成本，包括违反服务水平协议 (SLA) 的罚款和 VM 租赁费。在深度神经网络的支持下，强化学习 (RL) 方法可以构建有效的调度策略来解决 CDMWS 问题。RL 中的传统策略网络通常使用基本的前馈架构来单独确定分配任何 VM 实例的适用性，而不会同时考虑所有 VM 来了解它们的全局信息。本文提出了一种用于云工作流调度的新型自注意策略网络 (SPN-CWS)，它可以从所有 VM 中捕获全局信息。我们还开发了一个基于进化策略的 RL (ERL) 系统来可靠有效地训练 SPN-CWS。经过训练的 SPN-CWS 可以同时有效地处理所有候选 VM 实例，以识别最适合执行每个工作流任务的 VM 实例。综合实验表明，我们的方法在多个基准 CDMWS 问题上的表现明显优于几种最先进的算法。]]></description>
      <guid>https://arxiv.org/abs/2409.18444</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能时代的数据分析</title>
      <link>https://arxiv.org/abs/2409.18475</link>
      <description><![CDATA[arXiv:2409.18475v1 公告类型：新
摘要：本文探讨了人工智能工具重塑数据分析的潜力，重点关注设计考虑和挑战。我们探讨了大型语言和多模态模型的出现如何通过将高级用户意图转化为可执行代码、图表和见解来为增强数据分析工作流程的各个阶段提供新的机会。然后，我们研究以人为本的设计原则，这些原则促进了直观的交互，建立了用户信任，并简化了跨多个应用程序的人工智能辅助分析工作流程。最后，我们讨论了阻碍这些基于人工智能的系统开发的研究挑战，例如增强模型能力、评估和基准测试以及了解最终用户的需求。]]></description>
      <guid>https://arxiv.org/abs/2409.18475</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Align$^2$LLaVA：用于多模态教学策划的级联人类和大型语言模型偏好对齐</title>
      <link>https://arxiv.org/abs/2409.18541</link>
      <description><![CDATA[arXiv:2409.18541v1 公告类型：新 
摘要：多模态大型语言模型 (MLLM)（例如 LLaVA 系列模型）的最新进展是由大量机器生成的指令跟踪数据调整驱动的。然而，这种自动指令收集管道无意中引入了数据质量的显著变化。本文介绍了一种新颖的指令管理算法，该算法源自两个独特的视角，即人类和 LLM 偏好对齐，以将大量机器生成的多模态指令压缩为紧凑且高质量的形式：（i）对于人类偏好对齐，我们收集了机器生成的多模态指令数据集并建立了一套全面的主观和客观标准，以指导人类专家进行数据质量评估。通过这样做，在带注释的数据集上训练了一个奖励模型，以内化人类对指令对齐的细微理解。 (ii) 对于 LLM 偏好对齐，给定奖励模型选择的指令，我们建议利用 MLLM 中使用的内部 LLM 将视觉指令的编写风格与内部 LLM 本身的编写风格对齐，从而实现 LLM 对齐指令的改进。大量实验表明，我们可以通过将合成多模态指令压缩高达 90% 来保持甚至提高模型性能。令人印象深刻的是，通过将总训练样本大小从 158k 大幅减少到 14k（小 9$\times$），我们的模型在各种 MLLM 基准测试中始终优于其全尺寸数据集对应模型。我们的项目可在 https://github.com/DCDmllm/Align2LLaVA 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.18541</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有管道架构的目标导向型客户服务聊天机器人的机器学习模型的实验评估</title>
      <link>https://arxiv.org/abs/2409.18568</link>
      <description><![CDATA[arXiv:2409.18568v1 公告类型：新
摘要：将机器学习 (ML) 集成到客户服务聊天机器人中可增强其理解和响应用户查询的能力，最终提高服务性能。但是，对于某些用户来说，它们可能显得不自然，并影响客户体验。因此，对每个管道组件的 ML 模型进行细致评估对于优化性能至关重要，尽管功能的差异可能会导致不公平的比较。在本文中，我们针对具有管道架构的目标导向型客户服务聊天机器人提出了一种量身定制的实验评估方法，重点关注三个关键组件：自然语言理解 (NLU)、对话管理 (DM) 和自然语言生成 (NLG)。我们的方法强调个人评估以确定最佳 ML 模型。具体而言，我们专注于优化超参数并评估 NLU（利用 BERT 和 LSTM）、DM（采用 DQN 和 DDQN）和 NLG（利用 GPT-2 和 DialoGPT）的候选模型。结果表明，对于 NLU 组件，BERT 在意图检测方面表现出色，而 LSTM 在槽位填充方面更胜一筹。对于 DM 组件，DDQN 模型的表现优于 DQN，因为它实现了更少的轮次、更高的奖励以及更高的成功率。对于 NLG，大型语言模型 GPT-2 在 BLEU、METEOR 和 ROUGE 指标上超越了 DialoGPT。这些发现旨在为未来开发和优化客户服务聊天机器人的研究提供基准，为模型性能和最佳超参数提供宝贵见解。]]></description>
      <guid>https://arxiv.org/abs/2409.18568</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“哦，法学硕士，我问你，请给我一个决策树”：使用大型语言模型进行零样本决策树归纳和嵌入</title>
      <link>https://arxiv.org/abs/2409.18594</link>
      <description><![CDATA[arXiv:2409.18594v1 公告类型：新
摘要：大型语言模型 (LLM) 提供了强大的手段来利用先验知识进行预测建模，当数据有限时。在这项工作中，我们展示了 LLM 如何使用其压缩的世界知识来生成本质上可解释的机器学习模型，即决策树，而无需任何训练数据。我们发现这些零样本决策树可以在一些小型表格数据集上超越数据驱动的树，并且从这些树派生的嵌入平均表现与数据驱动的基于树的嵌入相当。因此，我们的知识驱动的决策树归纳和嵌入方法为低数据环境下的数据驱动机器学习方法提供了强大的新基线。]]></description>
      <guid>https://arxiv.org/abs/2409.18594</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ASAG2024：简答题评分综合基准</title>
      <link>https://arxiv.org/abs/2409.18596</link>
      <description><![CDATA[arXiv:2409.18596v1 公告类型：新
摘要：开放式问题比封闭式问题更能测试学生的理解程度，通常是首选的评估方法。然而，开放式问题评分繁琐，容易受到个人偏见的影响。因此，人们一直在努力通过自动化来加快评分过程。简答评分 (SAG) 系统旨在自动对学生的答案进行评分。尽管 SAG 方法和能力有所增长，但目前还没有跨不同科目、评分标准和分布的综合简答评分基准。因此，很难评估当前自动评分方法的通用性。在这项初步工作中，我们引入了组合 ASAG2024 基准，以方便自动评分系统的比较。将七个常用的简答评分数据集组合在一个通用的结构和评分标准中。为了进行基准测试，我们评估了一组最新的 SAG 方法，结果表明，虽然基于 LLM 的方法取得了新的高分，但它们仍远未达到人类的表现。这为未来人机 SAG 系统的研究开辟了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.18596</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督认知</title>
      <link>https://arxiv.org/abs/2409.18624</link>
      <description><![CDATA[arXiv:2409.18624v1 公告类型：新
摘要：无监督学习方法对认知模型有启发作用。到目前为止，最成功的无监督学习方法都围绕着数学空间中的样本聚类。在本文中，我们提出了一种最先进的基于原始的无监督学习方法，用于受新认知模型启发的决策。这种以表示为中心的方法以与输入无关的方式将输入空间建设性地建模为分布式层次结构。我们将我们的方法与无监督学习分类中的最新技术以及癌症类型分类中的最新技术进行了比较。我们展示了我们的提案如何优于以前的最先进技术。我们还评估了我们的提案的一些类似认知的属性，它不仅优于比较的算法（甚至是监督学习算法），而且还表现出不同的、更像认知的行为。]]></description>
      <guid>https://arxiv.org/abs/2409.18624</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用搜索算法反驳谱图论猜想</title>
      <link>https://arxiv.org/abs/2409.18626</link>
      <description><![CDATA[arXiv:2409.18626v1 公告类型：新
摘要：我们对自动反驳谱图论猜想很感兴趣。大多数现有工作要么通过有限大小的图的详尽生成，要么通过深度强化学习来解决这个问题。详尽生成受生成图的大小限制，而深度强化学习需要数小时或数天才能反驳一个猜想。我们建议使用搜索算法来解决这些缺点，以在几秒钟内找到谱图论猜想的潜在大反例。我们将广泛的搜索算法应用于 Graffiti 中的一系列猜想。在 Graffiti 中已经驳斥的 13 个猜想中，我们的算法能够在几秒钟内驳斥 12 个。我们还驳斥了 Graffiti 中迄今为止开放的第 197 个猜想。]]></description>
      <guid>https://arxiv.org/abs/2409.18626</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>