<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>论证与机器学习</title>
      <link>https://arxiv.org/abs/2410.23724</link>
      <description><![CDATA[arXiv:2410.23724v1 公告类型：新
摘要：本章概述了研究工作，这些工作提出了计算论证和机器学习之间某种程度的相互影响的方法。我们对文献的回顾确定了两个广泛的主题，代表了这两个领域之间相互作用的目的：机器学习的论证和论证的机器学习。在这两个主题中，我们系统地评估了各个维度的作品范围，包括学习类型和使用的论证框架形式。此外，我们确定了这两个领域之间的三种相互作用类型：协同方法，其中论证和机器学习组件紧密集成；分段方法，其中两者交错，使得一个组件的输出是另一个组件的输入；近似方法，其中一个组件在选定的细节级别上遮蔽另一个组件。我们得出关于某些形式的论证是否适合支持某些类型的机器学习的结论，反之亦然，从审查中可以看出清晰的模式。虽然所评论的作品为成功结合这两个研究领域提供了启发，但我们也确定并讨论了需要解决的局限性和挑战，以确保它们在人工智能进步的过程中仍然是富有成效的组合。]]></description>
      <guid>https://arxiv.org/abs/2410.23724</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现可靠的对齐：不确定性感知的 RLHF</title>
      <link>https://arxiv.org/abs/2410.23726</link>
      <description><![CDATA[arXiv:2410.23726v1 公告类型：新
摘要：大型语言模型与人类偏好对齐的最新进展得益于更大的奖励模型和更好的偏好数据。然而，这些方法中的大多数都依赖于奖励模型的准确性。强化学习与人类反馈 (RLHF) 中使用的奖励模型通常使用随机优化算法从小数据集中学习，因此容易出现高度可变性。我们在众多开源数据集上通过经验说明了奖励模型之间的不一致性。
我们从理论上表明，奖励模型的波动可能对对齐问题有害，因为派生的策略更适合奖励模型，因此如果奖励模型本身不确定，则风险更大。我们使用测量集中来激励一种不确定性感知的保守策略优化算法。我们表明，这种政策更具风险规避性，因为它们对不确定的奖励更加谨慎。我们从理论上证明了我们提出的方法比原始方法风险更小。
我们通过基于设计一组奖励模型的实验证实了我们的理论结果。我们使用这组奖励模型来使用我们的方法对齐语言模型，并观察到我们的实证结果与我们的理论预测相符。]]></description>
      <guid>https://arxiv.org/abs/2410.23726</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>编辑后模型性能下降的原因及解决方法</title>
      <link>https://arxiv.org/abs/2410.23843</link>
      <description><![CDATA[arXiv:2410.23843v1 公告类型：new 
摘要：知识编辑技术因能够低成本更新大规模语言模型中不正确或过时的知识而受到广泛关注。然而近期研究发现，编辑后的模型往往会表现出不同程度的性能下降，这一现象背后的原因及潜在的解决方案尚未给出。为了探究编辑模型性能下降的原因并优化编辑方法，本文从数据和模型两个角度探究其背后的原因。具体而言，1）从数据角度，为明确数据对编辑模型性能的影响，本文首先构建了一个多问题数据集（MQD）来评估不同类型的编辑数据对模型性能的影响。通过实验确定，编辑模型的性能主要受编辑目标的多样性和序列长度的影响。2）从模型角度，本文探究影响编辑模型性能的因素。结果表明编辑模型层的 L1 范数与编辑准确率之间存在很强的相关性，阐明了这是导致编辑性能瓶颈的重要因素。最后，为了提高编辑模型的性能，本文进一步提出了一种 Dump for Sequence (D4S) 方法，通过降低编辑层的 L1 范数成功克服了之前的编辑瓶颈，允许用户进行多次有效编辑，并最大限度地减少了模型损坏。我们的代码可以在 https://github.com/nlpkeg/D4S 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.23843</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图上规划：知识图谱上大型语言模型的自校正自适应规划</title>
      <link>https://arxiv.org/abs/2410.23875</link>
      <description><![CDATA[arXiv:2410.23875v1 Announce Type: new 
摘要：大型语言模型（LLM）在复杂任务上表现出卓越的推理能力，但仍然存在知识过时、幻觉和决策不透明等问题。相比之下，知识图谱（KG）可以为LLM提供明确且可编辑的知识，以缓解这些问题。现有的KG增强型LLM范式手动预定义了探索空间的广度，并要求在KG中进行无缺陷导航。然而，该范式无法基于问题语义自适应地探索KG中的推理路径并自我纠正错误的推理路径，导致效率和效果的瓶颈。为了解决这些限制，我们提出了一种新的自校正自适应规划范式，用于 KG 增强的 LLM，称为 Plan-on-Graph (PoG)，它首先将问题分解为几个子目标，然后重复自适应探索推理路径、更新记忆和反思自我纠正错误推理路径的需要的过程，直到得出答案。具体来说，设计了指导、记忆和反思三个重要机制来协同工作，以保证图推理的自校正规划的自适应广度。最后，在三个真实数据集上进行的大量实验证明了 PoG 的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2410.23875</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyRAT 进行神经网络验证</title>
      <link>https://arxiv.org/abs/2410.23903</link>
      <description><![CDATA[arXiv:2410.23903v1 公告类型：新
摘要：随着人工智能系统越来越受欢迎并应用于各种关键领域（健康、交通、能源等），对其安全性提供保证和信任的必要性是不可否认的。为此，我们提出了 PyRAT，这是一种基于抽象解释的工具，用于验证神经网络的安全性和鲁棒性。在本文中，我们描述了 PyRAT 用于从神经网络的输入开始查找神经网络可达状态的不同抽象，以及该工具的主要功能，以提供对神经网络的快速和准确分析。PyRAT 已经在多个合作中用于确保安全保障，其在 VNN-Comp 2024 上获得第二名，展示了其性能。]]></description>
      <guid>https://arxiv.org/abs/2410.23903</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RL-STaR：自学推理器的强化学习框架的理论分析</title>
      <link>https://arxiv.org/abs/2410.23912</link>
      <description><![CDATA[arXiv:2410.23912v1 公告类型：新 
摘要：大型语言模型 (LLM) 的推理能力随着思路链 (CoT) 的提示而得到改善，使模型能够逐步解决复杂任务。然而，训练 CoT 能力需要详细的推理数据，而这些数据往往很少。自学推理器 (STaR) 框架通过使用强化学习自动生成推理步骤来解决这一问题，减少对人工标记数据的依赖。尽管 STaR 及其变体已证明取得了实证成功，但缺乏解释这些改进的理论基础。这项工作为理解强化学习对 CoT 推理和 STaR 的有效性提供了一个理论框架。我们的贡献是：(1) 对策略改进的分析，说明了为什么 LLM 推理会随着 STaR 而迭代改进；(2) 收敛到最佳推理策略的条件； (3) 检查 STaR 的稳健性，解释它如何在偶尔出现错误步骤的情况下提高推理能力；(4) 启动有效推理改进所需的预训练模型质量标准。该框架旨在将实证研究结果与理论见解结合起来，推动 LLM 推理强化学习方法的发展。]]></description>
      <guid>https://arxiv.org/abs/2410.23912</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>总结因果图中的平均受控和平均自然微直接效应</title>
      <link>https://arxiv.org/abs/2410.23975</link>
      <description><![CDATA[arXiv:2410.23975v1 公告类型：新
摘要：在本文中，我们研究了因果系统中平均控制直接效应和平均自然直接效应的可识别性，这些因果系统由摘要因果图表示，摘要因果图是完整因果图的抽象，通常用于动态系统中，其中循环和省略的时间信息使因果推理变得复杂。与传统的线性设置不同，在传统的线性设置中，直接效应通常更容易识别和估计，而非参数直接效应对于处理现实世界的复杂性至关重要，特别是在流行病学背景下，变量之间的关系（例如遗传、环境和行为因素）通常是非线性的，更难定义和识别。特别是，我们给出了在存在隐藏混杂的情况下从摘要因果图中识别平均控制微直接效应和平均自然微直接效应的充分条件。此外，我们表明，在没有隐藏混淆且我们只对通过调整实现的可识别性感兴趣的环境中，给出的平均控制微直接效应的条件也是必要的。]]></description>
      <guid>https://arxiv.org/abs/2410.23975</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AndroidLab：Android 自主代理的训练和系统基准测试</title>
      <link>https://arxiv.org/abs/2410.24024</link>
      <description><![CDATA[arXiv:2410.24024v1 公告类型：新
摘要：自主代理对于与现实世界的交互变得越来越重要。特别是 Android 代理，最近成为一种经常被提及的交互方法。然而，现有的用于训练和评估 Android 代理的研究缺乏对开源和闭源模型的系统研究。在这项工作中，我们提出了 AndroidLab 作为一个系统的 Android 代理框架。它包括一个具有不同模态的操作环境、动作空间和一个可重现的基准。它在同一动作空间中支持大型语言模型 (LLM) 和多模态模型 (LMM)。AndroidLab 基准包括预定义的 Android 虚拟设备和在这些设备上构建的 9 个应用程序中的 138 个任务。通过使用 AndroidLab 环境，我们开发了一个 Android 指令数据集并训练了六个开源 LLM 和 LMM，将 LLM 的平均成功率从 4.59\% 提高到 21.50\%，将 LMM 的平均成功率从 1.93\% 提高到 13.28\%。 AndroidLab 是开源的，可在 \url{https://github.com/THUDM/Android-Lab} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2410.24024</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数值规划的图学习</title>
      <link>https://arxiv.org/abs/2410.24080</link>
      <description><![CDATA[arXiv:2410.24080v1 公告类型：新
摘要：图形学习自然非常适合用于符号、以对象为中心的规划，因为它能够利用规划领域中展示的关系结构，并将具有任意数量对象的规划实例作为输入。数值规划是符号规划的扩展，其中状态现在也可以显示数值变量。在这项工作中，我们提出了数据高效且可解释的机器学习模型，用于学习解决数值规划任务。这涉及为具有连续和分类属性的图构建新的图形内核，以及用于学习启发式函数进行数值规划的新优化方法。实验表明，我们的图内核比用于数值规划的图神经网络效率更高，泛化性更好，并且与独立于领域的数值规划器相比，覆盖性能也更具竞争力。代码可在 https://github.com/DillonZChen/goose 获得]]></description>
      <guid>https://arxiv.org/abs/2410.24080</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Text2Motion：从自然语言指令到可行计划</title>
      <link>https://arxiv.org/abs/2303.12153</link>
      <description><![CDATA[arXiv:2303.12153v5 公告类型：交叉 
摘要：我们提出了 Text2Motion，这是一个基于语言的规划框架，使机器人能够解决需要长期推理的顺序操作任务。给定自然语言指令，我们的框架构建任务和运动级计划，并验证该计划是否达到推断的符号目标。Text2Motion 使用编码在技能库的 Q 函数中的可行性启发式方法来指导使用大型语言模型进行任务规划。以前的基于语言的规划器只考虑单个技能的可行性，而 Text2Motion 通过在搜索过程中执行几何可行性规划来主动解决跨越技能序列的几何依赖关系。我们在一系列需要长期推理、抽象目标解释和部分可供性感知处理的问题上评估了我们的方法。我们的实验表明，Text2Motion 可以以 82% 的成功率解决这些具有挑战性的问题，而之前最先进的基于语言的规划方法只能达到 13%。因此，Text2Motion 为具有技能间几何依赖关系的语义多样化顺序操作任务提供了有希望的泛化特性。]]></description>
      <guid>https://arxiv.org/abs/2303.12153</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解析生成策略的失败模式：运行时监控一致性和进度</title>
      <link>https://arxiv.org/abs/2410.04640</link>
      <description><![CDATA[arXiv:2410.04640v2 公告类型：交叉 
摘要：通过模仿学习训练的机器人行为策略在偏离训练数据的条件下容易失败。因此，在测试时监控学习到的策略并提供故障早期预警的算法对于促进可扩展部署是必不可少的。我们提出了 Sentinel，这是一个运行时监控框架，将故障检测分为两个互补的类别：1) 不稳定故障，我们使用时间动作一致性的统计度量来检测；2) 任务进展故障，我们使用视觉语言模型 (VLM) 来检测策略何时自信且一致地采取无法解决任务的行动。我们的方法有两个主要优势。首先，由于学习到的策略表现出不同的故障模式，因此结合互补的检测器可以显着提高故障检测的准确性。其次，使用统计时间动作一致性度量可确保我们以可忽略不计的计算成本快速检测到多模态生成策略何时表现出不稳定的行为。相反，我们只使用 VLM 来检测对时间不太敏感的故障模式。我们在模拟和现实世界中针对机器人移动操作领域训练的扩散策略背景下展示了我们的方法。通过统一时间一致性检测和 VLM 运行时监控，Sentinel 检测到的故障比单独使用两种检测器多 18%，并且性能明显优于基线，从而凸显了将专用检测器分配给互补故障类别的重要性。定性结果可在 https://sites.google.com/stanford.edu/sentinel 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.04640</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FVEval：了解数字硬件形式验证中的语言模型功能</title>
      <link>https://arxiv.org/abs/2410.23299</link>
      <description><![CDATA[arXiv:2410.23299v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 卓越的推理和代码生成能力激发了人们对应用 LLM 实现数字芯片设计任务自动化的极大兴趣。特别是，最近的工作研究了将这些模型应用于形式验证 (FV) 的早期想法，这是一种验证硬件实现的方法，可以提供强有力的信心保证，但需要大量的人力。虽然 LLM 驱动的自动化的价值显而易见，但由于缺乏整体评估，我们对模型性能的理解受到了阻碍。作为回应，我们提出了 FVEval，这是第一个全面的基准和评估框架，用于表征与 FV 相关的任务中的 LLM 性能。基准测试由三个子任务组成，它们在不同级别上衡量 LLM 的能力：从根据自然语言描述生成 SystemVerilog 断言 (SVA) 到推理设计 RTL 并直接提出断言而无需额外的人工输入。作为测试实例，我们提供了专家编写的验证材料集合和方法，以可扩展地生成与工业 FV 工作流程相一致的合成示例。我们根据 FVEval 对各种现有的 LLM（包括专有和开源）进行了评估，在此基础上，我们研究了当今 LLM 的现状以及如何进一步使它们的应用能够提高数字 FV 的生产力。我们的基准和评估代码可在 \url{https://github.com/NVlabs/FVEval} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.23299</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用卷积神经网络在医疗物联网 (IoMT) 中实现高级网络攻击检测</title>
      <link>https://arxiv.org/abs/2410.23306</link>
      <description><![CDATA[arXiv:2410.23306v1 公告类型：交叉 
摘要：医疗物联网 (IoMT) 与医疗保健系统的日益融合显著增强了患者护理，但也带来了严重的网络安全挑战。本文提出了一种基于卷积神经网络 (CNN) 的新方法，用于检测 IoMT 环境中的网络攻击。与以前主要使用传统机器学习 (ML) 模型或更简单的深度神经网络 (DNN) 的研究不同，所提出的模型利用 CNN 的功能有效地分析网络流量数据的时间特征。在 CICIoMT2024 数据集上进行训练和评估，该数据集包含一系列 IoMT 设备中的 18 种不同类型的网络攻击，所提出的 CNN 模型与以前最先进的方法相比表现出卓越的性能，在二元、分类和多类分类任务中实现了 99% 的完美准确率。这一性能超越了传统的 ML 模型，例如 Logistic 回归、AdaBoost、DNN 和随机森林。这些发现凸显了 CNN 大幅改善 IoMT 网络安全的潜力，从而确保联网医疗保健系统的保护和完整性。]]></description>
      <guid>https://arxiv.org/abs/2410.23306</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>系统地分析不同 LLM 架构中的即时注入漏洞</title>
      <link>https://arxiv.org/abs/2410.23308</link>
      <description><![CDATA[arXiv:2410.23308v1 公告类型：交叉 
摘要：本研究系统地分析了 36 个大型语言模型 (LLM) 对各种提示注入攻击的脆弱性，这是一种利用精心设计的提示来引发恶意 LLM 行为的技术。在 144 次提示注入测试中，我们观察到模型参数与漏洞之间存在很强的相关性，通过逻辑回归和随机森林特征分析等统计分析表明参数大小和架构显着影响敏感性。结果显示，56% 的测试导致成功的提示注入，强调了各种参数大小的广泛漏洞，聚类分析识别了与特定模型配置相关的不同漏洞配置文件。此外，我们的分析发现了某些提示注入技术之间的相关性，表明漏洞可能存在重叠。这些发现强调了在关键基础设施和敏感行业部署的 LLM 中迫切需要强大的多层防御。成功的提示注入攻击可能导致严重后果，包括数据泄露、未经授权的访问或错误信息。未来的研究应该探索多语言和多步骤防御以及自适应缓解策略，以加强多样化现实环境中的 LLM 安全性。]]></description>
      <guid>https://arxiv.org/abs/2410.23308</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机中的道德主体：在大型语言模型中探索自由意志</title>
      <link>https://arxiv.org/abs/2410.23310</link>
      <description><![CDATA[arXiv:2410.23310v1 公告类型：交叉 
摘要：本研究探讨了确定性系统（特别是大型语言模型 (LLM)）展示道德主体和兼容自由意志的功能能力的潜力。我们以丹尼特的兼容框架为基础，建立了自由意志的功能定义，该定义建立在跨学科理论基础之上，该理论基础融合了香农的信息论、丹尼特的兼容论和弗洛里迪的信息哲学。该框架强调了理性响应和价值观一致在确定道德责任方面的重要性，而不是要求形而上学的自由意志。香农的理论强调了处理复杂信息在实现自适应决策方面的作用，而弗洛里迪的哲学通过将主体概念化为一个频谱来调和这些观点，从而允许基于系统的复杂性和响应性对道德地位进行分级观察。我们对法学硕士在道德困境中的决策的分析表明，他们具有理性思考的能力，能够根据新信息和发现的不一致之处调整选择。因此，他们表现出与我们对自由意志的功能定义相一致的道德主体特征。这些结果挑战了关于意识对道德责任必要性的传统观点，表明具有自指推理能力的系统可以在人工和生物环境中体现一定程度的自由意志和道德推理。本研究提出了一个简洁的框架，用于将自由意志理解为一个涵盖人工和生物系统的范围，为人工智能时代的主体和伦理的进一步跨学科研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.23310</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VL-Cache：用于视觉语言模型推理加速的稀疏性和模态感知 KV 缓存压缩</title>
      <link>https://arxiv.org/abs/2410.23317</link>
      <description><![CDATA[arXiv:2410.23317v1 公告类型：交叉 
摘要：视觉语言模型 (VLM) 在一系列多功能任务中表现出色。加速 VLM 的一个关键挑战是存储和访问对长视觉上下文（例如图像或视频）进行编码的大型键值 (KV) 缓存。虽然现有的 KV 缓存压缩方法对大型语言模型 (LLM) 有效，但直接将它们迁移到 VLM 会导致准确性和加速不理想。为了弥补这一差距，我们提出了 VL-Cache，这是一种专为加速 VLM 推理而量身定制的新型 KV 缓存压缩方法。在本文中，我们首先通过区分预填充和解码阶段的视觉和文本标记来研究 VLM 注意力的独特稀疏模式。基于这些观察，我们引入了一种层自适应稀疏感知缓存预算分配方法，该方法有效地将有限的缓存预算分配到不同的层上，从而在不影响准确性的情况下进一步减少 KV 缓存大小。此外，我们开发了一种模态感知 token 评分策略，以更好地评估 token 重要性。在多个基准数据集上的经验结果表明，仅保留 10% 的 KV 缓存即可实现与全缓存相当的准确率。在速度基准测试中，我们的方法将生成 100 个 token 的端到端延迟提高了 2.33 倍，将解码速度提高了 7.08 倍，同时将 GPU 中 KV 缓存的内存占用减少了 90%。]]></description>
      <guid>https://arxiv.org/abs/2410.23317</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lina-Speech：门控线性注意力是一种快速且参数高效的文本转语音合成学习器</title>
      <link>https://arxiv.org/abs/2410.23320</link>
      <description><![CDATA[arXiv:2410.23320v1 公告类型：交叉 
摘要：神经编解码器语言模型利用可扩展架构（如自回归变换器）和大规模语音数据集，在文本转语音 (TTS) 合成中实现了最先进的性能。通过将语音克隆构建为快速连续任务，这些模型擅长从短音频样本中克隆语音。然而，这种方法在处理大量或冗长的语音摘录方面的能力有限，因为源语音和目标语音的连接必须在训练期间确定的最大上下文长度内。在这项工作中，我们引入了 Lina-Speech，这是一种用新兴的循环架构（如门控线性注意 (GLA)）取代传统自注意机制的模型。在 RWKV 初始状态调整成功的基础上，我们将这项技术扩展到语音克隆，从而能够在合成中使用多个语音样本并充分利用上下文窗口。这种方法速度快、易于部署，并且在数据集大小为 3 到 15 分钟时可实现与微调基线相当的性能。值得注意的是，Lina-Speech 可与最先进的基线模型相媲美或超越，包括一些参数数量高达四倍或以端到端方式训练的模型。我们发布了代码和检查点。音频样本可在 https://theodorblackbird.github.io/blog/demo_lina/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.23320</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用非洲语言之间的音系相似性实现语音到语音的翻译</title>
      <link>https://arxiv.org/abs/2410.23323</link>
      <description><![CDATA[arXiv:2410.23323v1 公告类型：交叉 
摘要：本文通过利用同一门类内选定的非洲语言之间的语言相似性，对直接语音到语音翻译 (S2ST) 进行了一项初步研究，特别是在传统数据注释昂贵或不切实际的情况下。我们提出了一个基于片段的模型，该模型可以映射语言门内和跨语言门的语音片段，从而有效地消除了对大型配对数据集的需求。通过利用配对片段和引导扩散，我们的模型可以实现数据集中任意两种语言之间的翻译。我们在肯尼亚广播公司 (KBC) 的专有数据集上评估该模型，该数据集包括五种语言：斯瓦希里语、卢奥语、基库尤语、南迪语和英语。该模型在片段配对和翻译质量方面表现出色，尤其是对于同一门类内的语言。我们的实验表明，片段长度显着影响翻译准确性，平均长度的片段可产生最高的配对质量。与传统级联 ASR-MT 技术的比较分析表明，所提出的模型可提供几乎相当的翻译性能。这项研究强调了利用语言组内的语言相似性来执行高效 S2ST 的潜力，尤其是在资源匮乏的语言环境中。]]></description>
      <guid>https://arxiv.org/abs/2410.23323</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>声乐教育中的迁移学习：描述女中音的有限样本的技术评估</title>
      <link>https://arxiv.org/abs/2410.23325</link>
      <description><![CDATA[arXiv:2410.23325v1 公告类型：交叉
摘要：由于歌手声音的个体差异和歌唱技巧的量化标准不同，音乐领域的声乐教育很难量化。深度学习在处理复杂数据和进行定量分析方面具有很大的应用潜力。然而，对女中音等罕见声乐类型进行有限样本的准确评估需要使用深度学习模型进行大量注释良好的数据支持。为了实现这一目标，我们通过使用在 ImageNet 和 Urbansound8k 数据集上预先训练的深度学习模型进行迁移学习，以提高声乐技巧评估的精度。此外，我们通过构建一个专门的数据集，即女中音人声集 (MVS)，用于声乐技巧评估，解决了样本不足的问题。我们的实验结果表明，迁移学习使所有模型的整体准确率 (OAcc) 平均提高了 8.3%，最高精度为 94.2%。我们不但提供了一种评估女中音唱法技巧的新方法，而且还为音乐教育引入了一种新的定量评估方法。]]></description>
      <guid>https://arxiv.org/abs/2410.23325</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于金属植入物附近加速多光谱 MRI 的可变分辨率采样和深度学习图像恢复</title>
      <link>https://arxiv.org/abs/2410.23329</link>
      <description><![CDATA[arXiv:2410.23329v1 公告类型：交叉 
摘要：目的：本研究提出了一种用于金属植入物附近多光谱 MRI 的可变分辨率 (VR) 采样和深度学习重建方法，旨在减少扫描时间同时保持图像质量。背景：金属植入物的使用越来越多，受金属伪影影响的 MRI 扫描也越来越多。多光谱成像 (MSI) 减少了这些伪影，但牺牲了采集效率。方法：这项回顾性研究针对金属硬件患者的 1.5T MSI 膝关节和髋关节数据，使用了一种新颖的光谱欠采样方案，将采集效率提高了约 40%。基于 U-Net 的深度学习模型经过重建训练。使用 SSIM、PSNR 和 RESI 指标评估图像质量。结果：与传统重建 (CR-VR) 相比，欠采样 VR 数据 (DL-VR) 的深度学习重建显示出明显更高的 SSIM 和 PSNR 值 (p&lt;0.001)，边缘锐度得到改善。 DL 重建图像的边缘锐度与完全采样参考相匹配（p=0.5）。结论：这种方法可以通过减少扫描时间或提高分辨率来增强金属植入物附近的 MRI 检查。需要进一步的前瞻性研究来评估临床价值。]]></description>
      <guid>https://arxiv.org/abs/2410.23329</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>