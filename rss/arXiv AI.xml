<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 30 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>制造业的大型语言模型</title>
      <link>https://arxiv.org/abs/2410.21418</link>
      <description><![CDATA[arXiv:2410.21418v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展有可能改变制造业，为优化流程、提高效率和推动创新提供新的机会。本文全面探讨了 LLM 与制造领域的集成，重点关注其自动化和增强制造业各个方面的潜力，从产品设计和开发到质量控制、供应链优化和人才管理。通过对多个制造任务的广泛评估，我们展示了 GPT-4V 等最先进的 LLM 在理解和执行复杂指令、从大量数据中提取有价值的见解以及促进知识共享方面的卓越能力。我们还深入探讨了 LLM 在重塑制造业教育、自动化编码过程、增强机器人控制系统以及通过工业元宇宙创建沉浸式、数据丰富的虚拟环境方面的变革潜力。通过强调法学硕士在制造业中的实际应用和新兴用例，本文旨在为专业人士、研究人员和决策者提供宝贵的资源，帮助他们利用这些技术的力量应对现实世界的挑战、推动卓越运营并在日益激烈的竞争环境中实现可持续增长。]]></description>
      <guid>https://arxiv.org/abs/2410.21418</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以取代临床研究中的数据科学家吗？</title>
      <link>https://arxiv.org/abs/2410.21591</link>
      <description><![CDATA[arXiv:2410.21591v1 公告类型：新
摘要：数据科学在临床研究中起着至关重要的作用，但它需要具有编码和医学数据分析专业知识的专业人员。大型语言模型 (LLM) 在支持医疗任务和在一般编码测试中表现良好方面表现出色方面表现出色。然而，这些测试并没有评估 LLM 处理医学数据科学任务的能力，也没有探索它们在临床研究中的实际效用。为了解决这个问题，我们开发了一个由 293 个真实世界数据科学编码任务组成的数据集，基于 39 项已发表的临床研究，涵盖 Python 中的 128 个任务和 R 中的 165 个任务。该数据集使用患者数据模拟了真实的临床研究场景。我们的研究结果表明，尖端的 LLM 难以生成完美的解决方案，经常无法遵循输入指令、理解目标数据并遵守标准分析实践。因此，LLM 尚未准备好完全自动化数据科学任务。我们对高级适应方法进行了基准测试，发现其中两种方法特别有效：思路链提示，它为数据分析提供了分步计划，从而使代码准确性提高了 60%；自我反思，使 LLM 能够迭代改进其代码，从而使准确性提高了 38%。基于这些见解，我们开发了一个平台，将 LLM 集成到医疗专业人员的数据科学工作流程中。在一项针对五名医生的用户研究中，我们发现虽然 LLM 无法完全自动化编码任务，但它们显著简化了编程过程。我们发现他们提交的代码解决方案中有 80% 是从 LLM 生成的代码中合并而来的，在某些情况下重用率高达 96%。我们的分析强调了 LLM 在集成到专家工作流程中时提高临床研究中数据科学效率的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.21591</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实时代理的异步工具使用</title>
      <link>https://arxiv.org/abs/2410.21620</link>
      <description><![CDATA[arXiv:2410.21620v1 公告类型：新
摘要：虽然前沿大型语言模型 (LLM) 是能够使用工具的代理，但当前的 AI 系统仍然以严格的回合制方式运行，无视时间的流逝。这种同步设计迫使用户查询和工具使用按顺序进行，从而阻止系统进行多任务处理并降低交互性。为了解决这一限制，我们引入了能够并行处理和实时使用工具的异步 AI 代理。我们的主要贡献是用于代理执行和提示的事件驱动有限状态机架构，并集成了自动语音识别和文本转语音。从最初为实时操作系统开发的概念中汲取灵感，这项工作提出了一个概念框架和实用工具，用于创建能够流畅、多任务交互的 AI 代理。]]></description>
      <guid>https://arxiv.org/abs/2410.21620</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MARCO：多代理实时聊天编排</title>
      <link>https://arxiv.org/abs/2410.21784</link>
      <description><![CDATA[arXiv:2410.21784v1 公告类型：新
摘要：大型语言模型的进步使得多智能体框架的开发能够解决复杂的现实问题，例如自动执行需要与各种工具交互、推理和人工协作的任务。我们提出了 MARCO，这是一个使用 LLM 自动执行任务的多智能体实时聊天编排框架。MARCO 解决了利用 LLM 执行复杂、多步骤任务的关键挑战。它结合了强大的护栏来引导 LLM 行为、验证输出以及从因输出格式不一致、函数和参数幻觉以及缺乏领域知识而导致的错误中恢复。通过大量实验，我们证明了 MARCO 的卓越性能，在数字餐厅服务平台对话和零售对话数据集的任务执行中分别具有 94.48% 和 92.74% 的准确率，同时延迟提高了 44.91%，成本降低了 33.71%。我们还报告了护栏对性能提升的影响，并对各种 LLM 模型（开源和专有）进行了比较。MARCO 的模块化和通用设计使其能够适应跨域自动执行任务，并通过多轮交互执行复杂的用例。]]></description>
      <guid>https://arxiv.org/abs/2410.21784</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体系统的逆向注意智能体</title>
      <link>https://arxiv.org/abs/2410.21794</link>
      <description><![CDATA[arXiv:2410.21794v1 公告类型：新
摘要：多智能体系统面临的一个主要挑战是让智能体能够动态地适应对手和队友可能不断变化的多样化环境。使用传统方法训练的智能体往往只在其训练队列的范围内表现出色；当面对不熟悉的智能体时，他们的表现会显著下降。为了解决这一缺点，我们引入了逆向注意力智能体，它采用了心智理论中的概念，使用注意力机制以算法方式实现，并以端到端的方式进行训练。对于确定这些智能体的最终行动至关重要，它们的注意力模型中的权重明确表示对不同目标的注意力。此外，我们提出了一个逆向注意力网络，它根据观察和先前的行动推断出智能体的 ToM。该网络推断其他智能体的注意力状态，从而改进注意力权重以调整智能体的最终行动。我们在连续的环境中进行实验，解决包括合作、竞争和两者结合的艰巨任务。他们证明逆向注意力网络能够成功推断其他代理的注意力，并且此信息可提高代理性能。额外的人类实验表明，与基线代理模型相比，我们的逆向注意力代理表现出与人类的出色合作，并且更好地模仿人类行为。]]></description>
      <guid>https://arxiv.org/abs/2410.21794</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有时间最优运输奖励的机器人策略学习</title>
      <link>https://arxiv.org/abs/2410.21795</link>
      <description><![CDATA[arXiv:2410.21795v1 公告类型：新
摘要：奖励规范是强化学习中最棘手的问题之一，在实践中通常需要繁琐的手工工程。
解决这一挑战的一种有前途的方法是采用现有的专家视频演示进行策略学习。
最近的一些工作研究了如何仅从单个/几个专家视频演示中学习机器人策略。
例如，通过最佳传输（OT）进行奖励标记已被证明是一种有效的策略，可以通过测量机器人轨迹和专家演示之间的一致性来生成代理奖励。
然而，以前的工作大多忽略了OT奖励对时间顺序信息不变，这可能会给奖励信号带来额外的噪音。
为了解决这个问题，在本文中，我们引入了时间最优传输（TemporalOT）奖励来结合时间顺序信息来学习更准确的基于OT的代理奖励。
在Meta-world基准任务上的大量实验验证了该方法的有效性。
代码位于：https://github.com/fuyw/TemporalOT]]></description>
      <guid>https://arxiv.org/abs/2410.21795</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大脑启发的情感同理心机制构建利他主义和道德 AI 代理</title>
      <link>https://arxiv.org/abs/2410.21882</link>
      <description><![CDATA[arXiv:2410.21882v1 Announce Type: new 
摘要：随着人工智能与人类社会的密切互动，确保其决策安全、利他、符合人类的伦理道德价值观至关重要。然而，现有关于将伦理道德考量嵌入人工智能的研究仍然不足，先前基于原则和规则的外部约束不足以为人工智能提供长期稳定性和泛化能力。相比之下，基于同理心的内在利他动机更愿意、自发和稳健。因此，本文致力于通过类似人类的情感同理心机制自主驱动智能体获得道德行为。我们借鉴人脑道德直觉决策的神经机制，模拟镜像神经元系统，构建了一个受大脑启发的情感同理心驱动的利他决策模型。在这里，同理心直接影响多巴胺的释放，形成内在利他动机。基于道德功利主义原则，我们设计了融合内在同理心和外在自我任务目标的道德奖励函数，并开发了一个融合同理心过程、个人目标和利他目标的综合实验场景。该模型使智能体能够通过平衡自身利益和他人福祉来做出一致的道德决策（优先考虑利他主义）。我们进一步引入抑制神经元来调节不同程度的同理心，并验证了同理心水平与利他偏好之间的正相关性，得出与心理行为实验结果一致的结论。这项工作为利用类人内在同理心机制开发道德人工智能提供了可行的解决方案，并为人类与人工智能的和谐共存做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.21882</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于路径的图推荐器摘要解释——扩展版本</title>
      <link>https://arxiv.org/abs/2410.22020</link>
      <description><![CDATA[arXiv:2410.22020v1 公告类型：新
摘要：基于路径的解释为基于图的推荐模型提供了内在见解。然而，大多数以前的工作都集中在向用户解释单个项目的推荐。在本文中，我们提出了总结性解释，即强调为什么一个用户或一组用户会收到一组项目推荐，以及为什么一个项目或一组项目被推荐给一组用户，作为提供对推荐者集体行为见解的有效手段。我们还提出了一种使用高效图算法总结解释的新方法，特别是 Steiner 树和奖品收集 Steiner 树。我们的方法在保留基本信息的同时减少了总结性解释的大小和复杂性，使解释对用户更易于理解，对模型开发人员更有用。跨多个指标的评估表明，我们的总结在大多数情况下在各种质量方面都优于基线解释方法。]]></description>
      <guid>https://arxiv.org/abs/2410.22020</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过架构绘制神经符号人工智能图景：通过符号推理增强深度学习的手册</title>
      <link>https://arxiv.org/abs/2410.22077</link>
      <description><![CDATA[arXiv:2410.22077v1 公告类型：新
摘要：将符号技术与统计技术相结合是人工智能领域长期存在的问题。其动机是，任何一个领域的优势都与另一个领域的弱点相匹配，并且通过结合这两种方法，可以限制任何一种方法的弱点。神经符号人工智能专注于这种集成，其中统计方法特别是神经网络。近年来，该研究领域取得了重大进展，神经符号系统的表现优于单独的逻辑或神经模型。然而，相对而言，神经符号人工智能仍处于起步阶段，尚未被机器学习从业者广泛采用。在本次调查中，我们首次根据神经符号技术的架构将其映射到框架系列中，这有几个好处：首先，它允许我们将不同优势的框架链接到它们各自的架构。其次，它使我们能够说明工程师如何在将符号方法视为黑箱的同时增强他们的神经网络。第三，它使我们能够绘制该领域的大部分内容，以便未来的研究人员能够识别密切相关的框架。]]></description>
      <guid>https://arxiv.org/abs/2410.22077</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用生成和测试与传播算法解决认知逻辑程序</title>
      <link>https://arxiv.org/abs/2410.22130</link>
      <description><![CDATA[arXiv:2410.22130v1 公告类型：新
摘要：本文介绍了一种基于生成和测试的认知逻辑程序求解器的通用框架，该框架可以用不同的生成器和测试程序实例化，并且我们证明了使用这些框架构建的求解器的正确性的充分条件。它还介绍了一种结合认知后果传播的新生成器程序，并表明这可以成倍减少需要测试的候选者数量，同时只产生线性开销。我们根据这些理论发现实现了一个新的求解器，并通过实验表明，它的性能优于现有的求解器，在众所周知的基准上实现了约 3.3 倍的速度提升和解决了 91% 以上的实例。]]></description>
      <guid>https://arxiv.org/abs/2410.22130</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ADAM：开放世界环境中的具体因果代理</title>
      <link>https://arxiv.org/abs/2410.22194</link>
      <description><![CDATA[arXiv:2410.22194v1 公告类型：新 
摘要：在像 Minecraft 这样的开放世界环境中，现有的代理在不断学习结构化知识（尤其是因果关系）方面面临挑战。这些挑战源于黑盒模型固有的不透明性和训练过程中对先验知识的过度依赖，从而削弱了它们的可解释性和泛化能力。为此，我们引入了 ADAM，即 Minecraft 中的具身因果代理，它可以自主导航开放世界，感知多模态上下文，学习因果世界知识，并通过终身学习解决复杂任务。ADAM 由四个关键组件提供支持：1）交互模块，使代理能够在记录交互过程的同时执行操作；2）因果模型模块，负责从头开始构建不断增长的因果图，从而增强可解释性并减少对先验知识的依赖； 3）控制器模块，包括规划器、执行器和内存池，使用学习到的因果图完成任务；4）感知模块，由多模态大型语言模型驱动，使 ADAM 能够像人类玩家一样感知。大量实验表明，ADAM 从头开始​​构建了近乎完美的因果图，能够高效地分解和执行任务，具有很强的可解释性。值得注意的是，在我们修改的 Minecraft 游戏中，在没有先验知识的情况下，ADAM 保持了其性能并表现出非凡的鲁棒性和泛化能力。ADAM 开创了一种以协同方式整合因果方法和具体代理的新范式。我们的项目页面是 https://opencausalab.github.io/ADAM。]]></description>
      <guid>https://arxiv.org/abs/2410.22194</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现个人和代表价值一致的民主化奖励设计</title>
      <link>https://arxiv.org/abs/2410.22203</link>
      <description><![CDATA[arXiv:2410.22203v1 公告类型：新
摘要：由于价值观的多样性和主观性，将人工智能代理与人类价值观保持一致具有挑战性。标准对齐方法通常会汇总人群反馈，这可能会导致独特或少数人的偏好被抑制。我们引入了交互式反思对话对齐，这种方法以迭代方式让用户反思和指定他们的主观价值定义。该系统通过基于语言模型的偏好引出来学习个人价值定义，并构建可用于对齐人工智能行为的个性化奖励模型。我们通过两项有 30 名参与者的研究评估了我们的系统，一项研究关注“尊重”，另一项研究关注自动驾驶汽车的道德决策。我们的研究结果展示了价值观一致行为的多种定义，并表明我们的系统可以准确捕捉每个人的独特理解。这种方法可以实现个性化对齐，并可以为更具代表性和可解释性的集体对齐策略提供信息。]]></description>
      <guid>https://arxiv.org/abs/2410.22203</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不完全信息下结构化论证的渐进语义方法</title>
      <link>https://arxiv.org/abs/2410.22209</link>
      <description><![CDATA[arXiv:2410.22209v1 公告类型：新
摘要：渐进语义在论证中表现出巨大的潜力，特别是在从判断预测到可解释的人工智能等许多现实世界环境中部署定量双极论证框架 (QBAF) 方面。在本文中，我们提供了一种获取结构化论证框架的渐进语义的新方法，其中论证的构建块及其之间的关系是已知的，这与 QBAF 不同，在 QBAF 中论证是抽象实体。与现有方法不同，我们的方法可以容纳有关论证前提的不完整信息。我们通过引入该方法的两个不同实例来展示我们方法的潜力，利用这些更复杂框架中现有的 QBAF 渐进语义。我们还为结构化论证中的渐进语义定义了一组新属性，并讨论了它们对一组现有属性的适用性。最后，我们对实例进行了全面的理论分析，证明了它们相对于现有的 QBAF 和结构化论证的渐进语义的优势。]]></description>
      <guid>https://arxiv.org/abs/2410.22209</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>请减少晕屏现象：揭秘和检测虚拟现实应用中的立体视觉不一致现象</title>
      <link>https://arxiv.org/abs/2406.09313</link>
      <description><![CDATA[arXiv:2406.09313v2 公告类型：交叉 
摘要：虚拟现实（VR）应用的质量至关重要，尤其是VR图形用户界面（GUI）的渲染质量。与传统的2D应用不同，VR应用通过分别为用户的左眼和右眼渲染两个不同的2D图像来为用户创建3D数字场景。然而，立体视觉不一致（表示为“SVI”）问题会破坏用户大脑的渲染过程，导致用户不适甚至对健康产生不利影响。这类问题普遍存在，但仍未得到充分探索。我们对来自15个VR平台的282个SVI错误报告进行了实证分析，总结了15种表现形式。实证分析表明，自动检测SVI问题具有挑战性，主要是因为：（1）缺乏训练数据；（2）SVI问题的表现形式多样、复杂，并且通常特定于应用程序； (3) 大多数可访问的 VR 应用都是闭源商业软件。现有的基于模式的监督分类方法可能不适用或无法有效检测 SVI 问题。为了应对这些挑战，我们提出了一个名为 StereoID 的无监督黑盒测试框架，仅基于渲染的 GUI 状态来识别立体视觉不一致。StereoID 根据实际左眼图像生成合成右眼图像，并计算合成右眼图像与实际右眼图像之间的距离以检测 SVI 问题。我们提出了一种深度感知条件立体图像转换器来支持图像生成过程，该转换器可捕捉左眼和右眼图像之间预期的透视变化。我们构建了一个大规模未标记 VR 立体截图数据集，其中包含来自 288 个真实世界 VR 应用的超过 171K 张图像，用于实验。经过大量实验，StereoID 在检测用户报告和野生 VR 应用中的 SVI 问题方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2406.09313</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉的空间智能代理的扎实 GUI 理解：以虚拟现实应用程序为例</title>
      <link>https://arxiv.org/abs/2409.10811</link>
      <description><![CDATA[arXiv:2409.10811v3 公告类型：交叉 
摘要：近年来，空间计算虚拟现实 (VR) 已成为一种变革性技术，为用户提供跨多样化虚拟环境的沉浸式和交互式体验。用户可以通过立体三维 (3D) 图形用户界面 (GUI) 上的可交互 GUI 元素 (IGE) 与 VR 应用程序交互。准确识别这些 IGE 至关重要，是许多软件工程任务的基础，包括自动化测试和有效的 GUI 搜索。最新的 2D 移动应用程序 IGE 检测方法通常基于大规模手动标记的 GUI 数据集训练监督对象检测模型，通常使用一组预定义的可点击 GUI 元素类别，如按钮和微调器。由于存在许多挑战，包括开放词汇和异构 IGE 类别所带来的复杂性、上下文敏感交互性的复杂性以及获得准确的 IGE 检测结果所需的精确空间感知和视觉语义对齐，因此此类方法很难应用于 VR 应用中的 IGE 检测。因此，有必要开展针对 VR 应用的 IGE 研究。在本文中，我们提出了第一个用于虚拟现实应用的零样本上下文敏感可交互 GUI 元素检测框架，名为 Orienter。通过模仿人类行为，Orienter 首先观察和理解 VR 应用场景的语义上下文，然后再进行检测。检测过程在反馈导向的验证和反射循环中迭代。具体而言，Orienter 包含三个组件，包括 (1) 语义上下文理解、(2) 反射导向的 IGE 候选检测和 (3) 上下文敏感的交互性分类。大量实验表明，Orienter 比最先进的 GUI 元素检测方法更有效。]]></description>
      <guid>https://arxiv.org/abs/2409.10811</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有 OOD 状态校正和 OOD 动作抑制的离线强化学习</title>
      <link>https://arxiv.org/abs/2410.19400</link>
      <description><![CDATA[arXiv:2410.19400v2 公告类型：交叉 
摘要：在离线强化学习 (RL) 中，解决分布外 (OOD) 动作问题一直是一个焦点，但我们认为存在一个 OOD 状态问题，该问题也会损害性能，但尚未得到充分探索。这样的问题描述了代理在测试阶段遇到离线数据集之外的状态时的情况，导致行为不受控制和性能下降。为此，我们提出了 SCAS，这是一种简单而有效的方法，它将离线 RL 中的 OOD 状态校正和 OOD 动作抑制统一起来。从技术上讲，SCAS 实现了价值感知的 OOD 状态校正，能够将代理从 OOD 状态校正为高价值的分布内状态。理论和实证结果表明，SCAS 还表现出抑制 OOD 动作的效果。在标准离线 RL 基准测试中，SCAS 无需额外的超参数调整即可实现出色的性能。此外，得益于其 OOD 状态校正功能，SCAS 表现出增强的抵抗环境干扰的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2410.19400</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球人工智能监管比较：欧盟、中国和美国的政策观点</title>
      <link>https://arxiv.org/abs/2410.21279</link>
      <description><![CDATA[arXiv:2410.21279v1 公告类型：交叉 
摘要：作为一种强大且快速发展的双重用途技术，人工智能既带来了巨大的好处，也带来了令人担忧的风险。作为回应，世界各地的管理机构正在制定一系列监管人工智能的法律和政策。本文比较了欧盟、中国和美国采取的三种不同方法。在美国，我们探讨联邦和州一级的人工智能监管，重点关注加利福尼亚州正在审议的参议院第 1047 号法案。每个监管体系都反映了不同的文化、政治和经济观点。每个体系还强调了监管风险收益权衡的不同区域观点，对安全与创新、合作与竞争之间的平衡有不同的判断。最后，监管框架之间的差异反映了对集中权威的信任与对更分散的自利利益相关者自由市场的信任之间的对比立场。总之，这些不同的人工智能创新和监管方法相互影响，影响更广泛的国际社会，以及人工智能监管的未来。]]></description>
      <guid>https://arxiv.org/abs/2410.21279</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TraderTalk：一种用于模拟人类双边交易互动的法学硕士行为 ABM</title>
      <link>https://arxiv.org/abs/2410.21280</link>
      <description><![CDATA[arXiv:2410.21280v1 公告类型：交叉 
摘要：我们引入了一种新颖的混合方法，该方法使用大型语言模型 (LLM) 生成的行为增强基于代理的模型 (ABM)，以模拟人类交易交互。我们将我们的模型称为 TraderTalk。利用在大量人工编写的文本上训练的 LLM，我们捕捉到金融交易中双边对话的详细和细微的表示。将这种基于代理的生成模型 (GABM) 应用于政府债券市场，我们复制了两个风格化的虚拟人之间的交易决策。我们的方法解决了结构性挑战，例如协调现实的基于 LLM 的代理之间的轮换，以及设计挑战，包括代理模型对 LLM 输出的解释。通过机会性地而不是系统地探索提示设计，我们增强了代理交互的真实性，而不会出现详尽的过度拟合或模型依赖。我们的方法成功复制了相关资产市场中观察到的交易量与订单量比率，证明了 LLM 增强型 ABM 在金融模拟中的潜力]]></description>
      <guid>https://arxiv.org/abs/2410.21280</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的生成式人工智能的社会影响</title>
      <link>https://arxiv.org/abs/2410.21281</link>
      <description><![CDATA[arXiv:2410.21281v1 公告类型：交叉 
摘要：不管喜欢与否，不管准备好与否，我们都可能进入人类历史的新阶段，人工智能（AI）将主导经济生产和社会生活——人工智能革命。在人工智能革命真正到来之前，我们是时候推测人工智能将如何影响社会世界了。在本文中，我们重点关注基于 LLM 的生成式人工智能（GELLMAI）的社会影响，讨论有助于其技术发展的社会因素及其在加强国家间和国家内社会不平等方面的潜在作用。有迹象表明，美国和中国将引领该领域，并将成为世界人工智能主导地位的主要竞争对手。我们推测人工智能革命可能会催生一个后知识社会，在这个社会中，知识本身将变得不像今天世界那么重要。相反，个人关系和社会身份将变得更加重要。软技能也是如此。]]></description>
      <guid>https://arxiv.org/abs/2410.21281</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用伪代码和图神经网络对学生编程作业中的逻辑错误进行定位</title>
      <link>https://arxiv.org/abs/2410.21282</link>
      <description><![CDATA[arXiv:2410.21282v1 公告类型：交叉 
摘要：伪代码广泛用于入门编程课程，指导计算机科学学生进行算法设计，利用自然语言定义算法行为。这种学习方法使学生能够将伪代码转换为源代码并执行它以验证其算法的正确性。此过程通常会引入两种类型的错误：语法错误和逻辑错误。语法错误通常伴随着编译器反馈，这有助于学生识别错误的行。相比之下，逻辑错误更具挑战性，因为它们不会触发编译器错误并且缺乏即时诊断反馈，因此更难检测和纠正。为了应对这一挑战，我们开发了一个系统，旨在在行级别定位学生编程作业中的逻辑错误。我们的方法利用伪代码作为支架来构建代码-伪代码图，将源代码中的符号连接到伪代码对应部分。然后，我们使用图神经网络来定位逻辑错误并提出纠正建议。此外，我们还设计了一种方法，可以在语法错误更正过程中高效地收集容易出现逻辑错误的程序，并将其编译成一个数据集，其中包含单行和多行逻辑错误，并附有错误行的索引。我们的实验结果令人鼓舞，证明了前 10 个可疑行中逻辑错误的定位准确率为 99.2%，凸显了我们的方法在提高学生编码能力和纠错技能方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.21282</guid>
      <pubDate>Wed, 30 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>