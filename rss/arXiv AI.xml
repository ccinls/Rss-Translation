<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 10 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>缺少前提加剧了过度思考：推理模型是否失去了批判性思维技能？</title>
      <link>https://arxiv.org/abs/2504.06514</link>
      <description><![CDATA[ARXIV：2504.06514V1公告类型：新 
摘要：我们发现推理LLM的响应长度，无论是通过强化学习还是受监督的学习训练，都会大幅度增加缺失的前提（MIP）的问题，最终以多余的和无效的思维。这种新引入的方案在很大程度上加剧了普遍的过度思考问题，我们将其称为MIP跨思考。这样的故障违反了``测试时间缩放定律&#39;&#39;，但在我们使用MIP策划的多个数据集中广泛观察到，这表明廉价过度思考和缺乏批判性思维的危害。令人惊讶的是，在MIP方案中未经专门培训的推理训练的LLM表现出更好的性能，产生了更短的响应，可以迅速识别出不适当的查询。这意味着当前推理LLM的培训配方的关键缺陷，这并不能充分鼓励有效的思维，从而导致滥用思维模式。为了进一步研究这种失败的原因，我们对推理长度，过度思考模式以及对不同类型的LLM的批判性思维的位置进行了细粒度分析。此外，我们的扩展消融研究表明，通过蒸馏推理模型的响应，过度思考具有感染性。这些结果提高了人们对缓解问题的过度思考和解散新见解的理解。]]></description>
      <guid>https://arxiv.org/abs/2504.06514</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>正确的预测，错误的推理：发现RA疾病诊断中的LLM未对准</title>
      <link>https://arxiv.org/abs/2504.06581</link>
      <description><![CDATA[ARXIV：2504.06581V1公告类型：新 
摘要：大语言模型（LLMS）提供了一种有希望的预筛查工具，改善了早期疾病检测，并为贫困社区提供了增强的医疗保健机会。各种疾病的早期诊断仍然是医疗保健中的重大挑战，这主要是由于早期症状的非特异性性质，专家医生的短缺以及对延长临床评估的需求，所有这些都会延迟治疗和不利影响患者的结果。在各种疾病的预测中，LLM具有令人印象深刻的准确性，因此有可能在各种医疗状况下彻底改变临床预筛查和决策。在这项工作中，我们研究了与现实世界患者数据的类风湿关节炎（RA）LLM的诊断能力。与医学专家的诊断一起收集了患者数据，与RA疾病预测的专家诊断相比，评估了LLMS的性能。我们注意到疾病诊断的一种有趣的模式，并发现了意外的\ textit {预测和解释之间的错位}。我们使用不同的LLM代理进行了一系列多轮分析。表现最佳的模型准确地预测了大约95 \％的时间的类风湿关节炎（RA）疾病。但是，当医学专家评估该模型产生的推理时，他们发现近68％的推理不正确。这项研究强调了LLMS高预测准确性与其缺陷的推理之间存在明显的错位，这引发了有关依靠LLM在临床环境中的解释的重要问题。 \ textbf {llms提供了不正确的推理，可以得出正确的RA疾病诊断答案。}]]></description>
      <guid>https://arxiv.org/abs/2504.06581</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FamilyTool：多跳个性化工具使用基准</title>
      <link>https://arxiv.org/abs/2504.06766</link>
      <description><![CDATA[ARXIV：2504.06766V1公告类型：新 
摘要：将工具学习与大语言模型（LLM）的集成通过利用外部工具来扩展其在处理复杂任务方面的功能。但是，工具学习的现有基准不足解决了关键的现实个性化场景，尤其是那些在动态环境中需要多跳推理和诱导知识适应的基准。为了弥合这一差距，我们介绍了FamilyTool，这是一种基于家庭知识图（KG）的小型基准，该基准模拟了个性化的多跳工具使用方案。 FamilyTool挑战LLM的查询跨越1到3个关系啤酒花（例如，推断家庭联系和偏好），并结合了电感KG设置，其中模型必须适应不看到的用户偏好和关系而不重新训练，这是对先前方法的共同限制，从而损害了普遍的一般性。我们进一步提出了Kgetool：一个简单的kg扬声器评估管道，以系统地评估LLMS在这些设置中的工具使用能力。实验表明，最新的LLMS的性能差距很大，随着Hop的复杂性的提高和感应性场景暴露出严重的概括缺陷，精度急剧下降。这些发现强调了当前LLM在处理个性化的，不断发展的现实世界环境中的局限性，并强调了迫切需要在工具学习框架中进步。 FamilyTool是评估和推进LLM代理在复杂，动态环境中的推理，适应性和可伸缩性的关键资源。代码和数据集可在GitHub上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.06766</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM代理的基于案例推理的综述：理论基础，建筑组件和认知整合</title>
      <link>https://arxiv.org/abs/2504.06943</link>
      <description><![CDATA[ARXIV：2504.06943V1公告类型：新 
摘要：由大语言模型（LLM）提供动力的代理商最近在各种任务中表现出了令人印象深刻的功能。尽管如此，他们仍面临需要特定，结构化知识，灵活性或负责任决策的任务的限制。尽管代理人能够感知自己的环境，从而形成推论，计划和执行针对目标的行动，但他们经常面临诸如幻觉和跨互动之间缺乏上下文记忆之类的问题。本文探讨了如何通过引用过去的经验来解决新问题的策略如何将基于案例的推理（CBR）集成到LLM代理框架中。这种集成使LLM能够利用明确的知识，增强其有效性。我们系统地回顾了这些增强剂的理论基础，确定关键框架组件，并为病例检索，适应和学习的CBR过程制定数学模型。我们还根据其他方法来评估CBR增强剂，例如经过经过经过经过经过经验的推理和标准检索效果的生成，分析其相对优势。此外，我们探讨了通过目标驱动的自治机制利用CBR的认知维度（包括自我反省，内省和好奇心）如何进一步增强LLM代理能力。为了促进对神经符号混合系统的持续研究，这项工作将CBR视为一种可行的技术，用于增强自动LLM代理的推理技能和认知方面。]]></description>
      <guid>https://arxiv.org/abs/2504.06943</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$ \ pi $ -Nesy：一种可能的神经符号方法</title>
      <link>https://arxiv.org/abs/2504.07055</link>
      <description><![CDATA[ARXIV：2504.07055V1公告类型：新 
摘要：在本文中，我们介绍了一种神经符号方法，该方法结合了由神经网络执行的低级感知任务，并具有由基于可能的规则的系统执行的高级推理任务。目标是能够为每个输入实例得出其属于目标（meta-）概念的可能性。这个（元）概念通过基于可能的规则的系统连接到中间概念。使用神经网络推断出每个中间概念的每个中间概念的概率。低级感知任务与高级推理任务之间的连接在于由概率分布（通过SoftMax激活）建模的神经网络输出的转换。中间概念的使用对于解释目的是有价值的：使用基于规则的系统，将输入实例的分类作为（meta-）概念的元素可以通过认可中间概念的事实来证明。
  从技术方面来看，我们的贡献包括设计有效方法，用于定义与基于规则的系统相关的矩阵关系和方程系统。相应的矩阵和方程是用于从基于规则的系统执行推论的关键数据结构，并根据培训数据样本了解该系统中规则参数的值。此外，提出了有关处理不一致的关系方程系统的最新结果，提出了一种根据多个培训数据样本学习规则参数的方法。与最先进的神经符号符号符号相比，有关MNIST加法问题和MNIST Sudoku难题的实验突出了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.07055</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Skillweaver：网络代理可以通过发现和磨练技能来自我破坏</title>
      <link>https://arxiv.org/abs/2504.07079</link>
      <description><![CDATA[ARXIV：2504.07079V1公告类型：新 
摘要：为了在复杂的环境中生存和壮成长，人类通过环境探索，经验的分层抽象发展为可重复使用的技能，并协作构建不断增长的技能曲目。尽管最近取得了进步，但自主网络代理仍然缺乏至关重要的自我完善能力，在程序知识抽象，精炼技能和技能构成方面挣扎。在这项工作中，我们介绍了一个以技能为中心的框架SkillWeaver，使代理人可以自主合成可重复使用的技能作为API来自我破坏。鉴于一个新网站，代理商自主发现技能，执行练习，并将实践体验提炼成强大的API。迭代探索不断扩大轻巧的插件API库，从而显着增强了代理商的功能。 Webarena和Real-World网站的实验证明了SkillWeaver的功效，相对成功率提高了31.8％和39.8％。此外，由强剂合成的API通过可转移的技能大大提高了较弱的代理，从而在Webarena上提高了高达54.3％的改善。这些结果证明了将各种网站互动磨练到API中的有效性，这些网站互动可以在各种网络代理之间无缝共享。]]></description>
      <guid>https://arxiv.org/abs/2504.07079</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>援助零：可靠地解决援助游戏</title>
      <link>https://arxiv.org/abs/2504.07091</link>
      <description><![CDATA[ARXIV：2504.07091V1公告类型：新 
摘要：援助游戏是从人类反馈（RLHF）进行培训AI助手的强化学习的有希望的替代方法。帮助游戏可以通过将助手与用户之间的互动建模为两人游戏，从而解决RLHF的关键缺点，例如欺骗行为的激励措施，助手无法观察他们的共同目标。尽管它们具有潜力，但仅在简单的设置中才探索了援助游戏。将它们扩展到更复杂的环境很困难，因为它既需要在不确定性下解决棘手的决策问题，又需要准确地对人类用户的行为进行建模。我们提出了解决援助游戏的第一种可扩展方法，并将其应用于新的，具有挑战性的基于Minecraft的援助游戏，其目标超过10美元^{400} $可能的目标。我们的方法，AssistZero，通过神经网络扩展了Alphazero，该神经网络可以预测人类的行动和奖励，从而使其能够在不确定性下进行计划。我们表明，在基于Minecraft的援助游戏中，Assisterzero优于无模型的RL算法和模仿学习。在人类的一项研究中，我们的辅助培训助手大大减少了参与者完成Minecraft建筑任务的行动数量。我们的结果表明，援助游戏是在复杂环境中培训有效的AI助手的可访问框架。我们的代码和型号可在https://github.com/cassidylaidlaw/minecraft-building-assistance-game上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.07091</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CMAT：一个多代理协作调整框架，用于增强小语言模型</title>
      <link>https://arxiv.org/abs/2404.01663</link>
      <description><![CDATA[ARXIV：2404.01663V5公告类型：交叉 
摘要：开放大语模型（LLM）在自然语言处理的领域中显着提高了各种任务的令人印象深刻的表现。尽管在LLMS中取得了重大进步，但它们的有效操作仍然很大程度上依赖于人类的投入，以准确地指导对话流动，以使代理的调整是一种至关重要的优化技术，涉及人类的供应，以供您进行此类指导，从而使我们的依赖性依赖于这种指导。我们的依赖性依赖于我们的工作。模型，经过精心策划的高质量数据集训练。我们还介绍了协作多代理调整（CMAT）框架，这是一种创新的系统，旨在通过基于环境反馈的自适应重量更新来增强语言代理功能。该框架促进了多个智能代理商之间的协作学习和实时适应，从而增强了他们的上下文意识和长期记忆。在这项研究中，我们提出了一个新的通信代理框架，该框架将多代理系统与环境反馈机制集成在一起，提供了一种可扩展的方法来探索合作行为。值得注意的是，尽管参数较少，但我们的Tinyagent-7b模型与GPT-3.5表现出表现，尽管参数较少，这表明LLM的效率和有效性有了很大的提高。]]></description>
      <guid>https://arxiv.org/abs/2404.01663</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CPU设计空间探索中的多目标优化：您需要注意</title>
      <link>https://arxiv.org/abs/2410.18368</link>
      <description><![CDATA[ARXIV：2410.18368V1公告类型：交叉 
摘要：设计空间探索（DSE）使建筑师能够系统地评估各种设计选项，指导最合适的配置的决策，以满足特定目标，例如优化性能，功率和区域。但是，现代CPU的日益增长的复杂性大大增加了微构造参数的数量，并扩大了整体设计空间，使DSE更具挑战性和耗时。由于模型不准确，对参数影响的见解有限，从而阻碍了紧密的时间范围内最佳的微构造，因此现有的DSE框架在大规模设计空间中挣扎。
  在这项工作中，我们引入了注意。它的关键思想是使用注意机制来建立对微构造参数对预测性能的贡献的直接映射。这种方法增强了性能模型的预测准确性和解释性。此外，权重进行了动态调整，使模型能够响应设计变化，并有效地指出负责性能瓶颈的关键微构造参数/组件。因此，注意精确，有目的地并迅速发现最佳设计。 SPEC 2017上的实验表明，与最先进的DSE框架相比，PastionDSE显着减少了80 \％的勘探时间，并且在越来越多的参数和越来越多的参数和越来越多。]]></description>
      <guid>https://arxiv.org/abs/2410.18368</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用LLM在AI系统中的用户故事：USTAI数据集</title>
      <link>https://arxiv.org/abs/2504.00513</link>
      <description><![CDATA[ARXIV：2504.00513V1公告类型：交叉 
摘要：AI系统正在在各个部门和域中广泛采用。创建高质量的AI系统要求对于将AI系统与业务目标和消费者价值观以及社会责任保持一致至关重要。但是，由于AI系统的不确定性质以及对敏感数据的严重依赖，需要进行更多的研究来解决对AI系统需求的启发和分析。凭借许多AI系统的专有性，缺乏针对AI系统的开源要求和技术要求文档，从而限制了更广泛的研究和调查。本文以大型语言模型（LLM）作为人类生成的文本的一种有希望的替代方法，研究了LLM的潜在用途，以基于学术论文的摘要为AI系统生成用户故事。我们使用三个LLM进行了经验评估，并从$ 26 $域中的$ 42摘要产生了$ 1260 $的用户故事。我们使用质量用户故事（QUS）框架评估其质量。此外，我们确定相关的非功能要求（NFR）和道德原则。我们的分析表明，调查的LLM可以生成受各种利益相关者需求启发的用户故事，提供了一种有前途的方法来生成用于研究目的的用户故事，并有助于在早期需求中启发AI系统的启发阶段。我们已经编译并策划了各种LLM生成的故事集合到数据集中（USTAI），该数据集现已公开使用。]]></description>
      <guid>https://arxiv.org/abs/2504.00513</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Stealthrank：LLM通过隐形及时优化进行排名</title>
      <link>https://arxiv.org/abs/2504.05804</link>
      <description><![CDATA[ARXIV：2504.05804V1公告类型：交叉 
摘要：大型语言模型（LLM）集成到信息检索系统中引入了新的攻击表面，尤其是对于对抗性排名操作。我们提出Stealthrank，这是一种新颖的对抗排名攻击，可以操纵LLM驱动的产品推荐系统，同时保持文本流利度和隐身。与经常引入可检测异常的现有方法不同，StealthRank采用了基于能量的优化框架与Langevin Dynamics结合使用，以生成嵌入了嵌入产品描述中却有有效却有效影响LLM排名机制的产品描述中的stealthrank提示（SRP） - 对话文本序列。我们评估了跨多个LLM的Stealthrank，这证明了其秘密提高目标产品排名的能力，同时避免了可以轻松检测到的明确操纵痕迹。我们的结果表明，StealthRank始终在有效性和隐身方面都优于最先进的对抗排名基线，从而突出了LLM驱动的推荐系统中的关键脆弱性。]]></description>
      <guid>https://arxiv.org/abs/2504.05804</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>惊叹：可解释的跨模式代理系统，用于通过分层检索检测错误信息检测</title>
      <link>https://arxiv.org/abs/2504.06269</link>
      <description><![CDATA[ARXIV：2504.06269V1公告类型：交叉 
摘要：错误信息继续在当今信息生态系统中构成重大挑战，从而深刻塑造了公众的看法和行为。在其各种表现形式中，脱节（OOC）的错误信息特别晦涩，因为它通过将真实的图像与误导性的文本叙述配对而扭曲了含义。检测OOC错误信息的现有方法主要依赖于图像文本对之间的粗粒度相似性指标，这些指标通常无法捕获细微的不一致或提供有意义的解释性。虽然多模式的大语言模型（MLLM）在视觉推理和解释生成中表现出显着的功能，但它们尚未证明能够解决稳健OOC检测所需的复杂，细粒度和跨模式区别。为了克服这些局限性，我们引入了Amair，这是一个基于检索的框架，旨在通过多模式事件和实体的多范围索引来利用外部知识。我们的方法将多范围的上下文分析与多代理推理体系结构集成在一起，以系统地评估多模式新闻内容的一致性和完整性。全面的实验验证了惊叹的有效性和韧性，证明了其与最先进的方法相比，准确性高4.3％，同时提供可解释且可操作的见解能力。]]></description>
      <guid>https://arxiv.org/abs/2504.06269</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有监督的扩散建模来解决点击率预测中的冷启动问题</title>
      <link>https://arxiv.org/abs/2504.06270</link>
      <description><![CDATA[ARXIV：2504.06270V1公告类型：交叉 
摘要：预测点击率是建议和广告平台中的关键功能，因为CTR预测的输出确定了向用户显示的项目的顺序。嵌入\＆MLP范式已成为工业推荐系统的标准方法，并已被广泛部署。但是，这种范式遇到了冷启动的问题，那里没有或仅有有限的用户操作数据，导致学习不良的ID嵌入。冷启动的问题阻碍了新项目的性能。为了解决这个问题，我们设计了一种新颖的扩散模型，以生成对新项目的热烈嵌入。具体而言，我们定义了ID嵌入空间和侧面信息空间之间的新扩散过程。此外，鉴于我们的扩散模型是非马克维亚人，我们可以从扩散步骤中得出一个子序列。我们的扩散模型均由变异推理和二进制跨透明镜目标进行监督，从而使其能够在冷启动和热身阶段中为项目生成热身的嵌入。此外，我们对三个建议数据集进行了广泛的实验。结果证实了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.06270</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ER-rag：通过基于ER的异质数据源的统一建模来增强抹布</title>
      <link>https://arxiv.org/abs/2504.06271</link>
      <description><![CDATA[ARXIV：2504.06271V1公告类型：交叉 
摘要：大型语言模型（LLMS）在提问（QA）任务中表现出色，并且检索效果生成（RAG）通过合并来自网页，数据库和知识图的各种来源的外部证据，从而提高了其精度。但是，当前的抹布方法依赖于针对单个数据源的特定特定策略，提出了低资源或黑盒环境的挑战，并在跨来源分散的证据时使操作变得复杂。为了解决这些局限性，我们提出了ER-rag，该框架可以使用实体关系（ER）模型统一跨异构数据源的证据集成。 ER-rag通过基于ER的API和加入操作标准化实体检索和关系查询。它采用了两个阶段的生成过程：首先，偏好优化模块选择最佳来源；其次，另一个模块基于源模式构建API链。这种统一的方法允许在各种数据源之间进行有效的微调和无缝集成。 ER-Rag通过赢得2024 KDDCUP CRAG挑战的所有三首曲目，证明了其有效性，并使用8B LLM骨干线在商业抹布管道上取得了表现。它的表现优于Hybrid竞争对手的LLM得分3.1％，并将检索加速5.5倍。]]></description>
      <guid>https://arxiv.org/abs/2504.06271</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Raven：大规模视频收集的多模式实体发现的代理框架</title>
      <link>https://arxiv.org/abs/2504.06272</link>
      <description><![CDATA[ARXIV：2504.06272V1公告类型：交叉 
摘要：我们为Raven提供了一个自适应AI代理框架，专为多模式实体发现和大规模视频收集中的检索而设计。 Raven自动处理视频数据，以生成有关下游任务的结构化，可操作的表示形式，将信息综合的信息综合。关键贡献包括（1）一个类别理解的步骤来推断视频主题和通用实体，（2）动态定义特定领域特定的内脏和属性的模式生成机制，以及（3）利用语义检索和架构引导的提示的丰富的实体提取过程。 Raven被设计为模型不合时宜，允许基于应用程序特定要求的不同视觉语言模型（VLM）和大型语言模型（LLMS）集成。这种灵活性支持个性化搜索，内容发现和可扩展信息检索中的各种应用程序，从而在大量数据集中实现了实用应用程序。]]></description>
      <guid>https://arxiv.org/abs/2504.06272</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有专家知识的多样化和有效的基于检索的收债系统</title>
      <link>https://arxiv.org/abs/2504.06273</link>
      <description><![CDATA[ARXIV：2504.06273V1公告类型：交叉 
摘要：设计有效的债务收集系统对于提高运营效率和降低金融行业的成本至关重要。但是，维持脚本多样性，上下文相关性和连贯性的挑战使这项任务特别困难。本文根据主要商业银行的实际债务人收集器数据提供了一种债务收集系统。我们从现实世界中收集对话中构建脚本库，并为上下文相关性提出了一个基于两阶段检索的响应系统。实验结果表明，我们的系统改善了脚本多样性，增强了响应相关性，并通过知识蒸馏实现了实用的部署效率。这项工作提供了可扩展和自动化的解决方案，为在现实世界应用程序中推进收债实践提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.06273</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合小组分析和推荐通过基于Deep Never Network的多任务学习</title>
      <link>https://arxiv.org/abs/2504.06274</link>
      <description><![CDATA[ARXIV：2504.06274V1公告类型：交叉 
摘要：小组推荐系统的目的是生成与小组集体偏好相符的建议，引入与个人建议方案中的挑战显着不同的挑战。本文通过基于Deep Never Network的多任务学习介绍了联合小组分析和建议，该框架统一了单个模型中的小组分析和建议任务。通过共同学习这些任务，该模型对群体动态有了更深入的了解，从而提高了建议准确性。这两个任务之间的共享表示有助于发现两者必不可少的潜在特征，从而导致更丰富，更有信息的组嵌入。为了进一步提高性能，集成了注意机制，以动态评估不同组特征和项目属性的相关性，从而确保模型优先考虑最有影响力的信息。对现实世界数据集的实验和评估表明，我们的多任务学习方法在准确性方面始终超过基线模型，从而验证其有效性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2504.06274</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过音频到文本对齐的多媒体内容的级联体系结构，用于提取多媒体内容</title>
      <link>https://arxiv.org/abs/2504.06275</link>
      <description><![CDATA[ARXIV：2504.06275V1公告类型：交叉 
摘要：本研究提出了通过音频到文本对齐方式进行多媒体含量提取性汇总的级联体系结构。提出的框架解决了从YouTube视频等多媒体来源中提取关键见解的挑战。它使用Microsoft Azure语音与高级提取性摘要模型（包括Whisper，Pegasus和Facebook Bart Xsum）集成了音频到文本转换。该系统采用pytube，pydub和语音识别等工具，用于内容检索，音频提取和转录。语言分析通过命名的实体识别和语义角色标签得到增强。使用Rouge和F1分数进行评估表明，尽管诸如转录错误之类的挑战，但级联体系结构的表现要优于常规摘要方法。未来的改进可能包括模型微调和实时处理。这项研究通过改善信息检索，可访问性和用户体验来有助于多媒体摘要。]]></description>
      <guid>https://arxiv.org/abs/2504.06275</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>个性化和值得信赖的代理人的动态评估框架：一种多项式适应性方法</title>
      <link>https://arxiv.org/abs/2504.06277</link>
      <description><![CDATA[ARXIV：2504.06277V1公告类型：交叉 
摘要：生成AI的最新进展已大大增加了对个性化代理的兴趣。随着个性化的增加，还需要更需要相信这些代理商的决策和采取行动。但是，这些代理的评估方法仍然过时且不足，通常无法捕获用户交互的动态和不断发展的性质。在这篇概念上的文章中，我们主张评估个性化和适应性代理的范式转变。我们提出了一个全面的小说框架，该框架对用户角色进行了独特的属性和偏好的建模。在此框架中，代理商通过结构化访谈与这些模拟用户进行互动，以收集他们的偏好并提供自定义的建议。然后，使用大型语言模型（LLM）驱动的模拟对这些建议进行动态评估，从而实现自适应和迭代评估过程。我们的灵活框架旨在支持各种代理和应用程序，以确保对专注于积极主动，个性化和值得信赖方面的建议策略进行全面和多功能的评估。]]></description>
      <guid>https://arxiv.org/abs/2504.06277</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>行人过境意图预测的时间上下文事件学习</title>
      <link>https://arxiv.org/abs/2504.06292</link>
      <description><![CDATA[ARXIV：2504.06292V1公告类型：交叉 
摘要：通过准确预测行人穿越意图（PCI），确保弱势道路使用者的安全性在自主和辅助驾驶的背景下起着至关重要的作用。在大多数PCI预测方法中广泛使用了自我视图中的观察视频帧集以预测交叉意图。但是，由于视频帧的高冗余性，他们努力捕获沿时间维度相关的关键事件，这导致PCI预测的次优性能。我们的研究通过引入一种名为\下划线{t} Emporal- \下列{C} onTextual Event \ undewennline \ usewennline {l} renning（tcl）的新方法来应对挑战。 TCL由时间合并模块（TMM）组成，该模块旨在通过将观察到的视频帧聚集到多个关键的时间事件中来管理冗余。然后，使用上下文注意块（CAB）来适应多个事件特征以及视觉和非视觉数据。通过综合关键事件的关键信息的时间特征提取和上下文关注，TCL可以学习PCI预测的表达性表示。在三个广泛采用的数据集上进行了广泛的实验，包括PIE，JAAD-BEH和JAAD-ALL。结果表明，TCL大大超过了最新方法。可以在https://github.com/dadaguailhb/tcl上访问我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2504.06292</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>