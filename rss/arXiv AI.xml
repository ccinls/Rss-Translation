<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CEASEFIRE：一种打击非法枪支贩运的人工智能系统</title>
      <link>https://arxiv.org/abs/2406.14949</link>
      <description><![CDATA[arXiv:2406.14949v1 公告类型：新
摘要：现代技术已导致非法枪支贩运部分与网络犯罪融合，同时使其线下方面变得更加复杂。执法人员面临着需要高科技解决方案的艰巨挑战。本文介绍了一个由先进人工智能驱动的现实世界系统，以方便他们开展日常工作。]]></description>
      <guid>https://arxiv.org/abs/2406.14949</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:58 GMT</pubDate>
    </item>
    <item>
      <title>利用全脑成像转录组学数据进行可信的增强型多视角多模式阿尔茨海默病预测</title>
      <link>https://arxiv.org/abs/2406.14977</link>
      <description><![CDATA[arXiv:2406.14977v1 公告类型：新
摘要：脑转录组学提供了对大脑协调其功能和过程的分子机制的洞察。然而，现有的预测阿尔茨海默病 (AD) 的多模态方法主要依赖于成像和有时的遗传数据，往往忽略了大脑的转录组学基础。此外，在努力整合模态之间的互补信息的同时，大多数研究都忽视了模态之间的信息差异。在这里，我们提出了 TMM，一个用于 AD 诊断的可信多视图多模态图注意框架，使用广泛的全脑转录组学和成像数据。首先，我们从转录组学和多模态放射组学数据构建特定于视图的大脑区域共功能网络 (RRI)，以结合来自生物分子和成像角度的相互作用信息。接下来，我们将图注意 (GAT) 处理应用于每个 RRI 网络以生成图嵌入，并使用跨模态注意将转录组学衍生的嵌入与每个成像衍生的嵌入融合在一起。最后，设计了一种新颖的真假协调类概率 (TFCP) 策略来评估和自适应调整每种 AD 诊断模态的预测置信度。我们使用包含全脑转录组数据的 AHBA 数据库和包含三种成像模态 (AV45-PET、FDG-PET 和 VBM-MRI) 的 ADNI 数据库来评估 TMM。结果证明，与最先进的方法相比，我们的方法在识别 AD、EMCI 和 LMCI 方面具有优势。代码和数据可在 https://github.com/Yaolab-fantastic/TMM 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14977</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:58 GMT</pubDate>
    </item>
    <item>
      <title>人机协作做出最准确的鉴别诊断</title>
      <link>https://arxiv.org/abs/2406.14981</link>
      <description><![CDATA[arXiv:2406.14981v1 公告类型：新
摘要：人工智能系统，特别是大型语言模型 (LLM)，越来越多地被用于影响个人和整个社会的高风险决策，通常没有足够的保障措施来确保安全、质量和公平。然而，LLM 会产生幻觉、缺乏常识并且有偏见——这些缺点可能反映了 LLM 固有的局限性，因此可能无法通过更复杂的架构、更多数据或更多的人为反馈来弥补。因此，仅依靠 LLM 进行复杂、高风险的决策是有问题的。在这里，我们提出了一种混合集体智能系统，它通过利用人类经验和 LLM 处理的大量信息的互补优势来减轻这​​些风险。我们将我们的方法应用于开放式医学诊断，将医生做出的 40,762 个鉴别诊断与 2,133 个医疗病例中的五个最先进的 LLM 的诊断相结合。我们表明，医生和法学硕士的混合集体表现优于单个医生和医生集体，以及单个法学硕士和法学硕士团队。这一结果适用于各种医学专业和专业经验，可以归因于人类和法学硕士的互补贡献，这导致了不同类型的错误。我们的方法凸显了集体人类和机器智能在复杂、开放领域（如医疗诊断）提高准确性的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.14981</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:58 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的临床级组织病理学诊断异常检测</title>
      <link>https://arxiv.org/abs/2406.14866</link>
      <description><![CDATA[arXiv:2406.14866v1 公告类型：新
摘要：虽然先前的研究已经证明了人工智能在影像数据中诊断疾病的潜力，但临床实施仍然落后。部分原因是人工智能模型需要使用大量仅适用于常见疾病的示例进行训练。然而，在临床现实中，只有少数疾病是常见的，而大多数疾病不太常见（长尾分布）。当前的人工智能模型忽略或错误分类了这些疾病。我们提出了一种深度异常检测方法，该方法只需要来自常见疾病的训练数据即可检测所有不太常见的疾病。我们收集了两个大型现实世界胃肠道活检数据集，这是该问题的典型。其中，十个最常见的发现占病例的约 90%，而其余 10% 包含 56 种疾病实体，包括许多癌症。来自 5,423 个病例的 1700 万张组织学图像用于训练和评估。无需针对疾病进行任何特定训练，我们表现最佳的模型就能可靠地检测出各种罕见（“异常”）病理，AU​​ROC 分别为 95.0%（胃）和 91.0%（结肠），并可在扫描仪和医院中推广。根据设计，所提出的异常检测有望检测出胃肠道活检诊断尾部的任何病理改变，包括罕见的原发性或转移性癌症。这项研究建立了基于 AI 的组织病理学异常检测的首个有效临床应用，可以标记异常病例、促进病例优先排序、减少误诊并提高 AI 模型的总体安全性，从而推动 AI 在常规诊断及其他领域的采用和自动化。]]></description>
      <guid>https://arxiv.org/abs/2406.14866</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>GIEBench：面向大型语言模型的基于群体身份的共情整体评估</title>
      <link>https://arxiv.org/abs/2406.14903</link>
      <description><![CDATA[arXiv:2406.14903v2 公告类型：新
摘要：随着大型语言模型 (LLM) 的不断发展和广泛应用，LLM 对不同群体身份表现出同理心并理解其观点的能力越来越被人们认识到至关重要。大多数现有的 LLM 同理心评估基准主要关注人类的普遍情感，例如悲伤和痛苦，往往忽视了个人群体身份的背景。为了解决这一差距，我们推出了 GIEBench，这是一个全面的基准，包括 11 个身份维度，涵盖 97 个群体身份，总共有 999 个与特定群体身份相关的单选题。GIEBench 旨在评估 LLM 在面对特定群体身份（例如性别、年龄、职业和种族）时的同理心，强调他们从所识别群体的角度做出回应的能力。这支持持续开发针对不同身份用户的富有同理心的 LLM 应用程序。我们对 23 名法学硕士的评估显示，虽然这些法学硕士理解不同的身份立场，但如果没有明确的指示来采纳这些观点，他们就无法始终如一地对这些身份表现出同等的同理心。这凸显了需要更好地协调法学硕士与不同价值观，以更好地适应人类身份的多面性。我们的数据集可在 https://github.com/GIEBench/GIEBench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14903</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>LLM2FEA：利用生成进化多任务处理发现新颖的设计</title>
      <link>https://arxiv.org/abs/2406.14917</link>
      <description><![CDATA[arXiv:2406.14917v1 公告类型：新
摘要：生成人工智能的快速研究和发展使得人们能够根据文本提示生成高质量的图像、文本和 3D 模型。这一进步促使人们探究是否可以利用这些模型为创意和工程应用创建数字工件。借鉴其他领域的创新设计可能是这个问题的答案之一，就像人类在“仿生学”的历史实践中从大自然的典范设计中寻求灵感一样。这提出了一个有趣的可能性，即使用生成模型同时解决多个领域的设计任务，促进跨领域学习并产生一系列创新的设计解决方案。在本文中，我们提出 LLM2FEA 作为通过跨多个领域迁移知识来发现生成模型中新颖设计的首次尝试。通过使用多因素进化算法 (MFEA) 来驱动大型语言模型，LLM2FEA 整合了来自各个领域的知识来生成提示，指导生成模型发现新颖且实用的对象。在 3D 气动设计背景下的实验结果验证了所提出的 LLM2FEA 的发现能力。LLM2FEA 生成的设计不仅在一定程度上满足实用性要求，而且具有新颖且美观的形状，展示了 LLM2FEA 在发现任务中的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2406.14917</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>信息不对称条件下的自主智能体协同任务</title>
      <link>https://arxiv.org/abs/2406.14928</link>
      <description><![CDATA[arXiv:2406.14928v1 公告类型：新
摘要：大型语言模型多智能体系统 (LLM-MAS) 在解决复杂任务方面取得了巨大进展。它在共享信息的前提下，在系统内进行智能体之间的通信以协作解决任务。然而，当利用智能体的通信来加强人类合作时，由于信息不对称而出现了新的挑战，因为每个智能体只能访问其人类用户的信息。以前的 MAS 在这种情况下很难完成任务。为了解决这个问题，我们提出了一种新的 MAS 范式，称为 iAgents，它表示信息多智能体系统。在 iAgents 中，人类社交网络在智能体网络中得到镜像，其中智能体主动交换任务解决所需的人类信息，从而克服信息不对称。iAgents 采用一种新颖的智能体推理机制 InfoNav，来引导智能体的通信实现有效的信息交换。 iAgents 与 InfoNav 结合，将人类信息组织在混合内存中，为代理提供准确、全面的信息交换。此外，我们引入了 InformativeBench，这是第一个专门用于评估信息不对称下 LLM 代理的任务解决能力的基准。实验结果表明，iAgents 可以在 140 个个人和 588 个关系的社交网络中协作，自主交流超过 30 轮，并从近 70,000 条消息中检索信息，在 3 分钟内完成任务。]]></description>
      <guid>https://arxiv.org/abs/2406.14928</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 作为研究科学家：探究 GPT 作为研究图书管理员、研究伦理学家、数据生成器和数据预测者的能力</title>
      <link>https://arxiv.org/abs/2406.14765</link>
      <description><![CDATA[arXiv:2406.14765v1 公告类型：新 
摘要：ChatGPT 是一名优秀的研究科学家吗？我们使用心理科学作为测试领域，系统地探究了 GPT-3.5 和 GPT-4 在科学过程的四个核心组成部分中的能力：作为研究图书管理员、研究伦理学家、数据生成器和新数据预测器。在研究 1（研究图书管理员）中，与人类研究人员不同，GPT-3.5 和 GPT-4 产生了幻觉，分别有 36.0% 和 5.4% 的时间权威地生成虚构的参考资料，尽管 GPT-4 表现出了不断进化的承认其虚构的能力。在研究 2（研究伦理学家）中，GPT-4（虽然不是 GPT-3.5）被证明能够检测到虚构研究协议中的 p-hacking 等违规行为，纠正了 88.6% 的明显问题和 72.6% 的微妙问题。在研究 3（数据生成器）中，两个模型一致地复制了先前在大型语言语料库中发现的文化偏见模式，这表明 ChatGPT 可以模拟已知结果，这是数据生成和假设生成等技能有用的前提条件。相比之下，在研究 4（新数据预测器）中，两个模型都无法成功预测训练数据中不存在的新结果，而且在预测更多或更少的新结果时，它们似乎都没有利用大量新信息。总之，这些结果表明，GPT 是一个有缺陷但正在迅速进步的图书管理员，已经是一个优秀的研究伦理学家，能够在具有已知特征的简单领域生成数据，但不擅长预测新的经验数据模式以帮助未来的实验。]]></description>
      <guid>https://arxiv.org/abs/2406.14765</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的思考能力有多强？评估生成式人工智能思维质量的框架</title>
      <link>https://arxiv.org/abs/2406.14769</link>
      <description><![CDATA[arXiv:2406.14769v1 公告类型：新
摘要：生成式人工智能（例如具有大型语言模型的人工智能）为创新评估设计实践创造了机会。由于最近的技术发展，需要了解生成式人工智能在模拟认知技能方面的局限性和能力。评估学生的批判性思维能力自古以来就是评估的一个特点，但数字评估的需求为公平、学术诚信和评估作者身份带来了独特的挑战。教育工作者需要一个框架来确定他们的评估对生成式人工智能的脆弱性，以指导评估设计实践。本文提出了一个框架，探讨了当前行业基准 LLM ChatGPT4 应用程序的功能。本文介绍了问题映射、人工智能漏洞测试、评分、评估 (MAGE) 框架，以便在他们自己的学科背景下有条不紊地批评他们的评估。这次批评将提供具体和有针对性的迹象，表明他们在批判性思维技能方面的弱点。这可以作为他们任务评估设计的基础。]]></description>
      <guid>https://arxiv.org/abs/2406.14769</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>学习使用深度 Q 学习选择自动规划中的目标</title>
      <link>https://arxiv.org/abs/2406.14779</link>
      <description><![CDATA[arXiv:2406.14779v1 公告类型：新
摘要：在这项工作中，我们提出了一种规划和行动架构，该架构配备了一个模块，该模块学习使用深度 Q 学习选择子目标。这使我们能够在面对具有实时限制的场景时减少规划器的负载。我们在用作智能系统应用程序标准测试平台的视频游戏环境中训练了该架构，并在同一游戏的不同级别上对其进行了测试，以评估其泛化能力。随着更多训练数据的提供，我们已经测量了我们的方法的性能，并将其与最先进的经典规划器和标准深度 Q 学习算法进行了比较。获得的结果表明，当同时考虑计划质量（计划长度）和时间要求时，我们的模型比考虑的替代方法表现更好。一方面，它比标准深度 Q 学习更具样本效率，并且能够更好地跨级别进行泛化。另一方面，与最先进的自动规划器相比，它减少了解决问题的时间，但代价是只多花了 9% 的操作即可获得计划。]]></description>
      <guid>https://arxiv.org/abs/2406.14779</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>ACR：自动群组检索的基准</title>
      <link>https://arxiv.org/abs/2406.14780</link>
      <description><![CDATA[arXiv:2406.14780v1 公告类型：新
摘要：识别患者队列是众多医疗保健任务的基础，包括临床试验招募和回顾性研究。医疗保健组织中当前的队列检索方法依赖于结构化数据的自动查询和手动管理，这既耗时又费力，而且通常会产生低质量的结果。大型语言模型 (LLM) 和信息检索 (IR) 的最新进展为彻底改变这些系统提供了有希望的途径。主要挑战包括管理广泛的资格标准和处理非结构化电子病历 (EMR) 的纵向性质，同时确保解决方案对于实际应用仍然具有成本效益。本文介绍了一项新任务，即自动队列检索 (ACR)，并评估了 LLM 和商业、特定领域的神经符号方法的性能。我们提供了一个基准任务、一个查询数据集、一个 EMR 数据集和一个评估框架。我们的研究结果强调了对能够对广泛的患者数据库进行纵向推理的高效、高质量 ACR 系统的必要性。]]></description>
      <guid>https://arxiv.org/abs/2406.14780</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>使用物理启发的生成设计框架自动进行建筑空间布局规划</title>
      <link>https://arxiv.org/abs/2406.14840</link>
      <description><![CDATA[arXiv:2406.14840v1 公告类型：新
摘要：确定空间布局是建筑项目方案设计阶段的主要活动之一。初始布局规划定义了内部空间的形状、尺寸和流通模式；这也会影响建筑的性能和成本。如果手动进行，空间布局规划可能很复杂、重复且耗时。在这项工作中，开发了一个用于自动生成空间建筑布局的生成设计框架。所提出的方法集成了一种新颖的物理启发式空间布局规划参数模型和一种进化优化元启发式方法。结果表明，这种生成设计框架可以在方案设计阶段生成各种各样的设计建议，适用于复杂的设计问题。]]></description>
      <guid>https://arxiv.org/abs/2406.14840</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>在 NCSA 培训下一代 AI 用户和开发人员</title>
      <link>https://arxiv.org/abs/2406.14744</link>
      <description><![CDATA[arXiv:2406.14744v1 公告类型：新
摘要：本文重点介绍伊利诺伊大学厄巴纳-香槟分校国家超级计算应用中心 (NCSA) 通过名为 FoDOMMaT 的本科生研究体验 (REU) 项目开展的人工智能 (AI) 培训工作。它还描述了我们对 AI 感兴趣的原因，并最后讨论了我们在六年内运行该项目及其前身所学到的东西。]]></description>
      <guid>https://arxiv.org/abs/2406.14744</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>SciDMT：用于检测科学提及的大规模语料库</title>
      <link>https://arxiv.org/abs/2406.14756</link>
      <description><![CDATA[arXiv:2406.14756v1 公告类型：新
摘要：我们介绍了 SciDMT，这是一个用于科学提及检测的增强和扩展语料库，与现有的相关资源相比，它提供了显着的进步。SciDMT 包含数据集 (D)、方法 (M) 和任务 (T) 的带注释的科学文档。该语料库由两部分组成：1) SciDMT 主语料库，其中包括 48,000 篇科学文章，其中有超过 180 万个弱注释的提及注释，格式为文本跨度；2) 评估集，其中包括 100 篇为评估目的而手动注释的科学文章。据我们所知，SciDMT 是最大的科学实体提及检测语料库。语料库的规模和多样性有助于开发和完善用于索引科学论文、增强信息检索和提高科学知识可访问性等任务的模型。我们通过使用 SciBERT 和 GPT-3.5 等先进的深度学习架构进行实验，证明了该语料库的实用性。我们的研究结果确立了性能基准，并突出了科学提及检测中尚未解决的挑战。SciDMT 为研究界提供了强大的基准，鼓励开发创新模型以进一步推动科学信息提取领域的发展。]]></description>
      <guid>https://arxiv.org/abs/2406.14756</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在医生笔记的高通量表型分析方面优于其他计算方法</title>
      <link>https://arxiv.org/abs/2406.14757</link>
      <description><![CDATA[arXiv:2406.14757v1 公告类型：新
摘要：高通量表型分析，即将患者的体征和症状自动映射到标准化的本体概念，对于从电子健康记录 (EHR) 中获取价值以支持精准医疗至关重要。尽管技术取得了进步，但高通量表型分析仍然是一个挑战。本研究比较了三种高通量表型分析的计算方法：结合生成式 AI 的大型语言模型 (LLM)、利用深度学习进行跨度分类的自然语言处理 (NLP) 方法以及将词向量与机器学习相结合的混合方法。实施 GPT-4（大型语言模型）的方法表现出卓越的性能，这表明大型语言模型有望成为医生笔记高通量表型分析的首选方法。]]></description>
      <guid>https://arxiv.org/abs/2406.14757</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>合规卡：用于自动化 AI 法规合规的计算工件</title>
      <link>https://arxiv.org/abs/2406.14758</link>
      <description><![CDATA[arXiv:2406.14758v1 公告类型：新
摘要：随着人工智能 (AI) 供应链变得越来越复杂，AI 系统和模型越来越有可能纳入外部来源的成分，例如数据集和其他模型。在这种情况下，确定 AI 系统或模型是否符合欧盟 AI 法案将需要收集有关整个 AI 系统或模型以及外部提供的成分的合规性相关元数据。然后必须进行分析，查看所有这些元数据，以对整个 AI 系统或模型的合规性做出预测。到目前为止，这个过程还没有实现自动化。因此，在这样做会有利的情况下，无法做出实时合规性判断，例如当今 AI 开发人员的迭代工作流程、在 Hugging Face 等社区上搜索和获取 AI 成分、联合和持续学习等等。为了解决这个缺点，我们引入了一个高度自动化的 AI 法案合规性分析系统。这个系统有两个关键要素。首先是一组相互关联的计算工件，用于捕获与合规性相关的元数据：(1) 整个 AI 系统或模型；(2) 任何组成部分，例如数据集和模型。其次是自动分析算法，该算法跨这些计算工件运行，以对整个 AI 系统或模型是否符合 AI 法案进行运行时预测。这些元素共同作用，有望增强和加速 AI 法案合规性评估。]]></description>
      <guid>https://arxiv.org/abs/2406.14758</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>SORRY-Bench：系统评估大型语言模型安全拒绝行为</title>
      <link>https://arxiv.org/abs/2406.14598</link>
      <description><![CDATA[arXiv:2406.14598v1 公告类型：新
摘要：评估对齐的大型语言模型 (LLM) 识别和拒绝不安全用户请求的能力对于安全、符合政策的部署至关重要。然而，现有的评估工作面临三个限制，我们通过我们提出的基准 SORRY-Bench 解决了这些限制。首先，现有方法通常使用不安全主题的粗粒度分类法，并且过度代表一些细粒度主题。例如，在我们评估的十个现有数据集中，拒绝自残指令的测试比欺诈活动测试的代表性低 3 倍以上。SORRY-Bench 通过使用 45 个潜在不安全主题和 450 个类平衡不安全指令的细粒度分类法对此进行了改进，这些分类法是通过人机循环方法编译的。其次，提示的语言特征和格式经常被忽视，例如不同的语言、方言等——许多评估中只隐性考虑了这些特征和格式。我们用 20 种不同的语言增强补充了 SORRY-Bench，以系统地研究这些影响。第三，现有的评估依赖于大型 LLM（例如 GPT-4）进行评估，这在计算上可能很昂贵。我们研究了创建快速、准确的自动安全评估器的设计选择。通过收集 7K+ 人工注释并对不同的 LLM 作为评判设计进行元评估，我们表明经过微调的 7B LLM 可以达到与 GPT-4 规模 LLM 相当的准确性，而且计算成本更低。综合这些，我们在 SORRY-Bench 上评估了 40 多个专有和开源 LLM，分析了它们独特的拒绝行为。我们希望我们的努力能够为以平衡、细致和有效的方式系统地评估 LLM 的安全拒绝能力奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2406.14598</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>从熟练的快递员那里收获高效的按需订单池：增强图形表示学习以细化实时多对一任务</title>
      <link>https://arxiv.org/abs/2406.14635</link>
      <description><![CDATA[arXiv:2406.14635v1 公告类型：新
摘要：最近，按需食品配送（OFD）服务显着增长，在下订单后数十分钟内即可完成配送。在 OFD 中，汇集多个订单以在实时订单分配中同时交付是关键的效率来源，这反过来可能会延长交付时间。构建高质量的订单池以协调平台效率与消费者和快递员的体验，对 OFD 平台至关重要。然而，订单分配的复杂性和实时性使得大量计算不切实际，大大限制了订单合并的潜力。此外，离线环境经常充斥着未知因素，对平台的可感知性和汇集决策构成挑战。然而，熟悉环境的熟练快递员（SC）的交付行为可以提高系统意识并有效地为决策提供信息。因此，基于为 OFD 量身定制的增强属性异构网络嵌入方法，构建了 SC 交付网络（SCDN）。它旨在从丰富的时空信息中提取特征，挖掘供应链轨迹中订单组合的潜力。通过低维向量的可扩展相似度计算，可以有效地修剪订单分配的广阔搜索空间，从而更容易实时识别全面、高质量的池化结果。SCDN 目前已在美团调度系统中部署。在线测试表明，使用 SCDN，池化质量和程度得到了极大提升。我们的系统可以在中午高峰时段将快递员的效率提高 45-55%，同时保证准时送达的承诺。]]></description>
      <guid>https://arxiv.org/abs/2406.14635</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 RNNT 损失调整语音前缀以改进 LLM 预测</title>
      <link>https://arxiv.org/abs/2406.14701</link>
      <description><![CDATA[arXiv:2406.14701v1 公告类型：新
摘要：在本文中，我们重点关注解决将 LLM 应用于 ASR 时面临的限制。最近的研究利用前缀 LM 类型的模型，将语音直接作为前缀应用于 ASR 的 LLM。我们发现优化语音前缀可以提高 ASR 性能，并提出应用 RNNT 损失来执行语音前缀调整。这是一种简单的方法，不会增加模型复杂性或改变推理管道。我们还提出了基于语言的软提示，以进一步改进冻结的 LLM。对 10 种印度语言的实时测试集的实证分析表明，我们提出的语音前缀调整在冻结和微调的 LLM 中都能带来改进。我们对 10 个印度语言的平均识别结果表明，与使用微调的 LLM 的基线相比，提出的具有 RNNT 损失的前缀调整使 WER 相对提高了 12%。我们提出的冻结 LLM 方法比基本的软提示前缀 LM 带来了 31% 的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2406.14701</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>GPT 真的能做到吗？量化人类与人工智能对算法理解的层次尺度</title>
      <link>https://arxiv.org/abs/2406.14722</link>
      <description><![CDATA[arXiv:2406.14722v1 公告类型：新
摘要：随着大型语言模型 (LLM) 执行（有时擅长）越来越复杂的认知任务，一个自然而然的问题是人工智能是否真正理解。LLM 中的理解研究尚处于起步阶段，社区尚未纳入哲学、心理学和教育领域的成熟研究。我们发起了这项研究，特别关注理解算法，并提出了理解层次的层次结构。我们使用该层次结构设计和开展一项针对人类受试者（本科生和研究生）以及大型语言模型（GPT 的几代）的研究，揭示了有趣的相似之处和不同之处。我们希望我们的严格标准将有助于跟踪人工智能在这些认知领域的进展。]]></description>
      <guid>https://arxiv.org/abs/2406.14722</guid>
      <pubDate>Tue, 25 Jun 2024 06:27:54 GMT</pubDate>
    </item>
    </channel>
</rss>