<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 17 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>代理检索增强生成：对代理 RAG 的调查</title>
      <link>https://arxiv.org/abs/2501.09136</link>
      <description><![CDATA[arXiv:2501.09136v1 公告类型：新
摘要：大型语言模型 (LLM) 通过实现类似人类的文本生成和自然语言理解，彻底改变了人工智能 (AI)。然而，它们对静态训练数据的依赖限制了它们响应动态、实时查询的能力，导致输出过时或不准确。检索增强生成 (RAG) 已成为一种解决方案，它通过集成实时数据检索来增强 LLM，以提供与上下文相关的最新响应。尽管前景光明，但传统的 RAG 系统受到静态工作流程的限制，缺乏多步推理和复杂任务管理所需的适应性。
代理检索增强生成 (Agentic RAG) 通过将自主 AI 代理嵌入 RAG 管道来超越这些限制。这些代理利用代理设计模式反射、规划、工具使用和多代理协作来动态管理检索策略，迭代改进上下文理解，并调整工作流以满足复杂的任务要求。这种集成使 Agentic RAG 系统能够在不同的应用程序中提供无与伦比的灵活性、可扩展性和上下文感知。
本调查对 Agentic RAG 进行了全面探索，从其基本原理和 RAG 范式的演变开始。它介绍了 Agentic RAG 架构的详细分类，重点介绍了医疗保健、金融和教育等行业的关键应用，并研究了实际的实施策略。此外，它还解决了扩展这些系统、确保道德决策和优化实际应用性能方面的挑战，同时提供了有关实施 Agentic RAG 的框架和工具的详细见解]]></description>
      <guid>https://arxiv.org/abs/2501.09136</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>采用区块链技术实现跨境合规与信任</title>
      <link>https://arxiv.org/abs/2501.09182</link>
      <description><![CDATA[arXiv:2501.09182v1 公告类型：新
摘要：随着人工智能 (AI) 系统越来越成为关键基础设施和全球运营不可或缺的一部分，对统一、可信赖的治理框架的需求比以往任何时候都更加迫切。本文提出了一种新颖的人工智能治理方法，利用区块链和分布式账本技术 (DLT) 建立一个去中心化的、全球公认的框架，确保跨境人工智能系统的安全性、隐私性和可信赖性。本文介绍了金融领域的具体实施场景，概述了未来十年分阶段的部署时间表，并根据当前研究提出了解决方案以应对潜在挑战。通过综合区块链、人工智能伦理和网络安全方面的进步，本文为去中心化的人工智能治理框架提供了全面的路线图，该框架能够适应全球人工智能监管复杂且不断发展的格局。]]></description>
      <guid>https://arxiv.org/abs/2501.09182</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的身份欺诈检测：系统评价</title>
      <link>https://arxiv.org/abs/2501.09239</link>
      <description><![CDATA[arXiv:2501.09239v1 公告类型：新
摘要：随着数字服务的快速发展，大量个人身份信息 (PII) 存储在线，并容易受到身份欺诈等网络攻击。最近，人工智能 (AI) 深度伪造技术的使用大大增加了身份欺诈的复杂性。欺诈者可能会使用这些技术来创建高度复杂的伪造个人身份证件、照片和视频。身份欺诈领域的这些进步对身份欺诈检测和整个社会构成了挑战。迫切需要审查和了解身份欺诈检测方法、其局限性和潜在解决方案。本研究旨在通过使用众所周知的系统文献综述方法来满足这一重要需求。本文回顾了 4 个主要学术文献数据库中的 43 篇选定论文。特别是，审查结果强调了两种类型的身份欺诈预防和检测方法，即深入挑战和开放挑战。结果还被整合成基于人工智能的身份欺诈检测和预防方法的分类法，包括关键见解和趋势。总的来说，本文为研究人员和从业人员在数字身份欺诈这一重要领域的进一步研究和开发提供了基础知识。]]></description>
      <guid>https://arxiv.org/abs/2501.09239</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文本语义到柔性设计：基于稳定扩散模型的住宅布局生成方法</title>
      <link>https://arxiv.org/abs/2501.09279</link>
      <description><![CDATA[arXiv:2501.09279v1 公告类型：新
摘要：基于人工智能的住宅布局设计的灵活性仍然是一个重大挑战，因为基于规则的启发式方法和基于图形的生成等传统方法通常缺乏灵活性，并且需要用户具备大量的设计知识。为了解决这些限制，我们提出了一种基于稳定扩散模型的跨模态设计方法来生成灵活的住宅布局。该方法为学习目标提供了多种输入类型，允许用户指定边界和布局。它结合了自然语言作为设计约束，并引入了 ControlNet，通过两种不同的途径实现稳定的布局生成。我们还提出了一种方案，将设计专业知识封装在知识图谱中并将其转化为自然语言，提供可解释的设计知识表示。这种输入选项的可理解性和多样性使专业人士和非专业人士能够直接表达设计要求，增强了灵活性和可控性。最后，实验验证了所提出方法在多模态约束下的灵活性，比最先进的模型更好，即使关于房间区域或连接的特定语义信息不完整。]]></description>
      <guid>https://arxiv.org/abs/2501.09279</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEAL：低秩自适应的纠缠白盒水印</title>
      <link>https://arxiv.org/abs/2501.09284</link>
      <description><![CDATA[arXiv:2501.09284v1 公告类型：新
摘要：最近，由于 LoRA 及其变体的效率和简单性，它们已成为训练和共享大型预训练模型的特定任务版本的事实上的策略。然而，LoRA 权重的版权保护问题，特别是通过基于水印的技术，仍然没有得到充分探索。为了解决这一差距，我们提出了 SEAL（LoRA 权重上的安全水印），即 LoRA 的通用白盒水印。SEAL 在可训练的 LoRA 权重之间嵌入一个秘密的、不可训练的矩阵，作为声明所有权的护照。然后，SEAL 通过训练将护照与 LoRA 权重纠缠在一起，而不会因纠缠而产生额外的损失，并在隐藏护照后分配微调后的权重。在应用 SEAL 时，我们观察到常识推理、文本/视觉指令调整和文本到图像合成任务中的性能没有下降。我们证明 SEAL 能够抵御各种已知攻击：删除、混淆和模糊攻击。]]></description>
      <guid>https://arxiv.org/abs/2501.09284</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SOP-Agent：通过特定领域的 SOP 为通用 AI 代理提供支持</title>
      <link>https://arxiv.org/abs/2501.09316</link>
      <description><![CDATA[arXiv:2501.09316v1 公告类型：新
摘要：尽管通用 AI 代理取得了重大进步，但仍有几个挑战阻碍了它们在现实场景中的实际应用。首先，大型语言模型 (LLM) 有限的规划能力限制了 AI 代理有效解决需要长期规划的复杂任务。其次，通用 AI 代理难以有效利用领域特定知识和人类专业知识。在本文中，我们介绍了标准操作程序引导代理 (SOP-agent)，这是一种通过用自然语言编写的伪代码样式标准操作程序 (SOP) 构建领域特定代理的新框架。正式地，我们将 SOP 表示为决策图，遍历该决策图以指导代理完成 SOP 指定的任务。我们对多个领域的任务进行了广泛的实验，包括决策、搜索和推理、代码生成、数据清理和接地客户服务。 SOP 代理表现出了出色的多功能性，其性能优于通用代理框架，可与特定领域的代理系统相媲美。此外，我们还推出了 Grounded Customer Service Benchmark，这是第一个旨在评估 AI 代理在基于 SOP 的客户服务场景中的 Grounded 决策能力的基准。]]></description>
      <guid>https://arxiv.org/abs/2501.09316</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>YETI（尚未干预）多模式 AI 代理在增强现实任务中的主动干预</title>
      <link>https://arxiv.org/abs/2501.09355</link>
      <description><![CDATA[arXiv:2501.09355v1 公告类型：新
摘要：多模态 AI 代理是能够以交互和协作的方式协助人类用户解决日常任务的 AI 模型。增强现实 (AR) 头戴式设备可以通过为 AI 代理提供以自我为中心的多模态（音频和视频）观察功能，以独特的方式改善解决日常程序任务的用户体验。此类 AR 功能可以帮助 AI 代理查看和聆听用户采取的与人类用户的多模态能力相关的操作。现有的 AI 代理，无论是大型语言模型 (LLM) 还是多模态视觉语言模型 (VLM)，本质上都是被动的，这意味着模型无法在不阅读或听取人类用户的提示的情况下采取行动。另一方面，AI 代理的主动性可以帮助人类用户检测和纠正代理观察到的任务中的任何错误，在用户正确完成任务时鼓励用户，或者只是与用户交谈——类似于人类教导或协助用户。我们提出的 YET to Intervene (YETI) 多模态代理专注于识别可能需要代理主动干预的情况的研究问题。这使代理能够了解何时可以干预与人类用户的对话，从而帮助用户纠正使用 AR 完成烹饪等任务时的错误。我们的 YETI 代理根据连续视频帧上的可解释结构相似性 (SSIM) 概念学习场景理解信号。我们还定义了对齐信号，AI 代理可以学习识别与用户在任务上的操作相对应的视频帧是否与预期操作一致。我们的 AI 代理使用这些信号来确定何时应该主动干预。我们将结果与 HoloAssist 多模态基准中的主动干预实例进行比较，其中专家代理指导用户完成程序任务。]]></description>
      <guid>https://arxiv.org/abs/2501.09355</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将指令调整与预训练相结合</title>
      <link>https://arxiv.org/abs/2501.09368</link>
      <description><![CDATA[arXiv:2501.09368v1 公告类型：新
摘要：指令调整增强了大型语言模型 (LLM) 在不同任务中遵循人类指令的能力，依靠高质量的数据集来指导行为。然而，这些数据集，无论是手动策划的还是合成生成的，通常都集中度很窄，与预训练期间捕获的广泛分布不一致，限制了 LLM 的泛化和预训练知识的有效利用。我们提出了*将指令调整与预训练对齐* (AITP)，这种方法通过识别指令调整数据集中的覆盖率不足并将代表性不足的预训练数据重写为高质量的指令-响应对来弥补这一差距。这种方法丰富了数据集的多样性，同时保留了特定于任务的目标。在八个基准上对三个完全开放的 LLM 进行的评估表明，AITP 的性能得到了持续的提升。消融强调了自适应数据选择、受控重写和平衡集成的好处，强调了将指令调整与预训练分布相结合以充分发挥 LLM 潜力的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.09368</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负责任的法学硕士调查：固有风险、恶意使用和缓解策略</title>
      <link>https://arxiv.org/abs/2501.09431</link>
      <description><![CDATA[arXiv:2501.09431v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 在支持众多实际应用和产生积极的社会影响方面具有巨大潜力，但它们在隐私泄露、幻觉输出和价值错位的固有风险方面仍然面临重大挑战，并且在越狱后可能被恶意用于生成有毒内容和不道德的目的。因此，在本调查中，我们对旨在缓解这些问题的最新进展进行了全面回顾，这些进展涵盖了 LLM 开发和使用的四个阶段：数据收集和预训练、微调和对齐、提示和推理以及后处理和审核。我们详细阐述了在隐私保护、幻觉减少、价值对齐、毒性消除和越狱防御方面提高 LLM 性能的最新进展。与之前仅关注负责任的法学硕士 (LLM) 单一维度的调查不同，本次调查提出了一个涵盖不同维度的统一框架，为增强法学硕士 (LLM) 以更好地服务于实际应用提供了全面的视角。]]></description>
      <guid>https://arxiv.org/abs/2501.09431</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能支持多样性和包容性</title>
      <link>https://arxiv.org/abs/2501.09534</link>
      <description><![CDATA[arXiv:2501.09534v1 公告类型：新
摘要：在本文中，我们详细阐述了人工智能如何支持多样性和包容性，并举例说明了在这方面开展的研究项目。我们首先研究了使大型语言模型 (LLM) 更加透明、包容和意识到社会偏见的挑战和进展。尽管像 ChatGPT 这样的 LLM 具有令人印象深刻的能力，但它们很难理解不同的文化背景并进行有意义的、像人类一样的对话。一个关键问题是语言处理中的偏见，尤其是机器翻译中的偏见，会加剧不平等。解决这些偏见需要采取多学科方法来确保人工智能促进多样性、公平性和包容性。我们还强调了人工智能在识别媒体中的偏见内容方面的作用，这对于提高代表性很重要。通过检测对社会群体的不平等描述，人工智能可以帮助挑战刻板印象并创造更具包容性的技术。透明的人工智能算法清楚地解释了它们的决策，对于建立信任和减少人工智能系统中的偏见至关重要。我们还强调人工智能系统需要多样化和包容性的训练数据。儿童成长监测等项目展示了如何使用广泛的数据来帮助解决营养不良和贫困等现实世界问题。我们介绍了一个项目，展示了如何应用人工智能来监控搜索引擎在传播有关 LGBTQ+ 社区的虚假信息方面的作用。此外，我们讨论了 SignON 项目，作为技术如何弥合听力障碍者和聋哑人士之间沟通鸿沟的一个例子，强调了合作和相互信任在开发包容性人工智能方面的重要性。总的来说，通过这篇论文，我们倡导人工智能系统不仅有效，而且要对社会负责，促进人机之间公平和包容的互动。]]></description>
      <guid>https://arxiv.org/abs/2501.09534</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能驱动的临床决策支持系统</title>
      <link>https://arxiv.org/abs/2501.09628</link>
      <description><![CDATA[arXiv:2501.09628v1 公告类型：新
摘要：随着人工智能 (AI) 越来越多地融入医疗保健服务，本章探讨了开发可靠且合乎道德的临床决策支持系统 (CDSS) 的关键方面。从传统统计模型到复杂机器学习方法的根本转变开始，这项工作研究了严格的验证策略和绩效评估方法，包括模型校准和决策曲线分析的关键作用。本章强调，在医疗保健领域创建值得信赖的人工智能系统不仅需要技术准确性；它需要仔细考虑公平性、可解释性和隐私。强调了通过人工智能确保公平医疗保健服务的挑战，讨论了识别和减轻临床预测模型中偏见的方法。然后，本章深入探讨了可解释性作为以人为本的 CDSS 的基石。这一重点反映了这样一种理解，即医疗保健专业人员不仅必须信任人工智能的建议，还必须理解其背后的原因。讨论在分析医疗人工智能系统中的隐私漏洞方面取得了进展，从深度学习模型中的数据泄露到针对模型解释的复杂攻击。本文探讨了差异隐私和联合学习等隐私保护策略，同时承认隐私保护和模型性能之间固有的权衡。从技术验证到伦理考量，这一进展反映了开发能够无缝可靠地融入日常临床实践的人工智能系统所面临的多方面挑战，同时保持最高的患者护理和数据保护标准。]]></description>
      <guid>https://arxiv.org/abs/2501.09628</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平台感知任务规划</title>
      <link>https://arxiv.org/abs/2501.09632</link>
      <description><![CDATA[arXiv:2501.09632v1 公告类型：新
摘要：自主系统规划通常需要使用不同抽象级别的模型进行推理，并协调两组相互竞争的目标：高级任务目标是指系统与外部环境的交互，以及旨在保持子系统完整性和正确交互的低级平台约束。这两个模型之间复杂的相互作用使得很难对整个系统进行推理，尤其是当目标是找到具有稳健性保证的计划时，考虑到系统较低层的不确定性行为。
在本文中，我们介绍了平台感知任务规划 (PAMP) 的问题，并在时间持续动作的设置中解决该问题。PAMP 问题不同于标准时间规划，因为它具有存在性：处理任务目标的高级计划需要满足安全性和可执行性约束，以应对平台和环境低级模型的所有可能的非确定性执行。我们提出了两种解决 PAMP 的方法。第一种基线方法融合了任务和平台级别，而第二种方法基于抽象-细化循环，利用规划器和验证引擎的组合。我们证明了所提出方法的合理性和完整性，并通过实验对其进行了验证，证明了异构建模的重要性以及基于抽象-细化的技术的优越性。]]></description>
      <guid>https://arxiv.org/abs/2501.09632</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电子健康记录：迈向医疗保健领域的数字孪生</title>
      <link>https://arxiv.org/abs/2501.09640</link>
      <description><![CDATA[arXiv:2501.09640v1 公告类型：新
摘要：从传统的纸质记录到复杂的电子健康记录 (EHR) 的关键转变，使得通过描述性统计数据系统地收集和分析患者数据成为可能，从而深入了解患者群体的模式和趋势。这种演变继续朝着预测分析的方向发展，使医疗保健提供者能够在患者结果和潜在并发症发生之前预测它们。从基本的数字记录保存到复杂的预测模型和数字孪生的这一进步反映了医疗保健向更综合、以患者为中心的方法的更广泛演变，这些方法将数据驱动的洞察力与个性化的护理服务相结合。本章探讨了医疗保健信息系统的发展和意义，首先考察了英国和美国的 EHR 实施情况。它全面概述了国际疾病分类 (ICD) 系统，追溯了其从 ICD-9 到 ICD-10 的发展。本次讨论的核心是 MIMIC-III 数据库，这是医疗保健数据共享的一项里程碑式成就，可以说是全球研究人员免费获得的最全面的重症监护数据库。 MIMIC-III 使获取高质量医疗数据的途径民主化，为研究和分析提供了前所未有的机会。本章通过案例研究研究了其结构、临床结果分析能力和实际应用，特别关注死亡率和住院时间指标、生命体征提取和 ICD 编码。通过详细的实体关系图和实际示例，本文说明了 MIMIC 的复杂数据结构，并演示了不同的查询方法如何导致略有不同的结果，强调了了解数据库架构对于准确提取数据至关重要。]]></description>
      <guid>https://arxiv.org/abs/2501.09640</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CarMem：通过类别界限增强 LLM 语音助手的长期记忆</title>
      <link>https://arxiv.org/abs/2501.09645</link>
      <description><![CDATA[arXiv:2501.09645v1 公告类型：新
摘要：在当今的助手领域，个性化增强了互动，促进了长期关系，并加深了参与度。然而，许多系统在保留用户偏好方面遇到了困难，导致用户重复请求和脱离。此外，行业应用中对用户偏好的不受监管和不透明的提取引发了人们对隐私和信任的重大担忧，尤其是在欧洲等监管严格的地区。为了应对这些挑战，我们提出了一种语音助手的长期记忆系统，该系统围绕预定义的类别构建。这种方法利用大型语言模型来有效地提取、存储和检索这些类别中的偏好，确保个性化和透明度。我们还引入了一个合成的多轮、多会话对话数据集 (CarMem)，该数据集基于真实的行业数据，针对车载语音助手设置进行了定制。根据数据集的基准测试，我们的系统在偏好提取方面实现了 0.78 到 0.95 的 F1 分数，具体取决于类别粒度。我们的维护策略将冗余偏好减少了 95%，将矛盾偏好减少了 92%，而最佳检索的准确率为 0.87。总之，结果表明该系统适用于工业应用。]]></description>
      <guid>https://arxiv.org/abs/2501.09645</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NS-Gym：非平稳马尔可夫决策过程的开源模拟环境和基准</title>
      <link>https://arxiv.org/abs/2501.09646</link>
      <description><![CDATA[arXiv:2501.09646v1 公告类型：新
摘要：在许多实际应用中，代理必须在由于各种外生因素而条件发生变化的环境中做出连续决策。这些非平稳环境对传统决策模型构成了重大挑战，传统决策模型通常假设平稳动态。非平稳马尔可夫决策过程 (NS-MDP) 提供了一个框架来建模和解决这种变化条件下的决策问题。然而，缺乏标准化的基准和模拟工具阻碍了该领域的系统评估和进步。我们提出了 NS-Gym，这是第一个专门为 NS-MDP 设计的模拟工具包，集成在流行的 Gymnasium 框架中。在 NS-Gym 中，我们将表征非平稳性的环境参数的演变与代理的决策模块分开，从而允许模块化和灵活地适应动态环境。我们回顾了该领域的先前工作，并提出了一个工具包，其中封装了 NS-MDP 中的关键问题特征和类型。该工具包首次尝试开发一组标准化接口和基准问题，以便在非平稳条件下对算法进行一致且可重复的评估。我们还使用 NS-Gym 对 NS-MDP 的先前研究中的六种算法方法进行了基准测试。我们的愿景是，NS-Gym 将使研究人员能够评估其决策算法对非平稳条件的适应性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2501.09646</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛树搜索与速度障碍，实现动态环境中安全高效的运动规划</title>
      <link>https://arxiv.org/abs/2501.09649</link>
      <description><![CDATA[arXiv:2501.09649v1 公告类型：新
摘要：在线运动规划对于在具有动态障碍物（例如人群）的密集环境中移动的智能机器人来说是一个具有挑战性的问题。在这项工作中，我们提出了一种新颖的方法，用于在最少的动态障碍物信息下实现最佳且安全的在线运动规划。具体来说，我们的方法只需要障碍物的当前位置及其最大速度，但不需要任何有关其确切轨迹或动态模型的信息。所提出的方法结合了蒙特卡洛树搜索 (MCTS)（通过模型模拟进行在线最优规划）和速度障碍物 (VO)（用于避障）。我们在杂乱的模拟环境中进行实验，其中有墙壁，以及多达 40 个以随机速度和方向移动的动态障碍物。通过消融研究，我们展示了 VO 在提高 MCTS 效率、在模拟树中选择最安全和最有价值的动作方面的关键贡献。此外，我们展示了我们的方法相对于最先进的规划器（包括非线性模型预测控制（NMPC））在改进碰撞率、计算和任务性能方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2501.09649</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中推理时间对齐的奖励引导控制生成：教程和回顾</title>
      <link>https://arxiv.org/abs/2501.09685</link>
      <description><![CDATA[arXiv:2501.09685v1 公告类型：新
摘要：本教程提供了有关推理时间指导和对齐方法的深入指南，用于优化扩散模型中的下游奖励函数。虽然扩散模型以其生成建模能力而闻名，但在生物学等领域的实际应用通常需要最大化特定指标（例如稳定性、蛋白质亲和力、与目标结构的接近度）的样本生成。在这些情况下，扩散模型不仅可以适应生成真实的样本，还可以在推理时明确最大化所需的度量而无需微调。本教程探讨了此类推理时间算法的基础方面。我们从统一的角度回顾了这些方法，证明了当前的技术——例如基于顺序蒙特卡罗 (SMC) 的指导、基于值的采样和分类器指导——旨在近似软最优去噪过程（即 RL 中的策略），将预训练的去噪过程与价值函数相结合，作为从中间状态到终端奖励预测的前瞻函数。在这个框架内，我们提出了几种文献中尚未涉及的新算法。此外，我们还讨论了 (1) 与推理时间技术相结合的微调方法、(2) 基于搜索算法（如蒙特卡洛树搜索）的推理时间算法，这些算法在当前的研究中受到的关注有限，以及 (3) 语言模型和扩散模型中推理时间算法之间的联系。本蛋白质设计教程的代码可在 https://github.com/masa-ue/AlignInversePro 上找到]]></description>
      <guid>https://arxiv.org/abs/2501.09685</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向大型推理模型：大型语言模型强化推理综述</title>
      <link>https://arxiv.org/abs/2501.09686</link>
      <description><![CDATA[arXiv:2501.09686v1 公告类型：新
摘要：语言长期以来被认为是人类推理的重要工具。大型语言模型 (LLM) 的突破引发了人们对利用这些模型解决复杂推理任务的重大研究兴趣。研究人员已经超越了简单的自回归标记生成，引入了“思想”的概念——一系列表示推理过程中间步骤的标记。这种创新范式使 LLM 能够模仿复杂的人类推理过程，例如树搜索和反思性思维。最近，一种新兴的学习推理趋势应用强化学习 (RL) 来训练 LLM 掌握推理过程。这种方法可以通过反复试验搜索算法自动生成高质量的推理轨迹，通过提供更多的训练数据显著扩展了 LLM 的推理能力。此外，最近的研究表明，鼓励 LLM 在测试时推理期间用更多的标记“思考”可以进一步显著提高推理准确性。因此，训练时间和测试时间扩展相结合，展示了一个新的研究前沿——通往大型推理模型的道路。OpenAI o1 系列的推出标志着这一研究方向的一个重要里程碑。在本次调查中，我们全面回顾了 LLM 推理的最新进展。我们首先介绍 LLM 的基础背景，然后探索推动大型推理模型发展的关键技术组件，重点关注自动数据构建、学习推理技术和测试时间扩展。我们还分析了构建大型推理模型的流行开源项目，并总结了开放挑战和未来的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2501.09686</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Goofus & Gallant 故事集，用于实践价值观的协调</title>
      <link>https://arxiv.org/abs/2501.09707</link>
      <description><![CDATA[arXiv:2501.09707v1 公告类型：新
摘要：价值观或原则是人类社会的关键要素，它们影响人们按照公认的标准社会规则行事和运作，以维持社会秩序。随着人工智能系统在人类社会中变得无处不在，人们主要担心它们可能会违反这些规范或价值观并可能造成伤害。因此，为了防止有意或无意的伤害，人工智能系统应该采取符合这些原则的行动。训练系统表现出这种类型的行为很困难，通常需要专门的数据集。这项工作提出了一个多模态数据集，通过自然语言和艺术图像描述了现实生活中的规范和非规范行为。这个训练集包含精选的图像集，旨在向幼儿传授社会原则。鉴于这一事实，我们认为这是一个用于训练社会规范代理的理想数据集。]]></description>
      <guid>https://arxiv.org/abs/2501.09707</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KU AIGEN ICL EDI@BC8 第 3 轨道：推进表型命名实体识别和畸形体检报告的规范化</title>
      <link>https://arxiv.org/abs/2501.09744</link>
      <description><![CDATA[arXiv:2501.09744v1 公告类型：新
摘要：BioCreative8 Track 3 的目标是提取嵌入在 EHR 文本中的表型关键医学发现，然后将这些发现规范化为其人类表型本体 (HPO) 术语。然而，表型发现中存在多种表面形式，因此很难准确地将它们规范化为正确的 HPO 术语。为了应对这一挑战，我们探索了各种命名实体识别模型，并实施了同义词边缘化等数据增强技术来增强规范化步骤。我们的流程导致精确的提取和规范化 F1 分数比响应挑战收到的所有提交的平均分数高出 2.6\%。此外，就规范化 F1 分数而言，我们的方法比平均表现高出 1.9\%。这些发现有助于推动自动化医疗数据提取和规范化技术的发展，展示了未来生物医学领域研究和应用的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2501.09744</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>